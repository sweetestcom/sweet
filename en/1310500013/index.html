<!DOCTYPE html>
<html lang="en" dir="ltr">
    <head><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content='The following is a conversation with Tommaso Poggio.
He&amp;rsquo;s a professor at MIT and is a director of the Center
for Brains, Minds, and Machines.
Cited over 100,000 times, his work
has had a profound impact on our understanding
of the nature of intelligence in both biological and artificial
neural networks.
He has been an advisor to many highly impactful researchers
and entrepreneurs in AI, including
Demis Hassabis of DeepMind, Amnon Shashua of Mobileye,'>
<title>Lex Fridman Podcast - #13 - Tomaso Poggio: Brains, Minds, and Machines | SWIEST</title>

<link rel='canonical' href='https://swiest.com/en/1310500013/'>

<link rel="stylesheet" href="/scss/style.min.91b18679590f4ceed910ade4d64b1e7375cc0770ef5b8c1d822f42424f9ff2c8.css"><script>
    document.oncontextmenu = function(){ return false; };
    document.onselectstart = function(){ return false; };
    document.oncopy = function(){ return false; };
    document.oncut = function(){ return false; };
</script>

<script src="https://apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js"></script>


<script type="text/javascript">
    $(document).ready(function(){
     
     $("#back-to-top").hide();
     
     $(function () {
      $(window).scroll(function(){
       if ($(window).scrollTop()>600){
        $("#back-to-top").fadeIn(500);
       }else{
        $("#back-to-top").fadeOut(500);
       }
     });
     
     $("#back-to-top").click(function(){
      $('body,html').animate({scrollTop:0},500);
       return false;
      });
     });
    });
    </script><meta property='og:title' content='Lex Fridman Podcast - #13 - Tomaso Poggio: Brains, Minds, and Machines'>
<meta property='og:description' content='The following is a conversation with Tommaso Poggio.
He&amp;rsquo;s a professor at MIT and is a director of the Center
for Brains, Minds, and Machines.
Cited over 100,000 times, his work
has had a profound impact on our understanding
of the nature of intelligence in both biological and artificial
neural networks.
He has been an advisor to many highly impactful researchers
and entrepreneurs in AI, including
Demis Hassabis of DeepMind, Amnon Shashua of Mobileye,'>
<meta property='og:url' content='https://swiest.com/en/1310500013/'>
<meta property='og:site_name' content='SWIEST - Transcripts ¬∑ Screenplays ¬∑ Lyrics'>
<meta property='og:type' content='article'><meta property='article:section' content='Post' /><meta property='article:tag' content='English' /><meta property='article:tag' content='Podcast' /><meta property='article:tag' content='Lex Fridman Podcast' /><meta property='article:published_time' content='2022-03-13T17:00:00&#43;00:00'/><meta property='article:modified_time' content='2022-03-13T17:00:00&#43;00:00'/>
<meta name="twitter:title" content="Lex Fridman Podcast - #13 - Tomaso Poggio: Brains, Minds, and Machines">
<meta name="twitter:description" content="The following is a conversation with Tommaso Poggio.
He&amp;rsquo;s a professor at MIT and is a director of the Center
for Brains, Minds, and Machines.
Cited over 100,000 times, his work
has had a profound impact on our understanding
of the nature of intelligence in both biological and artificial
neural networks.
He has been an advisor to many highly impactful researchers
and entrepreneurs in AI, including
Demis Hassabis of DeepMind, Amnon Shashua of Mobileye,">
    <link rel="shortcut icon" href="/favicon.ico" />
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9206135835124064" crossorigin="anonymous"></script>
<script type="text/javascript">amzn_assoc_ad_type = "link_enhancement_widget";amzn_assoc_tracking_id = "swiest00-20";amzn_assoc_linkid = "b583d47a9f44ec47064a228dad7fb822";amzn_assoc_placement = "";amzn_assoc_marketplace = "amazon";amzn_assoc_region = "US";</script><script src="//ws-na.amazon-adsystem.com/widgets/q?ServiceVersion=20070822&Operation=GetScript&ID=OneJS&WS=1&MarketPlace=US"></script>
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    </head>
    <body class="
    article-page
    ">
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "dark");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky ">
    <button class="hamburger hamburger--spin" type="button" id="toggle-menu" aria-label="Toggle Menu">
        <span class="hamburger-box">
            <span class="hamburger-inner"></span>
        </span>
    </button>

    <header>
        
            
            <figure class="site-avatar">
                <a href="/">
                
                    
                    
                    
                        
                        <img src="/img/avatar_hu307e6a33fa6fd661ccda3b77024ef5c2_252345_300x0_resize_box_3.png" width="300"
                            height="300" class="site-logo" loading="lazy" alt="Avatar">
                    
                
                </a>
                
                    <span class="emoji">‚ú®</span>
                
            </figure>
            
        
        
        <div class="site-meta">
            <h1 class="site-name"><a href="/">SWIEST - Transcripts ¬∑ Screenplays ¬∑ Lyrics</a></h1>
            <h2 class="site-description">üåçüåèüåé</h2>
        </div>
    </header><ol class="menu" id="main-menu">
        
        
        
        <li >
            <a href='/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <polyline points="5 12 3 12 12 3 21 12 19 12" />
  <path d="M5 12v7a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-7" />
  <path d="M9 21v-6a2 2 0 0 1 2 -2h2a2 2 0 0 1 2 2v6" />
</svg>



                
                <span>Home</span>
            </a>
        </li>
        
        
        <li >
            <a href='/archives/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <rect x="3" y="4" width="18" height="4" rx="2" />
  <path d="M5 8v10a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-10" />
  <line x1="10" y1="12" x2="14" y2="12" />
</svg>



                
                <span>Archives</span>
            </a>
        </li>
        
        
        <li >
            <a href='/search/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="10" cy="10" r="7" />
  <line x1="21" y1="21" x2="15" y2="15" />
</svg>



                
                <span>Search</span>
            </a>
        </li>
        
        
        <li >
            <a href='/chart/podcastchart.html' target="_blank">
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-apple-podcast" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="#ffffff" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M18.364 18.364a9 9 0 1 0 -12.728 0" />
  <path d="M11.766 22h.468a2 2 0 0 0 1.985 -1.752l.5 -4a2 2 0 0 0 -1.985 -2.248h-1.468a2 2 0 0 0 -1.985 2.248l.5 4a2 2 0 0 0 1.985 1.752z" />
  <path d="M12 9m-2 0a2 2 0 1 0 4 0a2 2 0 1 0 -4 0" />
</svg>
                
                <span>Podcast Charts</span>
            </a>
        </li>
        

        <div class="menu-bottom-section">
                <li id="i18n-switch">  
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-language" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M4 5h7" />
  <path d="M9 3v2c0 4.418 -2.239 8 -5 8" />
  <path d="M5 9c-.003 2.144 2.952 3.908 6.7 4" />
  <path d="M12 20l4 -9l4 9" />
  <path d="M19.1 18h-6.2" />
</svg>



                    <select name="language" onchange="window.location.href = this.selectedOptions[0].value">
                        
                            <option value="https://swiest.com/" selected>English</option>
                        
                            <option value="https://swiest.com/af/" >Afrikaans</option>
                        
                            <option value="https://swiest.com/am/" >·ä†·àõ·à≠·äõ</option>
                        
                            <option value="https://swiest.com/ar/" >ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</option>
                        
                            <option value="https://swiest.com/be/" >–±–µ–ª–∞—Ä—É—Å–∫—ñ</option>
                        
                            <option value="https://swiest.com/az/" >Az…ôrbaycan</option>
                        
                            <option value="https://swiest.com/bg/" >–±—ä–ª–≥–∞—Ä—Å–∫–∏</option>
                        
                            <option value="https://swiest.com/bn/" >‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ</option>
                        
                            <option value="https://swiest.com/bo/" >‡Ωñ‡Ωº‡Ωë‡ºã‡Ω¶‡æê‡Ωë‡ºã</option>
                        
                            <option value="https://swiest.com/bs/" >Bosanski</option>
                        
                            <option value="https://swiest.com/ca/" >Catal√†</option>
                        
                            <option value="https://swiest.com/zh-hans/" >ÁÆÄ‰Ωì‰∏≠Êñá</option>
                        
                            <option value="https://swiest.com/zh-hant/" >ÁπÅÈ´î‰∏≠Êñá</option>
                        
                            <option value="https://swiest.com/cs/" >ƒåe≈°tina</option>
                        
                            <option value="https://swiest.com/el/" >ŒµŒªŒªŒ∑ŒΩŒπŒ∫Œ¨</option>
                        
                            <option value="https://swiest.com/da/" >Dansk</option>
                        
                            <option value="https://swiest.com/de/" >Deutsch</option>
                        
                            <option value="https://swiest.com/eo/" >Esperanto</option>
                        
                            <option value="https://swiest.com/es-es/" >Espa√±ol (Espa√±a)</option>
                        
                            <option value="https://swiest.com/es-419/" >Espa√±ol (Latinoam√©rica)</option>
                        
                            <option value="https://swiest.com/et/" >Eesti</option>
                        
                            <option value="https://swiest.com/eu/" >Euskara</option>
                        
                            <option value="https://swiest.com/haw/" > ª≈ålelo Hawai ªi</option>
                        
                            <option value="https://swiest.com/fa/" >ŸÅÿßÿ±ÿ≥€å</option>
                        
                            <option value="https://swiest.com/fi/" >Suomi</option>
                        
                            <option value="https://swiest.com/fo/" >F√∏royskt</option>
                        
                            <option value="https://swiest.com/fr/" >Fran√ßais</option>
                        
                            <option value="https://swiest.com/fy/" >Frysk</option>
                        
                            <option value="https://swiest.com/ga/" >Gaeilge</option>
                        
                            <option value="https://swiest.com/gl/" >Galego</option>
                        
                            <option value="https://swiest.com/gu/" >‡™ó‡´Å‡™ú‡™∞‡™æ‡™§‡´Ä</option>
                        
                            <option value="https://swiest.com/he/" >◊¢÷¥◊ë◊®÷¥◊ô◊™</option>
                        
                            <option value="https://swiest.com/km/" >·ûÄ·ûò·üí·ûñ·ûª·ûá·û∂·üî</option>
                        
                            <option value="https://swiest.com/hi/" >‡§π‡§ø‡§®‡•ç‡§¶‡•Ä</option>
                        
                            <option value="https://swiest.com/hr/" >Hrvatski</option>
                        
                            <option value="https://swiest.com/ht/" >Krey√≤l Ayisyen</option>
                        
                            <option value="https://swiest.com/hu/" >Magyar</option>
                        
                            <option value="https://swiest.com/hy/" >’Ä’°’µ’•÷Ä’•’∂</option>
                        
                            <option value="https://swiest.com/ig/" >√Ås·ª•ÃÄs·ª•ÃÅ √ågb√≤</option>
                        
                            <option value="https://swiest.com/id/" >Bahasa Indonesia</option>
                        
                            <option value="https://swiest.com/is/" >√çslenska</option>
                        
                            <option value="https://swiest.com/it/" >Italiano</option>
                        
                            <option value="https://swiest.com/ja/" >Êó•Êú¨Ë™û</option>
                        
                            <option value="https://swiest.com/jv/" >Basa Jawa</option>
                        
                            <option value="https://swiest.com/ka/" >·É•·Éê·É†·Éó·É£·Éö·Éò</option>
                        
                            <option value="https://swiest.com/kk/" >“ö–∞–∑–∞“õ—à–∞</option>
                        
                            <option value="https://swiest.com/kn/" >‡≤ï‡≤®‡≥ç‡≤®‡≤°</option>
                        
                            <option value="https://swiest.com/ko/" >ÌïúÍµ≠Ïñ¥</option>
                        
                            <option value="https://swiest.com/or/" >‡¨ì‡¨°‡¨º‡¨ø‡¨Ü</option>
                        
                            <option value="https://swiest.com/ckb/" >⁄©Ÿàÿ±ÿØ€å</option>
                        
                            <option value="https://swiest.com/ky/" >–ö—ã—Ä–≥—ã–∑—á–∞</option>
                        
                            <option value="https://swiest.com/la/" >Latina</option>
                        
                            <option value="https://swiest.com/lb/" >L√´tzebuergesch</option>
                        
                            <option value="https://swiest.com/lo/" >‡∫û‡∫≤‡∫™‡∫≤‡∫•‡∫≤‡∫ß</option>
                        
                            <option value="https://swiest.com/lt/" >Lietuvi≈≥</option>
                        
                            <option value="https://swiest.com/lv/" >Latvie≈°u</option>
                        
                            <option value="https://swiest.com/mk/" >–ú–∞–∫–µ–¥–æ–Ω—Å–∫–∏</option>
                        
                            <option value="https://swiest.com/ml/" >‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç</option>
                        
                            <option value="https://swiest.com/mn/" >–ú–æ–Ω–≥–æ–ª —Ö—ç–ª</option>
                        
                            <option value="https://swiest.com/mr/" >‡§Æ‡§∞‡§æ‡§†‡•Ä</option>
                        
                            <option value="https://swiest.com/sw/" >Kiswahili</option>
                        
                            <option value="https://swiest.com/ms/" >Bahasa Melayu</option>
                        
                            <option value="https://swiest.com/my/" >·Äô·Äº·Äî·Ä∫·Äô·Ä¨</option>
                        
                            <option value="https://swiest.com/ne/" >‡§®‡•á‡§™‡§æ‡§≤‡•Ä</option>
                        
                            <option value="https://swiest.com/nl/" >Nederlands</option>
                        
                            <option value="https://swiest.com/no/" >Norsk</option>
                        
                            <option value="https://swiest.com/pa/" >‡®™‡©∞‡®ú‡®æ‡®¨‡©Ä</option>
                        
                            <option value="https://swiest.com/pl/" >Polski</option>
                        
                            <option value="https://swiest.com/pt-br/" >Portugu√™s Brasil</option>
                        
                            <option value="https://swiest.com/pt-pt/" >Portugu√™s Europeu</option>
                        
                            <option value="https://swiest.com/ro/" >Rom√¢nƒÉ</option>
                        
                            <option value="https://swiest.com/ru/" >–†—É—Å—Å–∫–∏–π</option>
                        
                            <option value="https://swiest.com/si/" >‡∑É‡∑í‡∂Ç‡∑Ñ‡∂Ω</option>
                        
                            <option value="https://swiest.com/sk/" >Slovenƒçina</option>
                        
                            <option value="https://swiest.com/sl/" >Sloven≈°ƒçina</option>
                        
                            <option value="https://swiest.com/sq/" >Shqip</option>
                        
                            <option value="https://swiest.com/sr/" >–°—Ä–ø—Å–∫–∏ (Srpski)</option>
                        
                            <option value="https://swiest.com/su/" >Basa Sunda</option>
                        
                            <option value="https://swiest.com/sv/" >Svenska</option>
                        
                            <option value="https://swiest.com/ta/" >‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç</option>
                        
                            <option value="https://swiest.com/te/" >‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å</option>
                        
                            <option value="https://swiest.com/tg/" >–¢–æ“∑–∏–∫”£</option>
                        
                            <option value="https://swiest.com/th/" >‡πÑ‡∏ó‡∏¢</option>
                        
                            <option value="https://swiest.com/tl/" >Filipino</option>
                        
                            <option value="https://swiest.com/tr/" >T√ºrk√ße</option>
                        
                            <option value="https://swiest.com/uk/" >–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞</option>
                        
                            <option value="https://swiest.com/ur/" >ÿßÿ±ÿØŸà</option>
                        
                            <option value="https://swiest.com/uz/" >O&#39;zbekcha</option>
                        
                            <option value="https://swiest.com/vi/" >Ti·∫øng Vi·ªát</option>
                        
                            <option value="https://swiest.com/yi/" >◊ê◊ô◊ì◊ô◊©</option>
                        
                            <option value="https://swiest.com/zh-hk/" >Á≤µË™û</option>
                        
                            <option value="https://swiest.com/zu/" >IsiZulu</option>
                        
                    </select>
                </li>
            
            
            
                <li id="dark-mode-toggle">
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="8" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="16" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                    <span>Dark Mode</span>
                </li>
            
        </div>
    </ol>
</aside>

    

            <main class="main full-width">
    <article class="main-article">
    <header class="article-header">

    <div class="article-details">
    
    <header class="article-category">
        
            <a href="/categories/podcast/" >
                Podcast
            </a>
        
            <a href="/categories/lex-fridman-podcast/" >
                Lex Fridman Podcast
            </a>
        
    </header>
    

    <div class="article-title-wrapper">
        <h2 class="article-title">
            <a href="/en/1310500013/">Lex Fridman Podcast - #13 - Tomaso Poggio: Brains, Minds, and Machines</a>
        </h2>
    
        
    </div>

    
    
    
    
    <footer class="article-time">
        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M11.795 21h-6.795a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v4" />
  <circle cx="18" cy="18" r="4" />
  <path d="M15 3v4" />
  <path d="M7 3v4" />
  <path d="M3 11h16" />
  <path d="M18 16.496v1.504l1 1" />
</svg>
                <time class="article-time--published">2022-03-13</time>
            </div>
        

        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



                <time class="article-time--reading">
                    47 minute read
                </time>
            </div>
        
    </footer>
    

    
</div>

</header>

    <section class="article-content">
    
    
    <p>The following is a conversation with Tommaso Poggio.</p>
<p>He&rsquo;s a professor at MIT and is a director of the Center</p>
<p>for Brains, Minds, and Machines.</p>
<p>Cited over 100,000 times, his work</p>
<p>has had a profound impact on our understanding</p>
<p>of the nature of intelligence in both biological and artificial</p>
<p>neural networks.</p>
<p>He has been an advisor to many highly impactful researchers</p>
<p>and entrepreneurs in AI, including</p>
<p>Demis Hassabis of DeepMind, Amnon Shashua of Mobileye,</p>
<p>and Christoph Koch of the Allen Institute for Brain Science.</p>
<p>This conversation is part of the MIT course</p>
<p>on artificial general intelligence</p>
<p>and the artificial intelligence podcast.</p>
<p>If you enjoy it, subscribe on YouTube, iTunes,</p>
<p>or simply connect with me on Twitter</p>
<p>at Lex Friedman, spelled F R I D.</p>
<p>And now, here&rsquo;s my conversation with Tommaso Poggio.</p>
<p>You&rsquo;ve mentioned that in your childhood,</p>
<p>you&rsquo;ve developed a fascination with physics, especially</p>
<p>the theory of relativity.</p>
<p>And that Einstein was also a childhood hero to you.</p>
<p>What aspect of Einstein&rsquo;s genius, the nature of his genius,</p>
<p>do you think was essential for discovering</p>
<p>the theory of relativity?</p>
<p>You know, Einstein was a hero to me,</p>
<p>and I&rsquo;m sure to many people, because he</p>
<p>was able to make, of course, a major, major contribution</p>
<p>to physics with simplifying a bit just a gedanken experiment,</p>
<p>a thought experiment, you know, imagining communication</p>
<p>with lights between a stationary observer</p>
<p>and somebody on a train.</p>
<p>And I thought, you know, the fact</p>
<p>that just with the force of his thought, of his thinking,</p>
<p>of his mind, he could get to something so deep</p>
<p>in terms of physical reality, how time</p>
<p>depend on space and speed, it was something</p>
<p>absolutely fascinating.</p>
<p>It was the power of intelligence,</p>
<p>the power of the mind.</p>
<p>Do you think the ability to imagine,</p>
<p>to visualize as he did, as a lot of great physicists do,</p>
<p>do you think that&rsquo;s in all of us human beings?</p>
<p>Or is there something special to that one particular human</p>
<p>being?</p>
<p>I think, you know, all of us can learn and have, in principle,</p>
<p>similar breakthroughs.</p>
<p>There are lessons to be learned from Einstein.</p>
<p>He was one of five PhD students at ETA,</p>
<p>the Eidgen√∂ssische Technische Hochschule in Zurich,</p>
<p>in physics.</p>
<p>And he was the worst of the five,</p>
<p>the only one who did not get an academic position when</p>
<p>he graduated, when he finished his PhD.</p>
<p>And he went to work, as everybody knows,</p>
<p>for the patent office.</p>
<p>And so it&rsquo;s not so much that he worked for the patent office,</p>
<p>but the fact that obviously he was smart,</p>
<p>but he was not a top student, obviously</p>
<p>was the anti conformist.</p>
<p>He was not thinking in the traditional way that probably</p>
<p>his teachers and the other students were doing.</p>
<p>So there is a lot to be said about trying</p>
<p>to do the opposite or something quite different from what</p>
<p>other people are doing.</p>
<p>That&rsquo;s certainly true for the stock market.</p>
<p>Never buy if everybody&rsquo;s buying.</p>
<p>And also true for science.</p>
<p>Yes.</p>
<p>So you&rsquo;ve also mentioned, staying</p>
<p>on the theme of physics, that you were excited at a young age</p>
<p>by the mysteries of the universe that physics could uncover.</p>
<p>Such, as I saw mentioned, the possibility of time travel.</p>
<p>So the most out of the box question,</p>
<p>I think I&rsquo;ll get to ask today, do you</p>
<p>think time travel is possible?</p>
<p>Well, it would be nice if it were possible right now.</p>
<p>In science, you never say no.</p>
<p>But your understanding of the nature of time.</p>
<p>Yeah.</p>
<p>It&rsquo;s very likely that it&rsquo;s not possible to travel in time.</p>
<p>We may be able to travel forward in time</p>
<p>if we can, for instance, freeze ourselves or go</p>
<p>on some spacecraft traveling close to the speed of light.</p>
<p>But in terms of actively traveling, for instance,</p>
<p>back in time, I find probably very unlikely.</p>
<p>So do you still hold the underlying dream</p>
<p>of the engineering intelligence that</p>
<p>will build systems that are able to do such huge leaps,</p>
<p>like discovering the kind of mechanism that would be</p>
<p>required to travel through time?</p>
<p>Do you still hold that dream or echoes of it</p>
<p>from your childhood?</p>
<p>Yeah.</p>
<p>I don&rsquo;t think whether there are certain problems that probably</p>
<p>cannot be solved, depending what you believe</p>
<p>about the physical reality, like maybe totally impossible</p>
<p>to create energy from nothing or to travel back in time,</p>
<p>but about making machines that can think as well as we do</p>
<p>or better, or more likely, especially</p>
<p>in the short and midterm, help us think better,</p>
<p>which is, in a sense, is happening already</p>
<p>with the computers we have.</p>
<p>And it will happen more and more.</p>
<p>But that I certainly believe.</p>
<p>And I don&rsquo;t see, in principle, why computers at some point</p>
<p>could not become more intelligent than we are,</p>
<p>although the word intelligence is a tricky one</p>
<p>and one we should discuss.</p>
<p>What I mean with that.</p>
<p>Intelligence, consciousness, words like love,</p>
<p>all these need to be disentangled.</p>
<p>So you&rsquo;ve mentioned also that you believe</p>
<p>the problem of intelligence is the greatest problem</p>
<p>in science, greater than the origin of life</p>
<p>and the origin of the universe.</p>
<p>You&rsquo;ve also, in the talk I&rsquo;ve listened to,</p>
<p>said that you&rsquo;re open to arguments against you.</p>
<p>So what do you think is the most captivating aspect</p>
<p>of this problem of understanding the nature of intelligence?</p>
<p>Why does it captivate you as it does?</p>
<p>Well, originally, I think one of the motivation</p>
<p>that I had as, I guess, a teenager when I was infatuated</p>
<p>with theory of relativity was really</p>
<p>that I found that there was the problem of time and space</p>
<p>and general relativity.</p>
<p>But there were so many other problems</p>
<p>of the same level of difficulty and importance</p>
<p>that I could, even if I were Einstein,</p>
<p>it was difficult to hope to solve all of them.</p>
<p>So what about solving a problem whose solution allowed</p>
<p>me to solve all the problems?</p>
<p>And this was, what if we could find the key to an intelligence</p>
<p>10 times better or faster than Einstein?</p>
<p>So that&rsquo;s sort of seeing artificial intelligence</p>
<p>as a tool to expand our capabilities.</p>
<p>But is there just an inherent curiosity in you</p>
<p>in just understanding what it is in here</p>
<p>that makes it all work?</p>
<p>Yes, absolutely, you&rsquo;re right.</p>
<p>So I started saying this was the motivation when</p>
<p>I was a teenager.</p>
<p>But soon after, I think the problem of human intelligence</p>
<p>became a real focus of my science and my research</p>
<p>because I think for me, the most interesting problem</p>
<p>is really asking who we are.</p>
<p>It&rsquo;s asking not only a question about science,</p>
<p>but even about the very tool we are using to do science, which</p>
<p>is our brain.</p>
<p>How does our brain work?</p>
<p>From where does it come from?</p>
<p>What are its limitations?</p>
<p>Can we make it better?</p>
<p>And that, in many ways, is the ultimate question</p>
<p>that underlies this whole effort of science.</p>
<p>So you&rsquo;ve made significant contributions</p>
<p>in both the science of intelligence</p>
<p>and the engineering of intelligence.</p>
<p>In a hypothetical way, let me ask,</p>
<p>how far do you think we can get in creating intelligence</p>
<p>systems without understanding the biological,</p>
<p>the understanding how the human brain creates intelligence?</p>
<p>Put another way, do you think we can</p>
<p>build a strong AI system without really getting at the core</p>
<p>understanding the functional nature of the brain?</p>
<p>Well, this is a real difficult question.</p>
<p>We did solve problems like flying</p>
<p>without really using too much our knowledge</p>
<p>about how birds fly.</p>
<p>It was important, I guess, to know that you could have</p>
<p>things heavier than air being able to fly, like birds.</p>
<p>But beyond that, probably we did not learn very much, some.</p>
<p>The Brothers Wright did learn a lot of observation</p>
<p>about birds and designing their aircraft.</p>
<p>But you can argue we did not use much of biology</p>
<p>in that particular case.</p>
<p>Now, in the case of intelligence,</p>
<p>I think that it&rsquo;s a bit of a bet right now.</p>
<p>If you ask, OK, we all agree we&rsquo;ll get at some point,</p>
<p>maybe soon, maybe later, to a machine that</p>
<p>is indistinguishable from my secretary,</p>
<p>say, in terms of what I can ask the machine to do.</p>
<p>I think we&rsquo;ll get there.</p>
<p>And now the question is, you can ask people,</p>
<p>do you think we&rsquo;ll get there without any knowledge</p>
<p>about the human brain?</p>
<p>Or that the best way to get there</p>
<p>is to understand better the human brain?</p>
<p>OK, this is, I think, an educated bet</p>
<p>that different people with different backgrounds</p>
<p>will decide in different ways.</p>
<p>The recent history of the progress</p>
<p>in AI in the last, I would say, five years or 10 years</p>
<p>has been that the main breakthroughs,</p>
<p>the main recent breakthroughs, really start from neuroscience.</p>
<p>I can mention reinforcement learning as one.</p>
<p>It&rsquo;s one of the algorithms at the core of AlphaGo,</p>
<p>which is the system that beat the kind of an official world</p>
<p>champion of Go, Lee Sedol, two, three years ago in Seoul.</p>
<p>That&rsquo;s one.</p>
<p>And that started really with the work of Pavlov in 1900,</p>
<p>Marvin Minsky in the 60s, and many other neuroscientists</p>
<p>later on.</p>
<p>And deep learning started, which is at the core, again,</p>
<p>of AlphaGo and systems like autonomous driving</p>
<p>systems for cars, like the systems that Mobileye,</p>
<p>which is a company started by one of my ex postdocs,</p>
<p>Amnon Shashua, did.</p>
<p>So that is at the core of those things.</p>
<p>And deep learning, really, the initial ideas</p>
<p>in terms of the architecture of these layered</p>
<p>hierarchical networks started with work of Torsten Wiesel</p>
<p>and David Hubel at Harvard up the river in the 60s.</p>
<p>So recent history suggests that neuroscience played a big role</p>
<p>in these breakthroughs.</p>
<p>My personal bet is that there is a good chance they continue</p>
<p>to play a big role.</p>
<p>Maybe not in all the future breakthroughs,</p>
<p>but in some of them.</p>
<p>At least in inspiration.</p>
<p>At least in inspiration, absolutely, yes.</p>
<p>So you studied both artificial and biological neural networks.</p>
<p>You said these mechanisms that underlie deep learning</p>
<p>and reinforcement learning.</p>
<p>But there is nevertheless significant differences</p>
<p>between biological and artificial neural networks</p>
<p>as they stand now.</p>
<p>So between the two, what do you find</p>
<p>is the most interesting, mysterious, maybe even</p>
<p>beautiful difference as it currently</p>
<p>stands in our understanding?</p>
<p>I must confess that until recently, I</p>
<p>found that the artificial networks, too simplistic</p>
<p>relative to real neural networks.</p>
<p>But recently, I&rsquo;ve been starting to think that, yes,</p>
<p>there is a very big simplification of what</p>
<p>you find in the brain.</p>
<p>But on the other hand, they are much closer</p>
<p>in terms of the architecture to the brain</p>
<p>than other models that we had, that computer science used</p>
<p>as model of thinking, which were mathematical logics, LISP,</p>
<p>Prologue, and those kind of things.</p>
<p>So in comparison to those, they&rsquo;re</p>
<p>much closer to the brain.</p>
<p>You have networks of neurons, which</p>
<p>is what the brain is about.</p>
<p>And the artificial neurons in the models, as I said,</p>
<p>caricature of the biological neurons.</p>
<p>But they&rsquo;re still neurons, single units communicating</p>
<p>with other units, something that is absent</p>
<p>in the traditional computer type models of mathematics,</p>
<p>reasoning, and so on.</p>
<p>So what aspect would you like to see</p>
<p>in artificial neural networks added over time</p>
<p>as we try to figure out ways to improve them?</p>
<p>So one of the main differences and problems</p>
<p>in terms of deep learning today, and it&rsquo;s not only</p>
<p>deep learning, and the brain, is the need for deep learning</p>
<p>techniques to have a lot of labeled examples.</p>
<p>For instance, for ImageNet, you have</p>
<p>like a training set, which is 1 million images, each one</p>
<p>labeled by some human in terms of which object is there.</p>
<p>And it&rsquo;s clear that in biology, a baby</p>
<p>may be able to see millions of images</p>
<p>in the first years of life, but will not</p>
<p>have millions of labels given to him or her by parents</p>
<p>or caretakers.</p>
<p>So how do you solve that?</p>
<p>I think there is this interesting challenge</p>
<p>that today, deep learning and related techniques</p>
<p>are all about big data, big data meaning</p>
<p>a lot of examples labeled by humans,</p>
<p>whereas in nature, you have this big data</p>
<p>is n going to infinity.</p>
<p>That&rsquo;s the best, n meaning labeled data.</p>
<p>But I think the biological world is more n going to 1.</p>
<p>A child can learn from a very small number</p>
<p>of labeled examples.</p>
<p>Like you tell a child, this is a car.</p>
<p>You don&rsquo;t need to say, like in ImageNet, this is a car,</p>
<p>this is a car, this is not a car, this is not a car,</p>
<p>1 million times.</p>
<p>And of course, with AlphaGo, or at least the AlphaZero</p>
<p>variants, because the world of Go</p>
<p>is so simplistic that you can actually</p>
<p>learn by yourself through self play,</p>
<p>you can play against each other.</p>
<p>In the real world, the visual system</p>
<p>that you&rsquo;ve studied extensively is a lot more complicated</p>
<p>than the game of Go.</p>
<p>On the comment about children, which</p>
<p>are fascinatingly good at learning new stuff,</p>
<p>how much of it do you think is hardware,</p>
<p>and how much of it is software?</p>
<p>Yeah, that&rsquo;s a good, deep question.</p>
<p>In a sense, it&rsquo;s the old question of nurture and nature,</p>
<p>how much is in the gene, and how much</p>
<p>is in the experience of an individual.</p>
<p>Obviously, it&rsquo;s both that play a role.</p>
<p>And I believe that the way evolution gives,</p>
<p>puts prior information, so to speak, hardwired,</p>
<p>is not really hardwired.</p>
<p>But that&rsquo;s essentially an hypothesis.</p>
<p>I think what&rsquo;s going on is that evolution has almost</p>
<p>necessarily, if you believe in Darwin, is very opportunistic.</p>
<p>And think about our DNA and the DNA of Drosophila.</p>
<p>Our DNA does not have many more genes than Drosophila.</p>
<p>The fly.</p>
<p>The fly, the fruit fly.</p>
<p>Now, we know that the fruit fly does not</p>
<p>learn very much during its individual existence.</p>
<p>It looks like one of these machinery</p>
<p>that it&rsquo;s really mostly, not 100%, but 95%,</p>
<p>hardcoded by the genes.</p>
<p>But since we don&rsquo;t have many more genes than Drosophila,</p>
<p>evolution could encode in as a general learning machinery,</p>
<p>and then had to give very weak priors.</p>
<p>Like, for instance, let me give a specific example,</p>
<p>which is recent work by a member of our Center for Brains,</p>
<p>Minds, and Machines.</p>
<p>We know because of work of other people in our group</p>
<p>and other groups, that there are cells</p>
<p>in a part of our brain, neurons, that are tuned to faces.</p>
<p>They seem to be involved in face recognition.</p>
<p>Now, this face area seems to be present in young children</p>
<p>and adults.</p>
<p>And one question is, is there from the beginning?</p>
<p>Is hardwired by evolution?</p>
<p>Or somehow it&rsquo;s learned very quickly.</p>
<p>So what&rsquo;s your, by the way, a lot of the questions I&rsquo;m asking,</p>
<p>the answer is we don&rsquo;t really know.</p>
<p>But as a person who has contributed</p>
<p>some profound ideas in these fields,</p>
<p>you&rsquo;re a good person to guess at some of these.</p>
<p>So of course, there&rsquo;s a caveat before a lot of the stuff</p>
<p>we talk about.</p>
<p>But what is your hunch?</p>
<p>Is the face, the part of the brain</p>
<p>that seems to be concentrated on face recognition,</p>
<p>are you born with that?</p>
<p>Or you just is designed to learn that quickly,</p>
<p>like the face of the mother and so on?</p>
<p>My hunch, my bias was the second one, learned very quickly.</p>
<p>And it turns out that Marge Livingstone at Harvard</p>
<p>has done some amazing experiments in which she raised</p>
<p>baby monkeys, depriving them of faces</p>
<p>during the first weeks of life.</p>
<p>So they see technicians, but the technician have a mask.</p>
<p>Yes.</p>
<p>And so when they looked at the area</p>
<p>in the brain of these monkeys that were usually</p>
<p>defined faces, they found no face preference.</p>
<p>So my guess is that what evolution does in this case</p>
<p>is there is a plastic area, which</p>
<p>is plastic, which is kind of predetermined</p>
<p>to be imprinted very easily.</p>
<p>But the command from the gene is not a detailed circuitry</p>
<p>for a face template.</p>
<p>Could be, but this will require probably a lot of bits.</p>
<p>You had to specify a lot of connection of a lot of neurons.</p>
<p>Instead, the command from the gene</p>
<p>is something like imprint, memorize what you see most</p>
<p>often in the first two weeks of life,</p>
<p>especially in connection with food and maybe nipples.</p>
<p>I don&rsquo;t know.</p>
<p>Well, source of food.</p>
<p>And so that area is very plastic at first and then solidifies.</p>
<p>It&rsquo;d be interesting if a variant of that experiment</p>
<p>would show a different kind of pattern associated</p>
<p>with food than a face pattern, whether that could stick.</p>
<p>There are indications that during that experiment,</p>
<p>what the monkeys saw quite often were</p>
<p>the blue gloves of the technicians that were giving</p>
<p>to the baby monkeys the milk.</p>
<p>And some of the cells, instead of being face sensitive</p>
<p>in that area, are hand sensitive.</p>
<p>That&rsquo;s fascinating.</p>
<p>Can you talk about what are the different parts of the brain</p>
<p>and, in your view, sort of loosely,</p>
<p>and how do they contribute to intelligence?</p>
<p>Do you see the brain as a bunch of different modules,</p>
<p>and they together come in the human brain</p>
<p>to create intelligence?</p>
<p>Or is it all one mush of the same kind</p>
<p>of fundamental architecture?</p>
<p>Yeah, that&rsquo;s an important question.</p>
<p>And there was a phase in neuroscience back in the 1950</p>
<p>or so in which it was believed for a while</p>
<p>that the brain was equipotential.</p>
<p>This was the term.</p>
<p>You could cut out a piece, and nothing special</p>
<p>happened apart a little bit less performance.</p>
<p>There was a surgeon, Lashley, who</p>
<p>did a lot of experiments of this type with mice and rats</p>
<p>and concluded that every part of the brain</p>
<p>was essentially equivalent to any other one.</p>
<p>It turns out that that&rsquo;s really not true.</p>
<p>There are very specific modules in the brain, as you said.</p>
<p>And people may lose the ability to speak</p>
<p>if you have a stroke in a certain region,</p>
<p>or may lose control of their legs in another region.</p>
<p>So they&rsquo;re very specific.</p>
<p>The brain is also quite flexible and redundant,</p>
<p>so often it can correct things and take over functions</p>
<p>from one part of the brain to the other.</p>
<p>But really, there are specific modules.</p>
<p>So the answer that we know from this old work, which</p>
<p>was basically based on lesions, either on animals,</p>
<p>or very often there was a mine of very interesting data</p>
<p>coming from the war, from different types of injuries</p>
<p>that soldiers had in the brain.</p>
<p>And more recently, functional MRI,</p>
<p>which allow you to check which part of the brain</p>
<p>are active when you are doing different tasks,</p>
<p>can replace some of this.</p>
<p>You can see that certain parts of the brain are involved,</p>
<p>are active in certain tasks.</p>
<p>Vision, language, yeah, that&rsquo;s right.</p>
<p>But sort of taking a step back to that part of the brain</p>
<p>that discovers that specializes in the face</p>
<p>and how that might be learned, what&rsquo;s your intuition behind?</p>
<p>Is it possible that from a physicist perspective,</p>
<p>when you get lower and lower, that it&rsquo;s all the same stuff</p>
<p>and it just, when you&rsquo;re born, it&rsquo;s plastic</p>
<p>and quickly figures out this part is going to be about vision,</p>
<p>this is going to be about language,</p>
<p>this is about common sense reasoning.</p>
<p>Do you have an intuition that that kind of learning</p>
<p>is going on really quickly, or is it really</p>
<p>kind of solidified in hardware?</p>
<p>That&rsquo;s a great question.</p>
<p>So there are parts of the brain like the cerebellum</p>
<p>or the hippocampus that are quite different from each other.</p>
<p>They clearly have different anatomy,</p>
<p>different connectivity.</p>
<p>Then there is the cortex, which is the most developed part</p>
<p>of the brain in humans.</p>
<p>And in the cortex, you have different regions</p>
<p>of the cortex that are responsible for vision,</p>
<p>for audition, for motor control, for language.</p>
<p>Now, one of the big puzzles of this</p>
<p>is that in the cortex is the cortex is the cortex.</p>
<p>Looks like it is the same in terms of hardware,</p>
<p>in terms of type of neurons and connectivity</p>
<p>across these different modalities.</p>
<p>So for the cortex, I think aside these other parts</p>
<p>of the brain like spinal cord, hippocampus,</p>
<p>cerebellum, and so on, for the cortex,</p>
<p>I think your question about hardware and software</p>
<p>and learning and so on, I think is rather open.</p>
<p>And I find it very interesting for Risa</p>
<p>to think about an architecture, computer architecture, that</p>
<p>is good for vision and at the same time is good for language.</p>
<p>Seems to be so different problem areas that you have to solve.</p>
<p>But the underlying mechanism might be the same.</p>
<p>And that&rsquo;s really instructive for artificial neural networks.</p>
<p>So we&rsquo;ve done a lot of great work in vision,</p>
<p>in human vision, computer vision.</p>
<p>And you mentioned the problem of human vision</p>
<p>is really as difficult as the problem of general intelligence.</p>
<p>And maybe that connects to the cortex discussion.</p>
<p>Can you describe the human visual cortex</p>
<p>and how the humans begin to understand the world</p>
<p>through the raw sensory information?</p>
<p>What&rsquo;s, for folks who are not familiar,</p>
<p>especially on the computer vision side,</p>
<p>we don&rsquo;t often actually take a step back except saying</p>
<p>with a sentence or two that one is inspired by the other.</p>
<p>What is it that we know about the human visual cortex?</p>
<p>That&rsquo;s interesting.</p>
<p>We know quite a bit.</p>
<p>At the same time, we don&rsquo;t know a lot.</p>
<p>But the bit we know, in a sense, we know a lot of the details.</p>
<p>And many we don&rsquo;t know.</p>
<p>And we know a lot of the top level,</p>
<p>the answer to the top level question.</p>
<p>But we don&rsquo;t know some basic ones,</p>
<p>even in terms of general neuroscience, forgetting vision.</p>
<p>Why do we sleep?</p>
<p>It&rsquo;s such a basic question.</p>
<p>And we really don&rsquo;t have an answer to that.</p>
<p>So taking a step back on that.</p>
<p>So sleep, for example, is fascinating.</p>
<p>Do you think that&rsquo;s a neuroscience question?</p>
<p>Or if we talk about abstractions, what do you</p>
<p>think is an interesting way to study intelligence</p>
<p>or most effective on the levels of abstraction?</p>
<p>Is it chemical, is it biological,</p>
<p>is it electrophysical, mathematical,</p>
<p>as you&rsquo;ve done a lot of excellent work on that side?</p>
<p>Which psychology, at which level of abstraction do you think?</p>
<p>Well, in terms of levels of abstraction,</p>
<p>I think we need all of them.</p>
<p>It&rsquo;s like if you ask me, what does it</p>
<p>mean to understand a computer?</p>
<p>That&rsquo;s much simpler.</p>
<p>But in a computer, I could say, well,</p>
<p>I understand how to use PowerPoint.</p>
<p>That&rsquo;s my level of understanding a computer.</p>
<p>It is reasonable.</p>
<p>It gives me some power to produce slides</p>
<p>and beautiful slides.</p>
<p>Now, you can ask somebody else.</p>
<p>He says, well, I know how the transistors work</p>
<p>that are inside the computer.</p>
<p>I can write the equation for transistor and diodes</p>
<p>and circuits, logical circuits.</p>
<p>And I can ask this guy, do you know how to operate PowerPoint?</p>
<p>No idea.</p>
<p>So do you think if we discovered computers walking amongst us</p>
<p>full of these transistors that are also operating</p>
<p>under windows and have PowerPoint,</p>
<p>do you think it&rsquo;s digging in a little bit more?</p>
<p>How useful is it to understand the transistor in order</p>
<p>to be able to understand PowerPoint</p>
<p>and these higher level intelligent processes?</p>
<p>So I think in the case of computers,</p>
<p>because they were made by engineers, by us,</p>
<p>this different level of understanding</p>
<p>are rather separate on purpose.</p>
<p>They are separate modules so that the engineer that</p>
<p>designed the circuit for the chips does not</p>
<p>need to know what is inside PowerPoint.</p>
<p>And somebody can write the software translating</p>
<p>from one to the other.</p>
<p>So in that case, I don&rsquo;t think understanding the transistor</p>
<p>helps you understand PowerPoint, or very little.</p>
<p>If you want to understand the computer, this question,</p>
<p>I would say you have to understand it</p>
<p>at different levels.</p>
<p>If you really want to build one, right?</p>
<p>But for the brain, I think these levels of understanding,</p>
<p>so the algorithms, which kind of computation,</p>
<p>the equivalent of PowerPoint, and the circuits,</p>
<p>the transistors, I think they are much more</p>
<p>intertwined with each other.</p>
<p>There is not a neatly level of the software separate</p>
<p>from the hardware.</p>
<p>And so that&rsquo;s why I think in the case of the brain,</p>
<p>the problem is more difficult and more than for computers</p>
<p>requires the interaction, the collaboration</p>
<p>between different types of expertise.</p>
<p>The brain is a big hierarchical mess.</p>
<p>You can&rsquo;t just disentangle levels.</p>
<p>I think you can, but it&rsquo;s much more difficult.</p>
<p>And it&rsquo;s not completely obvious.</p>
<p>And as I said, I think it&rsquo;s one of the, personally,</p>
<p>I think is the greatest problem in science.</p>
<p>So I think it&rsquo;s fair that it&rsquo;s difficult.</p>
<p>That&rsquo;s a difficult one.</p>
<p>That said, you do talk about compositionality</p>
<p>and why it might be useful.</p>
<p>And when you discuss why these neural networks,</p>
<p>in artificial or biological sense, learn anything,</p>
<p>you talk about compositionality.</p>
<p>See, there&rsquo;s a sense that nature can be disentangled.</p>
<p>Or, well, all aspects of our cognition</p>
<p>could be disentangled to some degree.</p>
<p>So why do you think, first of all,</p>
<p>how do you see compositionality?</p>
<p>And why do you think it exists at all in nature?</p>
<p>I spoke about, I use the term compositionality</p>
<p>when we looked at deep neural networks, multilayers,</p>
<p>and trying to understand when and why they are more powerful</p>
<p>than more classical one layer networks,</p>
<p>like linear classifier, kernel machines, so called.</p>
<p>And what we found is that in terms</p>
<p>of approximating or learning or representing</p>
<p>a function, a mapping from an input to an output,</p>
<p>like from an image to the label in the image,</p>
<p>if this function has a particular structure,</p>
<p>then deep networks are much more powerful than shallow networks</p>
<p>to approximate the underlying function.</p>
<p>And the particular structure is a structure of compositionality.</p>
<p>If the function is made up of functions of function,</p>
<p>so that you need to look on when you are interpreting an image,</p>
<p>classifying an image, you don&rsquo;t need</p>
<p>to look at all pixels at once.</p>
<p>But you can compute something from small groups of pixels.</p>
<p>And then you can compute something</p>
<p>on the output of this local computation and so on,</p>
<p>which is similar to what you do when you read a sentence.</p>
<p>You don&rsquo;t need to read the first and the last letter.</p>
<p>But you can read syllables, combine them in words,</p>
<p>combine the words in sentences.</p>
<p>So this is this kind of structure.</p>
<p>So that&rsquo;s as part of a discussion</p>
<p>of why deep neural networks may be more</p>
<p>effective than the shallow methods.</p>
<p>And is your sense, for most things</p>
<p>we can use neural networks for, those problems</p>
<p>are going to be compositional in nature, like language,</p>
<p>like vision?</p>
<p>How far can we get in this kind of way?</p>
<p>So here is almost philosophy.</p>
<p>Well, let&rsquo;s go there.</p>
<p>Yeah, let&rsquo;s go there.</p>
<p>So a friend of mine, Max Tegmark, who is a physicist at MIT.</p>
<p>I&rsquo;ve talked to him on this thing.</p>
<p>Yeah, and he disagrees with you, right?</p>
<p>A little bit.</p>
<p>Yeah, we agree on most.</p>
<p>But the conclusion is a bit different.</p>
<p>His conclusion is that for images, for instance,</p>
<p>the compositional structure of this function</p>
<p>that we have to learn or to solve these problems</p>
<p>comes from physics, comes from the fact</p>
<p>that you have local interactions in physics</p>
<p>between atoms and other atoms, between particle</p>
<p>of matter and other particles, between planets</p>
<p>and other planets, between stars and other.</p>
<p>It&rsquo;s all local.</p>
<p>And that&rsquo;s true.</p>
<p>But you could push this argument a bit further.</p>
<p>Not this argument, actually.</p>
<p>You could argue that maybe that&rsquo;s part of the truth.</p>
<p>But maybe what happens is kind of the opposite,</p>
<p>is that our brain is wired up as a deep network.</p>
<p>So it can learn, understand, solve</p>
<p>problems that have this compositional structure</p>
<p>and it cannot solve problems that don&rsquo;t have</p>
<p>this compositional structure.</p>
<p>So the problems we are accustomed to, we think about,</p>
<p>we test our algorithms on, are this compositional structure</p>
<p>because our brain is made up.</p>
<p>And that&rsquo;s, in a sense, an evolutionary perspective</p>
<p>that we&rsquo;ve.</p>
<p>So the ones that didn&rsquo;t have, that weren&rsquo;t</p>
<p>dealing with the compositional nature of reality died off?</p>
<p>Yes, but also could be maybe the reason</p>
<p>why we have this local connectivity in the brain,</p>
<p>like simple cells in cortex looking</p>
<p>only at the small part of the image, each one of them,</p>
<p>and then other cells looking at the small number</p>
<p>of these simple cells and so on.</p>
<p>The reason for this may be purely</p>
<p>that it was difficult to grow long range connectivity.</p>
<p>So suppose it&rsquo;s for biology.</p>
<p>It&rsquo;s possible to grow short range connectivity but not</p>
<p>long range also because there is a limited number of long range</p>
<p>that you can.</p>
<p>And so you have this limitation from the biology.</p>
<p>And this means you build a deep convolutional network.</p>
<p>This would be something like a deep convolutional network.</p>
<p>And this is great for solving certain class of problems.</p>
<p>These are the ones we find easy and important for our life.</p>
<p>And yes, they were enough for us to survive.</p>
<p>And you can start a successful business</p>
<p>on solving those problems with Mobileye.</p>
<p>Driving is a compositional problem.</p>
<p>So on the learning task, we don&rsquo;t</p>
<p>know much about how the brain learns</p>
<p>in terms of optimization.</p>
<p>So the thing that&rsquo;s stochastic gradient descent</p>
<p>is what artificial neural networks use for the most part</p>
<p>to adjust the parameters in such a way that it&rsquo;s</p>
<p>able to deal based on the label data,</p>
<p>it&rsquo;s able to solve the problem.</p>
<p>So what&rsquo;s your intuition about why it works at all?</p>
<p>How hard of a problem it is to optimize</p>
<p>a neural network, artificial neural network?</p>
<p>Is there other alternatives?</p>
<p>Just in general, your intuition is</p>
<p>behind this very simplistic algorithm</p>
<p>that seems to do pretty good, surprisingly so.</p>
<p>Yes.</p>
<p>So I find neuroscience, the architecture of cortex,</p>
<p>is really similar to the architecture of deep networks.</p>
<p>So there is a nice correspondence there</p>
<p>between the biology and this kind</p>
<p>of local connectivity, hierarchical architecture.</p>
<p>The stochastic gradient descent, as you said,</p>
<p>is a very simple technique.</p>
<p>It seems pretty unlikely that biology could do that</p>
<p>from what we know right now about cortex and neurons</p>
<p>and synapses.</p>
<p>So it&rsquo;s a big question open whether there</p>
<p>are other optimization learning algorithms that</p>
<p>can replace stochastic gradient descent.</p>
<p>And my guess is yes, but nobody has found yet a real answer.</p>
<p>I mean, people are trying, still trying,</p>
<p>and there are some interesting ideas.</p>
<p>The fact that stochastic gradient descent</p>
<p>is so successful, this has become clearly not so</p>
<p>mysterious.</p>
<p>And the reason is that it&rsquo;s an interesting fact.</p>
<p>It&rsquo;s a change, in a sense, in how</p>
<p>people think about statistics.</p>
<p>And this is the following, is that typically when</p>
<p>you had data and you had, say, a model with parameters,</p>
<p>you are trying to fit the model to the data,</p>
<p>to fit the parameter.</p>
<p>Typically, the kind of crowd wisdom type idea</p>
<p>was you should have at least twice the number of data</p>
<p>than the number of parameters.</p>
<p>Maybe 10 times is better.</p>
<p>Now, the way you train neural networks these days</p>
<p>is that they have 10 or 100 times more parameters</p>
<p>than data, exactly the opposite.</p>
<p>And it has been one of the puzzles about neural networks.</p>
<p>How can you get something that really works</p>
<p>when you have so much freedom?</p>
<p>From that little data, it can generalize somehow.</p>
<p>Right, exactly.</p>
<p>Do you think the stochastic nature of it</p>
<p>is essential, the randomness?</p>
<p>So I think we have some initial understanding</p>
<p>why this happens.</p>
<p>But one nice side effect of having</p>
<p>this overparameterization, more parameters than data,</p>
<p>is that when you look for the minima of a loss function,</p>
<p>like stochastic gradient descent is doing,</p>
<p>you find I made some calculations based</p>
<p>on some old basic theorem of algebra called the Bezu</p>
<p>theorem that gives you an estimate of the number</p>
<p>of solution of a system of polynomial equation.</p>
<p>Anyway, the bottom line is that there are probably</p>
<p>more minima for a typical deep networks</p>
<p>than atoms in the universe.</p>
<p>Just to say, there are a lot because</p>
<p>of the overparameterization.</p>
<p>A more global minimum, zero minimum, good minimum.</p>
<p>A more global minima.</p>
<p>Yeah, a lot of them.</p>
<p>So you have a lot of solutions.</p>
<p>So it&rsquo;s not so surprising that you can find them</p>
<p>relatively easily.</p>
<p>And this is because of the overparameterization.</p>
<p>The overparameterization sprinkles that entire space</p>
<p>with solutions that are pretty good.</p>
<p>It&rsquo;s not so surprising, right?</p>
<p>It&rsquo;s like if you have a system of linear equation</p>
<p>and you have more unknowns than equations, then you have,</p>
<p>we know, you have an infinite number of solutions.</p>
<p>And the question is to pick one.</p>
<p>That&rsquo;s another story.</p>
<p>But you have an infinite number of solutions.</p>
<p>So there are a lot of value of your unknowns</p>
<p>that satisfy the equations.</p>
<p>But it&rsquo;s possible that there&rsquo;s a lot of those solutions that</p>
<p>aren&rsquo;t very good.</p>
<p>What&rsquo;s surprising is that they&rsquo;re pretty good.</p>
<p>So that&rsquo;s a good question.</p>
<p>Why can you pick one that generalizes well?</p>
<p>Yeah.</p>
<p>That&rsquo;s a separate question with separate answers.</p>
<p>One theorem that people like to talk about that kind of</p>
<p>inspires imagination of the power of neural networks</p>
<p>is the universality, universal approximation theorem,</p>
<p>that you can approximate any computable function</p>
<p>with just a finite number of neurons</p>
<p>in a single hidden layer.</p>
<p>Do you find this theorem one surprising?</p>
<p>Do you find it useful, interesting, inspiring?</p>
<p>No, this one, I never found it very surprising.</p>
<p>It was known since the 80s, since I entered the field,</p>
<p>because it&rsquo;s basically the same as Weierstrass theorem, which</p>
<p>says that I can approximate any continuous function</p>
<p>with a polynomial of sufficiently,</p>
<p>with a sufficient number of terms, monomials.</p>
<p>So basically the same.</p>
<p>And the proofs are very similar.</p>
<p>So your intuition was there was never</p>
<p>any doubt that neural networks in theory</p>
<p>could be very strong approximators.</p>
<p>Right.</p>
<p>The question, the interesting question,</p>
<p>is that if this theorem says you can approximate, fine.</p>
<p>But when you ask how many neurons, for instance,</p>
<p>or in the case of polynomial, how many monomials,</p>
<p>I need to get a good approximation.</p>
<p>Then it turns out that that depends</p>
<p>on the dimensionality of your function,</p>
<p>how many variables you have.</p>
<p>But it depends on the dimensionality</p>
<p>of your function in a bad way.</p>
<p>It&rsquo;s, for instance, suppose you want</p>
<p>an error which is no worse than 10% in your approximation.</p>
<p>You come up with a network that approximate your function</p>
<p>within 10%.</p>
<p>Then it turns out that the number of units you need</p>
<p>are in the order of 10 to the dimensionality, d,</p>
<p>how many variables.</p>
<p>So if you have two variables, these two words,</p>
<p>you have 100 units and OK.</p>
<p>But if you have, say, 200 by 200 pixel images,</p>
<p>now this is 40,000, whatever.</p>
<p>We again go to the size of the universe pretty quickly.</p>
<p>Exactly, 10 to the 40,000 or something.</p>
<p>And so this is called the curse of dimensionality,</p>
<p>not quite appropriately.</p>
<p>And the hope is with the extra layers,</p>
<p>you can remove the curse.</p>
<p>What we proved is that if you have deep layers,</p>
<p>hierarchical architecture with the local connectivity</p>
<p>of the type of convolutional deep learning,</p>
<p>and if you&rsquo;re dealing with a function that</p>
<p>has this kind of hierarchical architecture,</p>
<p>then you avoid completely the curse.</p>
<p>You&rsquo;ve spoken a lot about supervised deep learning.</p>
<p>What are your thoughts, hopes, views</p>
<p>on the challenges of unsupervised learning</p>
<p>with GANs, with Generative Adversarial Networks?</p>
<p>Do you see those as distinct?</p>
<p>The power of GANs, do you see those</p>
<p>as distinct from supervised methods in neural networks,</p>
<p>or are they really all in the same representation ballpark?</p>
<p>GANs is one way to get estimation of probability</p>
<p>densities, which is a somewhat new way that people have not</p>
<p>done before.</p>
<p>I don&rsquo;t know whether this will really play an important role</p>
<p>in intelligence.</p>
<p>Or it&rsquo;s interesting.</p>
<p>I&rsquo;m less enthusiastic about it than many people in the field.</p>
<p>I have the feeling that many people in the field</p>
<p>are really impressed by the ability</p>
<p>of producing realistic looking images in this generative way.</p>
<p>Which describes the popularity of the methods.</p>
<p>But you&rsquo;re saying that while that&rsquo;s exciting and cool</p>
<p>to look at, it may not be the tool that&rsquo;s useful for it.</p>
<p>So you describe it kind of beautifully.</p>
<p>Current supervised methods go n to infinity</p>
<p>in terms of number of labeled points.</p>
<p>And we really have to figure out how to go to n to 1.</p>
<p>And you&rsquo;re thinking GANs might help,</p>
<p>but they might not be the right.</p>
<p>I don&rsquo;t think for that problem, which I really think</p>
<p>is important, I think they may help.</p>
<p>They certainly have applications,</p>
<p>for instance, in computer graphics.</p>
<p>And I did work long ago, which was</p>
<p>a little bit similar in terms of saying, OK, I have a network.</p>
<p>And I present images.</p>
<p>And I can input its images.</p>
<p>And output is, for instance, the pose of the image.</p>
<p>A face, how much is smiling, is rotated 45 degrees or not.</p>
<p>What about having a network that I train with the same data</p>
<p>set, but now I invert input and output.</p>
<p>Now the input is the pose or the expression, a number,</p>
<p>set of numbers.</p>
<p>And the output is the image.</p>
<p>And I train it.</p>
<p>And we did pretty good, interesting results</p>
<p>in terms of producing very realistic looking images.</p>
<p>It was a less sophisticated mechanism.</p>
<p>But the output was pretty less than GANs.</p>
<p>But the output was pretty much of the same quality.</p>
<p>So I think for a computer graphics type application,</p>
<p>yeah, definitely GANs can be quite useful.</p>
<p>And not only for that, but for helping,</p>
<p>for instance, on this problem of unsupervised example</p>
<p>of reducing the number of labeled examples.</p>
<p>I think people, it&rsquo;s like they think they can get out</p>
<p>more than they put in.</p>
<p>There&rsquo;s no free lunch, as you said.</p>
<p>What do you think, what&rsquo;s your intuition?</p>
<p>How can we slow the growth of N to infinity in supervised,</p>
<p>N to infinity in supervised learning?</p>
<p>So for example, Mobileye has very successfully,</p>
<p>I mean, essentially annotated large amounts of data</p>
<p>to be able to drive a car.</p>
<p>Now one thought is, so we&rsquo;re trying</p>
<p>to teach machines, school of AI.</p>
<p>And we&rsquo;re trying to, so how can we become better teachers,</p>
<p>maybe?</p>
<p>That&rsquo;s one way.</p>
<p>No, I like that.</p>
<p>Because again, one caricature of the history of computer</p>
<p>science, you could say, begins with programmers, expensive.</p>
<p>Continuous labelers, cheap.</p>
<p>And the future will be schools, like we have for kids.</p>
<p>Yeah.</p>
<p>Currently, the labeling methods were not</p>
<p>selective about which examples we teach networks with.</p>
<p>So I think the focus of making networks that learn much faster</p>
<p>is often on the architecture side.</p>
<p>But how can we pick better examples with which to learn?</p>
<p>Do you have intuitions about that?</p>
<p>Well, that&rsquo;s part of the problem.</p>
<p>But the other one is, if we look at biology,</p>
<p>a reasonable assumption, I think,</p>
<p>is in the same spirit that I said,</p>
<p>evolution is opportunistic and has weak priors.</p>
<p>The way I think the intelligence of a child,</p>
<p>the baby may develop is by bootstrapping weak priors</p>
<p>from evolution.</p>
<p>For instance, you can assume that you</p>
<p>have in most organisms, including human babies,</p>
<p>built in some basic machinery to detect motion</p>
<p>and relative motion.</p>
<p>And in fact, we know all insects from fruit flies</p>
<p>to other animals, they have this,</p>
<p>even in the retinas, in the very peripheral part.</p>
<p>It&rsquo;s very conserved across species, something</p>
<p>that evolution discovered early.</p>
<p>It may be the reason why babies tend</p>
<p>to look in the first few days to moving objects</p>
<p>and not to not moving objects.</p>
<p>Now, moving objects means, OK, they&rsquo;re attracted by motion.</p>
<p>But motion also means that motion</p>
<p>gives automatic segmentation from the background.</p>
<p>So because of motion boundaries, either the object</p>
<p>is moving or the eye of the baby is tracking the moving object</p>
<p>and the background is moving, right?</p>
<p>Yeah, so just purely on the visual characteristics</p>
<p>of the scene, that seems to be the most useful.</p>
<p>Right, so it&rsquo;s like looking at an object without background.</p>
<p>It&rsquo;s ideal for learning the object.</p>
<p>Otherwise, it&rsquo;s really difficult because you</p>
<p>have so much stuff.</p>
<p>So suppose you do this at the beginning, first weeks.</p>
<p>Then after that, you can recognize object.</p>
<p>Now they are imprinted, the number one,</p>
<p>even in the background, even without motion.</p>
<p>So that&rsquo;s, by the way, I just want</p>
<p>to ask on the object recognition problem.</p>
<p>So there is this being responsive to movement</p>
<p>and doing edge detection, essentially.</p>
<p>What&rsquo;s the gap between being effective at visually</p>
<p>recognizing stuff, detecting where it is,</p>
<p>and understanding the scene?</p>
<p>Is this a huge gap in many layers, or is it close?</p>
<p>No, I think that&rsquo;s a huge gap.</p>
<p>I think present algorithm with all the success that we have</p>
<p>and the fact that there are a lot of very useful,</p>
<p>I think we are in a golden age for applications</p>
<p>of low level vision and low level speech recognition</p>
<p>and so on, Alexa and so on.</p>
<p>There are many more things of similar level</p>
<p>to be done, including medical diagnosis and so on.</p>
<p>But we are far from what we call understanding</p>
<p>of a scene, of language, of actions, of people.</p>
<p>That is, despite the claims, that&rsquo;s, I think, very far.</p>
<p>We&rsquo;re a little bit off.</p>
<p>So in popular culture and among many researchers,</p>
<p>some of which I&rsquo;ve spoken with, the Stuart Russell</p>
<p>and Elon Musk, in and out of the AI field,</p>
<p>there&rsquo;s a concern about the existential threat of AI.</p>
<p>And how do you think about this concern?</p>
<p>And is it valuable to think about large scale, long term,</p>
<p>unintended consequences of intelligent systems</p>
<p>we try to build?</p>
<p>I always think it&rsquo;s better to worry first, early,</p>
<p>rather than late.</p>
<p>So worry is good.</p>
<p>Yeah.</p>
<p>I&rsquo;m not against worrying at all.</p>
<p>Personally, I think that it will take a long time</p>
<p>before there is real reason to be worried.</p>
<p>But as I said, I think it&rsquo;s good to put in place</p>
<p>and think about possible safety against.</p>
<p>What I find a bit misleading are things</p>
<p>like that have been said by people I know, like Elon Musk,</p>
<p>and what is Bostrom in particular,</p>
<p>and what is his first name?</p>
<p>Nick Bostrom.</p>
<p>Nick Bostrom, right.</p>
<p>And a couple of other people that, for instance, AI</p>
<p>is more dangerous than nuclear weapons.</p>
<p>I think that&rsquo;s really wrong.</p>
<p>That can be misleading.</p>
<p>Because in terms of priority, we should still</p>
<p>be more worried about nuclear weapons</p>
<p>and what people are doing about it and so on than AI.</p>
<p>And you&rsquo;ve spoken about Demis Hassabis</p>
<p>and yourself saying that you think</p>
<p>you&rsquo;ll be about 100 years out before we</p>
<p>have a general intelligence system that&rsquo;s</p>
<p>on par with a human being.</p>
<p>Do you have any updates for those predictions?</p>
<p>Well, I think he said.</p>
<p>He said 20, I think.</p>
<p>He said 20, right.</p>
<p>This was a couple of years ago.</p>
<p>I have not asked him again.</p>
<p>So should I have?</p>
<p>Your own prediction, what&rsquo;s your prediction</p>
<p>about when you&rsquo;ll be truly surprised?</p>
<p>And what&rsquo;s the confidence interval on that?</p>
<p>It&rsquo;s so difficult to predict the future and even</p>
<p>the present sometimes.</p>
<p>It&rsquo;s pretty hard to predict.</p>
<p>But I would be, as I said, this is completely,</p>
<p>I would be more like Rod Brooks.</p>
<p>I think he&rsquo;s about 200 years.</p>
<p>200 years.</p>
<p>When we have this kind of AGI system,</p>
<p>artificial general intelligence system,</p>
<p>you&rsquo;re sitting in a room with her, him, it.</p>
<p>Do you think the underlying design of such a system</p>
<p>is something we&rsquo;ll be able to understand?</p>
<p>It will be simple?</p>
<p>Do you think it&rsquo;ll be explainable,</p>
<p>understandable by us?</p>
<p>Your intuition, again, we&rsquo;re in the realm of philosophy</p>
<p>a little bit.</p>
<p>Well, probably no.</p>
<p>But again, it depends what you really</p>
<p>mean for understanding.</p>
<p>So I think we don&rsquo;t understand how deep networks work.</p>
<p>I think we are beginning to have a theory now.</p>
<p>But in the case of deep networks,</p>
<p>or even in the case of the simpler kernel machines</p>
<p>or linear classifier, we really don&rsquo;t understand</p>
<p>the individual units or so.</p>
<p>But we understand what the computation and the limitations</p>
<p>and the properties of it are.</p>
<p>It&rsquo;s similar to many things.</p>
<p>What does it mean to understand how a fusion bomb works?</p>
<p>How many of us understand the basic principle?</p>
<p>And some of us may understand deeper details.</p>
<p>In that sense, understanding is, as a community,</p>
<p>as a civilization, can we build another copy of it?</p>
<p>And in that sense, do you think there</p>
<p>will need to be some evolutionary component where</p>
<p>it runs away from our understanding?</p>
<p>Or do you think it could be engineered from the ground up,</p>
<p>the same way you go from the transistor to PowerPoint?</p>
<p>So many years ago, this was actually 40, 41 years ago,</p>
<p>I wrote a paper with David Marr, who</p>
<p>was one of the founding fathers of computer vision,</p>
<p>computational vision.</p>
<p>I wrote a paper about levels of understanding,</p>
<p>which is related to the question we discussed earlier</p>
<p>about understanding PowerPoint, understanding transistors,</p>
<p>and so on.</p>
<p>And in that kind of framework, we</p>
<p>had the level of the hardware and the top level</p>
<p>of the algorithms.</p>
<p>We did not have learning.</p>
<p>Recently, I updated adding levels.</p>
<p>And one level I added to those three was learning.</p>
<p>And you can imagine, you could have a good understanding</p>
<p>of how you construct a learning machine, like we do.</p>
<p>But being unable to describe in detail what the learning</p>
<p>machines will discover, right?</p>
<p>Now, that would be still a powerful understanding,</p>
<p>if I can build a learning machine,</p>
<p>even if I don&rsquo;t understand in detail every time it</p>
<p>learns something.</p>
<p>Just like our children, if they start</p>
<p>listening to a certain type of music,</p>
<p>I don&rsquo;t know, Miley Cyrus or something,</p>
<p>you don&rsquo;t understand why they came</p>
<p>to that particular preference.</p>
<p>But you understand the learning process.</p>
<p>That&rsquo;s very interesting.</p>
<p>So on learning for systems to be part of our world,</p>
<p>it has a certain, one of the challenging things</p>
<p>that you&rsquo;ve spoken about is learning ethics, learning</p>
<p>morals.</p>
<p>And how hard do you think is the problem of, first of all,</p>
<p>humans understanding our ethics?</p>
<p>What is the origin on the neural on the low level of ethics?</p>
<p>What is it at the higher level?</p>
<p>Is it something that&rsquo;s learnable from machines</p>
<p>in your intuition?</p>
<p>I think, yeah, ethics is learnable, very likely.</p>
<p>I think it&rsquo;s one of these problems where</p>
<p>I think understanding the neuroscience of ethics,</p>
<p>people discuss there is an ethics of neuroscience.</p>
<p>Yeah, yes.</p>
<p>How a neuroscientist should or should not behave.</p>
<p>Can you think of a neurosurgeon and the ethics</p>
<p>rule he has to be or he, she has to be.</p>
<p>But I&rsquo;m more interested on the neuroscience of ethics.</p>
<p>You&rsquo;re blowing my mind right now.</p>
<p>The neuroscience of ethics is very meta.</p>
<p>Yeah, and I think that would be important to understand also</p>
<p>for being able to design machines that</p>
<p>are ethical machines in our sense of ethics.</p>
<p>And you think there is something in neuroscience,</p>
<p>there&rsquo;s patterns, tools in neuroscience</p>
<p>that could help us shed some light on ethics?</p>
<p>Or is it mostly on the psychologists of sociology</p>
<p>in which higher level?</p>
<p>No, there is psychology.</p>
<p>But there is also, in the meantime,</p>
<p>there is evidence, fMRI, of specific areas of the brain</p>
<p>that are involved in certain ethical judgment.</p>
<p>And not only this, you can stimulate those area</p>
<p>with magnetic fields and change the ethical decisions.</p>
<p>Yeah, wow.</p>
<p>So that&rsquo;s work by a colleague of mine, Rebecca Sachs.</p>
<p>And there is other researchers doing similar work.</p>
<p>And I think this is the beginning.</p>
<p>But ideally, at some point, we&rsquo;ll</p>
<p>have an understanding of how this works.</p>
<p>And why it evolved, right?</p>
<p>The big why question.</p>
<p>Yeah, it must have some purpose.</p>
<p>Yeah, obviously it has some social purposes, probably.</p>
<p>If neuroscience holds the key to at least illuminate</p>
<p>some aspect of ethics, that means</p>
<p>it could be a learnable problem.</p>
<p>Yeah, exactly.</p>
<p>And as we&rsquo;re getting into harder and harder questions,</p>
<p>let&rsquo;s go to the hard problem of consciousness.</p>
<p>Is this an important problem for us</p>
<p>to think about and solve on the engineering of intelligence</p>
<p>side of your work, of our dream?</p>
<p>It&rsquo;s unclear.</p>
<p>So again, this is a deep problem,</p>
<p>partly because it&rsquo;s very difficult to define</p>
<p>consciousness.</p>
<p>And there is a debate among neuroscientists</p>
<p>about whether consciousness and philosophers, of course,</p>
<p>whether consciousness is something that requires</p>
<p>flesh and blood, so to speak.</p>
<p>Or could be that we could have silicon devices that</p>
<p>are conscious, or up to statement</p>
<p>like everything has some degree of consciousness</p>
<p>and some more than others.</p>
<p>This is like Giulio Tonioni and phi.</p>
<p>We just recently talked to Christoph Koch.</p>
<p>OK.</p>
<p>Christoph was my first graduate student.</p>
<p>Do you think it&rsquo;s important to illuminate</p>
<p>aspects of consciousness in order</p>
<p>to engineer intelligence systems?</p>
<p>Do you think an intelligent system would ultimately</p>
<p>have consciousness?</p>
<p>Are they interlinked?</p>
<p>Most of the people working in artificial intelligence,</p>
<p>I think, would answer, we don&rsquo;t strictly</p>
<p>need consciousness to have an intelligent system.</p>
<p>That&rsquo;s sort of the easier question,</p>
<p>because it&rsquo;s a very engineering answer to the question.</p>
<p>Pass the Turing test, we don&rsquo;t need consciousness.</p>
<p>But if you were to go, do you think</p>
<p>it&rsquo;s possible that we need to have</p>
<p>that kind of self awareness?</p>
<p>We may, yes.</p>
<p>So for instance, I personally think</p>
<p>that when test a machine or a person in a Turing test,</p>
<p>in an extended Turing test, I think</p>
<p>consciousness is part of what we require in that test,</p>
<p>implicitly, to say that this is intelligent.</p>
<p>Christoph disagrees.</p>
<p>Yes, he does.</p>
<p>Despite many other romantic notions he holds,</p>
<p>he disagrees with that one.</p>
<p>Yes, that&rsquo;s right.</p>
<p>So we&rsquo;ll see.</p>
<p>Do you think, as a quick question,</p>
<p>Ernest Becker&rsquo;s fear of death, do you</p>
<p>think mortality and those kinds of things</p>
<p>are important for consciousness and for intelligence?</p>
<p>The finiteness of life, finiteness of existence,</p>
<p>or is that just a side effect of evolution,</p>
<p>evolutionary side effect that&rsquo;s useful for natural selection?</p>
<p>Do you think this kind of thing that this interview is</p>
<p>going to run out of time soon, our life</p>
<p>will run out of time soon, do you</p>
<p>think that&rsquo;s needed to make this conversation good and life</p>
<p>good?</p>
<p>I never thought about it.</p>
<p>It&rsquo;s a very interesting question.</p>
<p>I think Steve Jobs, in his commencement speech</p>
<p>at Stanford, argued that having a finite life</p>
<p>was important for stimulating achievements.</p>
<p>So it was different.</p>
<p>Yeah, live every day like it&rsquo;s your last, right?</p>
<p>Yeah.</p>
<p>So rationally, I don&rsquo;t think strictly you need mortality</p>
<p>for consciousness.</p>
<p>But who knows?</p>
<p>They seem to go together in our biological system, right?</p>
<p>Yeah, yeah.</p>
<p>You&rsquo;ve mentioned before, and students are associated with,</p>
<p>AlphaGo immobilized the big recent success stories in AI.</p>
<p>And I think it&rsquo;s captivated the entire world of what AI can do.</p>
<p>So what do you think will be the next breakthrough?</p>
<p>And what&rsquo;s your intuition about the next breakthrough?</p>
<p>Of course, I don&rsquo;t know where the next breakthrough is.</p>
<p>I think that there is a good chance, as I said before,</p>
<p>that the next breakthrough will also</p>
<p>be inspired by neuroscience.</p>
<p>But which one, I don&rsquo;t know.</p>
<p>And there&rsquo;s, so MIT has this quest for intelligence.</p>
<p>And there&rsquo;s a few moon shots, which in that spirit,</p>
<p>which ones are you excited about?</p>
<p>Which projects kind of?</p>
<p>Well, of course, I&rsquo;m excited about one</p>
<p>of the moon shots, which is our Center for Brains, Minds,</p>
<p>and Machines, which is the one which is fully funded by NSF.</p>
<p>And it is about visual intelligence.</p>
<p>And that one is particularly about understanding.</p>
<p>Visual intelligence, so the visual cortex,</p>
<p>and visual intelligence in the sense</p>
<p>of how we look around ourselves and understand</p>
<p>the world around ourselves, meaning what is going on,</p>
<p>how we could go from here to there without hitting</p>
<p>obstacles, whether there are other agents,</p>
<p>people in the environment.</p>
<p>These are all things that we perceive very quickly.</p>
<p>And it&rsquo;s something actually quite close to being conscious,</p>
<p>not quite.</p>
<p>But there is this interesting experiment</p>
<p>that was run at Google X, which is in a sense</p>
<p>is just a virtual reality experiment,</p>
<p>but in which they had a subject sitting, say,</p>
<p>in a chair with goggles, like Oculus and so on, earphones.</p>
<p>And they were seeing through the eyes of a robot</p>
<p>nearby to cameras, microphones for receiving.</p>
<p>So their sensory system was there.</p>
<p>And the impression of all the subject, very strong,</p>
<p>they could not shake it off, was that they</p>
<p>were where the robot was.</p>
<p>They could look at themselves from the robot</p>
<p>and still feel they were where the robot is.</p>
<p>They were looking at their body.</p>
<p>Theirself had moved.</p>
<p>So some aspect of scene understanding</p>
<p>has to have ability to place yourself,</p>
<p>have a self awareness about your position in the world</p>
<p>and what the world is.</p>
<p>So we may have to solve the hard problem of consciousness</p>
<p>to solve it.</p>
<p>On their way, yes.</p>
<p>It&rsquo;s quite a moonshine.</p>
<p>So you&rsquo;ve been an advisor to some incredible minds,</p>
<p>including Demis Hassabis, Krzysztof Koch, Amna Shashua,</p>
<p>like you said.</p>
<p>All went on to become seminal figures</p>
<p>in their respective fields.</p>
<p>From your own success as a researcher</p>
<p>and from perspective as a mentor of these researchers,</p>
<p>having guided them in the way of advice,</p>
<p>what does it take to be successful in science</p>
<p>and engineering careers?</p>
<p>Whether you&rsquo;re talking to somebody in their teens,</p>
<p>20s, and 30s, what does that path look like?</p>
<p>It&rsquo;s curiosity and having fun.</p>
<p>And I think it&rsquo;s important also having</p>
<p>fun with other curious minds.</p>
<p>It&rsquo;s the people you surround with too,</p>
<p>so fun and curiosity.</p>
<p>Is there, you mentioned Steve Jobs,</p>
<p>is there also an underlying ambition</p>
<p>that&rsquo;s unique that you saw?</p>
<p>Or does it really does boil down</p>
<p>to insatiable curiosity and fun?</p>
<p>Well of course, it&rsquo;s being curious</p>
<p>in an active and ambitious way, yes.</p>
<p>Definitely.</p>
<p>But I think sometime in science,</p>
<p>there are friends of mine who are like this.</p>
<p>There are some of the scientists</p>
<p>like to work by themselves</p>
<p>and kind of communicate only when they complete their work</p>
<p>or discover something.</p>
<p>I think I always found the actual process</p>
<p>of discovering something is more fun</p>
<p>if it&rsquo;s together with other intelligent</p>
<p>and curious and fun people.</p>
<p>So if you see the fun in that process,</p>
<p>the side effect of that process</p>
<p>will be that you&rsquo;ll actually end up</p>
<p>discovering some interesting things.</p>
<p>So as you&rsquo;ve led many incredible efforts here,</p>
<p>what&rsquo;s the secret to being a good advisor,</p>
<p>mentor, leader in a research setting?</p>
<p>Is it a similar spirit?</p>
<p>Or yeah, what advice could you give</p>
<p>to people, young faculty and so on?</p>
<p>It&rsquo;s partly repeating what I said</p>
<p>about an environment that should be friendly</p>
<p>and fun and ambitious.</p>
<p>And I think I learned a lot</p>
<p>from some of my advisors and friends</p>
<p>and some who are physicists.</p>
<p>And there was, for instance,</p>
<p>this behavior that was encouraged</p>
<p>of when somebody comes with a new idea in the group,</p>
<p>you are, unless it&rsquo;s really stupid,</p>
<p>but you are always enthusiastic.</p>
<p>And then, and you&rsquo;re enthusiastic for a few minutes,</p>
<p>for a few hours.</p>
<p>Then you start asking critically a few questions,</p>
<p>testing this.</p>
<p>But this is a process that is,</p>
<p>I think it&rsquo;s very good.</p>
<p>You have to be enthusiastic.</p>
<p>Sometimes people are very critical from the beginning.</p>
<p>That&rsquo;s not&hellip;</p>
<p>Yes, you have to give it a chance</p>
<p>for that seed to grow.</p>
<p>That said, with some of your ideas,</p>
<p>which are quite revolutionary,</p>
<p>so there&rsquo;s a witness, especially in the human vision side</p>
<p>and neuroscience side,</p>
<p>there could be some pretty heated arguments.</p>
<p>Do you enjoy these?</p>
<p>Is that a part of science and academic pursuits</p>
<p>that you enjoy?</p>
<p>Yeah.</p>
<p>Is that something that happens in your group as well?</p>
<p>Yeah, absolutely.</p>
<p>I also spent some time in Germany.</p>
<p>Again, there is this tradition</p>
<p>in which people are more forthright,</p>
<p>less kind than here.</p>
<p>So in the U.S., when you write a bad letter,</p>
<p>you still say, this guy&rsquo;s nice.</p>
<p>Yes, yes.</p>
<p>So&hellip;</p>
<p>Yeah, here in America, it&rsquo;s degrees of nice.</p>
<p>Yes.</p>
<p>It&rsquo;s all just degrees of nice, yeah.</p>
<p>Right, right.</p>
<p>So as long as this does not become personal,</p>
<p>and it&rsquo;s really like a football game</p>
<p>with these rules, that&rsquo;s great.</p>
<p>That&rsquo;s fun.</p>
<p>So if you somehow found yourself in a position</p>
<p>to ask one question of an oracle,</p>
<p>like a genie, maybe a god,</p>
<p>and you&rsquo;re guaranteed to get a clear answer,</p>
<p>what kind of question would you ask?</p>
<p>What would be the question you would ask?</p>
<p>In the spirit of our discussion,</p>
<p>it could be, how could I become 10 times more intelligent?</p>
<p>And so, but see, you only get a clear short answer.</p>
<p>So do you think there&rsquo;s a clear short answer to that?</p>
<p>No.</p>
<p>And that&rsquo;s the answer you&rsquo;ll get.</p>
<p>Okay, so you&rsquo;ve mentioned Flowers of Algernon.</p>
<p>Oh, yeah.</p>
<p>As a story that inspires you in your childhood,</p>
<p>as this story of a mouse,</p>
<p>human achieving genius level intelligence,</p>
<p>and then understanding what was happening</p>
<p>while slowly becoming not intelligent again,</p>
<p>and this tragedy of gaining intelligence</p>
<p>and losing intelligence,</p>
<p>do you think in that spirit, in that story,</p>
<p>do you think intelligence is a gift or a curse</p>
<p>from the perspective of happiness and meaning of life?</p>
<p>You try to create an intelligent system</p>
<p>that understands the universe,</p>
<p>but on an individual level, the meaning of life,</p>
<p>do you think intelligence is a gift?</p>
<p>It&rsquo;s a good question.</p>
<p>I don&rsquo;t know.</p>
<p>As one of the, as one people consider</p>
<p>the smartest people in the world,</p>
<p>in some dimension, at the very least, what do you think?</p>
<p>I don&rsquo;t know, it may be invariant to intelligence,</p>
<p>that degree of happiness.</p>
<p>It would be nice if it were.</p>
<p>That&rsquo;s the hope.</p>
<p>Yeah.</p>
<p>You could be smart and happy and clueless and happy.</p>
<p>Yeah.</p>
<p>As always, on the discussion of the meaning of life,</p>
<p>it&rsquo;s probably a good place to end.</p>
<p>Tommaso, thank you so much for talking today.</p>
<p>Thank you, this was great.</p>

</section>


    <footer class="article-footer">
    
    <section class="article-tags">
        
            <a href="/tags/english/">English</a>
        
            <a href="/tags/podcast/">Podcast</a>
        
            <a href="/tags/lex-fridman-podcast/">Lex Fridman Podcast</a>
        
    </section>


    </footer>


    
</article>

    

    

<aside class="related-content--wrapper">
    <h2 class="section-title">Related content</h2>
    <div class="related-content">
        <div class="flex article-list--tile">
            
                
<article class="">
    <a href="/en/1310500372/">
        
	
        
        <div class="article-image">
            
            <img src="/img/related-content.png" loading="lazy" 
            data-key="en/1310500372" data-hash="" 
            style="opacity: 0.3;"/>
        </div>
        
        <div class="article-details">
            <h2 class="article-title">Lex Fridman Podcast - #368 - Eliezer Yudkowsky: Dangers of AI and the End of Human Civilization</h2>
            
            <footer class="article-time">
                <time datetime=''>Mar 30, 2023</time>
            </footer>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/en/1310500371/">
        
	
        
        <div class="article-image">
            
            <img src="/img/related-content.png" loading="lazy" 
            data-key="en/1310500371" data-hash="" 
            style="opacity: 0.3;"/>
        </div>
        
        <div class="article-details">
            <h2 class="article-title">Lex Fridman Podcast - #367 - Sam Altman: OpenAI CEO on GPT-4, ChatGPT, and the Future of AI</h2>
            
            <footer class="article-time">
                <time datetime=''>Mar 26, 2023</time>
            </footer>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/en/1310500370/">
        
	
        
        <div class="article-image">
            
            <img src="/img/related-content.png" loading="lazy" 
            data-key="en/1310500370" data-hash="" 
            style="opacity: 0.3;"/>
        </div>
        
        <div class="article-details">
            <h2 class="article-title">Lex Fridman Podcast - #366 - Shannon Curry: Johnny Depp &amp; Amber Heard Trial, Marriage, Dating &amp; Love</h2>
            
            <footer class="article-time">
                <time datetime=''>Mar 22, 2023</time>
            </footer>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/en/1310500369/">
        
	
        
        <div class="article-image">
            
            <img src="/img/related-content.png" loading="lazy" 
            data-key="en/1310500369" data-hash="" 
            style="opacity: 0.3;"/>
        </div>
        
        <div class="article-details">
            <h2 class="article-title">Lex Fridman Podcast - #365 - Sam Harris: Trump, Pandemic, Twitter, Elon, Bret, IDW, Kanye, AI &amp; UFOs</h2>
            
            <footer class="article-time">
                <time datetime=''>Mar 15, 2023</time>
            </footer>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/en/1310500368/">
        
	
        
        <div class="article-image">
            
            <img src="/img/related-content.png" loading="lazy" 
            data-key="en/1310500368" data-hash="" 
            style="opacity: 0.3;"/>
        </div>
        
        <div class="article-details">
            <h2 class="article-title">Lex Fridman Podcast - #364 - Chris Voss: FBI Hostage Negotiator</h2>
            
            <footer class="article-time">
                <time datetime=''>Mar 11, 2023</time>
            </footer>
        </div>
    </a>
</article>

            
        </div>
    </div>
</aside>

     
    
        
    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
            2021 - 
        
        2023 SWIEST - Transcripts ¬∑ Screenplays ¬∑ Lyrics
    </section>
    
    <section class="powerby">
        

        As an Amazon Associate I earn from qualifying purchases üõí<br/>

        Built with <a href="https://swiest.com/" target="_blank" rel="noopener">(Ôæâ‚óï„ÉÆ‚óï)Ôæâü™Ñüíûüíñü•∞ across the glüåçüåèüåébe</a> <br />
        
        
    </section>
</footer>


    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo="crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU="crossorigin="anonymous"
                defer
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css"crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css"crossorigin="anonymous"
            >

            </main>
        </div>
        <script 
                src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js"integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z&#43;KMkF24hUW8WePSA9HM="crossorigin="anonymous"
                
                >
            </script><script type="text/javascript" src="/ts/main.js" defer></script>


<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Noto+Serif&family=Noto+Serif+Armenian&family=Noto+Serif+Bengali&family=Noto+Serif+Devanagari&family=Noto+Serif+Georgian&family=Noto+Serif+Gujarati&family=Noto+Serif+HK&family=Noto+Serif+Hebrew&family=Noto+Serif+JP&family=Noto+Serif+KR&family=Noto+Serif+Kannada&family=Noto+Serif+Khmer&family=Noto+Serif+Lao&family=Noto+Serif+Makasar&family=Noto+Serif+Malayalam&family=Noto+Serif+Myanmar&family=Noto+Serif+Oriya&family=Noto+Serif+SC&family=Noto+Serif+Sinhala&family=Noto+Serif+TC&family=Noto+Serif+Tamil&family=Noto+Serif+Telugu&family=Noto+Serif+Thai&family=Noto+Serif+Tibetan&display=swap" rel="stylesheet">

    </body>
</html>
