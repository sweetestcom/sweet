<!doctype html><html lang=en dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Video Transcript Ôªøhi everyone my knight is fished home I&amp;rsquo;m
currently a PhD student in Carnegie
Mellon machine learning Department I&amp;rsquo;m
interning the robot II teams working
with Peter and watching today I&amp;rsquo;m going
to talk about robust vision based stated
estimator so the goal for the robot II
team is to actually build a very strong
robotic background such that we can use
it to solve real AGI you know we we are"><title>Robust Vision-Based State Estimation ÔΩú Hsiao-Yu 'Fish' Tung ÔΩú 2018 Summer Intern Open House ÔΩú OpenAI | SWIEST</title>
<link rel=canonical href=https://swiest.com/en/hyz1srfrbgm/><link rel=stylesheet href=/scss/style.min.9a6fe90535a0e5c60443841f100f7b698092d48dba43fdb6386bb69b6559bc3d.css><script>document.oncontextmenu=function(){return!1},document.onselectstart=function(){return!1},document.oncopy=function(){return!1},document.oncut=function(){return!1}</script><script src=https://apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js></script><script type=text/javascript>$(document).ready(function(){$("#back-to-top").hide(),$(function(){$(window).scroll(function(){$(window).scrollTop()>600?$("#back-to-top").fadeIn(500):$("#back-to-top").fadeOut(500)}),$("#back-to-top").click(function(){return $("body,html").animate({scrollTop:0},500),!1})})})</script><meta property="og:title" content="Robust Vision-Based State Estimation ÔΩú Hsiao-Yu 'Fish' Tung ÔΩú 2018 Summer Intern Open House ÔΩú OpenAI"><meta property="og:description" content="Video Transcript Ôªøhi everyone my knight is fished home I&amp;rsquo;m
currently a PhD student in Carnegie
Mellon machine learning Department I&amp;rsquo;m
interning the robot II teams working
with Peter and watching today I&amp;rsquo;m going
to talk about robust vision based stated
estimator so the goal for the robot II
team is to actually build a very strong
robotic background such that we can use
it to solve real AGI you know we we are"><meta property="og:url" content="https://swiest.com/en/hyz1srfrbgm/"><meta property="og:site_name" content="SWIEST - Transcripts ¬∑ Screenplays ¬∑ Lyrics"><meta property="og:type" content="article"><meta property="article:section" content="Post"><meta property="article:tag" content="English"><meta property="article:tag" content="Video Transcripts"><meta property="article:tag" content="OpenAI"><meta property="article:published_time" content="2023-11-06T01:31:16+00:00"><meta property="article:modified_time" content="2023-11-06T01:31:16+00:00"><meta name=twitter:title content="Robust Vision-Based State Estimation ÔΩú Hsiao-Yu 'Fish' Tung ÔΩú 2018 Summer Intern Open House ÔΩú OpenAI"><meta name=twitter:description content="Video Transcript Ôªøhi everyone my knight is fished home I&amp;rsquo;m
currently a PhD student in Carnegie
Mellon machine learning Department I&amp;rsquo;m
interning the robot II teams working
with Peter and watching today I&amp;rsquo;m going
to talk about robust vision based stated
estimator so the goal for the robot II
team is to actually build a very strong
robotic background such that we can use
it to solve real AGI you know we we are"><link rel="shortcut icon" href=/favicon.ico><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9206135835124064" crossorigin=anonymous></script><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"dark")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hu307e6a33fa6fd661ccda3b77024ef5c2_252345_300x0_resize_box_3.png width=300 height=300 class=site-logo loading=lazy alt=Avatar></a></figure><div class=site-meta><h1 class=site-name><a href=/>SWIEST - Transcripts ¬∑ Screenplays ¬∑ Lyrics</a></h1><h2 class=site-description>üßôü™Ñüåé</h2></div></header><ol class=menu id=main-menu><li><a href=/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg><span>Home</span></a></li><li><a href=/search/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg><span>Search</span></a></li><li><a href=/tags/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-tag" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11 3l9 9a1.5 1.5.0 010 2l-6 6a1.5 1.5.0 01-2 0L3 11V7a4 4 0 014-4h4"/><circle cx="9" cy="9" r="2"/></svg><span>Tags</span></a></li><li><a href=/chart/podcastchart.html target=_blank><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-apple-podcast" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M18.364 18.364a9 9 0 10-12.728.0"/><path d="M11.766 22h.468a2 2 0 001.985-1.752l.5-4A2 2 0 0012.734 14h-1.468a2 2 0 00-1.985 2.248l.5 4A2 2 0 0011.766 22z"/><path d="M12 9m-2 0a2 2 0 104 0 2 2 0 10-4 0"/></svg><span>Podcasts</span></a></li><li><a href=/radio.html target=_blank><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-radio" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M14 3 4.629 6.749A1 1 0 004 7.677V19a1 1 0 001 1h14a1 1 0 001-1V8a1 1 0 00-1-1H4.5"/><path d="M4 12h16"/><path d="M7 12v-2"/><path d="M17 16v.01"/><path d="M13 16v.01"/></svg><span>Radio</span></a></li><div class=menu-bottom-section><li id=i18n-switch><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-language" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 5h7"/><path d="M9 3v2c0 4.418-2.239 8-5 8"/><path d="M5 9c-.003 2.144 2.952 3.908 6.7 4"/><path d="M12 20l4-9 4 9"/><path d="M19.1 18h-6.2"/></svg><select name=language onchange="window.location.href=this.selectedOptions[0].value"><option value=https://swiest.com/ selected>English</option><option value=https://swiest.com/af/>Afrikaans</option><option value=https://swiest.com/am/>·ä†·àõ·à≠·äõ</option><option value=https://swiest.com/ar/>ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</option><option value=https://swiest.com/az/>Az…ôrbaycan</option><option value=https://swiest.com/be/>–±–µ–ª–∞—Ä—É—Å–∫—ñ</option><option value=https://swiest.com/bg/>–±—ä–ª–≥–∞—Ä—Å–∫–∏</option><option value=https://swiest.com/bn/>‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ</option><option value=https://swiest.com/bo/>‡Ωñ‡Ωº‡Ωë‡ºã‡Ω¶‡æê‡Ωë‡ºã</option><option value=https://swiest.com/bs/>Bosanski</option><option value=https://swiest.com/ca/>Catal√†</option><option value=https://swiest.com/zh-hans/>ÁÆÄ‰Ωì‰∏≠Êñá</option><option value=https://swiest.com/zh-hant/>ÁπÅÈ´î‰∏≠Êñá</option><option value=https://swiest.com/cs/>ƒåe≈°tina</option><option value=https://swiest.com/el/>ŒµŒªŒªŒ∑ŒΩŒπŒ∫Œ¨</option><option value=https://swiest.com/cy/>Cymraeg</option><option value=https://swiest.com/da/>Dansk</option><option value=https://swiest.com/de/>Deutsch</option><option value=https://swiest.com/eo/>Esperanto</option><option value=https://swiest.com/es-es/>Espa√±ol (Espa√±a)</option><option value=https://swiest.com/es-419/>Espa√±ol (Latinoam√©rica)</option><option value=https://swiest.com/et/>Eesti</option><option value=https://swiest.com/eu/>Euskara</option><option value=https://swiest.com/haw/> ª≈ålelo Hawai ªi</option><option value=https://swiest.com/fa/>ŸÅÿßÿ±ÿ≥€å</option><option value=https://swiest.com/fi/>Suomi</option><option value=https://swiest.com/fo/>F√∏royskt</option><option value=https://swiest.com/fr/>Fran√ßais</option><option value=https://swiest.com/fy/>Frysk</option><option value=https://swiest.com/ga/>Gaeilge</option><option value=https://swiest.com/gl/>Galego</option><option value=https://swiest.com/gu/>‡™ó‡´Å‡™ú‡™∞‡™æ‡™§‡´Ä</option><option value=https://swiest.com/he/>◊¢÷¥◊ë◊®÷¥◊ô◊™</option><option value=https://swiest.com/km/>·ûÄ·ûò·üí·ûñ·ûª·ûá·û∂·üî</option><option value=https://swiest.com/hi/>‡§π‡§ø‡§®‡•ç‡§¶‡•Ä</option><option value=https://swiest.com/hr/>Hrvatski</option><option value=https://swiest.com/ht/>Krey√≤l Ayisyen</option><option value=https://swiest.com/hu/>Magyar</option><option value=https://swiest.com/hy/>’Ä’°’µ’•÷Ä’•’∂</option><option value=https://swiest.com/ig/>√Ås·ª•ÃÄs·ª•ÃÅ √ågb√≤</option><option value=https://swiest.com/id/>Bahasa Indonesia</option><option value=https://swiest.com/is/>√çslenska</option><option value=https://swiest.com/it/>Italiano</option><option value=https://swiest.com/ja/>Êó•Êú¨Ë™û</option><option value=https://swiest.com/jv/>Basa Jawa</option><option value=https://swiest.com/ka/>·É•·Éê·É†·Éó·É£·Éö·Éò</option><option value=https://swiest.com/kk/>“ö–∞–∑–∞“õ—à–∞</option><option value=https://swiest.com/kn/>‡≤ï‡≤®‡≥ç‡≤®‡≤°</option><option value=https://swiest.com/ko/>ÌïúÍµ≠Ïñ¥</option><option value=https://swiest.com/or/>‡¨ì‡¨°‡¨º‡¨ø‡¨Ü</option><option value=https://swiest.com/ckb/>⁄©Ÿàÿ±ÿØ€å</option><option value=https://swiest.com/ky/>–ö—ã—Ä–≥—ã–∑—á–∞</option><option value=https://swiest.com/la/>Latina</option><option value=https://swiest.com/lb/>L√´tzebuergesch</option><option value=https://swiest.com/lo/>‡∫û‡∫≤‡∫™‡∫≤‡∫•‡∫≤‡∫ß</option><option value=https://swiest.com/lt/>Lietuvi≈≥</option><option value=https://swiest.com/lv/>Latvie≈°u</option><option value=https://swiest.com/mk/>–ú–∞–∫–µ–¥–æ–Ω—Å–∫–∏</option><option value=https://swiest.com/ml/>‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç</option><option value=https://swiest.com/mn/>–ú–æ–Ω–≥–æ–ª —Ö—ç–ª</option><option value=https://swiest.com/mr/>‡§Æ‡§∞‡§æ‡§†‡•Ä</option><option value=https://swiest.com/sw/>Kiswahili</option><option value=https://swiest.com/ms/>Bahasa Melayu</option><option value=https://swiest.com/my/>·Äô·Äº·Äî·Ä∫·Äô·Ä¨</option><option value=https://swiest.com/ne/>‡§®‡•á‡§™‡§æ‡§≤‡•Ä</option><option value=https://swiest.com/nl/>Nederlands</option><option value=https://swiest.com/no/>Norsk</option><option value=https://swiest.com/pa/>‡®™‡©∞‡®ú‡®æ‡®¨‡©Ä</option><option value=https://swiest.com/pl/>Polski</option><option value=https://swiest.com/pt-br/>Portugu√™s Brasil</option><option value=https://swiest.com/pt-pt/>Portugu√™s Europeu</option><option value=https://swiest.com/ro/>Rom√¢nƒÉ</option><option value=https://swiest.com/ru/>–†—É—Å—Å–∫–∏–π</option><option value=https://swiest.com/rw/>Kinyarwanda</option><option value=https://swiest.com/si/>‡∑É‡∑í‡∂Ç‡∑Ñ‡∂Ω</option><option value=https://swiest.com/sk/>Slovenƒçina</option><option value=https://swiest.com/sl/>Sloven≈°ƒçina</option><option value=https://swiest.com/sq/>Shqip</option><option value=https://swiest.com/sr/>–°—Ä–ø—Å–∫–∏ (Srpski)</option><option value=https://swiest.com/su/>Basa Sunda</option><option value=https://swiest.com/sv/>Svenska</option><option value=https://swiest.com/ta/>‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç</option><option value=https://swiest.com/te/>‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å</option><option value=https://swiest.com/tg/>–¢–æ“∑–∏–∫”£</option><option value=https://swiest.com/th/>‡πÑ‡∏ó‡∏¢</option><option value=https://swiest.com/tk/>T√ºrkmenler</option><option value=https://swiest.com/tl/>Filipino</option><option value=https://swiest.com/tr/>T√ºrk√ße</option><option value=https://swiest.com/uk/>–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞</option><option value=https://swiest.com/ur/>ÿßÿ±ÿØŸà</option><option value=https://swiest.com/uz/>O'zbekcha</option><option value=https://swiest.com/vi/>Ti·∫øng Vi·ªát</option><option value=https://swiest.com/yi/>◊ê◊ô◊ì◊ô◊©</option><option value=https://swiest.com/zh-hk/>Á≤µË™û</option><option value=https://swiest.com/zu/>IsiZulu</option></select></li><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><span>Dark Mode</span></li></div></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#video>Video</a></li><li><a href=#transcript>Transcript</a></li></ol></nav></div></section><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9206135835124064" crossorigin=anonymous></script><ins class=adsbygoogle style=display:block data-ad-client=ca-pub-9206135835124064 data-ad-slot=8754979142 data-ad-format=auto data-full-width-responsive=true></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script></aside><a id=back-to-top href=#><img src=/img/top_hu7c2829da96df0e9f8f0191d120020b22_22287_40x0_resize_box_3.png></a><main class="main full-width"><form action=/search/ class="search-form widget"><p><label>Search</label>
<input name=keyword required placeholder="Type something...">
<button title=Search><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg></button></p></form><article class=main-article><header class=article-header><div class=article-details><header class=article-tags><a href=/tags/english/>English
</a><a href=/tags/video-transcripts/>Video Transcripts
</a><a href=/tags/openai/>OpenAI</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/en/hyz1srfrbgm/>Robust Vision-Based State Estimation ÔΩú Hsiao-Yu 'Fish' Tung ÔΩú 2018 Summer Intern Open House ÔΩú OpenAI</a></h2></div><footer class=article-time><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg><time class=article-time--published>2023-11-06</time></div><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg><time class=article-time--reading>12 minute read</time></div></footer></div></header><div class=article-content><p style=text-align:center><a href=https://amzn.to/3Nrdcwk target=_blank>üéÅAmazon Prime</a>
<a href=https://amzn.to/3RIBkxg target=_blank>üìñKindle Unlimited</a>
<a href=https://amzn.to/3Rqmudl target=_blank>üéßAudible Plus</a>
<a href=https://amzn.to/3TuLbbj target=_blank>üéµAmazon Music Unlimited</a>
<a href="https://www.iherb.com/?rcode=EID1574" target=_blank>üåøiHerb</a>
<a href="https://accounts.binance.com/register?ref=72302422" target=_blank>üí∞Binance</a></p></div><div><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9206135835124064" crossorigin=anonymous></script><ins class=adsbygoogle style=display:block data-ad-client=ca-pub-9206135835124064 data-ad-slot=8754979142 data-ad-format=auto data-full-width-responsive=true></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script></div><section class=article-content><h2 id=video>Video</h2><div class=video-wrapper><iframe loading=lazy src=https://www.youtube.com/embed/hyZ1sRfRbgM allowfullscreen title="YouTube Video"></iframe></div><h2 id=transcript>Transcript</h2><p>Ôªøhi everyone my knight is fished home I&rsquo;m</p><p>currently a PhD student in Carnegie</p><p>Mellon machine learning Department I&rsquo;m</p><p>interning the robot II teams working</p><p>with Peter and watching today I&rsquo;m going</p><p>to talk about robust vision based stated</p><p>estimator so the goal for the robot II</p><p>team is to actually build a very strong</p><p>robotic background such that we can use</p><p>it to solve real AGI you know we we are</p><p>focusing on develop in general learning</p><p>based algorithm such that it can works</p><p>on a diverse of robotic tasks in order</p><p>to make sure the algorithm we develop is</p><p>general enough we need to pick up like a</p><p>pretty hard task in order to make sure</p><p>this algorithm really work so the task</p><p>we pick here is to have a shadow hand</p><p>rotating object to a desired pose so a</p><p>shadow hand robot is a robot that looks</p><p>exactly like human hand it has five</p><p>fingers it has several joint it can do</p><p>very delegated posts this task is</p><p>particularly difficult because if you as</p><p>a human engineer to hard-code this high</p><p>dimensional control it is nearly</p><p>impossible but before the robot can</p><p>start moving his fingers and try to</p><p>solve this task the first question we</p><p>want to answer is how do then the robot</p><p>know where is the object and what is the</p><p>object is posing in other words how do</p><p>the robot know what is the position and</p><p>orientation of the object in robotics</p><p>and reinforcement learning we call these</p><p>two state to ask the main States you can</p><p>actually use a 3d tracker</p><p>to use a 3d tracker you need to attach</p><p>some markers on the object you are</p><p>interested in we put our robot in a huge</p><p>cage where we can surrounded our robot</p><p>with a bunch of 3d sensors this sensors</p><p>will read off signal from the trackers</p><p>and then tell you what is the street</p><p>location of this markers so as you can</p><p>see this method actually can give a</p><p>pretty accurate object state but it is</p><p>pretty expensive and it kind of restrict</p><p>the robot to only see object in this</p><p>cage and besides if today I have a new</p><p>object I need to ask somebody to label</p><p>the marker first for me</p><p>which is impractical so here we want to</p><p>use like a more biologically inspired</p><p>solution which is just use cameras so we</p><p>can set up three cameras on this cage</p><p>the cameras are looking at our robot and</p><p>our object and from there we try to</p><p>infer the state of the object</p><p>so there are several benefit of building</p><p>a vision based state estimator it can be</p><p>more flexible as cheaper is easy to set</p><p>up and it&rsquo;s really what we want to feel</p><p>on our robot</p><p>so to summarize our environment look</p><p>like this you have the cage you have the</p><p>robot in the center you set up some</p><p>camera that is looking at your robot and</p><p>your object and from this cameras you</p><p>captured three images that is looking at</p><p>the scenes from a different point of</p><p>view and then the question we want to</p><p>ask is how do we go from these three</p><p>images to the state we want to know so</p><p>now I introduce our method our model is</p><p>a tip neural network we say neural</p><p>network is super powerful because it can</p><p>generalize a lot of tasks achieving</p><p>state-of-the-art results and most</p><p>importantly it doesn&rsquo;t require the</p><p>engineer to hard-code the features so</p><p>before going into how to train this</p><p>neural network let&rsquo;s go into detail of</p><p>how this new an hour actually looks like</p><p>so our now we&rsquo;re taking three images as</p><p>input we will pass each of the image</p><p>into several convolution layers and</p><p>fully connect layers and then we</p><p>aggregate an output from this</p><p>convolutional towers to predict our</p><p>final object state to train such Network</p><p>you need aside from the network itself</p><p>you</p><p>two additional seen one is a large</p><p>amount of data that contains a lot of</p><p>example of what are the inputs and what</p><p>are outfits like for here our inputs are</p><p>the three images and our output is the</p><p>state of the object so so then the</p><p>question is how do we get this large</p><p>data set we say it is impossible to get</p><p>it in the real world although we are</p><p>able to get the images we are not able</p><p>to know where are the objects so in</p><p>order to solve this problem we actually</p><p>use a simulator in a simulator we build</p><p>a very similar robot a very similar</p><p>object and we also set up three very</p><p>similar cameras that is shooting from</p><p>right top and left and then from this</p><p>simulator we can actually also read off</p><p>ground true state of the object so our</p><p>training data actually looks like what</p><p>what is on the right hand side that we</p><p>have three images pair with the ground</p><p>true state of the object besides that we</p><p>can also because it&rsquo;s in the simulator</p><p>we can easily change the texture and</p><p>color of our robots we can change the</p><p>lightness we can also change the</p><p>background so in to if we do that we can</p><p>get like a very diverse data set that</p><p>can cover maybe all the situation agent</p><p>my my encounter in the real world so by</p><p>having this large amount of data and</p><p>this objective function that basically</p><p>minimized the distance between your</p><p>prediction and the ground truth we are</p><p>able to train the network in the</p><p>simulator and it works well in the real</p><p>world so it actually can predict super</p><p>accurate state of the object in the real</p><p>world and we are able to use it to</p><p>really solve something with with this</p><p>state estimator however there&rsquo;s still</p><p>some problem with our current vision</p><p>system the problem is our simulator</p><p>actually need a very carefully aligned</p><p>camera in in in the simulator</p><p>means your camera need to have exactly</p><p>the same position as the one you have in</p><p>the real world so how we get this value</p><p>is the engineer need to go into the</p><p>simulator slightly adjust this camera</p><p>until the images are super aligned so</p><p>this actually requires extra effort</p><p>because every time we change the camera</p><p>rotation we need an engineer to do this</p><p>again another thing is if during test</p><p>time someone accidentally touch one of</p><p>the camera on the cage then the vision</p><p>system break so here I want to emphasize</p><p>how serious is this problem so I show</p><p>some state prediction error on real</p><p>images using a calibrated environment</p><p>and not calibrated in problem and you</p><p>can see on the blue curve is with</p><p>calibrated cameras and the others are</p><p>with misaligned camera and the</p><p>performance degrades a lot so why this</p><p>is why this is happening</p><p>because our neural network is actually</p><p>trying to find out someone useful</p><p>pattern and from this useful pattern you</p><p>want to drag LIGO to you the output you</p><p>want you want it to be predict because</p><p>your only objective function is this</p><p>Euclidean distance between the branches</p><p>and your prediction so if we sit back</p><p>and think how people figure out this</p><p>problem is I have this hand here today I</p><p>want to ask you like what is the</p><p>position and orientation of this cube in</p><p>this 3d coordinate system given only</p><p>this image captures from some random</p><p>camera well what will you do you</p><p>probably will say oh yeah of course</p><p>today we focus on objects so I</p><p>definitely need to like focus on the</p><p>object and you probably will also say I</p><p>want to know where this images captured</p><p>from so you might also look at the arm</p><p>of the robot to figure out what is the</p><p>camera position combining your object</p><p>detection and your position of the</p><p>camera all together you figure out what</p><p>is the global state of this object so in</p><p>order to answer this</p><p>and actually human need geometry</p><p>knowledge and also human need attention</p><p>on the right object so then the question</p><p>is how do we tell the robot that these</p><p>tools are important and you need to</p><p>somehow encode this in your solution the</p><p>solution is because in the simulator we</p><p>can get a bunch of 3d information we can</p><p>get whatever branches we want so in</p><p>order we can actually extract more</p><p>information from the simulator and then</p><p>add these two to the neural net we&rsquo;re</p><p>trying to tell him so let me introduce</p><p>these two so the first one is we want to</p><p>force the network to learn about</p><p>geometry so we say when we are doing the</p><p>previous practice we&rsquo;re actually trying</p><p>to infer where the camera is shooting</p><p>from so on top of the output there of</p><p>each of the image I will add an optional</p><p>task to say oh please predict as well</p><p>the camera position orientation to make</p><p>sure that the robot really understand</p><p>where this image is captured for so</p><p>biting adding this accurate test we can</p><p>actually improve the prediction on</p><p>position of the object so you can see</p><p>the red line is without this actuary</p><p>task and the green line is with this</p><p>after a task so by adding this we are</p><p>actually forced in an hour general to</p><p>generate like a more reasonable solution</p><p>for this the other scene is we want to</p><p>cast right attention to to this task so</p><p>previously we say oh because we are</p><p>answering like what is the state of the</p><p>object so we definitely need to watch</p><p>the object instead of focusing on the</p><p>background so we circle the object and</p><p>we say if I want to answer what is the</p><p>position of the camera I probably need</p><p>to focus on the arm of the robot so</p><p>these tools are the same we we feel like</p><p>the robot should add this focus on so</p><p>here I asked the robot to further</p><p>predict bounding box for this to object</p><p>note that the</p><p>pounding bass can be obtained from the</p><p>simulators in a simulator we can get</p><p>like any kind of cultures we wanted and</p><p>then from this bounding box location we</p><p>extract localized features and</p><p>concatenate lists localized features for</p><p>our final prediction so by doing this</p><p>this kind of forced attention actually</p><p>the network can improve on orientation</p><p>prediction so the red line is a bad sign</p><p>without any attention the blue line is</p><p>with attention on the cue and in the</p><p>bottom line the orange one is actually</p><p>forcing attention on the cube and also</p><p>the art of the robot so here is some</p><p>conclusion and take away from me is we</p><p>are proposing like a learning-based</p><p>vision system that is very robust to the</p><p>camera position and we also hope it can</p><p>transfer transfer well to the real</p><p>setting so previously in our release we</p><p>proposed this domain randomization where</p><p>we randomized all kinds of like textures</p><p>lightness and background in the</p><p>simulator but here I want to emphasize</p><p>like in order for for our visual model</p><p>to really understand 3d to understand</p><p>geometry</p><p>maybe we can extract more supervision</p><p>from the simulator the first thing is we</p><p>can enforce in geometry learning by</p><p>adding actual tasks like predicting</p><p>camera bells and we can force in right</p><p>attention by asking the the vision</p><p>system to predict bounding box and also</p><p>use the attended feature thank you</p><p>we have like a 1 minute Q&amp;A oh okay hi</p><p>oh please you&rsquo;d still so so actually I</p><p>have tried to randomize the camera</p><p>position like crazy like the camera can</p><p>move all around in this space but then</p><p>this actually decreased a lot on the on</p><p>the prediction of overall even in a</p><p>simulator so that means if you just have</p><p>this naive model that fit in image</p><p>passing through some convolution it is</p><p>now going to figure out this answer and</p><p>also we try to randomize the camera</p><p>position in our preview release and it</p><p>kind of like heard the final final</p><p>performance on the real image so we kind</p><p>of remove it so the thing is or narrower</p><p>structure is not good enough so that</p><p>even if we randomize the camera so much</p><p>it cannot learn something useful so it</p><p>needs something else to help it thanks</p><p>oh one more question</p><p>Oh does anyone too</p><p>hi how do you think that your approach</p><p>would work when cameras not in the hand</p><p>because you know camera will have you</p><p>know you have the extra complexity of</p><p>the depth sensing and so wise</p><p>differences there are types of wines</p><p>differences are not necessarily always</p><p>reflective of real-world difference in</p><p>distance so yeah how do you think that</p><p>this would work when the object is</p><p>further away it&rsquo;s further away so if the</p><p>object is kind of like it has a</p><p>distribution that is not in the</p><p>distribution we train then it definitely</p><p>will diverge in the real like we cannot</p><p>make sure or do you mean if we have</p><p>extra at that sensor well they help so</p><p>my question is more like do you think</p><p>the methodology would also apply when</p><p>you have the object further away such</p><p>that you have right here is that you</p><p>want the robot to be able to point to</p><p>the object yes so it&rsquo;s the state I guess</p><p>would just be the position of the object</p><p>so if all the cameras are here and like</p><p>kind of enclosing the robot there were a</p><p>lot of hand in a cage and the object is</p><p>over here yeah sure you can have all the</p><p>camera positioning and stuff figured out</p><p>but you want this extra distance to</p><p>account for right that the depth</p><p>perception capabilities with the camera</p><p>yeah so do you think that I think it&rsquo;s</p><p>like it&rsquo;s more like how do you think</p><p>that this approach</p><p>so I think that extra complexity can be</p><p>solved if you have like an additional</p><p>camera that is looking at the side so</p><p>then you can make sure this dimension is</p><p>correct but the thing is if something is</p><p>super far away like even for human like</p><p>if you have a car that is super far away</p><p>like is cross the street for you you</p><p>cannot predict precisely like what is</p><p>the distance between you and the car</p></section><footer class=article-footer><section class=article-tags><a href=/tags/english/>English</a>
<a href=/tags/video-transcripts/>Video Transcripts</a>
<a href=/tags/openai/>OpenAI</a></section></footer></article><div><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9206135835124064" crossorigin=anonymous></script><ins class=adsbygoogle style=display:block;text-align:center data-ad-layout=in-article data-ad-format=fluid data-ad-client=ca-pub-9206135835124064 data-ad-slot=1055602464></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script></div><aside class=related-content--wrapper><h2 class=section-title>Related content</h2><div class=related-content><div class="flex article-list--tile"><article><a href=/en/at2xkqjazns/><div class=article-image><img src=/img/related-content.png loading=lazy data-key=en/AT2XkqJAZns data-hash style=opacity:.3></div><div class=article-details><h2 class=article-title>Towards Epileptic Seizure Prediction with Deep Network ÔΩú Kata Slama ÔΩú OpenAI Scholars Demo Day 2020 ÔΩú OpenAI</h2></div></a></article><article><a href=/en/jzohw-eybtq/><div class=article-image><img src=/img/related-content.png loading=lazy data-key=en/JZOHW-eYBtQ data-hash style=opacity:.3></div><div class=article-details><h2 class=article-title>Introductions by Sam Altman & Greg Brockman ÔΩú OpenAI Scholars Demo Day 2020 ÔΩú OpenAI</h2></div></a></article><article><a href=/en/-fozam9xqs4/><div class=article-image><img src=/img/related-content.png loading=lazy data-key=en/-FoZAM9xqS4 data-hash style=opacity:.3></div><div class=article-details><h2 class=article-title>OpenAI Five vs. OG, Game 2 ÔΩú OpenAI Five Finals (4‚ß∏6) ÔΩú OpenAI</h2></div></a></article><article><a href=/en/u9mjuukhuzk/><div class=article-image><img src=/img/related-content.png loading=lazy data-key=en/U9mJuUkhUzk data-hash style=opacity:.3></div><div class=article-details><h2 class=article-title>OpenAI DevDay, Opening Keynote ÔΩú OpenAI</h2></div></a></article><article><a href=/en/lpe5gwuqa-k/><div class=article-image><img src=/img/related-content.png loading=lazy data-key=en/lpe5Gwuqa-k data-hash style=opacity:.3></div><div class=article-details><h2 class=article-title>Scaling Laws for Language Transfer Learning ÔΩú Christina Kim ÔΩú OpenAI Scholars Demo Day 2021 ÔΩú OpenAI</h2></div></a></article></div></div></aside><footer class=site-footer><section class=copyright>&copy;
2021 -
2023 SWIEST - Transcripts ¬∑ Screenplays ¬∑ Lyrics</section><section class=powerby>As an Amazon Associate I earn from qualifying purchases üõí<br>Built with <a href=https://swiest.com/ target=_blank rel=noopener>(Ôæâ‚óï„ÉÆ‚óï)Ôæâü™Ñüíûüíñü•∞ across the glüåçüåèüåébe</a><br></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Noto+Serif&family=Noto+Serif+Armenian&family=Noto+Serif+Bengali&family=Noto+Serif+Devanagari&family=Noto+Serif+Georgian&family=Noto+Serif+Gujarati&family=Noto+Serif+HK&family=Noto+Serif+Hebrew&family=Noto+Serif+JP&family=Noto+Serif+KR&family=Noto+Serif+Kannada&family=Noto+Serif+Khmer&family=Noto+Serif+Lao&family=Noto+Serif+Makasar&family=Noto+Serif+Malayalam&family=Noto+Serif+Myanmar&family=Noto+Serif+Oriya&family=Noto+Serif+SC&family=Noto+Serif+Sinhala&family=Noto+Serif+TC&family=Noto+Serif+Tamil&family=Noto+Serif+Telugu&family=Noto+Serif+Thai&family=Noto+Serif+Tibetan&display=swap" rel=stylesheet></body></html>