<!doctype html><html lang=en dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Video Transcript ﻿hi my name is Jota Jota I&amp;rsquo;m here to talk
about quantifying interpret ability of
models trained on quayne room now
for anyone else who might be new to
interpret ability I just want to clarify
clarify that phrase as Alethea power
said yesterday in their presentation
interpret ability is essentially the
field of mind reading for neural
networks unlike with humans when a human
makes the decision such as when you&amp;rsquo;re"><title>Quantifying Interpretability of Models Trained on Coi… ｜ Jorge Orbay ｜ OpenAI Scholars Demo Day 2020 ｜ OpenAI | SWIEST</title>
<link rel=canonical href=https://swiest.com/en/aee_dtufk4c/><link rel=stylesheet href=/scss/style.min.9a6fe90535a0e5c60443841f100f7b698092d48dba43fdb6386bb69b6559bc3d.css><script>document.oncontextmenu=function(){return!1},document.onselectstart=function(){return!1},document.oncopy=function(){return!1},document.oncut=function(){return!1}</script><script src=https://apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js></script><script type=text/javascript>$(document).ready(function(){$("#back-to-top").hide(),$(function(){$(window).scroll(function(){$(window).scrollTop()>600?$("#back-to-top").fadeIn(500):$("#back-to-top").fadeOut(500)}),$("#back-to-top").click(function(){return $("body,html").animate({scrollTop:0},500),!1})})})</script><meta property="og:title" content="Quantifying Interpretability of Models Trained on Coi… ｜ Jorge Orbay ｜ OpenAI Scholars Demo Day 2020 ｜ OpenAI"><meta property="og:description" content="Video Transcript ﻿hi my name is Jota Jota I&amp;rsquo;m here to talk
about quantifying interpret ability of
models trained on quayne room now
for anyone else who might be new to
interpret ability I just want to clarify
clarify that phrase as Alethea power
said yesterday in their presentation
interpret ability is essentially the
field of mind reading for neural
networks unlike with humans when a human
makes the decision such as when you&amp;rsquo;re"><meta property="og:url" content="https://swiest.com/en/aee_dtufk4c/"><meta property="og:site_name" content="SWIEST - Transcripts · Screenplays · Lyrics"><meta property="og:type" content="article"><meta property="article:section" content="Post"><meta property="article:tag" content="English"><meta property="article:tag" content="Video Transcripts"><meta property="article:tag" content="OpenAI"><meta property="article:published_time" content="2023-11-06T07:21:42+00:00"><meta property="article:modified_time" content="2023-11-06T07:21:42+00:00"><meta name=twitter:title content="Quantifying Interpretability of Models Trained on Coi… ｜ Jorge Orbay ｜ OpenAI Scholars Demo Day 2020 ｜ OpenAI"><meta name=twitter:description content="Video Transcript ﻿hi my name is Jota Jota I&amp;rsquo;m here to talk
about quantifying interpret ability of
models trained on quayne room now
for anyone else who might be new to
interpret ability I just want to clarify
clarify that phrase as Alethea power
said yesterday in their presentation
interpret ability is essentially the
field of mind reading for neural
networks unlike with humans when a human
makes the decision such as when you&amp;rsquo;re"><link rel="shortcut icon" href=/favicon.ico><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9206135835124064" crossorigin=anonymous></script><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"dark")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hu307e6a33fa6fd661ccda3b77024ef5c2_252345_300x0_resize_box_3.png width=300 height=300 class=site-logo loading=lazy alt=Avatar></a></figure><div class=site-meta><h1 class=site-name><a href=/>SWIEST - Transcripts · Screenplays · Lyrics</a></h1><h2 class=site-description>🧙🪄🌎</h2></div></header><ol class=menu id=main-menu><li><a href=/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg><span>Home</span></a></li><li><a href=/search/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg><span>Search</span></a></li><li><a href=/tags/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-tag" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11 3l9 9a1.5 1.5.0 010 2l-6 6a1.5 1.5.0 01-2 0L3 11V7a4 4 0 014-4h4"/><circle cx="9" cy="9" r="2"/></svg><span>Tags</span></a></li><li><a href=/chart/podcastchart.html target=_blank><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-apple-podcast" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M18.364 18.364a9 9 0 10-12.728.0"/><path d="M11.766 22h.468a2 2 0 001.985-1.752l.5-4A2 2 0 0012.734 14h-1.468a2 2 0 00-1.985 2.248l.5 4A2 2 0 0011.766 22z"/><path d="M12 9m-2 0a2 2 0 104 0 2 2 0 10-4 0"/></svg><span>Podcasts</span></a></li><li><a href=/radio.html target=_blank><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-radio" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M14 3 4.629 6.749A1 1 0 004 7.677V19a1 1 0 001 1h14a1 1 0 001-1V8a1 1 0 00-1-1H4.5"/><path d="M4 12h16"/><path d="M7 12v-2"/><path d="M17 16v.01"/><path d="M13 16v.01"/></svg><span>Radio</span></a></li><div class=menu-bottom-section><li id=i18n-switch><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-language" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 5h7"/><path d="M9 3v2c0 4.418-2.239 8-5 8"/><path d="M5 9c-.003 2.144 2.952 3.908 6.7 4"/><path d="M12 20l4-9 4 9"/><path d="M19.1 18h-6.2"/></svg><select name=language onchange="window.location.href=this.selectedOptions[0].value"><option value=https://swiest.com/ selected>English</option><option value=https://swiest.com/af/>Afrikaans</option><option value=https://swiest.com/am/>አማርኛ</option><option value=https://swiest.com/ar/>العربية</option><option value=https://swiest.com/az/>Azərbaycan</option><option value=https://swiest.com/be/>беларускі</option><option value=https://swiest.com/bg/>български</option><option value=https://swiest.com/bn/>বাংলা</option><option value=https://swiest.com/bo/>བོད་སྐད་</option><option value=https://swiest.com/bs/>Bosanski</option><option value=https://swiest.com/ca/>Català</option><option value=https://swiest.com/zh-hans/>简体中文</option><option value=https://swiest.com/zh-hant/>繁體中文</option><option value=https://swiest.com/cs/>Čeština</option><option value=https://swiest.com/el/>ελληνικά</option><option value=https://swiest.com/cy/>Cymraeg</option><option value=https://swiest.com/da/>Dansk</option><option value=https://swiest.com/de/>Deutsch</option><option value=https://swiest.com/eo/>Esperanto</option><option value=https://swiest.com/es-es/>Español (España)</option><option value=https://swiest.com/es-419/>Español (Latinoamérica)</option><option value=https://swiest.com/et/>Eesti</option><option value=https://swiest.com/eu/>Euskara</option><option value=https://swiest.com/haw/>ʻŌlelo Hawaiʻi</option><option value=https://swiest.com/fa/>فارسی</option><option value=https://swiest.com/fi/>Suomi</option><option value=https://swiest.com/fo/>Føroyskt</option><option value=https://swiest.com/fr/>Français</option><option value=https://swiest.com/fy/>Frysk</option><option value=https://swiest.com/ga/>Gaeilge</option><option value=https://swiest.com/gl/>Galego</option><option value=https://swiest.com/gu/>ગુજરાતી</option><option value=https://swiest.com/he/>עִברִית</option><option value=https://swiest.com/km/>កម្ពុជា។</option><option value=https://swiest.com/hi/>हिन्दी</option><option value=https://swiest.com/hr/>Hrvatski</option><option value=https://swiest.com/ht/>Kreyòl Ayisyen</option><option value=https://swiest.com/hu/>Magyar</option><option value=https://swiest.com/hy/>Հայերեն</option><option value=https://swiest.com/ig/>Ásụ̀sụ́ Ìgbò</option><option value=https://swiest.com/id/>Bahasa Indonesia</option><option value=https://swiest.com/is/>Íslenska</option><option value=https://swiest.com/it/>Italiano</option><option value=https://swiest.com/ja/>日本語</option><option value=https://swiest.com/jv/>Basa Jawa</option><option value=https://swiest.com/ka/>ქართული</option><option value=https://swiest.com/kk/>Қазақша</option><option value=https://swiest.com/kn/>ಕನ್ನಡ</option><option value=https://swiest.com/ko/>한국어</option><option value=https://swiest.com/or/>ଓଡ଼ିଆ</option><option value=https://swiest.com/ckb/>کوردی</option><option value=https://swiest.com/ky/>Кыргызча</option><option value=https://swiest.com/la/>Latina</option><option value=https://swiest.com/lb/>Lëtzebuergesch</option><option value=https://swiest.com/lo/>ພາສາລາວ</option><option value=https://swiest.com/lt/>Lietuvių</option><option value=https://swiest.com/lv/>Latviešu</option><option value=https://swiest.com/mk/>Македонски</option><option value=https://swiest.com/ml/>മലയാളം</option><option value=https://swiest.com/mn/>Монгол хэл</option><option value=https://swiest.com/mr/>मराठी</option><option value=https://swiest.com/sw/>Kiswahili</option><option value=https://swiest.com/ms/>Bahasa Melayu</option><option value=https://swiest.com/my/>မြန်မာ</option><option value=https://swiest.com/ne/>नेपाली</option><option value=https://swiest.com/nl/>Nederlands</option><option value=https://swiest.com/no/>Norsk</option><option value=https://swiest.com/pa/>ਪੰਜਾਬੀ</option><option value=https://swiest.com/pl/>Polski</option><option value=https://swiest.com/pt-br/>Português Brasil</option><option value=https://swiest.com/pt-pt/>Português Europeu</option><option value=https://swiest.com/ro/>Română</option><option value=https://swiest.com/ru/>Русский</option><option value=https://swiest.com/rw/>Kinyarwanda</option><option value=https://swiest.com/si/>සිංහල</option><option value=https://swiest.com/sk/>Slovenčina</option><option value=https://swiest.com/sl/>Slovenščina</option><option value=https://swiest.com/sq/>Shqip</option><option value=https://swiest.com/sr/>Српски (Srpski)</option><option value=https://swiest.com/su/>Basa Sunda</option><option value=https://swiest.com/sv/>Svenska</option><option value=https://swiest.com/ta/>தமிழ்</option><option value=https://swiest.com/te/>తెలుగు</option><option value=https://swiest.com/tg/>Тоҷикӣ</option><option value=https://swiest.com/th/>ไทย</option><option value=https://swiest.com/tk/>Türkmenler</option><option value=https://swiest.com/tl/>Filipino</option><option value=https://swiest.com/tr/>Türkçe</option><option value=https://swiest.com/uk/>Українська</option><option value=https://swiest.com/ur/>اردو</option><option value=https://swiest.com/uz/>O'zbekcha</option><option value=https://swiest.com/vi/>Tiếng Việt</option><option value=https://swiest.com/yi/>אידיש</option><option value=https://swiest.com/zh-hk/>粵語</option><option value=https://swiest.com/zu/>IsiZulu</option></select></li><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><span>Dark Mode</span></li></div></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#video>Video</a></li><li><a href=#transcript>Transcript</a></li></ol></nav></div></section><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9206135835124064" crossorigin=anonymous></script><ins class=adsbygoogle style=display:block data-ad-client=ca-pub-9206135835124064 data-ad-slot=8754979142 data-ad-format=auto data-full-width-responsive=true></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script></aside><a id=back-to-top href=#><img src=/img/top_hu7c2829da96df0e9f8f0191d120020b22_22287_40x0_resize_box_3.png></a><main class="main full-width"><form action=/search/ class="search-form widget"><p><label>Search</label>
<input name=keyword required placeholder="Type something...">
<button title=Search><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg></button></p></form><article class=main-article><header class=article-header><div class=article-details><header class=article-tags><a href=/tags/english/>English
</a><a href=/tags/video-transcripts/>Video Transcripts
</a><a href=/tags/openai/>OpenAI</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/en/aee_dtufk4c/>Quantifying Interpretability of Models Trained on Coi… ｜ Jorge Orbay ｜ OpenAI Scholars Demo Day 2020 ｜ OpenAI</a></h2></div><footer class=article-time><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg><time class=article-time--published>2023-11-06</time></div><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg><time class=article-time--reading>18 minute read</time></div></footer></div></header><div class=article-content><p style=text-align:center><a href=https://amzn.to/3Nrdcwk target=_blank>🎁Amazon Prime</a>
<a href=https://amzn.to/3RIBkxg target=_blank>📖Kindle Unlimited</a>
<a href=https://amzn.to/3Rqmudl target=_blank>🎧Audible Plus</a>
<a href=https://amzn.to/3TuLbbj target=_blank>🎵Amazon Music Unlimited</a>
<a href="https://www.iherb.com/?rcode=EID1574" target=_blank>🌿iHerb</a>
<a href="https://accounts.binance.com/register?ref=72302422" target=_blank>💰Binance</a></p></div><div><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9206135835124064" crossorigin=anonymous></script><ins class=adsbygoogle style=display:block data-ad-client=ca-pub-9206135835124064 data-ad-slot=8754979142 data-ad-format=auto data-full-width-responsive=true></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script></div><section class=article-content><h2 id=video>Video</h2><div class=video-wrapper><iframe loading=lazy src=https://www.youtube.com/embed/aEe_dTUfK4c allowfullscreen title="YouTube Video"></iframe></div><h2 id=transcript>Transcript</h2><p>﻿hi my name is Jota Jota I&rsquo;m here to talk</p><p>about quantifying interpret ability of</p><p>models trained on quayne room now</p><p>for anyone else who might be new to</p><p>interpret ability I just want to clarify</p><p>clarify that phrase as Alethea power</p><p>said yesterday in their presentation</p><p>interpret ability is essentially the</p><p>field of mind reading for neural</p><p>networks unlike with humans when a human</p><p>makes the decision such as when you&rsquo;re</p><p>seeing an image and you want to classify</p><p>what exactly that image looks like and</p><p>you and a human says oh this image of</p><p>the dog is of the dog you can ask the</p><p>human why they think it&rsquo;s dog whereas</p><p>with with okay whereas with which the</p><p>computer neural networks when we use</p><p>them you can&rsquo;t ask a neural network</p><p>exactly why do you think an image is</p><p>classified this way instead we use</p><p>interpret ability as a means of breaking</p><p>down neural networks understanding why</p><p>they make the choices they do so that is</p><p>interpret ability to be clear and also I</p><p>wanted to reduce myself before I get</p><p>into the details of this that just I&rsquo;m a</p><p>software engineer I joined the Scholars</p><p>program back in February under my mentor</p><p>called Cobb I learned reinforcement</p><p>learning for two months after which I</p><p>worked on this project and it&rsquo;s supposed</p><p>to be here today</p><p>so it&rsquo;s good start involved alright so</p><p>the whole goal of my project is testing</p><p>the diversity hypothesis now the</p><p>diversity hypothesis that&rsquo;s proposing</p><p>the original paper which is currently</p><p>unpublished for written by Jacob Felton</p><p>and Chris Ola to engineers and</p><p>researchers here at open AI and by the</p><p>way if you have access to this to their</p><p>draft I highly recommend checking it out</p><p>be a prett the diversity I promise this</p><p>is as follows interpretable features</p><p>tend to arise at a given level of</p><p>abstraction if and only if the training</p><p>distribution is diverse enough at that</p><p>level of up stretch so let&rsquo;s clarify a</p><p>few terms here one that diversity in</p><p>this context is in the in our use gonna</p><p>be just the amount of distinct input</p><p>that our neural network gets to train on</p><p>so for example with an image classifier</p><p>if you give a neural network 100</p><p>examples of images</p><p>train</p><p>and understand how to classify that</p><p>would be less diverse than a network</p><p>that&rsquo;s been given a hundred thousand</p><p>images to train on and understand them</p><p>and classify and when we speak of levels</p><p>of abstraction here we&rsquo;re mostly</p><p>speaking about different layers of our</p><p>neural network essentially neural</p><p>networks are divided into the layers</p><p>that early layers seem to catch simple</p><p>patterns like lines and shapes and later</p><p>layers tend to catch more complex and</p><p>abstracts patterns like dogs or cats</p><p>this is again in the context of just</p><p>image classification so essentially as a</p><p>model trains on more diverse data we</p><p>expect that it&rsquo;s easier for us to</p><p>understand why model makes the choices</p><p>it does and do we have any proof of this</p><p>yeah we did because this unpublished</p><p>paper made an experiment specifically in</p><p>the context of coin run which I&rsquo;ll go</p><p>into detail later but for now picture it</p><p>as a game similar to Mario Brothers or</p><p>essentially have a agent that is</p><p>controlling a little character that goes</p><p>around the level now as you can see in</p><p>this left slide that as models oh this</p><p>lower bar shows models and in a specific</p><p>architecture and a differing amount of</p><p>levels it&rsquo;s been trained on so on the</p><p>left side represents models have been</p><p>trained on great little data about 100</p><p>distinct training levels whereas the</p><p>right side shows models that the same</p><p>model trained on more training data we</p><p>can see that as expected it performs</p><p>well when tested against data hasn&rsquo;t</p><p>seen if it&rsquo;s been trained on a large</p><p>amount of data so essentially as you</p><p>train on more data you expect them</p><p>almost performed better in tests just as</p><p>the performance improves so does the</p><p>interpret ability of the features of</p><p>this model essentially meaning that</p><p>models that have been trained on very</p><p>little data in corn run in this instance</p><p>only have about 1 in every 5 features</p><p>that is even like understandable to</p><p>humans as in if the if a human breaks</p><p>down the network they can only</p><p>understand roughly one in every five</p><p>features or individual components of the</p><p>network and what they&rsquo;re doing whereas</p><p>as a model it&rsquo;s trained on more and more</p><p>training levels the amount of features</p><p>that are interpreted by humans goes up</p><p>to four out of five</p><p>and now essentially my goal here is to</p><p>test out B and and so this of course</p><p>indicates that the diversity hypothesis</p><p>is valid and my goal is to test out the</p><p>same the only difference is that the</p><p>researchers who generated this graph did</p><p>so the human loop this process takes a</p><p>while it&rsquo;s roughly an hour and a half</p><p>for every individual researcher to go</p><p>and look at the what these models are</p><p>going through and matching the features</p><p>with their results and trying to</p><p>understand what they&rsquo;re looking at and</p><p>it&rsquo;s a long process I&rsquo;d like to make a</p><p>definition for interpretability that&rsquo;s</p><p>algorithmic that a computer can use so</p><p>that we don&rsquo;t have to have a human in</p><p>the loop to test this idea of</p><p>interpreter this will help us scale up</p><p>an experiment so let&rsquo;s first start off</p><p>by breaking down the tools used in this</p><p>previous experiment and and the tools in</p><p>particular will be quite a run in</p><p>attribution so coin run the domain that</p><p>this training is done on is Mario</p><p>platformers mentioned before and I&rsquo;m</p><p>going to show an example of it so here</p><p>we see a player jumping through a</p><p>platform avoiding a little on me and</p><p>like that busts are right there and</p><p>grabbing the gold coin at the end now</p><p>the yes the player jumps through avoids</p><p>enemies and if it lands on an enemy it</p><p>fails the level it doesn&rsquo;t get reward if</p><p>it gets a gold coin it actually is</p><p>successful in in completing the level</p><p>now I want to emphasize that with coin</p><p>run essentially there&rsquo;s different assets</p><p>and textures or different textures for</p><p>the assets that as we go through levels</p><p>there&rsquo;s more diversity and just like</p><p>placement of platforms there&rsquo;s also what</p><p>the platform&rsquo;s look like but the</p><p>background looks like what the player</p><p>looks like so there&rsquo;s a lot of potential</p><p>diversity in how the assets are</p><p>recognized and how a network can</p><p>understand the the domain now it&rsquo;s good</p><p>attribution so how do we know what a</p><p>network is looking at or what it&rsquo;s</p><p>paying attention to this is what</p><p>attribution allows us to see so from a</p><p>technical point of view attribution is</p><p>the drip is when the derivative of a</p><p>network sorry when we get the output of</p><p>a network and we get its derivative with</p><p>respects to the input to an F</p><p>essentially we can abstract this away as</p><p>it allows us to see what a network is</p><p>most paying attention to you know when</p><p>it&rsquo;s classifying you&rsquo;re doing some</p><p>action with an endpoint so let&rsquo;s imagine</p><p>in the domain of classifying images what</p><p>that looks so in this first image we</p><p>have a picture of a bird we have an</p><p>image classifier that ran this image we</p><p>would expect the classifier to output</p><p>bird as a classification in the second</p><p>frame we run attribution on that network</p><p>with respect to this image and it tells</p><p>us and it gives us an output with the</p><p>same exact dimensions is the image</p><p>showing that the wider pixels here at</p><p>pixels the higher values are the ones</p><p>that the network is most paying</p><p>attention to so in this case we can see</p><p>that the network is paying attention to</p><p>the I have the bird the beak of the bird</p><p>the feathers along the bird&rsquo;s head and</p><p>even the plumage like closer to the base</p><p>and that&rsquo;s really interesting it doesn&rsquo;t</p><p>pay attention to grass at all and we can</p><p>see that if you map the the the most</p><p>noticeable pixels to the original image</p><p>you get this kind of results an image of</p><p>just the bird but essentially the grass</p><p>is not weighing in on a network&rsquo;s</p><p>decision of classify this image as a</p><p>bird so this allows us to see what then</p><p>it works in tension - can we use this on</p><p>coin rod and we can I&rsquo;m going to show an</p><p>example essentially we&rsquo;re doing a very</p><p>similar process except when a model is</p><p>being trained and running on coin run</p><p>we&rsquo;re specifically are putting two</p><p>things the controls of the players</p><p>that&rsquo;s how it controls the player when</p><p>it&rsquo;s playing and something called a</p><p>value function which is really just an</p><p>estimate of the models an estimate of</p><p>the models performance that it&rsquo;ll have a</p><p>high value if the model thinks it&rsquo;s</p><p>doing well and low if not so with this</p><p>results of attribution let&rsquo;s see what</p><p>the model is looking at in a very</p><p>specific track of a pointer we&rsquo;ll see</p><p>here as the player jumps through the</p><p>game you can actually see that the</p><p>models paying attention to buzz thoughts</p><p>in the game as in like it&rsquo;s actually</p><p>seeing oh there&rsquo;s like an enemy I have</p><p>to avoid it it&rsquo;s really easiest for</p><p>human to see okay this is exactly what</p><p>the models</p><p>looking at now I want to clarify that in</p><p>this context we&rsquo;re not running</p><p>attribution on the entire network but on</p><p>a section this allows us to see only</p><p>what the model thinks of in terms of</p><p>abstract ideas and more like developed</p><p>assets and where they are in the image</p><p>and it also allows us to have multiple</p><p>results which is why you see these</p><p>multiple colors that there&rsquo;s multiple</p><p>features that a network can use to</p><p>interpret the image now let&rsquo;s see what a</p><p>port interpreter will example would be</p><p>essentially a player runs through and as</p><p>jumps you can see there&rsquo;s these little</p><p>purple kind of shapes in the background</p><p>that&rsquo;s an feature that is picking up</p><p>random artifacts in the background it</p><p>has no idea what is like irrelevant to</p><p>itself and what&rsquo;s not whereas the other</p><p>model we can tell easily here human</p><p>would it be able to tell you what&rsquo;s this</p><p>model paying attention to we have no</p><p>idea it&rsquo;s just like these random shapes</p><p>in the background there&rsquo;s some aspects</p><p>of it that maybe you can guess what the</p><p>models looking at but old smelly I would</p><p>classify this feature as uninterpreted</p><p>so with this process this is a human the</p><p>loop process I just described can we</p><p>make this into something a human you can</p><p>do for us instead and we can or at least</p><p>we can track so this is kind of my</p><p>little trying to add something new here</p><p>I&rsquo;m gonna define interpretive</p><p>interpretability for this context of</p><p>coin run as just the area of intersect</p><p>of a quantity equivalent to the area of</p><p>intersection between Attribution and the</p><p>objects of interest divided by the</p><p>output of attribution so that&rsquo;s kind of</p><p>a mouthful but let&rsquo;s kind of break down</p><p>what that looks like essentially as a</p><p>character jumps through the game we have</p><p>this one example of a frame we can</p><p>actually separate what I call the</p><p>objects of interest which is really just</p><p>any objects that are in the background</p><p>and give them put them in an image where</p><p>everything has a value of one except for</p><p>the background so that&rsquo;s what this looks</p><p>like essentially everything is white</p><p>except a black brown the background</p><p>which is black and with this matte would</p><p>we call mask of assets we can add the</p><p>attribution results and let&rsquo;s say here</p><p>we have these two little spots from</p><p>attribution roughly ten pixels each and</p><p>we see that ten pixels are right on top</p><p>of a wall so it intersects with the</p><p>object of interests</p><p>ten or not during the background so</p><p>again with our quantity of attribute of</p><p>interpretability we see that the</p><p>numerator essentially the the</p><p>intersection is 10 pixels divided by the</p><p>total area of attribution which is 10</p><p>plus 10 20 pixels so 10 divided by 20</p><p>that&rsquo;s a 50% interpretability score for</p><p>this specific frame now if we do this</p><p>process not just for one frame but for</p><p>512 and we do it not just for one</p><p>feature but for all features of a neural</p><p>network we get the average of all those</p><p>results we can have what I claim to be</p><p>an interpretability scored for the model</p><p>now what does that look like well it</p><p>looks the same for all the models that</p><p>trained on going from models trained on</p><p>100 levels which in this context is very</p><p>small and models trained on 100,000</p><p>levels which is a model that is trained</p><p>on a lot of data and we have been expect</p><p>to have your interpretable features if</p><p>the hypothesis for valid now what is</p><p>this show because I myself gone through</p><p>this human the loop domain um experiment</p><p>and I trust that these human the loop</p><p>results are valid and do reflect you</p><p>interpret ability this means that my</p><p>definition for interpret ability</p><p>currently isn&rsquo;t working out there all</p><p>roughly at for 35 to 40 percent why is</p><p>that well it&rsquo;s very heavily because a</p><p>lot of my results of attribution are not</p><p>as small as I&rsquo;ve shown you in this</p><p>example we&rsquo;re often the examples be the</p><p>results of attribution are actually much</p><p>larger or on the order magnitude like 20</p><p>by 20 pixels and they take up a lot of</p><p>the screen and especially when you have</p><p>a lot of assets to take the majority of</p><p>screen it it ends up picking up about</p><p>the same amount of the mass every time</p><p>and it&rsquo;s just it&rsquo;s not a good method now</p><p>I can narrow down the scope because this</p><p>is partially due to a method I that&rsquo;s</p><p>just called using the receptive field</p><p>where you&rsquo;re essentially trying to</p><p>translate the results of attribution to</p><p>the input domain and it&rsquo;s it&rsquo;s currently</p><p>not essentially it&rsquo;s not working quite</p><p>well except after you have to use the</p><p>receptive field and a way in which</p><p>you&rsquo;re weighing them the more connected</p><p>parts of a network with the lesser</p><p>connected parts of the network</p><p>and so essentially some refinement and</p><p>obvious improvements can be done but</p><p>currently the measurement does not work</p><p>so what am I conclusions here I think</p><p>that this ability because</p><p>interpretability is still like something</p><p>that can be calculated with an</p><p>algorithmic process with you mean the</p><p>loop I think it can be done by computer</p><p>but we still have to refine this current</p><p>definition I have and this is just in</p><p>the domain of pointer and has to be</p><p>expanded to other domains to be</p><p>functional for us and what else so this</p><p>my experiment doesn&rsquo;t actually prove or</p><p>disprove the diversity hypothesis but I</p><p>still think that it&rsquo;s important to try</p><p>to further experiment and see if this</p><p>hypothesis is valid because the</p><p>hypothesis is very powerful that if we</p><p>understand that diversity of features</p><p>does increase with generalization of a</p><p>model this is a new axis by which we can</p><p>improve moms and it&rsquo;s very exciting but</p><p>so yes so that&rsquo;s my conclusions</p><p>I don&rsquo;t like technology very quickly</p><p>there&rsquo;s a little surance I&rsquo;m just my</p><p>mentor called caboose fantastic during</p><p>this program and honestly this work</p><p>wouldn&rsquo;t have been possible or I</p><p>wouldn&rsquo;t been able to do this work</p><p>without him</p><p>chicken healthy and crystal all the</p><p>original writers of the paper who did a</p><p>fantastic job and I highly recommend</p><p>looking at it if you have access this is</p><p>how you published would I yank a scene I</p><p>who ran the Scholars Program and have</p><p>done a great job doing it were very</p><p>supportive mario and francis for making</p><p>this presentation possible Alethea andre</p><p>Kathy come on look at that Pamela the</p><p>other scholars and there were fantastic</p><p>Greg and Brockman smallman for since</p><p>you&rsquo;re making everything here possible</p><p>and virtual Yang my fiancee who was also</p><p>a great support during this work thank</p><p>you very much</p><p>I will check now if there are any</p><p>questions how can you tell if a</p><p>distribution is diverse excellent</p><p>question is there a metric to quantify</p><p>the diversity property of a distribution</p><p>of a model great question so in this</p><p>case of a distribution or model so in</p><p>this case we&rsquo;re thinking of diversity in</p><p>the context of the input distribution</p><p>and I&rsquo;m sure there&rsquo;s better ways to do</p><p>this in other domains but the coin run</p><p>I&rsquo;m only defining diversity as the</p><p>amount of distinct levels that an agent</p><p>is trained on so it&rsquo;s really just kind</p><p>of trusting it&rsquo;s not trying to</p><p>discrimination of diversity isn&rsquo;t trying</p><p>to distinguish between how diverse two</p><p>different levels are more justice kind</p><p>of going with the easy first solution of</p><p>any distinct model is it like the amount</p><p>of distinct levels that have models</p><p>trained on are is the level of diversity</p><p>that&rsquo;s thank you for that question by</p><p>the way since you are using a dynamic</p><p>image video how is the attribution model</p><p>able to perform consistent</p><p>identification and tracking of the</p><p>objects is attending to let me swallow</p><p>that or digested I real quick since you</p><p>are hmm I was able to perform consistent</p><p>identification track the objects it&rsquo;s</p><p>it&rsquo;s a great question so ultimately the</p><p>model is operating on the frame-by-frame</p><p>basis there&rsquo;s no consistent like oh this</p><p>is what I used for attribution last time</p><p>this is what I&rsquo;m using this time so</p><p>there is a lot of flickering where it&rsquo;s</p><p>not that consistent but I think with the</p><p>examples I showed there was one that was</p><p>super interpretable and it shows just</p><p>how well it&rsquo;s actually generalizing and</p><p>and is human interpretable that it&rsquo;s</p><p>actually able to consistently recognized</p><p>features from one frame to the next it&rsquo;s</p><p>not that like it&rsquo;s sort of that shows</p><p>how well that it&rsquo;s generalized that even</p><p>in a dynamic image shirt in the other</p><p>video that it&rsquo;s still able to like</p><p>consistently make sense to humans say</p><p>you don&rsquo;t have to go frame by frame so</p><p>it&rsquo;s a great question I would say for</p><p>the less interpretable ones it doesn&rsquo;t</p><p>look consistent at all I had to pause if</p><p>you remember the less interprete below</p><p>model I had to pause the multiple times</p><p>just for you to see the Purple Haze and</p><p>see what it&rsquo;s picking up so so yeah I</p><p>hope that answers your question you can</p><p>ask another how is that tribution</p><p>different from sailing that&rsquo;s excellent</p><p>question attribution is Zaillian C Maps</p><p>the term attribution I don&rsquo;t know why it</p><p>picked ups in specific fields relative</p><p>to others but I want to show real quick</p><p>and give thanks so here we go cable</p><p>since from in a write this paper I&rsquo;m</p><p>referencing here deep inside of</p><p>convolutional networks coin that turns</p><p>salient see maps I believe they did this</p><p>before the term attribution caught on I</p><p>don&rsquo;t know why there&rsquo;s a different usage</p><p>in the field and also if anyone knows</p><p>why or if there is like a difference in</p><p>concepts I would love to know but yes</p><p>essentially they&rsquo;re the same thing</p><p>how would you think the interpretability</p><p>of the model as you define it would</p><p>scale to other games besides coin run</p><p>like bouncy ball hmm excellent question</p><p>my original goal or my strat amount not</p><p>my original my stretch goal when I</p><p>started was to actually try and</p><p>experiment should I lay define</p><p>interpretability for the context of coin</p><p>run on another project game I have to</p><p>admit in the heat of the moment of the</p><p>presentation I don&rsquo;t remember which game</p><p>bouncy ball is so there&rsquo;s a few things</p><p>to keep in mind here one that coin run</p><p>is a game in which the assets of value</p><p>take up about like 50% or less of the</p><p>screen at time if you&rsquo;re playing a game</p><p>like checkers the assets of allegoric</p><p>taking up the entire screen so it</p><p>doesn&rsquo;t actually change very well it&rsquo;s</p><p>that kind of game so bounce evolve if</p><p>it&rsquo;s the game where assets are</p><p>relatively rare they&rsquo;re not rare but at</p><p>least less than 50% of the screen I</p><p>think it could work</p><p>there&rsquo;s a few other nuances I&rsquo;m like</p><p>what else would the interpretability</p><p>definition work for oh yeah I hope that</p><p>answers question also make sure to check</p><p>out bouncy ball later another one why</p><p>does good attribution saliency imply</p><p>interpretability isn&rsquo;t this mostly an</p><p>accidental correlation dracolich though</p><p>useful and not a causal implication we</p><p>also digest this one real quick imply</p><p>interpretability</p><p>okay so essentially what the purpose of</p><p>testing the diversity hypothesis is is</p><p>testing if this is true if good</p><p>attribution sailings sleep kind of does</p><p>imply interpretability is that right no</p><p>not exactly</p><p>it&rsquo;s okay so I&rsquo;m going to say that good</p><p>attribution salience seat isn&rsquo;t itself</p><p>like not really a phrase what what makes</p><p>it good here we&rsquo;re using it it&rsquo;s just</p><p>the tool itself attribution that we&rsquo;re</p><p>just saying that if attribution aligns</p><p>with what we consider to be an object of</p><p>importance in a game then it is good and</p><p>so it&rsquo;s sort of</p><p>it&rsquo;s not an so it&rsquo;s sort of like it&rsquo;s</p><p>kind of coming back to this idea of like</p><p>what does it mean to be human interprete</p><p>beware for us.we and for this the</p><p>context of this experiments it&rsquo;s saying</p><p>that we humans pay attention to things I</p><p>like when you look with your eye that</p><p>you tend to focus on specific objects to</p><p>narrow down your domain in order to like</p><p>digest an image or kind of interpreted</p><p>and so in the same way we&rsquo;re sort of</p><p>expecting like okay there has to be</p><p>certain parts of the image that the</p><p>network is most sensitive to to make a</p><p>prop to first actually understand that</p><p>it&rsquo;s using those parts of the image it&rsquo;s</p><p>interprets I&rsquo;m not satisfied with this</p><p>dancer reach out to me I&rsquo;d love to talk</p><p>about this more and I also think that</p><p>Jacob Hilton would have a much better</p><p>response than myself because he wrote a</p><p>lot of this original work and Chris Ola</p><p>in the paper oh yeah but thank you for</p><p>the question is there another one</p><p>I don&rsquo;t think so mething mood is</p><p>grabbing screen so thank you very much</p></section><footer class=article-footer><section class=article-tags><a href=/tags/english/>English</a>
<a href=/tags/video-transcripts/>Video Transcripts</a>
<a href=/tags/openai/>OpenAI</a></section></footer></article><div><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9206135835124064" crossorigin=anonymous></script><ins class=adsbygoogle style=display:block;text-align:center data-ad-layout=in-article data-ad-format=fluid data-ad-client=ca-pub-9206135835124064 data-ad-slot=1055602464></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script></div><aside class=related-content--wrapper><h2 class=section-title>Related content</h2><div class=related-content><div class="flex article-list--tile"><article><a href=/en/at2xkqjazns/><div class=article-image><img src=/img/related-content.png loading=lazy data-key=en/AT2XkqJAZns data-hash style=opacity:.3></div><div class=article-details><h2 class=article-title>Towards Epileptic Seizure Prediction with Deep Network ｜ Kata Slama ｜ OpenAI Scholars Demo Day 2020 ｜ OpenAI</h2></div></a></article><article><a href=/en/jzohw-eybtq/><div class=article-image><img src=/img/related-content.png loading=lazy data-key=en/JZOHW-eYBtQ data-hash style=opacity:.3></div><div class=article-details><h2 class=article-title>Introductions by Sam Altman & Greg Brockman ｜ OpenAI Scholars Demo Day 2020 ｜ OpenAI</h2></div></a></article><article><a href=/en/-fozam9xqs4/><div class=article-image><img src=/img/related-content.png loading=lazy data-key=en/-FoZAM9xqS4 data-hash style=opacity:.3></div><div class=article-details><h2 class=article-title>OpenAI Five vs. OG, Game 2 ｜ OpenAI Five Finals (4⧸6) ｜ OpenAI</h2></div></a></article><article><a href=/en/u9mjuukhuzk/><div class=article-image><img src=/img/related-content.png loading=lazy data-key=en/U9mJuUkhUzk data-hash style=opacity:.3></div><div class=article-details><h2 class=article-title>OpenAI DevDay, Opening Keynote ｜ OpenAI</h2></div></a></article><article><a href=/en/lpe5gwuqa-k/><div class=article-image><img src=/img/related-content.png loading=lazy data-key=en/lpe5Gwuqa-k data-hash style=opacity:.3></div><div class=article-details><h2 class=article-title>Scaling Laws for Language Transfer Learning ｜ Christina Kim ｜ OpenAI Scholars Demo Day 2021 ｜ OpenAI</h2></div></a></article></div></div></aside><footer class=site-footer><section class=copyright>&copy;
2021 -
2023 SWIEST - Transcripts · Screenplays · Lyrics</section><section class=powerby>As an Amazon Associate I earn from qualifying purchases 🛒<br>Built with <a href=https://swiest.com/ target=_blank rel=noopener>(ﾉ◕ヮ◕)ﾉ🪄💞💖🥰 across the gl🌍🌏🌎be</a><br></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Noto+Serif&family=Noto+Serif+Armenian&family=Noto+Serif+Bengali&family=Noto+Serif+Devanagari&family=Noto+Serif+Georgian&family=Noto+Serif+Gujarati&family=Noto+Serif+HK&family=Noto+Serif+Hebrew&family=Noto+Serif+JP&family=Noto+Serif+KR&family=Noto+Serif+Kannada&family=Noto+Serif+Khmer&family=Noto+Serif+Lao&family=Noto+Serif+Makasar&family=Noto+Serif+Malayalam&family=Noto+Serif+Myanmar&family=Noto+Serif+Oriya&family=Noto+Serif+SC&family=Noto+Serif+Sinhala&family=Noto+Serif+TC&family=Noto+Serif+Tamil&family=Noto+Serif+Telugu&family=Noto+Serif+Thai&family=Noto+Serif+Tibetan&display=swap" rel=stylesheet></body></html>