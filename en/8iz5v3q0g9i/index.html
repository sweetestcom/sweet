<!doctype html><html lang=en dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Video Transcript ï»¿uh hi um my
talk is going to be about characterizing
test time compute on graph structured
problems
um most of my scholars project has been
spent thinking about
uh this question of whether we can uh
create models
that continuously improve their outputs
the more compute that we give them at
test time
this is something that i&amp;rsquo;ll call the
test time compute dream
and i think there&amp;rsquo;s much anthromorphic"><title>Characterizing Test Time Compute on Graph Structurâ€¦ ï½œ Kudzo Ahegbebu ï½œ OpenAI Scholars Demo Day 2021 ï½œ OpenAI | SWIEST</title>
<link rel=canonical href=https://swiest.com/en/8iz5v3q0g9i/><link rel=stylesheet href=/scss/style.min.9a6fe90535a0e5c60443841f100f7b698092d48dba43fdb6386bb69b6559bc3d.css><script>document.oncontextmenu=function(){return!1},document.onselectstart=function(){return!1},document.oncopy=function(){return!1},document.oncut=function(){return!1}</script><script src=https://apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js></script><script type=text/javascript>$(document).ready(function(){$("#back-to-top").hide(),$(function(){$(window).scroll(function(){$(window).scrollTop()>600?$("#back-to-top").fadeIn(500):$("#back-to-top").fadeOut(500)}),$("#back-to-top").click(function(){return $("body,html").animate({scrollTop:0},500),!1})})})</script><meta property="og:title" content="Characterizing Test Time Compute on Graph Structurâ€¦ ï½œ Kudzo Ahegbebu ï½œ OpenAI Scholars Demo Day 2021 ï½œ OpenAI"><meta property="og:description" content="Video Transcript ï»¿uh hi um my
talk is going to be about characterizing
test time compute on graph structured
problems
um most of my scholars project has been
spent thinking about
uh this question of whether we can uh
create models
that continuously improve their outputs
the more compute that we give them at
test time
this is something that i&amp;rsquo;ll call the
test time compute dream
and i think there&amp;rsquo;s much anthromorphic"><meta property="og:url" content="https://swiest.com/en/8iz5v3q0g9i/"><meta property="og:site_name" content="SWIEST - Transcripts Â· Screenplays Â· Lyrics"><meta property="og:type" content="article"><meta property="article:section" content="Post"><meta property="article:tag" content="English"><meta property="article:tag" content="Video Transcripts"><meta property="article:tag" content="OpenAI"><meta property="article:published_time" content="2023-11-06T12:33:19+00:00"><meta property="article:modified_time" content="2023-11-06T12:33:19+00:00"><meta name=twitter:title content="Characterizing Test Time Compute on Graph Structurâ€¦ ï½œ Kudzo Ahegbebu ï½œ OpenAI Scholars Demo Day 2021 ï½œ OpenAI"><meta name=twitter:description content="Video Transcript ï»¿uh hi um my
talk is going to be about characterizing
test time compute on graph structured
problems
um most of my scholars project has been
spent thinking about
uh this question of whether we can uh
create models
that continuously improve their outputs
the more compute that we give them at
test time
this is something that i&amp;rsquo;ll call the
test time compute dream
and i think there&amp;rsquo;s much anthromorphic"><link rel="shortcut icon" href=/favicon.ico><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9206135835124064" crossorigin=anonymous></script><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"dark")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hu307e6a33fa6fd661ccda3b77024ef5c2_252345_300x0_resize_box_3.png width=300 height=300 class=site-logo loading=lazy alt=Avatar></a></figure><div class=site-meta><h1 class=site-name><a href=/>SWIEST - Transcripts Â· Screenplays Â· Lyrics</a></h1><h2 class=site-description>ğŸ§™ğŸª„ğŸŒ</h2></div></header><ol class=menu id=main-menu><li><a href=/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg><span>Home</span></a></li><li><a href=/search/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg><span>Search</span></a></li><li><a href=/tags/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-tag" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11 3l9 9a1.5 1.5.0 010 2l-6 6a1.5 1.5.0 01-2 0L3 11V7a4 4 0 014-4h4"/><circle cx="9" cy="9" r="2"/></svg><span>Tags</span></a></li><li><a href=/chart/podcastchart.html target=_blank><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-apple-podcast" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M18.364 18.364a9 9 0 10-12.728.0"/><path d="M11.766 22h.468a2 2 0 001.985-1.752l.5-4A2 2 0 0012.734 14h-1.468a2 2 0 00-1.985 2.248l.5 4A2 2 0 0011.766 22z"/><path d="M12 9m-2 0a2 2 0 104 0 2 2 0 10-4 0"/></svg><span>Podcasts</span></a></li><li><a href=/radio.html target=_blank><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-radio" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M14 3 4.629 6.749A1 1 0 004 7.677V19a1 1 0 001 1h14a1 1 0 001-1V8a1 1 0 00-1-1H4.5"/><path d="M4 12h16"/><path d="M7 12v-2"/><path d="M17 16v.01"/><path d="M13 16v.01"/></svg><span>Radio</span></a></li><div class=menu-bottom-section><li id=i18n-switch><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-language" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 5h7"/><path d="M9 3v2c0 4.418-2.239 8-5 8"/><path d="M5 9c-.003 2.144 2.952 3.908 6.7 4"/><path d="M12 20l4-9 4 9"/><path d="M19.1 18h-6.2"/></svg><select name=language onchange="window.location.href=this.selectedOptions[0].value"><option value=https://swiest.com/ selected>English</option><option value=https://swiest.com/af/>Afrikaans</option><option value=https://swiest.com/am/>áŠ áˆ›áˆ­áŠ›</option><option value=https://swiest.com/ar/>Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</option><option value=https://swiest.com/az/>AzÉ™rbaycan</option><option value=https://swiest.com/be/>Ğ±ĞµĞ»Ğ°Ñ€ÑƒÑĞºÑ–</option><option value=https://swiest.com/bg/>Ğ±ÑŠĞ»Ğ³Ğ°Ñ€ÑĞºĞ¸</option><option value=https://swiest.com/bn/>à¦¬à¦¾à¦‚à¦²à¦¾</option><option value=https://swiest.com/bo/>à½–à½¼à½‘à¼‹à½¦à¾à½‘à¼‹</option><option value=https://swiest.com/bs/>Bosanski</option><option value=https://swiest.com/ca/>CatalÃ </option><option value=https://swiest.com/zh-hans/>ç®€ä½“ä¸­æ–‡</option><option value=https://swiest.com/zh-hant/>ç¹é«”ä¸­æ–‡</option><option value=https://swiest.com/cs/>ÄŒeÅ¡tina</option><option value=https://swiest.com/el/>ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬</option><option value=https://swiest.com/cy/>Cymraeg</option><option value=https://swiest.com/da/>Dansk</option><option value=https://swiest.com/de/>Deutsch</option><option value=https://swiest.com/eo/>Esperanto</option><option value=https://swiest.com/es-es/>EspaÃ±ol (EspaÃ±a)</option><option value=https://swiest.com/es-419/>EspaÃ±ol (LatinoamÃ©rica)</option><option value=https://swiest.com/et/>Eesti</option><option value=https://swiest.com/eu/>Euskara</option><option value=https://swiest.com/haw/>Ê»ÅŒlelo HawaiÊ»i</option><option value=https://swiest.com/fa/>ÙØ§Ø±Ø³ÛŒ</option><option value=https://swiest.com/fi/>Suomi</option><option value=https://swiest.com/fo/>FÃ¸royskt</option><option value=https://swiest.com/fr/>FranÃ§ais</option><option value=https://swiest.com/fy/>Frysk</option><option value=https://swiest.com/ga/>Gaeilge</option><option value=https://swiest.com/gl/>Galego</option><option value=https://swiest.com/gu/>àª—à«àªœàª°àª¾àª¤à«€</option><option value=https://swiest.com/he/>×¢Ö´×‘×¨Ö´×™×ª</option><option value=https://swiest.com/km/>á€á˜áŸ’á–á»á‡á¶áŸ”</option><option value=https://swiest.com/hi/>à¤¹à¤¿à¤¨à¥à¤¦à¥€</option><option value=https://swiest.com/hr/>Hrvatski</option><option value=https://swiest.com/ht/>KreyÃ²l Ayisyen</option><option value=https://swiest.com/hu/>Magyar</option><option value=https://swiest.com/hy/>Õ€Õ¡ÕµÕ¥Ö€Õ¥Õ¶</option><option value=https://swiest.com/ig/>Ãsá»¥Ì€sá»¥Ì ÃŒgbÃ²</option><option value=https://swiest.com/id/>Bahasa Indonesia</option><option value=https://swiest.com/is/>Ãslenska</option><option value=https://swiest.com/it/>Italiano</option><option value=https://swiest.com/ja/>æ—¥æœ¬èª</option><option value=https://swiest.com/jv/>Basa Jawa</option><option value=https://swiest.com/ka/>áƒ¥áƒáƒ áƒ—áƒ£áƒšáƒ˜</option><option value=https://swiest.com/kk/>ÒšĞ°Ğ·Ğ°Ò›ÑˆĞ°</option><option value=https://swiest.com/kn/>à²•à²¨à³à²¨à²¡</option><option value=https://swiest.com/ko/>í•œêµ­ì–´</option><option value=https://swiest.com/or/>à¬“à¬¡à¬¼à¬¿à¬†</option><option value=https://swiest.com/ckb/>Ú©ÙˆØ±Ø¯ÛŒ</option><option value=https://swiest.com/ky/>ĞšÑ‹Ñ€Ğ³Ñ‹Ğ·Ñ‡Ğ°</option><option value=https://swiest.com/la/>Latina</option><option value=https://swiest.com/lb/>LÃ«tzebuergesch</option><option value=https://swiest.com/lo/>àºàº²àºªàº²àº¥àº²àº§</option><option value=https://swiest.com/lt/>LietuviÅ³</option><option value=https://swiest.com/lv/>LatvieÅ¡u</option><option value=https://swiest.com/mk/>ĞœĞ°ĞºĞµĞ´Ğ¾Ğ½ÑĞºĞ¸</option><option value=https://swiest.com/ml/>à´®à´²à´¯à´¾à´³à´‚</option><option value=https://swiest.com/mn/>ĞœĞ¾Ğ½Ğ³Ğ¾Ğ» Ñ…ÑĞ»</option><option value=https://swiest.com/mr/>à¤®à¤°à¤¾à¤ à¥€</option><option value=https://swiest.com/sw/>Kiswahili</option><option value=https://swiest.com/ms/>Bahasa Melayu</option><option value=https://swiest.com/my/>á€™á€¼á€”á€ºá€™á€¬</option><option value=https://swiest.com/ne/>à¤¨à¥‡à¤ªà¤¾à¤²à¥€</option><option value=https://swiest.com/nl/>Nederlands</option><option value=https://swiest.com/no/>Norsk</option><option value=https://swiest.com/pa/>à¨ªà©°à¨œà¨¾à¨¬à©€</option><option value=https://swiest.com/pl/>Polski</option><option value=https://swiest.com/pt-br/>PortuguÃªs Brasil</option><option value=https://swiest.com/pt-pt/>PortuguÃªs Europeu</option><option value=https://swiest.com/ro/>RomÃ¢nÄƒ</option><option value=https://swiest.com/ru/>Ğ ÑƒÑÑĞºĞ¸Ğ¹</option><option value=https://swiest.com/rw/>Kinyarwanda</option><option value=https://swiest.com/si/>à·ƒà·’à¶‚à·„à¶½</option><option value=https://swiest.com/sk/>SlovenÄina</option><option value=https://swiest.com/sl/>SlovenÅ¡Äina</option><option value=https://swiest.com/sq/>Shqip</option><option value=https://swiest.com/sr/>Ğ¡Ñ€Ğ¿ÑĞºĞ¸ (Srpski)</option><option value=https://swiest.com/su/>Basa Sunda</option><option value=https://swiest.com/sv/>Svenska</option><option value=https://swiest.com/ta/>à®¤à®®à®¿à®´à¯</option><option value=https://swiest.com/te/>à°¤à±†à°²à±à°—à±</option><option value=https://swiest.com/tg/>Ğ¢Ğ¾Ò·Ğ¸ĞºÓ£</option><option value=https://swiest.com/th/>à¹„à¸—à¸¢</option><option value=https://swiest.com/tk/>TÃ¼rkmenler</option><option value=https://swiest.com/tl/>Filipino</option><option value=https://swiest.com/tr/>TÃ¼rkÃ§e</option><option value=https://swiest.com/uk/>Ğ£ĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ°</option><option value=https://swiest.com/ur/>Ø§Ø±Ø¯Ùˆ</option><option value=https://swiest.com/uz/>O'zbekcha</option><option value=https://swiest.com/vi/>Tiáº¿ng Viá»‡t</option><option value=https://swiest.com/yi/>××™×“×™×©</option><option value=https://swiest.com/zh-hk/>ç²µèª</option><option value=https://swiest.com/zu/>IsiZulu</option></select></li><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><span>Dark Mode</span></li></div></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#video>Video</a></li><li><a href=#transcript>Transcript</a></li></ol></nav></div></section><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9206135835124064" crossorigin=anonymous></script><ins class=adsbygoogle style=display:block data-ad-client=ca-pub-9206135835124064 data-ad-slot=8754979142 data-ad-format=auto data-full-width-responsive=true></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script></aside><a id=back-to-top href=#><img src=/img/top_hu7c2829da96df0e9f8f0191d120020b22_22287_40x0_resize_box_3.png></a><main class="main full-width"><form action=/search/ class="search-form widget"><p><label>Search</label>
<input name=keyword required placeholder="Type something...">
<button title=Search><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg></button></p></form><article class=main-article><header class=article-header><div class=article-details><header class=article-tags><a href=/tags/english/>English
</a><a href=/tags/video-transcripts/>Video Transcripts
</a><a href=/tags/openai/>OpenAI</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/en/8iz5v3q0g9i/>Characterizing Test Time Compute on Graph Structurâ€¦ ï½œ Kudzo Ahegbebu ï½œ OpenAI Scholars Demo Day 2021 ï½œ OpenAI</a></h2></div><footer class=article-time><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg><time class=article-time--published>2023-11-06</time></div><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg><time class=article-time--reading>14 minute read</time></div></footer></div></header><div class=article-content><p style=text-align:center><a href=https://amzn.to/3Nrdcwk target=_blank>ğŸAmazon Prime</a>
<a href=https://amzn.to/3RIBkxg target=_blank>ğŸ“–Kindle Unlimited</a>
<a href=https://amzn.to/3Rqmudl target=_blank>ğŸ§Audible Plus</a>
<a href=https://amzn.to/3TuLbbj target=_blank>ğŸµAmazon Music Unlimited</a>
<a href="https://www.iherb.com/?rcode=EID1574" target=_blank>ğŸŒ¿iHerb</a>
<a href="https://accounts.binance.com/register?ref=72302422" target=_blank>ğŸ’°Binance</a></p></div><div><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9206135835124064" crossorigin=anonymous></script><ins class=adsbygoogle style=display:block data-ad-client=ca-pub-9206135835124064 data-ad-slot=8754979142 data-ad-format=auto data-full-width-responsive=true></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script></div><section class=article-content><h2 id=video>Video</h2><div class=video-wrapper><iframe loading=lazy src=https://www.youtube.com/embed/8iz5v3Q0g9I allowfullscreen title="YouTube Video"></iframe></div><h2 id=transcript>Transcript</h2><p>ï»¿uh hi um my</p><p>talk is going to be about characterizing</p><p>test time compute on graph structured</p><p>problems</p><p>um most of my scholars project has been</p><p>spent thinking about</p><p>uh this question of whether we can uh</p><p>create models</p><p>that continuously improve their outputs</p><p>the more compute that we give them at</p><p>test time</p><p>this is something that i&rsquo;ll call the</p><p>test time compute dream</p><p>and i think there&rsquo;s much anthromorphic</p><p>motivation here after all as humans when</p><p>we&rsquo;re being evaluated our answers</p><p>tend to become better the longer we&rsquo;re</p><p>given to think</p><p>machine learning models for the most</p><p>part don&rsquo;t exhibit this ability which</p><p>seems a little weird so i tend to bucket</p><p>this test time compute stuff</p><p>into two general categories one is</p><p>generalization</p><p>improvement mechanisms which deal with</p><p>the question of how can we create models</p><p>that use test time compute to learn more</p><p>general algorithms instead of learning</p><p>simple statistical associations and data</p><p>ideally we&rsquo;d like these models to use</p><p>the extra compute</p><p>to resolve ambiguity and to correct and</p><p>refine</p><p>their own answers the second side of</p><p>this coin</p><p>is efficiency stuff and this deals with</p><p>the question of how we can</p><p>decouple the amount of parameters that a</p><p>model has</p><p>from uh the amount of time that it takes</p><p>to run the model at inference with the</p><p>motivation</p><p>here being that if we can construct</p><p>models that are larger</p><p>but that don&rsquo;t incur a larger</p><p>computational cost for those extra</p><p>parameters than we would okay so how did</p><p>we</p><p>tackle this question</p><p>um the overwhelming vast majority of</p><p>this project was actually spent</p><p>on something i&rsquo;ll likely only spend a</p><p>single slide talking about</p><p>in the interest of time and that&rsquo;s the</p><p>shortest path task</p><p>the shortest path is a sequence to</p><p>sequence modeling task in which i give</p><p>the model a pair of</p><p>tokens representing pairs of u.s cities</p><p>and i expected to output</p><p>a sequence of target tokens that</p><p>represent the</p><p>shortest path between the destinations</p><p>the stuff i&rsquo;ll mostly be presenting on</p><p>only really took shape in the past three</p><p>or four weeks and it involved</p><p>investigating some of these test time</p><p>properties</p><p>on uh graph neural networks operating</p><p>over the game of sudoku</p><p>okay like i said most of my project was</p><p>spent on the shortest pathwork</p><p>in which we were trying to answer this</p><p>question if we control the</p><p>flop the total flop budget of um</p><p>our models is there ever a point where</p><p>the test time performance of models like</p><p>the one that you see on the left</p><p>which use this sort of top layer</p><p>occurrence</p><p>ever begins to approach or match the</p><p>performance of models that don&rsquo;t have</p><p>this recurrence but maybe are larger</p><p>have been trained for longer the way we</p><p>did this was by keeping the training</p><p>complete</p><p>budget in terms of flops fixed for all</p><p>the models and then training these</p><p>recurrent models</p><p>with a fixed number of time steps during</p><p>training with loss evaluated at every</p><p>single time step</p><p>and then during test time evaluating</p><p>them with more steps of recurrence</p><p>see if it ever reaches a point where the</p><p>extra compute</p><p>allows them to in some sense catch up to</p><p>the larger models that were trained</p><p>without this</p><p>recurrence long story short it largely</p><p>doesn&rsquo;t seem</p><p>to work we never really see this sort of</p><p>phase transition</p><p>recurrence alone doesn&rsquo;t seem to be</p><p>enough</p><p>to be clear if you run a linear probe on</p><p>the embedding space for these models</p><p>they actually seem to learn something</p><p>like the locations or something at least</p><p>isometric to the locations of the cities</p><p>fairly quickly which indicates that the</p><p>problem isn&rsquo;t actually learning where</p><p>the cities are</p><p>it seems to be that even with the extra</p><p>recurrence the extra compute</p><p>learning a general shortest path</p><p>algorithm</p><p>is difficult occurrence alone doesn&rsquo;t</p><p>seem to be enough</p><p>we need additional structure on top of</p><p>that</p><p>which is where the graph neural network</p><p>stuff comes in</p><p>so graph neural networks or networks</p><p>that operate on graph structured data</p><p>there are a few main parts the first</p><p>part is this input representation phase</p><p>where you pass in</p><p>your graph structured data x here</p><p>represents the nodes</p><p>in your graph which contain the features</p><p>that you care about</p><p>these could be the locations of u.s</p><p>cities or the values of cells on a</p><p>sudoku board</p><p>a represents the adjacencies which</p><p>encode some concept</p><p>of the edges of the graph in other words</p><p>what relationships</p><p>nodes have with each other the gnn</p><p>processes this graph by iteratively</p><p>performing a learned message passing</p><p>operation between the nodes where it</p><p>attempts to refine</p><p>its internal representation of those</p><p>nodes at the end</p><p>of this refinement phase we can then run</p><p>classification tasks on either the</p><p>individual nodes</p><p>or if we aggregate the nodes we can run</p><p>classification on the entire graph</p><p>okay a key feature of these gnns is this</p><p>graph refinement equation which i&rsquo;ll</p><p>come back to</p><p>at least twice in this presentation um</p><p>it looks wild in its general form but</p><p>all it really is is</p><p>just three parts um it says that the</p><p>hidden state</p><p>for a node i is updated by a function</p><p>that takes in</p><p>the node embedding for that node and all</p><p>pairs of that node&rsquo;s neighbors</p><p>passed through some function and then</p><p>aggregated using your favorite</p><p>aggregation function</p><p>cool okay so how do we do this for</p><p>sudoku</p><p>well every cell on the sudoku board</p><p>corresponds to a node</p><p>on the graph this node on the graph</p><p>the nodes on this graph refine their</p><p>representations by passing messages to</p><p>themselves or</p><p>or their neighbors using that graph</p><p>refinement equation we just saw</p><p>and now what&rsquo;s typically done is that</p><p>you run this graph refinement phase for</p><p>a fixed number of times let&rsquo;s say 10</p><p>time steps</p><p>and then at the very end you run your</p><p>linear projection and you make a</p><p>prediction</p><p>what we do a little differently here is</p><p>that we make a prediction at every point</p><p>along the graph refinement phase and we</p><p>evaluate the loss at every single point</p><p>as well</p><p>this allows the model to be more robust</p><p>to being evaluated during the graph for</p><p>fun</p><p>to being evaluated with more graph</p><p>refinement iterations at test time than</p><p>it was trained on</p><p>um at training</p><p>okay so how does this actually look like</p><p>in practice here&rsquo;s one solving sudoku</p><p>this is real data by the way what&rsquo;s cool</p><p>about this is that it appears to</p><p>prioritize spending the extra compute</p><p>resources</p><p>on attending to and refining tokens that</p><p>have assigned a</p><p>low probability high uncertainty to in</p><p>the previous time steps</p><p>the red things become more green and the</p><p>green things stay green</p><p>okay this is cool because it&rsquo;s a sign</p><p>that the test time computer dream is at</p><p>least in principle</p><p>possible if we look at this graph which</p><p>shows the gnn</p><p>operating over two data sets one is</p><p>normal and the other is hard</p><p>we see generalization in two different</p><p>senses</p><p>one as we increase the amount of</p><p>iterations or test time compute</p><p>we see that the accuracy of the network</p><p>improves in an almost</p><p>monotonically increasing way by the way</p><p>the accuracy here is measured on the</p><p>sequence level which means that</p><p>i only count it if it gets the entire</p><p>board correct</p><p>the other sense is that if we give the</p><p>network problems that are harder</p><p>than the ones it was trained on it still</p><p>performs well okay</p><p>so if the argument here is that more</p><p>test time compute more iterations is</p><p>good</p><p>what would happen if we could evaluate</p><p>this model at infinite depth</p><p>in other words could we do better in</p><p>order to answer this question we need to</p><p>steal the machinery of deep equilibrium</p><p>models</p><p>now i don&rsquo;t have a whole lot of time to</p><p>go into the details</p><p>of deep equilibrium models but i suggest</p><p>that you check out</p><p>the paper by xiao zubai or the europe&rsquo;s</p><p>workshop from this past year the gist is</p><p>that deep equilibrium models</p><p>are inspired by the observation that we</p><p>can often rewrite</p><p>a standard neural network as an implicit</p><p>function</p><p>that instead of specifying explicitly</p><p>how to compute</p><p>the layer&rsquo;s output as a function of its</p><p>input we instead specify the conditions</p><p>in which we would like the layer&rsquo;s</p><p>output to satisfy</p><p>after rewriting these layers as implicit</p><p>functions it turns out</p><p>that most of them converge to a fixed</p><p>point which allows us to</p><p>instead of keeping track of the</p><p>intermediaries that graph refinement</p><p>phase in our auto grad library we could</p><p>instead</p><p>use an arbitrary black box root finding</p><p>algorithm</p><p>and to evaluate this convergence point</p><p>this is equivalent to running an</p><p>infinite depth weight tied feed forward</p><p>network</p><p>but has the notable advantage that we</p><p>can analytically back</p><p>propagate through this equilibrium point</p><p>using something called the implicit</p><p>function theorem</p><p>cool um yeah how&rsquo;s this relevant to gnns</p><p>well if you take a look at that graph</p><p>refinement equation from earlier</p><p>it looks exactly like a fixed point</p><p>equation which means that we can apply</p><p>the machinery of deep equilibrium nuts</p><p>here if you try this out it actually</p><p>works really well with a big caveat that</p><p>i&rsquo;ll related to early stopping that i&rsquo;ll</p><p>get to in the next slide</p><p>these early training curves are</p><p>preliminary but kind of dramatic</p><p>the deep equilibrium sorry the deep</p><p>equilibrium</p><p>gnn trains a lot faster than the</p><p>traditional gnn</p><p>further because we&rsquo;re using the</p><p>machinery of d people agreements to save</p><p>us from having to keep</p><p>track of the intermediate steps of that</p><p>graph refinement phase</p><p>in our auto grad library the memory</p><p>usage of the dp equilibrium</p><p>is smaller than the regular one as well</p><p>okay so what&rsquo;s the caveat</p><p>well uh as far as i can tell every</p><p>single time i&rsquo;ve been</p><p>uh i&rsquo;ve run this i&rsquo;ve run into this</p><p>weird collapse</p><p>that happens where it starts training</p><p>and it&rsquo;s doing really great</p><p>and then it dies and i haven&rsquo;t quite</p><p>been able to figure out why this happens</p><p>i suspect it has to do with the growth</p><p>of the spectral norm of the operators</p><p>inside the gnn</p><p>as it&rsquo;s being evaluated by the fixed</p><p>point iterator but it also</p><p>just could be a bug in my code um</p><p>stopping training early when this</p><p>degeneracy begins is proven to be fine</p><p>and i&rsquo;m still investigating the problem</p><p>but i just wanted to point this out for</p><p>completeness</p><p>okay shifting gears a little bit can we</p><p>do better</p><p>still in another way gnns are fine as</p><p>we&rsquo;ve seen they seem to do well</p><p>on these relational reasoning style</p><p>tasks but one potential oddity is that</p><p>we must be explicit about the network</p><p>the structure of the network of the</p><p>graph that is we must explicitly tell</p><p>the network which nodes are connected to</p><p>each other nodes</p><p>for sudoku for instance we must be</p><p>explicit about saying that things that</p><p>are in the same row</p><p>things that are in the same column</p><p>things that are in the same cell</p><p>are connected could we instead learn the</p><p>adjacencies from scratch from the raw</p><p>unstructured data here&rsquo;s the idea</p><p>okay transformers seem to be pretty good</p><p>at learning how</p><p>how relevant pairs of tokens are to each</p><p>other</p><p>on the other hand gnns are good at</p><p>operating over</p><p>structured data what if we could use the</p><p>tension head from a standard transformer</p><p>to extract an adjacency matrix which we</p><p>then feed into</p><p>the gnn here&rsquo;s how it works we first</p><p>feed</p><p>a small transformer our input with a</p><p>small modification that at the top</p><p>layer we use the probability scores to</p><p>categorically sample the top k</p><p>indices which are the most relevant to</p><p>that particular token</p><p>that extracts k neighborhoods for each</p><p>token which we can then feed into our</p><p>tnn</p><p>now sampling indices is a</p><p>non-differentiable operation</p><p>however we can compensate for this by</p><p>using the surrogate loss thing outlined</p><p>below</p><p>this is taken from a paper by john</p><p>shulman and</p><p>uh it just provides a general framework</p><p>for gradient estimation through</p><p>stochastic compute graphs</p><p>the formulism just gives us a way to</p><p>convert stochastic compute graphs into</p><p>deterministic compute graphs</p><p>and evaluate a surrogate loss using</p><p>standard back propagation that provides</p><p>an</p><p>unbiased estimator of the gradient</p><p>through the stochastic node</p><p>cool okay so if you try this out it</p><p>works kind of um the reality is that it</p><p>just</p><p>trains much slower than the standard gnn</p><p>and</p><p>you know vanilla policy gradients are</p><p>high variance they&rsquo;re kind of messy</p><p>but and the performance actually is</p><p>worse than the standard gnn but it does</p><p>show that in principle we could train a</p><p>gnn</p><p>from scratch that learns the adjacencies</p><p>from scratch as well which is</p><p>kind of cool okay</p><p>conclusion yeah so uh test time compute</p><p>mechanisms i think are largely</p><p>underexplored but hold much promise they</p><p>have the potential for improved</p><p>generalization mechanisms</p><p>potential for improved sample efficiency</p><p>i think</p><p>recurrence plus message passing seems to</p><p>be a really interesting combination</p><p>and if the methods of this presentation</p><p>seem</p><p>uh contrived that&rsquo;s because they are but</p><p>ultimately like i&rsquo;m</p><p>while the specific methods are kind of</p><p>crude i&rsquo;m bullish on the idea of test</p><p>time compute in general and i think that</p><p>the next few years we&rsquo;ll see</p><p>critical breakthroughs that make use of</p><p>ideas that have test time compute at</p><p>their core</p><p>that&rsquo;s it i&rsquo;d like to thank my mentor</p><p>will gus and i&rsquo;d also like to thank</p><p>uh the program organizers and my cohort</p><p>and uh all the people that um gave me</p><p>early feedback</p><p>on uh some of this stuff and thank you</p><p>and now i&rsquo;ll take questions</p><p>uh let&rsquo;s see let me stop sharing</p><p>okay so this first question here</p><p>is</p><p>how do i extend this gnn setting to</p><p>sequence modeling</p><p>like the language modeling loss in uh</p><p>gpt</p><p>yeah so um you could imagine that each</p><p>output token corresponds to either</p><p>uh yeah you could do this in a couple</p><p>ways like you could imagine like an auto</p><p>regressive type thing</p><p>where like you&rsquo;re at each point</p><p>evaluating the state of the entire graph</p><p>and outputting an output sequence and</p><p>then feeding that output sequence into</p><p>uh the sort of beginning of the model</p><p>and then running this again</p><p>doing this sort of auto aggressively is</p><p>one way um</p><p>and then yeah but i&rsquo;m sure there are</p><p>other ways that i&rsquo;m just not</p><p>familiar with but yeah so what type of</p><p>problems you expect test time to</p><p>compute to really shine in yeah this is</p><p>a great question i think</p><p>sorry my dog gets really excited here uh</p><p>i think ultimately</p><p>uh test time compute will shine in</p><p>problems that really have sort of these</p><p>relational reasoning style tasks where</p><p>we need to</p><p>relate our previous outputs to</p><p>things that we&rsquo;re currently processing</p><p>or problems where we need to condition</p><p>the amount of computes that we do on the</p><p>complexity of our inputs</p><p>okay uh does the stochastic compute</p><p>graph mean that gnns can be applied to</p><p>settings without inductive biases</p><p>that&rsquo;s the ultimate hope i think this is</p><p>just very crude early work that shows</p><p>that you could</p><p>potentially also just learn the</p><p>adjacencies without</p><p>hand uh baking the inductive bias though</p><p>i mean i think part of the appeal of</p><p>graph neural networks is that like</p><p>they&rsquo;re so easy to bake in inductive</p><p>biases that you just</p><p>feed in the graph as</p><p>it is and that is the inductive bias for</p><p>your data</p><p>so there&rsquo;s definitely a trade-off here</p><p>and it&rsquo;s not like super clear that doing</p><p>this is like</p><p>always the right thing to do okay last</p><p>question</p><p>what does it look like if you threshold</p><p>the learned adjacency</p><p>weights to produce a discrete graph</p><p>structure is</p><p>is this roughly right threshold the</p><p>learned adjacency weights</p><p>oh right so yeah that&rsquo;s that&rsquo;s a good</p><p>point</p><p>these are discrete that&rsquo;s the whole</p><p>point of the sampling thing</p><p>is that the adjacencies are the indices</p><p>for each token which correspond to the</p><p>other tokens that are</p><p>are um they&rsquo;re near it so this isn&rsquo;t</p><p>like a tension where we&rsquo;re doing like a</p><p>soft max over</p><p>over um over the other output tokens</p><p>like</p><p>we&rsquo;re using the transformers probability</p><p>scores</p><p>and then we&rsquo;re discretely sampling like</p><p>which we&rsquo;re using the transformers</p><p>attention</p><p>uh scores asks our weights</p><p>for our discrete sampling if that makes</p><p>sense</p><p>um but yeah cool</p><p>i think i&rsquo;m over time so um</p><p>yeah i&rsquo;ll hand it back over to francis i</p><p>guess</p></section><footer class=article-footer><section class=article-tags><a href=/tags/english/>English</a>
<a href=/tags/video-transcripts/>Video Transcripts</a>
<a href=/tags/openai/>OpenAI</a></section></footer></article><div><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9206135835124064" crossorigin=anonymous></script><ins class=adsbygoogle style=display:block;text-align:center data-ad-layout=in-article data-ad-format=fluid data-ad-client=ca-pub-9206135835124064 data-ad-slot=1055602464></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script></div><aside class=related-content--wrapper><h2 class=section-title>Related content</h2><div class=related-content><div class="flex article-list--tile"><article><a href=/en/at2xkqjazns/><div class=article-image><img src=/img/related-content.png loading=lazy data-key=en/AT2XkqJAZns data-hash style=opacity:.3></div><div class=article-details><h2 class=article-title>Towards Epileptic Seizure Prediction with Deep Network ï½œ Kata Slama ï½œ OpenAI Scholars Demo Day 2020 ï½œ OpenAI</h2></div></a></article><article><a href=/en/jzohw-eybtq/><div class=article-image><img src=/img/related-content.png loading=lazy data-key=en/JZOHW-eYBtQ data-hash style=opacity:.3></div><div class=article-details><h2 class=article-title>Introductions by Sam Altman & Greg Brockman ï½œ OpenAI Scholars Demo Day 2020 ï½œ OpenAI</h2></div></a></article><article><a href=/en/-fozam9xqs4/><div class=article-image><img src=/img/related-content.png loading=lazy data-key=en/-FoZAM9xqS4 data-hash style=opacity:.3></div><div class=article-details><h2 class=article-title>OpenAI Five vs. OG, Game 2 ï½œ OpenAI Five Finals (4â§¸6) ï½œ OpenAI</h2></div></a></article><article><a href=/en/u9mjuukhuzk/><div class=article-image><img src=/img/related-content.png loading=lazy data-key=en/U9mJuUkhUzk data-hash style=opacity:.3></div><div class=article-details><h2 class=article-title>OpenAI DevDay, Opening Keynote ï½œ OpenAI</h2></div></a></article><article><a href=/en/lpe5gwuqa-k/><div class=article-image><img src=/img/related-content.png loading=lazy data-key=en/lpe5Gwuqa-k data-hash style=opacity:.3></div><div class=article-details><h2 class=article-title>Scaling Laws for Language Transfer Learning ï½œ Christina Kim ï½œ OpenAI Scholars Demo Day 2021 ï½œ OpenAI</h2></div></a></article></div></div></aside><footer class=site-footer><section class=copyright>&copy;
2021 -
2023 SWIEST - Transcripts Â· Screenplays Â· Lyrics</section><section class=powerby>As an Amazon Associate I earn from qualifying purchases ğŸ›’<br>Built with <a href=https://swiest.com/ target=_blank rel=noopener>(ï¾‰â—•ãƒ®â—•)ï¾‰ğŸª„ğŸ’ğŸ’–ğŸ¥° across the glğŸŒğŸŒğŸŒbe</a><br></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Noto+Serif&family=Noto+Serif+Armenian&family=Noto+Serif+Bengali&family=Noto+Serif+Devanagari&family=Noto+Serif+Georgian&family=Noto+Serif+Gujarati&family=Noto+Serif+HK&family=Noto+Serif+Hebrew&family=Noto+Serif+JP&family=Noto+Serif+KR&family=Noto+Serif+Kannada&family=Noto+Serif+Khmer&family=Noto+Serif+Lao&family=Noto+Serif+Makasar&family=Noto+Serif+Malayalam&family=Noto+Serif+Myanmar&family=Noto+Serif+Oriya&family=Noto+Serif+SC&family=Noto+Serif+Sinhala&family=Noto+Serif+TC&family=Noto+Serif+Tamil&family=Noto+Serif+Telugu&family=Noto+Serif+Thai&family=Noto+Serif+Tibetan&display=swap" rel=stylesheet></body></html>