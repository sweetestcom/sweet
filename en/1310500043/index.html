<!DOCTYPE html>
<html lang="en" dir="ltr">
    <head><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content='The following is a conversation with Gary Marcus.
He&amp;rsquo;s a professor emeritus at NYU,
founder of Robust AI and Geometric Intelligence.
The latter is a machine learning company
that was acquired by Uber in 2016.
He&amp;rsquo;s the author of several books,
Unnatural and Artificial Intelligence,
including his new book, Rebooting AI,
Building Machines We Can Trust.
Gary has been a critical voice,
highlighting the limits of deep learning and AI in general'>
<title>Lex Fridman Podcast - #43 - Gary Marcus: Toward a Hybrid of Deep Learning and Symbolic AI | SWIEST</title>

<link rel='canonical' href='https://swiest.com/en/1310500043/'>

<link rel="stylesheet" href="/scss/style.min.91b18679590f4ceed910ade4d64b1e7375cc0770ef5b8c1d822f42424f9ff2c8.css"><script>
    document.oncontextmenu = function(){ return false; };
    document.onselectstart = function(){ return false; };
    document.oncopy = function(){ return false; };
    document.oncut = function(){ return false; };
</script>

<script src="https://apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js"></script>


<script type="text/javascript">
    $(document).ready(function(){
     
     $("#back-to-top").hide();
     
     $(function () {
      $(window).scroll(function(){
       if ($(window).scrollTop()>600){
        $("#back-to-top").fadeIn(500);
       }else{
        $("#back-to-top").fadeOut(500);
       }
     });
     
     $("#back-to-top").click(function(){
      $('body,html').animate({scrollTop:0},500);
       return false;
      });
     });
    });
    </script><meta property='og:title' content='Lex Fridman Podcast - #43 - Gary Marcus: Toward a Hybrid of Deep Learning and Symbolic AI'>
<meta property='og:description' content='The following is a conversation with Gary Marcus.
He&amp;rsquo;s a professor emeritus at NYU,
founder of Robust AI and Geometric Intelligence.
The latter is a machine learning company
that was acquired by Uber in 2016.
He&amp;rsquo;s the author of several books,
Unnatural and Artificial Intelligence,
including his new book, Rebooting AI,
Building Machines We Can Trust.
Gary has been a critical voice,
highlighting the limits of deep learning and AI in general'>
<meta property='og:url' content='https://swiest.com/en/1310500043/'>
<meta property='og:site_name' content='SWIEST - Transcripts ¬∑ Screenplays ¬∑ Lyrics'>
<meta property='og:type' content='article'><meta property='article:section' content='Post' /><meta property='article:tag' content='English' /><meta property='article:tag' content='Podcast' /><meta property='article:tag' content='Lex Fridman Podcast' /><meta property='article:published_time' content='2022-04-12T17:00:00&#43;00:00'/><meta property='article:modified_time' content='2022-04-12T17:00:00&#43;00:00'/>
<meta name="twitter:title" content="Lex Fridman Podcast - #43 - Gary Marcus: Toward a Hybrid of Deep Learning and Symbolic AI">
<meta name="twitter:description" content="The following is a conversation with Gary Marcus.
He&amp;rsquo;s a professor emeritus at NYU,
founder of Robust AI and Geometric Intelligence.
The latter is a machine learning company
that was acquired by Uber in 2016.
He&amp;rsquo;s the author of several books,
Unnatural and Artificial Intelligence,
including his new book, Rebooting AI,
Building Machines We Can Trust.
Gary has been a critical voice,
highlighting the limits of deep learning and AI in general">
    <link rel="shortcut icon" href="/favicon.ico" />
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9206135835124064" crossorigin="anonymous"></script>
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    </head>
    <body class="
    article-page
    ">
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "dark");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky ">
    <button class="hamburger hamburger--spin" type="button" id="toggle-menu" aria-label="Toggle Menu">
        <span class="hamburger-box">
            <span class="hamburger-inner"></span>
        </span>
    </button>

    <header>
        
            
            <figure class="site-avatar">
                <a href="/">
                
                    
                    
                    
                        
                        <img src="/img/avatar_hu307e6a33fa6fd661ccda3b77024ef5c2_252345_300x0_resize_box_3.png" width="300"
                            height="300" class="site-logo" loading="lazy" alt="Avatar">
                    
                
                </a>
                
                    <span class="emoji">‚ú®</span>
                
            </figure>
            
        
        
        <div class="site-meta">
            <h1 class="site-name"><a href="/">SWIEST - Transcripts ¬∑ Screenplays ¬∑ Lyrics</a></h1>
            <h2 class="site-description">üåçüåèüåé</h2>
        </div>
    </header><ol class="menu" id="main-menu">
        
        
        
        <li >
            <a href='/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <polyline points="5 12 3 12 12 3 21 12 19 12" />
  <path d="M5 12v7a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-7" />
  <path d="M9 21v-6a2 2 0 0 1 2 -2h2a2 2 0 0 1 2 2v6" />
</svg>



                
                <span>Home</span>
            </a>
        </li>
        
        
        <li >
            <a href='/archives/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <rect x="3" y="4" width="18" height="4" rx="2" />
  <path d="M5 8v10a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-10" />
  <line x1="10" y1="12" x2="14" y2="12" />
</svg>



                
                <span>Archives</span>
            </a>
        </li>
        
        
        <li >
            <a href='/search/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="10" cy="10" r="7" />
  <line x1="21" y1="21" x2="15" y2="15" />
</svg>



                
                <span>Search</span>
            </a>
        </li>
        
        
        <li >
            <a href='/chart/podcastchart.html' target="_blank">
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-apple-podcast" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="#ffffff" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M18.364 18.364a9 9 0 1 0 -12.728 0" />
  <path d="M11.766 22h.468a2 2 0 0 0 1.985 -1.752l.5 -4a2 2 0 0 0 -1.985 -2.248h-1.468a2 2 0 0 0 -1.985 2.248l.5 4a2 2 0 0 0 1.985 1.752z" />
  <path d="M12 9m-2 0a2 2 0 1 0 4 0a2 2 0 1 0 -4 0" />
</svg>
                
                <span>Podcast Charts</span>
            </a>
        </li>
        

        <div class="menu-bottom-section">
                <li id="i18n-switch">  
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-language" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M4 5h7" />
  <path d="M9 3v2c0 4.418 -2.239 8 -5 8" />
  <path d="M5 9c-.003 2.144 2.952 3.908 6.7 4" />
  <path d="M12 20l4 -9l4 9" />
  <path d="M19.1 18h-6.2" />
</svg>



                    <select name="language" onchange="window.location.href = this.selectedOptions[0].value">
                        
                            <option value="https://swiest.com/" selected>English</option>
                        
                            <option value="https://swiest.com/af/" >Afrikaans</option>
                        
                            <option value="https://swiest.com/am/" >·ä†·àõ·à≠·äõ</option>
                        
                            <option value="https://swiest.com/ar/" >ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</option>
                        
                            <option value="https://swiest.com/az/" >Az…ôrbaycan</option>
                        
                            <option value="https://swiest.com/be/" >–±–µ–ª–∞—Ä—É—Å–∫—ñ</option>
                        
                            <option value="https://swiest.com/bg/" >–±—ä–ª–≥–∞—Ä—Å–∫–∏</option>
                        
                            <option value="https://swiest.com/bn/" >‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ</option>
                        
                            <option value="https://swiest.com/bo/" >‡Ωñ‡Ωº‡Ωë‡ºã‡Ω¶‡æê‡Ωë‡ºã</option>
                        
                            <option value="https://swiest.com/bs/" >Bosanski</option>
                        
                            <option value="https://swiest.com/ca/" >Catal√†</option>
                        
                            <option value="https://swiest.com/zh-hans/" >ÁÆÄ‰Ωì‰∏≠Êñá</option>
                        
                            <option value="https://swiest.com/zh-hant/" >ÁπÅÈ´î‰∏≠Êñá</option>
                        
                            <option value="https://swiest.com/cs/" >ƒåe≈°tina</option>
                        
                            <option value="https://swiest.com/el/" >ŒµŒªŒªŒ∑ŒΩŒπŒ∫Œ¨</option>
                        
                            <option value="https://swiest.com/cy/" >Cymraeg</option>
                        
                            <option value="https://swiest.com/da/" >Dansk</option>
                        
                            <option value="https://swiest.com/de/" >Deutsch</option>
                        
                            <option value="https://swiest.com/eo/" >Esperanto</option>
                        
                            <option value="https://swiest.com/es-es/" >Espa√±ol (Espa√±a)</option>
                        
                            <option value="https://swiest.com/es-419/" >Espa√±ol (Latinoam√©rica)</option>
                        
                            <option value="https://swiest.com/et/" >Eesti</option>
                        
                            <option value="https://swiest.com/eu/" >Euskara</option>
                        
                            <option value="https://swiest.com/haw/" > ª≈ålelo Hawai ªi</option>
                        
                            <option value="https://swiest.com/fa/" >ŸÅÿßÿ±ÿ≥€å</option>
                        
                            <option value="https://swiest.com/fi/" >Suomi</option>
                        
                            <option value="https://swiest.com/fo/" >F√∏royskt</option>
                        
                            <option value="https://swiest.com/fr/" >Fran√ßais</option>
                        
                            <option value="https://swiest.com/fy/" >Frysk</option>
                        
                            <option value="https://swiest.com/ga/" >Gaeilge</option>
                        
                            <option value="https://swiest.com/gl/" >Galego</option>
                        
                            <option value="https://swiest.com/gu/" >‡™ó‡´Å‡™ú‡™∞‡™æ‡™§‡´Ä</option>
                        
                            <option value="https://swiest.com/he/" >◊¢÷¥◊ë◊®÷¥◊ô◊™</option>
                        
                            <option value="https://swiest.com/km/" >·ûÄ·ûò·üí·ûñ·ûª·ûá·û∂·üî</option>
                        
                            <option value="https://swiest.com/hi/" >‡§π‡§ø‡§®‡•ç‡§¶‡•Ä</option>
                        
                            <option value="https://swiest.com/hr/" >Hrvatski</option>
                        
                            <option value="https://swiest.com/ht/" >Krey√≤l Ayisyen</option>
                        
                            <option value="https://swiest.com/hu/" >Magyar</option>
                        
                            <option value="https://swiest.com/hy/" >’Ä’°’µ’•÷Ä’•’∂</option>
                        
                            <option value="https://swiest.com/ig/" >√Ås·ª•ÃÄs·ª•ÃÅ √ågb√≤</option>
                        
                            <option value="https://swiest.com/id/" >Bahasa Indonesia</option>
                        
                            <option value="https://swiest.com/is/" >√çslenska</option>
                        
                            <option value="https://swiest.com/it/" >Italiano</option>
                        
                            <option value="https://swiest.com/ja/" >Êó•Êú¨Ë™û</option>
                        
                            <option value="https://swiest.com/jv/" >Basa Jawa</option>
                        
                            <option value="https://swiest.com/ka/" >·É•·Éê·É†·Éó·É£·Éö·Éò</option>
                        
                            <option value="https://swiest.com/kk/" >“ö–∞–∑–∞“õ—à–∞</option>
                        
                            <option value="https://swiest.com/kn/" >‡≤ï‡≤®‡≥ç‡≤®‡≤°</option>
                        
                            <option value="https://swiest.com/ko/" >ÌïúÍµ≠Ïñ¥</option>
                        
                            <option value="https://swiest.com/or/" >‡¨ì‡¨°‡¨º‡¨ø‡¨Ü</option>
                        
                            <option value="https://swiest.com/ckb/" >⁄©Ÿàÿ±ÿØ€å</option>
                        
                            <option value="https://swiest.com/ky/" >–ö—ã—Ä–≥—ã–∑—á–∞</option>
                        
                            <option value="https://swiest.com/la/" >Latina</option>
                        
                            <option value="https://swiest.com/lb/" >L√´tzebuergesch</option>
                        
                            <option value="https://swiest.com/lo/" >‡∫û‡∫≤‡∫™‡∫≤‡∫•‡∫≤‡∫ß</option>
                        
                            <option value="https://swiest.com/lt/" >Lietuvi≈≥</option>
                        
                            <option value="https://swiest.com/lv/" >Latvie≈°u</option>
                        
                            <option value="https://swiest.com/mk/" >–ú–∞–∫–µ–¥–æ–Ω—Å–∫–∏</option>
                        
                            <option value="https://swiest.com/ml/" >‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç</option>
                        
                            <option value="https://swiest.com/mn/" >–ú–æ–Ω–≥–æ–ª —Ö—ç–ª</option>
                        
                            <option value="https://swiest.com/mr/" >‡§Æ‡§∞‡§æ‡§†‡•Ä</option>
                        
                            <option value="https://swiest.com/sw/" >Kiswahili</option>
                        
                            <option value="https://swiest.com/ms/" >Bahasa Melayu</option>
                        
                            <option value="https://swiest.com/my/" >·Äô·Äº·Äî·Ä∫·Äô·Ä¨</option>
                        
                            <option value="https://swiest.com/ne/" >‡§®‡•á‡§™‡§æ‡§≤‡•Ä</option>
                        
                            <option value="https://swiest.com/nl/" >Nederlands</option>
                        
                            <option value="https://swiest.com/no/" >Norsk</option>
                        
                            <option value="https://swiest.com/pa/" >‡®™‡©∞‡®ú‡®æ‡®¨‡©Ä</option>
                        
                            <option value="https://swiest.com/pl/" >Polski</option>
                        
                            <option value="https://swiest.com/pt-br/" >Portugu√™s Brasil</option>
                        
                            <option value="https://swiest.com/pt-pt/" >Portugu√™s Europeu</option>
                        
                            <option value="https://swiest.com/ro/" >Rom√¢nƒÉ</option>
                        
                            <option value="https://swiest.com/ru/" >–†—É—Å—Å–∫–∏–π</option>
                        
                            <option value="https://swiest.com/rw/" >Kinyarwanda</option>
                        
                            <option value="https://swiest.com/si/" >‡∑É‡∑í‡∂Ç‡∑Ñ‡∂Ω</option>
                        
                            <option value="https://swiest.com/sk/" >Slovenƒçina</option>
                        
                            <option value="https://swiest.com/sl/" >Sloven≈°ƒçina</option>
                        
                            <option value="https://swiest.com/sq/" >Shqip</option>
                        
                            <option value="https://swiest.com/sr/" >–°—Ä–ø—Å–∫–∏ (Srpski)</option>
                        
                            <option value="https://swiest.com/su/" >Basa Sunda</option>
                        
                            <option value="https://swiest.com/sv/" >Svenska</option>
                        
                            <option value="https://swiest.com/ta/" >‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç</option>
                        
                            <option value="https://swiest.com/te/" >‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å</option>
                        
                            <option value="https://swiest.com/tg/" >–¢–æ“∑–∏–∫”£</option>
                        
                            <option value="https://swiest.com/th/" >‡πÑ‡∏ó‡∏¢</option>
                        
                            <option value="https://swiest.com/tl/" >Filipino</option>
                        
                            <option value="https://swiest.com/tr/" >T√ºrk√ße</option>
                        
                            <option value="https://swiest.com/uk/" >–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞</option>
                        
                            <option value="https://swiest.com/ur/" >ÿßÿ±ÿØŸà</option>
                        
                            <option value="https://swiest.com/uz/" >O&#39;zbekcha</option>
                        
                            <option value="https://swiest.com/vi/" >Ti·∫øng Vi·ªát</option>
                        
                            <option value="https://swiest.com/yi/" >◊ê◊ô◊ì◊ô◊©</option>
                        
                            <option value="https://swiest.com/zh-hk/" >Á≤µË™û</option>
                        
                            <option value="https://swiest.com/zu/" >IsiZulu</option>
                        
                    </select>
                </li>
            
            
            
                <li id="dark-mode-toggle">
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="8" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="16" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                    <span>Dark Mode</span>
                </li>
            
        </div>
    </ol>
</aside>

    

            <main class="main full-width">
    <article class="main-article">
    <header class="article-header">

    <div class="article-details">
    
    <header class="article-category">
        
            <a href="/categories/podcast/" >
                Podcast
            </a>
        
            <a href="/categories/lex-fridman-podcast/" >
                Lex Fridman Podcast
            </a>
        
    </header>
    

    <div class="article-title-wrapper">
        <h2 class="article-title">
            <a href="/en/1310500043/">Lex Fridman Podcast - #43 - Gary Marcus: Toward a Hybrid of Deep Learning and Symbolic AI</a>
        </h2>
    
        
    </div>

    
    
    
    
    <footer class="article-time">
        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M11.795 21h-6.795a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v4" />
  <circle cx="18" cy="18" r="4" />
  <path d="M15 3v4" />
  <path d="M7 3v4" />
  <path d="M3 11h16" />
  <path d="M18 16.496v1.504l1 1" />
</svg>
                <time class="article-time--published">2022-04-12</time>
            </div>
        

        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



                <time class="article-time--reading">
                    75 minute read
                </time>
            </div>
        
    </footer>
    

    
</div>

</header>
<div class="article-translations">
    <ul>üéÅ<a href="https://amzn.to/471i0jl" target="_blank">üõíAmazon Prime</a>
       <a href="https://amzn.to/3QDVlVf" target="_blank">üìñKindle Unlimited</a>
       <a href="https://amzn.to/3FqzNoB" target="_blank">üéßAudible Plus</a>
       <a href="https://amzn.to/3tMT3dm" target="_blank">üéµAmazon Music Unlimited</a>
       <a href="https://www.iherb.com/?rcode=EID1574" target="_blank">üåøiHerb</a>
</ul>
</div>
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9206135835124064"
     crossorigin="anonymous"></script>
    
    <ins class="adsbygoogle"
         style="display:block"
         data-ad-client="ca-pub-9206135835124064"
         data-ad-slot="8754979142"
         data-ad-format="auto"
         data-full-width-responsive="true"></ins>
    <script>
         (adsbygoogle = window.adsbygoogle || []).push({});
    </script>
</div>


    <section class="article-content">
    
    
    <p>The following is a conversation with Gary Marcus.</p>
<p>He&rsquo;s a professor emeritus at NYU,</p>
<p>founder of Robust AI and Geometric Intelligence.</p>
<p>The latter is a machine learning company</p>
<p>that was acquired by Uber in 2016.</p>
<p>He&rsquo;s the author of several books,</p>
<p>Unnatural and Artificial Intelligence,</p>
<p>including his new book, Rebooting AI,</p>
<p>Building Machines We Can Trust.</p>
<p>Gary has been a critical voice,</p>
<p>highlighting the limits of deep learning and AI in general</p>
<p>and discussing the challenges before our AI community</p>
<p>that must be solved in order to achieve</p>
<p>artificial general intelligence.</p>
<p>As I&rsquo;m having these conversations,</p>
<p>I try to find paths toward insight, towards new ideas.</p>
<p>I try to have no ego in the process.</p>
<p>It gets in the way.</p>
<p>I&rsquo;ll often continuously try on several hats, several roles.</p>
<p>One, for example, is the role of a three year old</p>
<p>who understands very little about anything</p>
<p>and asks big what and why questions.</p>
<p>The other might be a role of a devil&rsquo;s advocate</p>
<p>who presents counter ideas with the goal of arriving</p>
<p>at greater understanding through debate.</p>
<p>Hopefully, both are useful, interesting,</p>
<p>and even entertaining at times.</p>
<p>I ask for your patience as I learn</p>
<p>to have better conversations.</p>
<p>This is the Artificial Intelligence Podcast.</p>
<p>If you enjoy it, subscribe on YouTube,</p>
<p>give it five stars on iTunes, support it on Patreon,</p>
<p>or simply connect with me on Twitter</p>
<p>at Lex Friedman, spelled F R I D M A N.</p>
<p>And now, here&rsquo;s my conversation with Gary Marcus.</p>
<p>Do you think human civilization will one day have</p>
<p>to face an AI driven technological singularity</p>
<p>that will, in a societal way,</p>
<p>modify our place in the food chain</p>
<p>of intelligent living beings on this planet?</p>
<p>I think our place in the food chain has already changed.</p>
<p>So there are lots of things people used to do by hand</p>
<p>that they do with machine.</p>
<p>If you think of a singularity as like one single moment,</p>
<p>which is, I guess, what it suggests,</p>
<p>I don&rsquo;t know if it&rsquo;ll be like that,</p>
<p>but I think that there&rsquo;s a lot of gradual change</p>
<p>and AI is getting better and better.</p>
<p>I mean, I&rsquo;m here to tell you why I think it&rsquo;s not nearly</p>
<p>as good as people think, but the overall trend is clear.</p>
<p>Maybe Rick Hertzweil thinks it&rsquo;s an exponential</p>
<p>and I think it&rsquo;s linear.</p>
<p>In some cases, it&rsquo;s close to zero right now,</p>
<p>but it&rsquo;s all gonna happen.</p>
<p>I mean, we are gonna get to human level intelligence</p>
<p>or whatever you want, artificial general intelligence</p>
<p>at some point, and that&rsquo;s certainly gonna change</p>
<p>our place in the food chain,</p>
<p>because a lot of the tedious things that we do now,</p>
<p>we&rsquo;re gonna have machines do,</p>
<p>and a lot of the dangerous things that we do now,</p>
<p>we&rsquo;re gonna have machines do.</p>
<p>I think our whole lives are gonna change</p>
<p>from people finding their meaning through their work</p>
<p>through people finding their meaning</p>
<p>through creative expression.</p>
<p>So the singularity will be a very gradual,</p>
<p>in fact, removing the meaning of the word singularity.</p>
<p>It&rsquo;ll be a very gradual transformation in your view.</p>
<p>I think that it&rsquo;ll be somewhere in between,</p>
<p>and I guess it depends what you mean by gradual and sudden.</p>
<p>I don&rsquo;t think it&rsquo;s gonna be one day.</p>
<p>I think it&rsquo;s important to realize</p>
<p>that intelligence is a multidimensional variable.</p>
<p>So people sort of write this stuff</p>
<p>as if IQ was one number, and the day that you hit 262</p>
<p>or whatever, you displace the human beings.</p>
<p>And really, there&rsquo;s lots of facets to intelligence.</p>
<p>So there&rsquo;s verbal intelligence,</p>
<p>and there&rsquo;s motor intelligence,</p>
<p>and there&rsquo;s mathematical intelligence and so forth.</p>
<p>Machines, in their mathematical intelligence,</p>
<p>far exceed most people already.</p>
<p>In their ability to play games,</p>
<p>they far exceed most people already.</p>
<p>In their ability to understand language,</p>
<p>they lag behind my five year old,</p>
<p>far behind my five year old.</p>
<p>So there are some facets of intelligence</p>
<p>that machines have grasped, and some that they haven&rsquo;t,</p>
<p>and we have a lot of work left to do</p>
<p>to get them to, say, understand natural language,</p>
<p>or to understand how to flexibly approach</p>
<p>some kind of novel MacGyver problem solving</p>
<p>kind of situation.</p>
<p>And I don&rsquo;t know that all of these things will come at once.</p>
<p>I think there are certain vital prerequisites</p>
<p>that we&rsquo;re missing now.</p>
<p>So for example, machines don&rsquo;t really have common sense now.</p>
<p>So they don&rsquo;t understand that bottles contain water,</p>
<p>and that people drink water to quench their thirst,</p>
<p>and that they don&rsquo;t wanna dehydrate.</p>
<p>They don&rsquo;t know these basic facts about human beings,</p>
<p>and I think that that&rsquo;s a rate limiting step</p>
<p>for many things.</p>
<p>It&rsquo;s a great limiting step for reading, for example,</p>
<p>because stories depend on things like,</p>
<p>oh my God, that person&rsquo;s running out of water.</p>
<p>That&rsquo;s why they did this thing.</p>
<p>Or if they only had water, they could put out the fire.</p>
<p>So you watch a movie, and your knowledge</p>
<p>about how things work matter.</p>
<p>And so a computer can&rsquo;t understand that movie</p>
<p>if it doesn&rsquo;t have that background knowledge.</p>
<p>Same thing if you read a book.</p>
<p>And so there are lots of places where,</p>
<p>if we had a good machine interpretable set of common sense,</p>
<p>many things would accelerate relatively quickly,</p>
<p>but I don&rsquo;t think even that is a single point.</p>
<p>There&rsquo;s many different aspects of knowledge.</p>
<p>And we might, for example, find that we make a lot</p>
<p>of progress on physical reasoning,</p>
<p>getting machines to understand, for example,</p>
<p>how keys fit into locks, or that kind of stuff,</p>
<p>or how this gadget here works, and so forth and so on.</p>
<p>And so machines might do that long before they do</p>
<p>really good psychological reasoning,</p>
<p>because it&rsquo;s easier to get kind of labeled data</p>
<p>or to do direct experimentation on a microphone stand</p>
<p>than it is to do direct experimentation on human beings</p>
<p>to understand the levers that guide them.</p>
<p>That&rsquo;s a really interesting point, actually,</p>
<p>whether it&rsquo;s easier to gain common sense knowledge</p>
<p>or psychological knowledge.</p>
<p>I would say the common sense knowledge</p>
<p>includes both physical knowledge and psychological knowledge.</p>
<p>And the argument I was making.</p>
<p>Well, you said physical versus psychological.</p>
<p>Yeah, physical versus psychological.</p>
<p>And the argument I was making is physical knowledge</p>
<p>might be more accessible, because you could have a robot,</p>
<p>for example, lift a bottle, try putting a bottle cap on it,</p>
<p>see that it falls off if it does this,</p>
<p>and see that it could turn it upside down,</p>
<p>and so the robot could do some experimentation.</p>
<p>We do some of our psychological reasoning</p>
<p>by looking at our own minds.</p>
<p>So I can sort of guess how you might react to something</p>
<p>based on how I think I would react to it.</p>
<p>And robots don&rsquo;t have that intuition,</p>
<p>and they also can&rsquo;t do experiments on people</p>
<p>in the same way or we&rsquo;ll probably shut them down.</p>
<p>So if we wanted to have robots figure out</p>
<p>how I respond to pain by pinching me in different ways,</p>
<p>like that&rsquo;s probably, it&rsquo;s not gonna make it</p>
<p>past the human subjects board</p>
<p>and companies are gonna get sued or whatever.</p>
<p>So there&rsquo;s certain kinds of practical experience</p>
<p>that are limited or off limits to robots.</p>
<p>That&rsquo;s a really interesting point.</p>
<p>What is more difficult to gain a grounding in?</p>
<p>Because to play devil&rsquo;s advocate,</p>
<p>I would say that human behavior is easier expressed</p>
<p>in data and digital form.</p>
<p>And so when you look at Facebook algorithms,</p>
<p>they get to observe human behavior.</p>
<p>So you get to study and manipulate even a human behavior</p>
<p>in a way that you perhaps cannot study</p>
<p>or manipulate the physical world.</p>
<p>So it&rsquo;s true why you said pain is like physical pain,</p>
<p>but that&rsquo;s again, the physical world.</p>
<p>Emotional pain might be much easier to experiment with,</p>
<p>perhaps unethical, but nevertheless,</p>
<p>some would argue it&rsquo;s already going on.</p>
<p>I think that you&rsquo;re right, for example,</p>
<p>that Facebook does a lot of experimentation</p>
<p>in psychological reasoning.</p>
<p>In fact, Zuckerberg talked about AI</p>
<p>at a talk that he gave in NIPS.</p>
<p>I wasn&rsquo;t there, but the conference</p>
<p>has been renamed NeurIPS,</p>
<p>but he used to be called NIPS when he gave the talk.</p>
<p>And he talked about Facebook basically</p>
<p>having a gigantic theory of mind.</p>
<p>So I think it is certainly possible.</p>
<p>I mean, Facebook does some of that.</p>
<p>I think they have a really good idea</p>
<p>of how to addict people to things.</p>
<p>They understand what draws people back to things.</p>
<p>I think they exploit it in ways</p>
<p>that I&rsquo;m not very comfortable with.</p>
<p>But even so, I think that there are only some slices</p>
<p>of human experience that they can access</p>
<p>through the kind of interface they have.</p>
<p>And of course, they&rsquo;re doing all kinds of VR stuff,</p>
<p>and maybe that&rsquo;ll change and they&rsquo;ll expand their data.</p>
<p>And I&rsquo;m sure that that&rsquo;s part of their goal.</p>
<p>So it is an interesting question.</p>
<p>I think love, fear, insecurity,</p>
<p>all of the things that,</p>
<p>I would say some of the deepest things</p>
<p>about human nature and the human mind</p>
<p>could be explored through digital form.</p>
<p>It&rsquo;s that you&rsquo;re actually the first person</p>
<p>just now that brought up,</p>
<p>I wonder what is more difficult.</p>
<p>Because I think folks who are the slow,</p>
<p>and we&rsquo;ll talk a lot about deep learning,</p>
<p>but the people who are thinking beyond deep learning</p>
<p>are thinking about the physical world.</p>
<p>You&rsquo;re starting to think about robotics</p>
<p>in the home robotics.</p>
<p>How do we make robots manipulate objects,</p>
<p>which requires an understanding of the physical world</p>
<p>and then requires common sense reasoning.</p>
<p>And that has felt to be like the next step</p>
<p>for common sense reasoning,</p>
<p>but you&rsquo;ve now brought up the idea</p>
<p>that there&rsquo;s also the emotional part.</p>
<p>And it&rsquo;s interesting whether that&rsquo;s hard or easy.</p>
<p>I think some parts of it are and some aren&rsquo;t.</p>
<p>So my company that I recently founded with Rod Brooks,</p>
<p>from MIT for many years and so forth,</p>
<p>we&rsquo;re interested in both.</p>
<p>We&rsquo;re interested in physical reasoning</p>
<p>and psychological reasoning, among many other things.</p>
<p>And there are pieces of each of these that are accessible.</p>
<p>So if you want a robot to figure out</p>
<p>whether it can fit under a table,</p>
<p>that&rsquo;s a relatively accessible piece of physical reasoning.</p>
<p>If you know the height of the table</p>
<p>and you know the height of the robot, it&rsquo;s not that hard.</p>
<p>If you wanted to do physical reasoning about Jenga,</p>
<p>it gets a little bit more complicated</p>
<p>and you have to have higher resolution data</p>
<p>in order to do it.</p>
<p>With psychological reasoning,</p>
<p>it&rsquo;s not that hard to know, for example,</p>
<p>that people have goals and they like to act on those goals,</p>
<p>but it&rsquo;s really hard to know exactly what those goals are.</p>
<p>But ideas of frustration.</p>
<p>I mean, you could argue it&rsquo;s extremely difficult</p>
<p>to understand the sources of human frustration</p>
<p>as they&rsquo;re playing Jenga with you, or not.</p>
<p>You could argue that it&rsquo;s very accessible.</p>
<p>There&rsquo;s some things that are gonna be obvious</p>
<p>and some not.</p>
<p>So I don&rsquo;t think anybody really can do this well yet,</p>
<p>but I think it&rsquo;s not inconceivable</p>
<p>to imagine machines in the not so distant future</p>
<p>being able to understand that if people lose in a game,</p>
<p>that they don&rsquo;t like that.</p>
<p>That&rsquo;s not such a hard thing to program</p>
<p>and it&rsquo;s pretty consistent across people.</p>
<p>Most people don&rsquo;t enjoy losing</p>
<p>and so that makes it relatively easy to code.</p>
<p>On the other hand, if you wanted to capture everything</p>
<p>about frustration, well, people can get frustrated</p>
<p>for a lot of different reasons.</p>
<p>They might get sexually frustrated,</p>
<p>they might get frustrated,</p>
<p>they can get their promotion at work,</p>
<p>all kinds of different things.</p>
<p>And the more you expand the scope,</p>
<p>the harder it is for anything like the existing techniques</p>
<p>to really do that.</p>
<p>So I&rsquo;m talking to Garret Kasparov next week</p>
<p>and he seemed pretty frustrated</p>
<p>with his game against Deep Blue, so.</p>
<p>Yeah, well, I&rsquo;m frustrated with my game</p>
<p>against him last year,</p>
<p>because I played him, I had two excuses,</p>
<p>I&rsquo;ll give you my excuses up front,</p>
<p>but it won&rsquo;t mitigate the outcome.</p>
<p>I was jet lagged and I hadn&rsquo;t played in 25 or 30 years,</p>
<p>but the outcome is he completely destroyed me</p>
<p>and it wasn&rsquo;t even close.</p>
<p>Have you ever been beaten in any board game by a machine?</p>
<p>I have, I actually played the predecessor to Deep Blue.</p>
<p>Deep Thought, I believe it was called,</p>
<p>and that too crushed me.</p>
<p>And that was, and after that you realize it&rsquo;s over for us.</p>
<p>Well, there&rsquo;s no point in my playing Deep Blue.</p>
<p>I mean, it&rsquo;s a waste of Deep Blue&rsquo;s computation.</p>
<p>I mean, I played Kasparov</p>
<p>because we both gave lectures this same event</p>
<p>and he was playing 30 people.</p>
<p>I forgot to mention that.</p>
<p>Not only did he crush me,</p>
<p>but he crushed 29 other people at the same time.</p>
<p>I mean, but the actual philosophical and emotional experience</p>
<p>of being beaten by a machine, I imagine is a,</p>
<p>I mean, to you who thinks about these things</p>
<p>may be a profound experience.</p>
<p>Or no, it was a simple mathematical experience.</p>
<p>Yeah, I think a game like chess particularly</p>
<p>where you have perfect information,</p>
<p>it&rsquo;s two player closed end</p>
<p>and there&rsquo;s more computation for the computer,</p>
<p>it&rsquo;s no surprise the machine wins.</p>
<p>I mean, I&rsquo;m not sad when a computer,</p>
<p>I&rsquo;m not sad when a computer calculates</p>
<p>a cube root faster than me.</p>
<p>Like, I know I can&rsquo;t win that game.</p>
<p>I&rsquo;m not gonna try.</p>
<p>Well, with a system like AlphaGo or AlphaZero,</p>
<p>do you see a little bit more magic in a system like that</p>
<p>even though it&rsquo;s simply playing a board game?</p>
<p>But because there&rsquo;s a strong learning component?</p>
<p>You know, I find you should mention that</p>
<p>in the context of this conversation</p>
<p>because Kasparov and I are working on an article</p>
<p>that&rsquo;s gonna be called AI is not magic.</p>
<p>And, you know, neither one of us thinks that it&rsquo;s magic.</p>
<p>And part of the point of this article</p>
<p>is that AI is actually a grab bag of different techniques</p>
<p>and some of them have,</p>
<p>or they each have their own unique strengths and weaknesses.</p>
<p>So, you know, you read media accounts</p>
<p>and it&rsquo;s like, ooh, AI, it must be magical</p>
<p>or it can solve any problem.</p>
<p>Well, no, some problems are really accessible</p>
<p>like chess and go and other problems like reading</p>
<p>are completely outside the current technology.</p>
<p>And it&rsquo;s not like you can take the technology,</p>
<p>that drives AlphaGo and apply it to reading</p>
<p>and get anywhere.</p>
<p>You know, DeepMind has tried that a bit.</p>
<p>They have all kinds of resources.</p>
<p>You know, they built AlphaGo and they have,</p>
<p>you know, I wrote a piece recently that they lost</p>
<p>and you can argue about the word lost,</p>
<p>but they spent $530 million more than they made last year.</p>
<p>So, you know, they&rsquo;re making huge investments.</p>
<p>They have a large budget</p>
<p>and they have applied the same kinds of techniques</p>
<p>to reading or to language.</p>
<p>It&rsquo;s just much less productive there</p>
<p>because it&rsquo;s a fundamentally different kind of problem.</p>
<p>Chess and go and so forth are closed end problems.</p>
<p>The rules haven&rsquo;t changed in 2,500 years.</p>
<p>There&rsquo;s only so many moves you can make.</p>
<p>You can talk about the exponential</p>
<p>as you look at the combinations of moves,</p>
<p>but fundamentally, you know, the go board has 361 squares.</p>
<p>That&rsquo;s it.</p>
<p>That&rsquo;s the only, you know, those intersections</p>
<p>are the only places that you can place your stone.</p>
<p>Whereas when you&rsquo;re reading,</p>
<p>the next sentence could be anything.</p>
<p>You know, it&rsquo;s completely up to the writer</p>
<p>what they&rsquo;re gonna do next.</p>
<p>That&rsquo;s fascinating that you think this way.</p>
<p>You&rsquo;re clearly a brilliant mind</p>
<p>who points out the emperor has no clothes,</p>
<p>but so I&rsquo;ll play the role of a person who says.</p>
<p>You&rsquo;re gonna put clothes on the emperor?</p>
<p>Good luck with it.</p>
<p>It romanticizes the notion of the emperor, period,</p>
<p>suggesting that clothes don&rsquo;t even matter.</p>
<p>Okay, so that&rsquo;s really interesting</p>
<p>that you&rsquo;re talking about language.</p>
<p>So there&rsquo;s the physical world</p>
<p>of being able to move about the world,</p>
<p>making an omelet and coffee and so on.</p>
<p>There&rsquo;s language where you first understand</p>
<p>what&rsquo;s being written and then maybe even more complicated</p>
<p>than that, having a natural dialogue.</p>
<p>And then there&rsquo;s the game of go and chess.</p>
<p>I would argue that language is much closer to go</p>
<p>than it is to the physical world.</p>
<p>Like it is still very constrained.</p>
<p>When you say the possibility of the number of sentences</p>
<p>that could come, it is huge,</p>
<p>but it nevertheless is much more constrained.</p>
<p>It feels maybe I&rsquo;m wrong than the possibilities</p>
<p>that the physical world brings us.</p>
<p>There&rsquo;s something to what you say</p>
<p>in some ways in which I disagree.</p>
<p>So one interesting thing about language</p>
<p>is that it abstracts away.</p>
<p>This bottle, I don&rsquo;t know if it would be in the field of view</p>
<p>is on this table and I use the word on here</p>
<p>and I can use the word on here, maybe not here,</p>
<p>but that one word encompasses in analog space</p>
<p>sort of infinite number of possibilities.</p>
<p>So there is a way in which language filters down</p>
<p>the variation of the world and there&rsquo;s other ways.</p>
<p>So we have a grammar and more or less</p>
<p>you have to follow the rules of that grammar.</p>
<p>You can break them a little bit,</p>
<p>but by and large we follow the rules of grammar</p>
<p>and so that&rsquo;s a constraint on language.</p>
<p>So there are ways in which language is a constrained system.</p>
<p>On the other hand, there are many arguments</p>
<p>that say there&rsquo;s an infinite number of possible sentences</p>
<p>and you can establish that by just stacking them up.</p>
<p>So I think there&rsquo;s water on the table,</p>
<p>you think that I think there&rsquo;s water on the table,</p>
<p>your mother thinks that you think that I think</p>
<p>that water&rsquo;s on the table, your brother thinks</p>
<p>that maybe your mom is wrong to think</p>
<p>that you think that I think, right?</p>
<p>So we can make sentences of infinite length</p>
<p>or we can stack up adjectives.</p>
<p>This is a very silly example, a very, very silly example,</p>
<p>a very, very, very, very, very, very silly example</p>
<p>and so forth.</p>
<p>So there are good arguments</p>
<p>that there&rsquo;s an infinite range of sentences.</p>
<p>In any case, it&rsquo;s vast by any reasonable measure</p>
<p>and for example, almost anything in the physical world</p>
<p>we can talk about in the language world</p>
<p>and interestingly, many of the sentences that we understand,</p>
<p>we can only understand if we have a very rich model</p>
<p>of the physical world.</p>
<p>So I don&rsquo;t ultimately want to adjudicate the debate</p>
<p>that I think you just set up, but I find it interesting.</p>
<p>Maybe the physical world is even more complicated</p>
<p>than language, I think that&rsquo;s fair, but.</p>
<p>Language is really, really complicated.</p>
<p>It&rsquo;s really, really hard.</p>
<p>Well, it&rsquo;s really, really hard for machines,</p>
<p>for linguists, people trying to understand it.</p>
<p>It&rsquo;s not that hard for children</p>
<p>and that&rsquo;s part of what&rsquo;s driven my whole career.</p>
<p>I was a student of Steven Pinker&rsquo;s</p>
<p>and we were trying to figure out</p>
<p>why kids could learn language when machines couldn&rsquo;t.</p>
<p>I think we&rsquo;re gonna get into language,</p>
<p>we&rsquo;re gonna get into communication intelligence</p>
<p>and neural networks and so on,</p>
<p>but let me return to the high level,</p>
<p>the futuristic for a brief moment.</p>
<p>So you&rsquo;ve written in your book, in your new book,</p>
<p>it would be arrogant to suppose that we could forecast</p>
<p>where AI will be or the impact it will have</p>
<p>in a thousand years or even 500 years.</p>
<p>So let me ask you to be arrogant.</p>
<p>What do AI systems with or without physical bodies</p>
<p>look like 100 years from now?</p>
<p>If you would just, you can&rsquo;t predict,</p>
<p>but if you were to philosophize and imagine, do.</p>
<p>Can I first justify the arrogance</p>
<p>before you try to push me beyond it?</p>
<p>Sure.</p>
<p>I mean, there are examples like,</p>
<p>people figured out how electricity worked,</p>
<p>they had no idea that that was gonna lead to cell phones.</p>
<p>I mean, things can move awfully fast</p>
<p>once new technologies are perfected.</p>
<p>Even when they made transistors,</p>
<p>they weren&rsquo;t really thinking that cell phones</p>
<p>would lead to social networking.</p>
<p>There are nevertheless predictions of the future,</p>
<p>which are statistically unlikely to come to be,</p>
<p>but nevertheless is the best.</p>
<p>You&rsquo;re asking me to be wrong.</p>
<p>Asking you to be statistically.</p>
<p>In which way would I like to be wrong?</p>
<p>Pick the least unlikely to be wrong thing,</p>
<p>even though it&rsquo;s most very likely to be wrong.</p>
<p>I mean, here&rsquo;s some things</p>
<p>that we can safely predict, I suppose.</p>
<p>We can predict that AI will be faster than it is now.</p>
<p>It will be cheaper than it is now.</p>
<p>It will be better in the sense of being more general</p>
<p>and applicable in more places.</p>
<p>It will be pervasive.</p>
<p>I mean, these are easy predictions.</p>
<p>I&rsquo;m sort of modeling them in my head</p>
<p>on Jeff Bezos&rsquo;s famous predictions.</p>
<p>He says, I can&rsquo;t predict the future,</p>
<p>not in every way, I&rsquo;m paraphrasing.</p>
<p>But I can predict that people</p>
<p>will never wanna pay more money for their stuff.</p>
<p>They&rsquo;re never gonna want it to take longer to get there.</p>
<p>So you can&rsquo;t predict everything,</p>
<p>but you can predict something.</p>
<p>Sure, of course it&rsquo;s gonna be faster and better.</p>
<p>But what we can&rsquo;t really predict</p>
<p>is the full scope of where AI will be in a certain period.</p>
<p>I mean, I think it&rsquo;s safe to say that,</p>
<p>although I&rsquo;m very skeptical about current AI,</p>
<p>that it&rsquo;s possible to do much better.</p>
<p>You know, there&rsquo;s no in principled argument</p>
<p>that says AI is an insolvable problem,</p>
<p>that there&rsquo;s magic inside our brains</p>
<p>that will never be captured.</p>
<p>I mean, I&rsquo;ve heard people make those kind of arguments.</p>
<p>I don&rsquo;t think they&rsquo;re very good.</p>
<p>So AI&rsquo;s gonna come, and probably 500 years</p>
<p>is plenty to get there.</p>
<p>And then once it&rsquo;s here, it really will change everything.</p>
<p>So when you say AI&rsquo;s gonna come,</p>
<p>are you talking about human level intelligence?</p>
<p>So maybe I&hellip;</p>
<p>I like the term general intelligence.</p>
<p>So I don&rsquo;t think that the ultimate AI,</p>
<p>if there is such a thing, is gonna look just like humans.</p>
<p>I think it&rsquo;s gonna do some things</p>
<p>that humans do better than current machines,</p>
<p>like reason flexibly.</p>
<p>And understand language and so forth.</p>
<p>But it doesn&rsquo;t mean they have to be identical to humans.</p>
<p>So for example, humans have terrible memory,</p>
<p>and they suffer from what some people</p>
<p>call motivated reasoning.</p>
<p>So they like arguments that seem to support them,</p>
<p>and they dismiss arguments that they don&rsquo;t like.</p>
<p>There&rsquo;s no reason that a machine should ever do that.</p>
<p>So you see that those limitations of memory</p>
<p>as a bug, not a feature.</p>
<p>Absolutely.</p>
<p>I&rsquo;ll say two things about that.</p>
<p>One is I was on a panel with Danny Kahneman,</p>
<p>the Nobel Prize winner, last night,</p>
<p>and we were talking about this stuff.</p>
<p>And I think what we converged on</p>
<p>is that humans are a low bar to exceed.</p>
<p>They may be outside of our skill right now,</p>
<p>but as AI programmers, but eventually AI will exceed it.</p>
<p>So we&rsquo;re not talking about human level AI.</p>
<p>We&rsquo;re talking about general intelligence</p>
<p>that can do all kinds of different things</p>
<p>and do it without some of the flaws that human beings have.</p>
<p>The other thing I&rsquo;ll say is I wrote a whole book,</p>
<p>actually, about the flaws of humans.</p>
<p>It&rsquo;s actually a nice bookend to the,</p>
<p>or counterpoint to the current book.</p>
<p>So I wrote a book called Cluj,</p>
<p>which was about the limits of the human mind.</p>
<p>The current book is kind of about those few things</p>
<p>that humans do a lot better than machines.</p>
<p>Do you think it&rsquo;s possible that the flaws</p>
<p>of the human mind, the limits of memory,</p>
<p>our mortality, our bias,</p>
<p>is a strength, not a weakness,</p>
<p>that that is the thing that enables,</p>
<p>from which motivation springs and meaning springs or not?</p>
<p>I&rsquo;ve heard a lot of arguments like this.</p>
<p>I&rsquo;ve never found them that convincing.</p>
<p>I think that there&rsquo;s a lot of making lemonade out of lemons.</p>
<p>So we, for example, do a lot of free association</p>
<p>where one idea just leads to the next</p>
<p>and they&rsquo;re not really that well connected.</p>
<p>And we enjoy that and we make poetry out of it</p>
<p>and we make kind of movies with free associations</p>
<p>and it&rsquo;s fun and whatever.</p>
<p>I don&rsquo;t think that&rsquo;s really a virtue of the system.</p>
<p>I think that the limitations in human reasoning</p>
<p>actually get us in a lot of trouble.</p>
<p>Like, for example, politically we can&rsquo;t see eye to eye</p>
<p>because we have the motivational reasoning I was talking</p>
<p>about and something related called confirmation bias.</p>
<p>So we have all of these problems that actually make</p>
<p>for a rougher society because we can&rsquo;t get along</p>
<p>because we can&rsquo;t interpret the data in shared ways.</p>
<p>And then we do some nice stuff with that.</p>
<p>So my free associations are different from yours</p>
<p>and you&rsquo;re kind of amused by them and that&rsquo;s great.</p>
<p>And hence poetry.</p>
<p>So there are lots of ways in which we take</p>
<p>a lousy situation and make it good.</p>
<p>Another example would be our memories are terrible.</p>
<p>So we play games like Concentration where you flip over</p>
<p>two cards, try to find a pair.</p>
<p>Can you imagine a computer playing that?</p>
<p>Computer&rsquo;s like, this is the dullest game in the world.</p>
<p>I know where all the cards are, I see it once,</p>
<p>I know where it is, what are you even talking about?</p>
<p>So we make a fun game out of having this terrible memory.</p>
<p>So we are imperfect in discovering and optimizing</p>
<p>some kind of utility function.</p>
<p>But you think in general, there is a utility function.</p>
<p>There&rsquo;s an objective function that&rsquo;s better than others.</p>
<p>I didn&rsquo;t say that.</p>
<p>But see, the presumption, when you say&hellip;</p>
<p>I think you could design a better memory system.</p>
<p>You could argue about utility functions</p>
<p>and how you wanna think about that.</p>
<p>But objectively, it would be really nice</p>
<p>to do some of the following things.</p>
<p>To get rid of memories that are no longer useful.</p>
<p>Objectively, that would just be good.</p>
<p>And we&rsquo;re not that good at it.</p>
<p>So when you park in the same lot every day,</p>
<p>you confuse where you parked today</p>
<p>with where you parked yesterday</p>
<p>with where you parked the day before and so forth.</p>
<p>So you blur together a series of memories.</p>
<p>There&rsquo;s just no way that that&rsquo;s optimal.</p>
<p>I mean, I&rsquo;ve heard all kinds of wacky arguments</p>
<p>of people trying to defend that.</p>
<p>But in the end of the day,</p>
<p>I don&rsquo;t think any of them hold water.</p>
<p>It&rsquo;s just above.</p>
<p>Or memories of traumatic events would be possibly</p>
<p>a very nice feature to have to get rid of those.</p>
<p>It&rsquo;d be great if you could just be like,</p>
<p>I&rsquo;m gonna wipe this sector.</p>
<p>I&rsquo;m done with that.</p>
<p>I didn&rsquo;t have fun last night.</p>
<p>I don&rsquo;t wanna think about it anymore.</p>
<p>Whoop, bye bye.</p>
<p>I&rsquo;m gone.</p>
<p>But we can&rsquo;t.</p>
<p>Do you think it&rsquo;s possible to build a system&hellip;</p>
<p>So you said human level intelligence is a weird concept, but&hellip;</p>
<p>Well, I&rsquo;m saying I prefer general intelligence.</p>
<p>General intelligence.</p>
<p>I mean, human level intelligence is a real thing.</p>
<p>And you could try to make a machine</p>
<p>that matches people or something like that.</p>
<p>I&rsquo;m saying that per se shouldn&rsquo;t be the objective,</p>
<p>but rather that we should learn from humans</p>
<p>the things they do well and incorporate that into our AI,</p>
<p>just as we incorporate the things that machines do well</p>
<p>that people do terribly.</p>
<p>So, I mean, it&rsquo;s great that AI systems</p>
<p>can do all this brute force computation that people can&rsquo;t.</p>
<p>And one of the reasons I work on this stuff</p>
<p>is because I would like to see machines solve problems</p>
<p>that people can&rsquo;t, that combine the strength,</p>
<p>or that in order to be solved would combine</p>
<p>the strengths of machines to do all this computation</p>
<p>with the ability, let&rsquo;s say, of people to read.</p>
<p>So I&rsquo;d like machines that can read</p>
<p>the entire medical literature in a day.</p>
<p>7,000 new papers or whatever the numbers,</p>
<p>comes out every day.</p>
<p>There&rsquo;s no way for any doctor or whatever to read them all.</p>
<p>A machine that could read would be a brilliant thing.</p>
<p>And that would be strengths of brute force computation</p>
<p>combined with kind of subtlety and understanding medicine</p>
<p>that a good doctor or scientist has.</p>
<p>So if we can linger a little bit</p>
<p>on the idea of general intelligence.</p>
<p>So Yann LeCun believes that human intelligence</p>
<p>isn&rsquo;t general at all, it&rsquo;s very narrow.</p>
<p>How do you think?</p>
<p>I don&rsquo;t think that makes sense.</p>
<p>We have lots of narrow intelligences for specific problems.</p>
<p>But the fact is, like, anybody can walk into,</p>
<p>let&rsquo;s say, a Hollywood movie,</p>
<p>and reason about the content</p>
<p>of almost anything that goes on there.</p>
<p>So you can reason about what happens in a bank robbery,</p>
<p>or what happens when someone is infertile</p>
<p>and wants to go to IVF to try to have a child,</p>
<p>or you can, the list is essentially endless.</p>
<p>And not everybody understands every scene in the movie,</p>
<p>but there&rsquo;s a huge range of things</p>
<p>that pretty much any ordinary adult can understand.</p>
<p>His argument is, is that actually,</p>
<p>the set of things seems large for us humans</p>
<p>because we&rsquo;re very limited in considering</p>
<p>the kind of possibilities of experiences that are possible.</p>
<p>But in fact, the amount of experience that are possible</p>
<p>is infinitely larger.</p>
<p>Well, I mean, if you wanna make an argument</p>
<p>that humans are constrained in what they can understand,</p>
<p>I have no issue with that.</p>
<p>I think that&rsquo;s right.</p>
<p>But it&rsquo;s still not the same thing at all</p>
<p>as saying, here&rsquo;s a system that can play Go.</p>
<p>It&rsquo;s been trained on five million games.</p>
<p>And then I say, can it play on a rectangular board</p>
<p>rather than a square board?</p>
<p>And you say, well, if I retrain it from scratch</p>
<p>on another five million games, it can.</p>
<p>That&rsquo;s really, really narrow, and that&rsquo;s where we are.</p>
<p>We don&rsquo;t have even a system that could play Go</p>
<p>and then without further retraining,</p>
<p>play on a rectangular board,</p>
<p>which any human could do with very little problem.</p>
<p>So that&rsquo;s what I mean by narrow.</p>
<p>And so it&rsquo;s just wordplay to say.</p>
<p>That is semantics, yeah.</p>
<p>Then it&rsquo;s just words.</p>
<p>Then yeah, you mean general in a sense</p>
<p>that you can do all kinds of Go board shapes flexibly.</p>
<p>Well, that would be like a first step</p>
<p>in the right direction,</p>
<p>but obviously that&rsquo;s not what it really meaning.</p>
<p>You&rsquo;re kidding.</p>
<p>What I mean by general is that you could transfer</p>
<p>the knowledge you learn in one domain to another.</p>
<p>So if you learn about bank robberies in movies</p>
<p>and there&rsquo;s chase scenes,</p>
<p>then you can understand that amazing scene in Breaking Bad</p>
<p>when Walter White has a car chase scene</p>
<p>with only one person.</p>
<p>He&rsquo;s the only one in it.</p>
<p>And you can reflect on how that car chase scene</p>
<p>is like all the other car chase scenes you&rsquo;ve ever seen</p>
<p>and totally different and why that&rsquo;s cool.</p>
<p>And the fact that the number of domains</p>
<p>you can do that with is finite</p>
<p>doesn&rsquo;t make it less general.</p>
<p>So the idea of general is you could just do it</p>
<p>on a lot of, don&rsquo;t transfer it across a lot of domains.</p>
<p>Yeah, I mean, I&rsquo;m not saying humans are infinitely general</p>
<p>or that humans are perfect.</p>
<p>I just said a minute ago, it&rsquo;s a low bar,</p>
<p>but it&rsquo;s just, it&rsquo;s a low bar.</p>
<p>But right now, like the bar is here and we&rsquo;re there</p>
<p>and eventually we&rsquo;ll get way past it.</p>
<p>So speaking of low bars,</p>
<p>you&rsquo;ve highlighted in your new book as well,</p>
<p>but a couple of years ago wrote a paper</p>
<p>titled Deep Learning, A Critical Appraisal</p>
<p>that lists 10 challenges faced</p>
<p>by current deep learning systems.</p>
<p>So let me summarize them as data efficiency,</p>
<p>transfer learning, hierarchical knowledge,</p>
<p>open ended inference, explainability,</p>
<p>integrating prior knowledge, cause of reasoning,</p>
<p>modeling on a stable world, robustness, adversarial examples</p>
<p>and so on.</p>
<p>And then my favorite probably is reliability</p>
<p>in the engineering of real world systems.</p>
<p>So whatever people can read the paper,</p>
<p>they should definitely read the paper,</p>
<p>should definitely read your book.</p>
<p>But which of these challenges is solved in your view</p>
<p>has the biggest impact on the AI community?</p>
<p>It&rsquo;s a very good question.</p>
<p>And I&rsquo;m gonna be evasive because I think that</p>
<p>they go together a lot.</p>
<p>So some of them might be solved independently of others,</p>
<p>but I think a good solution to AI</p>
<p>starts by having real,</p>
<p>what I would call cognitive models of what&rsquo;s going on.</p>
<p>So right now we have a approach that&rsquo;s dominant</p>
<p>where you take statistical approximations of things,</p>
<p>but you don&rsquo;t really understand them.</p>
<p>So you know that bottles are correlated in your data</p>
<p>with bottle caps,</p>
<p>but you don&rsquo;t understand that there&rsquo;s a thread</p>
<p>on the bottle cap that fits with the thread on the bottle</p>
<p>and then that&rsquo;s what tightens it.</p>
<p>If I tighten enough that there&rsquo;s a seal</p>
<p>and the water won&rsquo;t come out.</p>
<p>Like there&rsquo;s no machine that understands that.</p>
<p>And having a good cognitive model</p>
<p>of that kind of everyday phenomena</p>
<p>is what we call common sense.</p>
<p>And if you had that,</p>
<p>then a lot of these other things start to fall</p>
<p>into at least a little bit better place.</p>
<p>Right now you&rsquo;re like learning correlations between pixels</p>
<p>when you play a video game or something like that.</p>
<p>And it doesn&rsquo;t work very well.</p>
<p>It works when the video game is just the way</p>
<p>that you studied it and then you alter the video game</p>
<p>in small ways,</p>
<p>like you move the paddle and break out a few pixels</p>
<p>and the system falls apart.</p>
<p>Because it doesn&rsquo;t understand,</p>
<p>it doesn&rsquo;t have a representation of a paddle,</p>
<p>a ball, a wall, a set of bricks and so forth.</p>
<p>And so it&rsquo;s reasoning at the wrong level.</p>
<p>So the idea of common sense,</p>
<p>it&rsquo;s full of mystery,</p>
<p>you&rsquo;ve worked on it,</p>
<p>but it&rsquo;s nevertheless full of mystery,</p>
<p>full of promise.</p>
<p>What does common sense mean?</p>
<p>What does knowledge mean?</p>
<p>So the way you&rsquo;ve been discussing it now</p>
<p>is very intuitive.</p>
<p>It makes a lot of sense that that is something</p>
<p>we should have and that&rsquo;s something</p>
<p>deep learning systems don&rsquo;t have.</p>
<p>But the argument could be that we&rsquo;re oversimplifying it</p>
<p>because we&rsquo;re oversimplifying the notion of common sense</p>
<p>because that&rsquo;s how it feels like we as humans</p>
<p>at the cognitive level approach problems.</p>
<p>So maybe.</p>
<p>A lot of people aren&rsquo;t actually gonna read my book.</p>
<p>But if they did read the book,</p>
<p>one of the things that might come as a surprise to them</p>
<p>is that we actually say common sense is really hard</p>
<p>and really complicated.</p>
<p>So they would probably,</p>
<p>my critics know that I like common sense,</p>
<p>but that chapter actually starts by us beating up</p>
<p>not on deep learning,</p>
<p>but kind of on our own home team as it will.</p>
<p>So Ernie and I are first and foremost</p>
<p>people that believe in at least some</p>
<p>of what good old fashioned AI tried to do.</p>
<p>So we believe in symbols and logic and programming.</p>
<p>Things like that are important.</p>
<p>And we go through why even those tools</p>
<p>that we hold fairly dear aren&rsquo;t really enough.</p>
<p>So we talk about why common sense is actually many things.</p>
<p>And some of them fit really well with those</p>
<p>classical sets of tools.</p>
<p>So things like taxonomy.</p>
<p>So I know that a bottle is an object</p>
<p>or it&rsquo;s a vessel, let&rsquo;s say.</p>
<p>And I know a vessel is an object</p>
<p>and objects are material things in the physical world.</p>
<p>So I can make some inferences.</p>
<p>If I know that vessels need to not have holes in them,</p>
<p>then I can infer that in order to carry their contents,</p>
<p>then I can infer that a bottle</p>
<p>shouldn&rsquo;t have a hole in it in order to carry its contents.</p>
<p>So you can do hierarchical inference and so forth.</p>
<p>And we say that&rsquo;s great,</p>
<p>but it&rsquo;s only a tiny piece of what you need for common sense.</p>
<p>We give lots of examples that don&rsquo;t fit into that.</p>
<p>So another one that we talk about is a cheese grater.</p>
<p>You&rsquo;ve got holes in a cheese grater.</p>
<p>You&rsquo;ve got a handle on top.</p>
<p>You can build a model in the game engine sense of a model</p>
<p>so that you could have a little cartoon character</p>
<p>flying around through the holes of the grater.</p>
<p>But we don&rsquo;t have a system yet.</p>
<p>Taxonomy doesn&rsquo;t help us that much</p>
<p>that really understands why the handle is on top</p>
<p>and what you do with the handle,</p>
<p>or why all of those circles are sharp,</p>
<p>or how you&rsquo;d hold the cheese with respect to the grater</p>
<p>in order to make it actually work.</p>
<p>Do you think these ideas are just abstractions</p>
<p>that could emerge on a system</p>
<p>like a very large deep neural network?</p>
<p>I&rsquo;m a skeptic that that kind of emergence per se can work.</p>
<p>So I think that deep learning might play a role</p>
<p>in the systems that do what I want systems to do,</p>
<p>but it won&rsquo;t do it by itself.</p>
<p>I&rsquo;ve never seen a deep learning system</p>
<p>really extract an abstract concept.</p>
<p>What they do, principled reasons for that</p>
<p>stemming from how back propagation works,</p>
<p>how the architectures are set up.</p>
<p>One example is deep learning people</p>
<p>actually all build in something called convolution,</p>
<p>which Jan Lacune is famous for, which is an abstraction.</p>
<p>They don&rsquo;t have their systems learn this.</p>
<p>So the abstraction is an object that looks the same</p>
<p>if it appears in different places.</p>
<p>And what Lacune figured out and why,</p>
<p>essentially why he was a co winner of the Turing Award</p>
<p>was that if you programmed this in innately,</p>
<p>then your system would be a whole lot more efficient.</p>
<p>In principle, this should be learnable,</p>
<p>but people don&rsquo;t have systems that kind of reify things</p>
<p>and make them more abstract.</p>
<p>And so what you&rsquo;d really wind up with</p>
<p>if you don&rsquo;t program that in advance is a system</p>
<p>that kind of realizes that this is the same thing as this,</p>
<p>but then I take your little clock there</p>
<p>and I move it over and it doesn&rsquo;t realize</p>
<p>that the same thing applies to the clock.</p>
<p>So the really nice thing, you&rsquo;re right,</p>
<p>that convolution is just one of the things</p>
<p>that&rsquo;s like, it&rsquo;s an innate feature</p>
<p>that&rsquo;s programmed by the human expert.</p>
<p>We need more of those, not less.</p>
<p>Yes, but the nice feature is it feels like</p>
<p>that requires coming up with that brilliant idea,</p>
<p>can get you a Turing Award,</p>
<p>but it requires less effort than encoding</p>
<p>and something we&rsquo;ll talk about, the expert system.</p>
<p>So encoding a lot of knowledge by hand.</p>
<p>So it feels like there&rsquo;s a huge amount of limitations</p>
<p>which you clearly outline with deep learning,</p>
<p>but the nice feature of deep learning,</p>
<p>whatever it is able to accomplish,</p>
<p>it does a lot of stuff automatically</p>
<p>without human intervention.</p>
<p>Well, and that&rsquo;s part of why people love it, right?</p>
<p>But I always think of this quote from Bertrand Russell,</p>
<p>which is it has all the advantages</p>
<p>of theft over honest toil.</p>
<p>It&rsquo;s really hard to program into a machine</p>
<p>a notion of causality or even how a bottle works</p>
<p>or what containers are.</p>
<p>Ernie Davis and I wrote a, I don&rsquo;t know,</p>
<p>45 page academic paper trying just to understand</p>
<p>what a container is,</p>
<p>which I don&rsquo;t think anybody ever read the paper,</p>
<p>but it&rsquo;s a very detailed analysis of all the things,</p>
<p>well, not even all of it,</p>
<p>some of the things you need to do</p>
<p>in order to understand a container.</p>
<p>It would be a whole lot nice,</p>
<p>and I&rsquo;m a coauthor on the paper,</p>
<p>I made it a little bit better,</p>
<p>but Ernie did the hard work for that particular paper.</p>
<p>And it took him like three months</p>
<p>to get the logical statements correct.</p>
<p>And maybe that&rsquo;s not the right way to do it,</p>
<p>it&rsquo;s a way to do it.</p>
<p>But on that way of doing it,</p>
<p>it&rsquo;s really hard work to do something</p>
<p>as simple as understanding containers.</p>
<p>And nobody wants to do that hard work,</p>
<p>even Ernie didn&rsquo;t want to do that hard work.</p>
<p>Everybody would rather just like feed their system in</p>
<p>with a bunch of videos with a bunch of containers</p>
<p>and have the systems infer how containers work.</p>
<p>It would be like so much less effort,</p>
<p>let the machine do the work.</p>
<p>And so I understand the impulse,</p>
<p>I understand why people want to do that.</p>
<p>I just don&rsquo;t think that it works.</p>
<p>I&rsquo;ve never seen anybody build a system</p>
<p>that in a robust way can actually watch videos</p>
<p>and predict exactly which containers would leak</p>
<p>and which ones wouldn&rsquo;t or something like,</p>
<p>and I know someone&rsquo;s gonna go out and do that</p>
<p>since I said it, and I look forward to seeing it.</p>
<p>But getting these things to work robustly</p>
<p>is really, really hard.</p>
<p>So Yann LeCun, who was my colleague at NYU for many years,</p>
<p>thinks that the hard work should go into defining</p>
<p>an unsupervised learning algorithm</p>
<p>that will watch videos, use the next frame basically</p>
<p>in order to tell it what&rsquo;s going on.</p>
<p>And he thinks that&rsquo;s the Royal road</p>
<p>and he&rsquo;s willing to put in the work</p>
<p>in devising that algorithm.</p>
<p>Then he wants the machine to do the rest.</p>
<p>And again, I understand the impulse.</p>
<p>My intuition, based on years of watching this stuff</p>
<p>and making predictions 20 years ago that still hold</p>
<p>even though there&rsquo;s a lot more computation and so forth,</p>
<p>is that we actually have to do</p>
<p>a different kind of hard work,</p>
<p>which is more like building a design specification</p>
<p>for what we want the system to do,</p>
<p>doing hard engineering work to figure out</p>
<p>how we do things like what Yann did for convolution</p>
<p>in order to figure out how to encode complex knowledge</p>
<p>into the systems.</p>
<p>The current systems don&rsquo;t have that much knowledge</p>
<p>other than convolution, which is again,</p>
<p>this objects being in different places</p>
<p>and having the same perception, I guess I&rsquo;ll say.</p>
<p>Same appearance.</p>
<p>People don&rsquo;t want to do that work.</p>
<p>They don&rsquo;t see how to naturally fit one with the other.</p>
<p>I think that&rsquo;s, yes, absolutely.</p>
<p>But also on the expert system side,</p>
<p>there&rsquo;s a temptation to go too far the other way.</p>
<p>So we&rsquo;re just having an expert sort of sit down</p>
<p>and encode the description,</p>
<p>the framework for what a container is,</p>
<p>and then having the system reason the rest.</p>
<p>From my view, one really exciting possibility</p>
<p>is of active learning where it&rsquo;s continuous interaction</p>
<p>between a human and machine.</p>
<p>As the machine, there&rsquo;s kind of deep learning type</p>
<p>extraction of information from data patterns and so on,</p>
<p>but humans also guiding the learning procedures,</p>
<p>guiding both the process and the framework</p>
<p>of how the machine learns, whatever the task is.</p>
<p>I was with you with almost everything you said</p>
<p>except the phrase deep learning.</p>
<p>What I think you really want there</p>
<p>is a new form of machine learning.</p>
<p>So let&rsquo;s remember, deep learning is a particular way</p>
<p>of doing machine learning.</p>
<p>Most often it&rsquo;s done with supervised data</p>
<p>for perceptual categories.</p>
<p>There are other things you can do with deep learning,</p>
<p>some of them quite technical,</p>
<p>but the standard use of deep learning</p>
<p>is I have a lot of examples and I have labels for them.</p>
<p>So here are pictures.</p>
<p>This one&rsquo;s the Eiffel Tower.</p>
<p>This one&rsquo;s the Sears Tower.</p>
<p>This one&rsquo;s the Empire State Building.</p>
<p>This one&rsquo;s a cat.</p>
<p>This one&rsquo;s a pig and so forth.</p>
<p>You just get millions of examples, millions of labels,</p>
<p>and deep learning is extremely good at that.</p>
<p>It&rsquo;s better than any other solution that anybody has devised,</p>
<p>but it is not good at representing abstract knowledge.</p>
<p>It&rsquo;s not good at representing things</p>
<p>like bottles contain liquid and have tops to them</p>
<p>and so forth.</p>
<p>It&rsquo;s not very good at learning</p>
<p>or representing that kind of knowledge.</p>
<p>It is an example of having a machine learn something,</p>
<p>but it&rsquo;s a machine that learns a particular kind of thing,</p>
<p>which is object classification.</p>
<p>It&rsquo;s not a particularly good algorithm for learning</p>
<p>about the abstractions that govern our world.</p>
<p>There may be such a thing.</p>
<p>Part of what we counsel in the book</p>
<p>is maybe people should be working on devising such things.</p>
<p>So one possibility, just I wonder what you think about it,</p>
<p>is that deep neural networks do form abstractions,</p>
<p>but they&rsquo;re not accessible to us humans</p>
<p>in terms of we can&rsquo;t.</p>
<p>There&rsquo;s some truth in that.</p>
<p>So is it possible that either current or future</p>
<p>neural networks form very high level abstractions,</p>
<p>which are as powerful as our human abstractions</p>
<p>of common sense.</p>
<p>We just can&rsquo;t get a hold of them.</p>
<p>And so the problem is essentially</p>
<p>we need to make them explainable.</p>
<p>This is an astute question,</p>
<p>but I think the answer is at least partly no.</p>
<p>One of the kinds of classical neural network architecture</p>
<p>is what we call an auto associator.</p>
<p>It just tries to take an input,</p>
<p>goes through a set of hidden layers,</p>
<p>and comes out with an output.</p>
<p>And it&rsquo;s supposed to learn essentially</p>
<p>the identity function,</p>
<p>that your input is the same as your output.</p>
<p>So you think of it as binary numbers.</p>
<p>You&rsquo;ve got the one, the two, the four, the eight,</p>
<p>the 16, and so forth.</p>
<p>And so if you want to input 24,</p>
<p>you turn on the 16, you turn on the eight.</p>
<p>It&rsquo;s like binary one, one, and a bunch of zeros.</p>
<p>So I did some experiments in 1998</p>
<p>with the precursors of contemporary deep learning.</p>
<p>And what I showed was you could train these networks</p>
<p>on all the even numbers,</p>
<p>and they would never generalize to the odd number.</p>
<p>A lot of people thought that I was, I don&rsquo;t know,</p>
<p>an idiot or faking the experiment,</p>
<p>or it wasn&rsquo;t true or whatever.</p>
<p>But it is true that with this class of networks</p>
<p>that we had in that day,</p>
<p>that they would never ever make this generalization.</p>
<p>And it&rsquo;s not that the networks were stupid,</p>
<p>it&rsquo;s that they see the world in a different way than we do.</p>
<p>They were basically concerned,</p>
<p>what is the probability that the rightmost output node</p>
<p>is going to be one?</p>
<p>And as far as they were concerned,</p>
<p>in everything they&rsquo;d ever been trained on, it was a zero.</p>
<p>That node had never been turned on,</p>
<p>and so they figured, why turn it on now?</p>
<p>Whereas a person would look at the same problem and say,</p>
<p>well, it&rsquo;s obvious,</p>
<p>we&rsquo;re just doing the thing that corresponds.</p>
<p>The Latin for it is mutatis mutandis,</p>
<p>we&rsquo;ll change what needs to be changed.</p>
<p>And we do this, this is what algebra is.</p>
<p>So I can do f of x equals y plus two,</p>
<p>and I can do it for a couple of values,</p>
<p>I can tell you if y is three,</p>
<p>then x is five, and if y is four, x is six.</p>
<p>And now I can do it with some totally different number,</p>
<p>like a million, then you can say,</p>
<p>well, obviously it&rsquo;s a million and two,</p>
<p>because you have an algebraic operation</p>
<p>that you&rsquo;re applying to a variable.</p>
<p>And deep learning systems kind of emulate that,</p>
<p>but they don&rsquo;t actually do it.</p>
<p>The particular example,</p>
<p>you could fudge a solution to that particular problem.</p>
<p>The general form of that problem remains,</p>
<p>that what they learn is really correlations</p>
<p>between different input and output nodes.</p>
<p>And they&rsquo;re complex correlations</p>
<p>with multiple nodes involved and so forth.</p>
<p>Ultimately, they&rsquo;re correlative,</p>
<p>they&rsquo;re not structured over these operations over variables.</p>
<p>Now, someday, people may do a new form of deep learning</p>
<p>that incorporates that stuff,</p>
<p>and I think it will help a lot.</p>
<p>And there&rsquo;s some tentative work on things</p>
<p>like differentiable programming right now</p>
<p>that fall into that category.</p>
<p>But the sort of classic stuff</p>
<p>like people use for ImageNet doesn&rsquo;t have it.</p>
<p>And you have people like Hinton going around saying,</p>
<p>symbol manipulation, like what Marcus,</p>
<p>what I advocate is like the gasoline engine.</p>
<p>It&rsquo;s obsolete.</p>
<p>We should just use this cool electric power</p>
<p>that we&rsquo;ve got with the deep learning.</p>
<p>And that&rsquo;s really destructive,</p>
<p>because we really do need to have the gasoline engine stuff</p>
<p>that represents, I mean, I don&rsquo;t think it&rsquo;s a good analogy,</p>
<p>but we really do need to have the stuff</p>
<p>that represents symbols.</p>
<p>Yeah, and Hinton as well would say</p>
<p>that we do need to throw out everything and start over.</p>
<p>Hinton said that to Axios,</p>
<p>and I had a friend who interviewed him</p>
<p>and tried to pin him down</p>
<p>on what exactly we need to throw out,</p>
<p>and he was very evasive.</p>
<p>Well, of course, because we can&rsquo;t, if he knew.</p>
<p>Then he&rsquo;d throw it out himself.</p>
<p>But I mean, you can&rsquo;t have it both ways.</p>
<p>You can&rsquo;t be like, I don&rsquo;t know what to throw out,</p>
<p>but I am gonna throw out the symbols.</p>
<p>I mean, and not just the symbols,</p>
<p>but the variables and the operations over variables.</p>
<p>Don&rsquo;t forget, the operations over variables,</p>
<p>the stuff that I&rsquo;m endorsing</p>
<p>and which John McCarthy did when he founded AI,</p>
<p>that stuff is the stuff</p>
<p>that we build most computers out of.</p>
<p>There are people now who say,</p>
<p>we don&rsquo;t need computer programmers anymore.</p>
<p>Not quite looking at the statistics</p>
<p>of how much computer programmers</p>
<p>actually get paid right now.</p>
<p>We need lots of computer programmers,</p>
<p>and most of them, they do a little bit of machine learning,</p>
<p>but they still do a lot of code, right?</p>
<p>Code where it&rsquo;s like, if the value of X</p>
<p>is greater than the value of Y,</p>
<p>then do this kind of thing,</p>
<p>like conditionals and comparing operations over variables.</p>
<p>Like, there&rsquo;s this fantasy you can machine learn anything.</p>
<p>There&rsquo;s some things you would never wanna machine learn.</p>
<p>I would not use a phone operating system</p>
<p>that was machine learned.</p>
<p>Like, you made a bunch of phone calls</p>
<p>and you recorded which packets were transmitted</p>
<p>and you just machine learned it, it&rsquo;d be insane.</p>
<p>Or to build a web browser by taking logs of keystrokes</p>
<p>and images, screenshots,</p>
<p>and then trying to learn the relation between them.</p>
<p>Nobody would ever,</p>
<p>no rational person would ever try to build a browser</p>
<p>that made, they would use symbol manipulation,</p>
<p>the stuff that I think AI needs to avail itself of</p>
<p>in addition to deep learning.</p>
<p>Can you describe your view of symbol manipulation</p>
<p>in its early days?</p>
<p>Can you describe expert systems</p>
<p>and where do you think they hit a wall</p>
<p>or a set of challenges?</p>
<p>Sure, so I mean, first I just wanna clarify,</p>
<p>I&rsquo;m not endorsing expert systems per se.</p>
<p>You&rsquo;ve been kind of contrasting them.</p>
<p>There is a contrast,</p>
<p>but that&rsquo;s not the thing that I&rsquo;m endorsing.</p>
<p>So expert systems tried to capture things</p>
<p>like medical knowledge with a large set of rules.</p>
<p>So if the patient has this symptom and this other symptom,</p>
<p>then it is likely that they have this disease.</p>
<p>So there are logical rules</p>
<p>and they were symbol manipulating rules</p>
<p>of just the sort that I&rsquo;m talking about.</p>
<p>And the problem.</p>
<p>They encode a set of knowledge that the experts then put in.</p>
<p>And very explicitly so.</p>
<p>So you&rsquo;d have somebody interview an expert</p>
<p>and then try to turn that stuff into rules.</p>
<p>And at some level I&rsquo;m arguing for rules.</p>
<p>But the difference is those guys did in the 80s</p>
<p>was almost entirely rules,</p>
<p>almost entirely handwritten with no machine learning.</p>
<p>What a lot of people are doing now</p>
<p>is almost entirely one species of machine learning</p>
<p>with no rules.</p>
<p>And what I&rsquo;m counseling is actually a hybrid.</p>
<p>I&rsquo;m saying that both of these things have their advantage.</p>
<p>So if you&rsquo;re talking about perceptual classification,</p>
<p>how do I recognize a bottle?</p>
<p>Deep learning is the best tool we&rsquo;ve got right now.</p>
<p>If you&rsquo;re talking about making inferences</p>
<p>about what a bottle does,</p>
<p>something closer to the expert systems</p>
<p>is probably still the best available alternative.</p>
<p>And probably we want something that is better able</p>
<p>to handle quantitative and statistical information</p>
<p>than those classical systems typically were.</p>
<p>So we need new technologies</p>
<p>that are gonna draw some of the strengths</p>
<p>of both the expert systems and the deep learning,</p>
<p>but are gonna find new ways to synthesize them.</p>
<p>How hard do you think it is to add knowledge at the low level?</p>
<p>So mine human intellects to add extra information</p>
<p>to symbol manipulating systems?</p>
<p>In some domains it&rsquo;s not that hard,</p>
<p>but it&rsquo;s often really hard.</p>
<p>Partly because a lot of the things that are important,</p>
<p>people wouldn&rsquo;t bother to tell you.</p>
<p>So if you pay someone on Amazon Mechanical Turk</p>
<p>to tell you stuff about bottles,</p>
<p>they probably won&rsquo;t even bother to tell you</p>
<p>some of the basic level stuff</p>
<p>that&rsquo;s just so obvious to a human being</p>
<p>and yet so hard to capture in machines.</p>
<p>They&rsquo;re gonna tell you more exotic things,</p>
<p>and they&rsquo;re all well and good,</p>
<p>but they&rsquo;re not getting to the root of the problem.</p>
<p>So untutored humans aren&rsquo;t very good at knowing,</p>
<p>and why should they be,</p>
<p>what kind of knowledge the computer system developers</p>
<p>actually need?</p>
<p>I don&rsquo;t think that that&rsquo;s an irremediable problem.</p>
<p>I think it&rsquo;s historically been a problem.</p>
<p>People have had crowdsourcing efforts,</p>
<p>and they don&rsquo;t work that well.</p>
<p>There&rsquo;s one at MIT, we&rsquo;re recording this at MIT,</p>
<p>called Virtual Home, where,</p>
<p>and we talk about this in the book,</p>
<p>find the exact example there,</p>
<p>but people were asked to do things</p>
<p>like describe an exercise routine.</p>
<p>And the things that the people describe</p>
<p>are at a very low level</p>
<p>and don&rsquo;t really capture what&rsquo;s going on.</p>
<p>So they&rsquo;re like, go to the room</p>
<p>with the television and the weights,</p>
<p>turn on the television,</p>
<p>press the remote to turn on the television,</p>
<p>lift weight, put weight down, whatever.</p>
<p>It&rsquo;s like very micro level,</p>
<p>and it&rsquo;s not telling you</p>
<p>what an exercise routine is really about,</p>
<p>which is like, I wanna fit a certain number of exercises</p>
<p>in a certain time period,</p>
<p>I wanna emphasize these muscles.</p>
<p>You want some kind of abstract description.</p>
<p>The fact that you happen to press the remote control</p>
<p>in this room when you watch this television</p>
<p>isn&rsquo;t really the essence of the exercise routine.</p>
<p>But if you just ask people like, what did they do?</p>
<p>Then they give you this fine grain.</p>
<p>And so it takes a level of expertise</p>
<p>about how the AI works</p>
<p>in order to craft the right kind of knowledge.</p>
<p>So there&rsquo;s this ocean of knowledge that we all operate on.</p>
<p>Some of them may not even be conscious,</p>
<p>or at least we&rsquo;re not able to communicate it effectively.</p>
<p>Yeah, most of it we would recognize if somebody said it,</p>
<p>if it was true or not,</p>
<p>but we wouldn&rsquo;t think to say that it&rsquo;s true or not.</p>
<p>That&rsquo;s a really interesting mathematical property.</p>
<p>This ocean has the property</p>
<p>that every piece of knowledge in it,</p>
<p>we will recognize it as true if we&rsquo;re told,</p>
<p>but we&rsquo;re unlikely to retrieve it in the reverse.</p>
<p>So that interesting property,</p>
<p>I would say there&rsquo;s a huge ocean of that knowledge.</p>
<p>What&rsquo;s your intuition?</p>
<p>Is it accessible to AI systems somehow?</p>
<p>Can we?</p>
<p>So you said this.</p>
<p>I mean, most of it is not,</p>
<p>well, I&rsquo;ll give you an asterisk on this in a second,</p>
<p>but most of it has not ever been encoded</p>
<p>in machine interpretable form.</p>
<p>And so, I mean, if you say accessible,</p>
<p>there&rsquo;s two meanings of that.</p>
<p>One is like, could you build it into a machine?</p>
<p>Yes.</p>
<p>The other is like, is there some database</p>
<p>that we could go download and stick into our machine?</p>
<p>But the first thing, could we?</p>
<p>What&rsquo;s your intuition? I think we could.</p>
<p>I think it hasn&rsquo;t been done right.</p>
<p>You know, the closest, and this is the asterisk,</p>
<p>is the CYC psych system tried to do this.</p>
<p>A lot of logicians worked for Doug Lennon</p>
<p>for 30 years on this project.</p>
<p>I think they stuck too closely to logic,</p>
<p>didn&rsquo;t represent enough about probabilities,</p>
<p>tried to hand code it.</p>
<p>There are various issues,</p>
<p>and it hasn&rsquo;t been that successful.</p>
<p>That is the closest existing system</p>
<p>to trying to encode this.</p>
<p>Why do you think there&rsquo;s not more excitement</p>
<p>slash money behind this idea currently?</p>
<p>There was.</p>
<p>People view that project as a failure.</p>
<p>I think that they confuse the failure</p>
<p>of a specific instance that was conceived 30 years ago</p>
<p>for the failure of an approach,</p>
<p>which they don&rsquo;t do for deep learning.</p>
<p>So in 2010, people had the same attitude</p>
<p>towards deep learning.</p>
<p>They&rsquo;re like, this stuff doesn&rsquo;t really work.</p>
<p>And all these other algorithms work better and so forth.</p>
<p>And then certain key technical advances were made,</p>
<p>but mostly it was the advent</p>
<p>of graphics processing units that changed that.</p>
<p>It wasn&rsquo;t even anything foundational in the techniques.</p>
<p>And there was some new tricks,</p>
<p>but mostly it was just more compute and more data,</p>
<p>things like ImageNet that didn&rsquo;t exist before</p>
<p>that allowed deep learning.</p>
<p>And it could be, to work,</p>
<p>it could be that CYC just needs a few more things</p>
<p>or something like CYC,</p>
<p>but the widespread view is that that just doesn&rsquo;t work.</p>
<p>And people are reasoning from a single example.</p>
<p>They don&rsquo;t do that with deep learning.</p>
<p>They don&rsquo;t say nothing that existed in 2010,</p>
<p>and there were many, many efforts in deep learning</p>
<p>was really worth anything.</p>
<p>I mean, really, there&rsquo;s no model from 2010</p>
<p>in deep learning or the predecessors of deep learning</p>
<p>that has any commercial value whatsoever at this point.</p>
<p>They&rsquo;re all failures.</p>
<p>But that doesn&rsquo;t mean that there wasn&rsquo;t anything there.</p>
<p>I have a friend, I was getting to know him,</p>
<p>and he said, I had a company too,</p>
<p>I was talking about I had a new company.</p>
<p>He said, I had a company too, and it failed.</p>
<p>And I said, well, what did you do?</p>
<p>And he said, deep learning.</p>
<p>And the problem was he did it in 1986</p>
<p>or something like that.</p>
<p>And we didn&rsquo;t have the tools then, or 1990,</p>
<p>we didn&rsquo;t have the tools then, not the algorithms.</p>
<p>His algorithms weren&rsquo;t that different from model algorithms,</p>
<p>but he didn&rsquo;t have the GPUs to run it fast enough.</p>
<p>He didn&rsquo;t have the data.</p>
<p>And so it failed.</p>
<p>It could be that symbol manipulation per se</p>
<p>with modern amounts of data and compute</p>
<p>and maybe some advance in compute</p>
<p>for that kind of compute might be great.</p>
<p>My perspective on it is not that we want to resuscitate</p>
<p>that stuff per se, but we want to borrow lessons from it,</p>
<p>bring together with other things that we&rsquo;ve learned.</p>
<p>And it might have an ImageNet moment</p>
<p>where it would spark the world&rsquo;s imagination</p>
<p>and there&rsquo;ll be an explosion of symbol manipulation efforts.</p>
<p>Yeah, I think that people at AI2,</p>
<p>Paul Allen&rsquo;s AI Institute, are trying to build data sets.</p>
<p>Well, they&rsquo;re not doing it</p>
<p>for quite the reason that you say,</p>
<p>but they&rsquo;re trying to build data sets</p>
<p>that at least spark interest in common sense reasoning.</p>
<p>To create benchmarks.</p>
<p>Benchmarks for common sense.</p>
<p>That&rsquo;s a large part of what the AI2.org</p>
<p>is working on right now.</p>
<p>So speaking of compute,</p>
<p>Rich Sutton wrote a blog post titled Bitter Lesson.</p>
<p>I don&rsquo;t know if you&rsquo;ve read it,</p>
<p>but he said that the biggest lesson that can be read</p>
<p>from so many years of AI research</p>
<p>is that general methods that leverage computation</p>
<p>are ultimately the most effective.</p>
<p>Do you think that?</p>
<p>The most effective at what?</p>
<p>Right, so they have been most effective</p>
<p>for perceptual classification problems</p>
<p>and for some reinforcement learning problems.</p>
<p>And he works on reinforcement learning.</p>
<p>Well, no, let me push back on that.</p>
<p>You&rsquo;re actually absolutely right.</p>
<p>But I would also say they have been most effective generally</p>
<p>because everything we&rsquo;ve done up to&hellip;</p>
<p>Would you argue against that?</p>
<p>Is, to me, deep learning is the first thing</p>
<p>that has been successful at anything in AI.</p>
<p>And you&rsquo;re pointing out that this success</p>
<p>is very limited, folks,</p>
<p>but has there been something truly successful</p>
<p>before deep learning?</p>
<p>Sure, I mean, I want to make a larger point,</p>
<p>but on the narrower point, classical AI is used,</p>
<p>for example, in doing navigation instructions.</p>
<p>It&rsquo;s very successful.</p>
<p>Everybody on the planet uses it now,</p>
<p>like multiple times a day.</p>
<p>That&rsquo;s a measure of success, right?</p>
<p>So I don&rsquo;t think classical AI was wildly successful,</p>
<p>but there are cases like that.</p>
<p>They&rsquo;re just used all the time.</p>
<p>Nobody even notices them because they&rsquo;re so pervasive.</p>
<p>So there are some successes for classical AI.</p>
<p>I think deep learning has been more successful,</p>
<p>but my usual line about this, and I didn&rsquo;t invent it,</p>
<p>but I like it a lot,</p>
<p>is just because you can build a better ladder</p>
<p>doesn&rsquo;t mean you can build a ladder to the moon.</p>
<p>So the bitter lesson is if you have</p>
<p>a perceptual classification problem,</p>
<p>throwing a lot of data at it is better than anything else.</p>
<p>But that has not given us any material progress</p>
<p>in natural language understanding,</p>
<p>common sense reasoning,</p>
<p>like a robot would need to navigate a home.</p>
<p>Problems like that, there&rsquo;s no actual progress there.</p>
<p>So flip side of that, if we remove data from the picture,</p>
<p>another bitter lesson is that you just have</p>
<p>a very simple algorithm,</p>
<p>and you wait for compute to scale.</p>
<p>It doesn&rsquo;t have to be learning.</p>
<p>It doesn&rsquo;t have to be deep learning.</p>
<p>It doesn&rsquo;t have to be data driven,</p>
<p>but just wait for the compute.</p>
<p>So my question for you,</p>
<p>do you think compute can unlock some of the things</p>
<p>with either deep learning or symbol manipulation that?</p>
<p>Sure, but I&rsquo;ll put a proviso on that.</p>
<p>I think more compute&rsquo;s always better.</p>
<p>Nobody&rsquo;s gonna argue with more compute.</p>
<p>It&rsquo;s like having more money.</p>
<p>I mean, there&rsquo;s the data.</p>
<p>There&rsquo;s diminishing returns on more money.</p>
<p>Exactly, there&rsquo;s diminishing returns on more money,</p>
<p>but nobody&rsquo;s gonna argue</p>
<p>if you wanna give them more money, right?</p>
<p>Except maybe the people who signed the giving pledge,</p>
<p>and some of them have a problem.</p>
<p>They&rsquo;ve promised to give away more money</p>
<p>than they&rsquo;re able to.</p>
<p>But the rest of us, if you wanna give me more money, fine.</p>
<p>I&rsquo;m saying more money, more problems, but okay.</p>
<p>That&rsquo;s true too.</p>
<p>What I would say to you is your brain uses like 20 watts,</p>
<p>and it does a lot of things that deep learning doesn&rsquo;t do,</p>
<p>or that symbol manipulation doesn&rsquo;t do,</p>
<p>that AI just hasn&rsquo;t figured out how to do.</p>
<p>So it&rsquo;s an existence proof</p>
<p>that you don&rsquo;t need server resources</p>
<p>that are Google scale in order to have an intelligence.</p>
<p>I built, with a lot of help from my wife,</p>
<p>two intelligences that are 20 watts each,</p>
<p>and far exceed anything that anybody else</p>
<p>has built at a silicon.</p>
<p>Speaking of those two robots,</p>
<p>what have you learned about AI from having?</p>
<p>Well, they&rsquo;re not robots, but.</p>
<p>Sorry, intelligent agents.</p>
<p>Those two intelligent agents.</p>
<p>I&rsquo;ve learned a lot by watching my two intelligent agents.</p>
<p>I think that what&rsquo;s fundamentally interesting,</p>
<p>well, one of the many things</p>
<p>that&rsquo;s fundamentally interesting about them</p>
<p>is the way that they set their own problems to solve.</p>
<p>So my two kids are a year and a half apart.</p>
<p>They&rsquo;re both five and six and a half.</p>
<p>They play together all the time,</p>
<p>and they&rsquo;re constantly creating new challenges.</p>
<p>That&rsquo;s what they do, is they make up games,</p>
<p>and they&rsquo;re like, well, what if this, or what if that,</p>
<p>or what if I had this superpower,</p>
<p>or what if you could walk through this wall?</p>
<p>So they&rsquo;re doing these what if scenarios all the time,</p>
<p>and that&rsquo;s how they learn something about the world</p>
<p>and grow their minds, and machines don&rsquo;t really do that.</p>
<p>So that&rsquo;s interesting, and you&rsquo;ve talked about this,</p>
<p>you&rsquo;ve written about it, you&rsquo;ve thought about it,</p>
<p>nature versus nurture.</p>
<p>So what innate knowledge do you think we&rsquo;re born with,</p>
<p>and what do we learn along the way</p>
<p>in those early months and years?</p>
<p>Can I just say how much I like that question?</p>
<p>You phrased it just right, and almost nobody ever does,</p>
<p>which is what is the innate knowledge</p>
<p>and what&rsquo;s learned along the way?</p>
<p>So many people dichotomize it,</p>
<p>and they think it&rsquo;s nature versus nurture,</p>
<p>when it is obviously has to be nature and nurture.</p>
<p>They have to work together.</p>
<p>You can&rsquo;t learn this stuff along the way</p>
<p>unless you have some innate stuff,</p>
<p>but just because you have the innate stuff</p>
<p>doesn&rsquo;t mean you don&rsquo;t learn anything.</p>
<p>And so many people get that wrong, including in the field.</p>
<p>People think if I work in machine learning,</p>
<p>the learning side, I must not be allowed to work</p>
<p>on the innate side, or that will be cheating.</p>
<p>Exactly, people have said that to me,</p>
<p>and it&rsquo;s just absurd, so thank you.</p>
<p>But you could break that apart more.</p>
<p>I&rsquo;ve talked to folks who studied</p>
<p>the development of the brain,</p>
<p>and the growth of the brain in the first few days</p>
<p>in the first few months in the womb,</p>
<p>all of that, is that innate?</p>
<p>So that process of development from a stem cell</p>
<p>to the growth of the central nervous system and so on,</p>
<p>to the information that&rsquo;s encoded</p>
<p>through the long arc of evolution.</p>
<p>So all of that comes into play, and it&rsquo;s unclear.</p>
<p>It&rsquo;s not just whether it&rsquo;s a dichotomy or not.</p>
<p>It&rsquo;s where most, or where the knowledge is encoded.</p>
<p>So what&rsquo;s your intuition about the innate knowledge,</p>
<p>the power of it, what&rsquo;s contained in it,</p>
<p>what can we learn from it?</p>
<p>One of my earlier books was actually trying</p>
<p>to understand the biology of this.</p>
<p>The book was called The Birth of the Mind.</p>
<p>Like how is it the genes even build innate knowledge?</p>
<p>And from the perspective of the conversation</p>
<p>we&rsquo;re having today, there&rsquo;s actually two questions.</p>
<p>One is what innate knowledge or mechanisms,</p>
<p>or what have you, people or other animals</p>
<p>might be endowed with.</p>
<p>I always like showing this video</p>
<p>of a baby ibex climbing down a mountain.</p>
<p>That baby ibex, a few hours after its birth,</p>
<p>knows how to climb down a mountain.</p>
<p>That means that it knows, not consciously,</p>
<p>something about its own body and physics</p>
<p>and 3D geometry and all of this kind of stuff.</p>
<p>So there&rsquo;s one question about what does biology</p>
<p>give its creatures and what has evolved in our brains?</p>
<p>How is that represented in our brains?</p>
<p>The question I thought about in the book</p>
<p>The Birth of the Mind.</p>
<p>And then there&rsquo;s a question of what AI should have.</p>
<p>And they don&rsquo;t have to be the same.</p>
<p>But I would say that it&rsquo;s a pretty interesting</p>
<p>set of things that we are equipped with</p>
<p>that allows us to do a lot of interesting things.</p>
<p>So I would argue or guess, based on my reading</p>
<p>of the developmental psychology literature,</p>
<p>which I&rsquo;ve also participated in,</p>
<p>that children are born with a notion of space,</p>
<p>time, other agents, places,</p>
<p>and also this kind of mental algebra</p>
<p>that I was describing before.</p>
<p>No certain causation if I didn&rsquo;t just say that.</p>
<p>So at least those kinds of things.</p>
<p>They&rsquo;re like frameworks for learning the other things.</p>
<p>Are they disjoint in your view</p>
<p>or is it just somehow all connected?</p>
<p>You&rsquo;ve talked a lot about language.</p>
<p>Is it all kind of connected in some mesh</p>
<p>that&rsquo;s language like?</p>
<p>If understanding concepts all together or?</p>
<p>I don&rsquo;t think we know for people how they&rsquo;re represented</p>
<p>and machines just don&rsquo;t really do this yet.</p>
<p>So I think it&rsquo;s an interesting open question</p>
<p>both for science and for engineering.</p>
<p>Some of it has to be at least interrelated</p>
<p>in the way that the interfaces of a software package</p>
<p>have to be able to talk to one another.</p>
<p>So the systems that represent space and time</p>
<p>can&rsquo;t be totally disjoint because a lot of the things</p>
<p>that we reason about are the relations</p>
<p>between space and time and cause.</p>
<p>So I put this on and I have expectations</p>
<p>about what&rsquo;s gonna happen with the bottle cap</p>
<p>on top of the bottle and those span space and time.</p>
<p>If the cap is over here, I get a different outcome.</p>
<p>If the timing is different, if I put this here,</p>
<p>after I move that, then I get a different outcome.</p>
<p>That relates to causality.</p>
<p>So obviously these mechanisms, whatever they are,</p>
<p>can certainly communicate with each other.</p>
<p>So I think evolution had a significant role</p>
<p>to play in the development of this whole kluge, right?</p>
<p>How efficient do you think is evolution?</p>
<p>Oh, it&rsquo;s terribly inefficient except that.</p>
<p>Okay, well, can we do better?</p>
<p>Well, I&rsquo;ll come to that in a sec.</p>
<p>It&rsquo;s inefficient except that.</p>
<p>Once it gets a good idea, it runs with it.</p>
<p>So it took, I guess, a billion years,</p>
<p>if I went roughly a billion years, to evolve</p>
<p>to a vertebrate brain plan.</p>
<p>And once that vertebrate brain plan evolved,</p>
<p>it spread everywhere.</p>
<p>So fish have it and dogs have it and we have it.</p>
<p>We have adaptations of it and specializations of it,</p>
<p>but, and the same thing with a primate brain plan.</p>
<p>So monkeys have it and apes have it and we have it.</p>
<p>So there are additional innovations like color vision</p>
<p>and those spread really rapidly.</p>
<p>So it takes evolution a long time to get a good idea,</p>
<p>but, and I&rsquo;m being anthropomorphic and not literal here,</p>
<p>but once it has that idea, so to speak,</p>
<p>which cashes out into one set of genes or in the genome,</p>
<p>those genes spread very rapidly</p>
<p>and they&rsquo;re like subroutines or libraries,</p>
<p>I guess the word people might use nowadays</p>
<p>or be more familiar with.</p>
<p>They&rsquo;re libraries that get used over and over again.</p>
<p>So once you have the library for building something</p>
<p>with multiple digits, you can use it for a hand,</p>
<p>but you can also use it for a foot.</p>
<p>You just kind of reuse the library</p>
<p>with slightly different parameters.</p>
<p>Evolution does a lot of that,</p>
<p>which means that the speed over time picks up.</p>
<p>So evolution can happen faster</p>
<p>because you have bigger and bigger libraries.</p>
<p>And what I think has happened in attempts</p>
<p>at evolutionary computation is that people start</p>
<p>with libraries that are very, very minimal,</p>
<p>like almost nothing, and then progress is slow</p>
<p>and it&rsquo;s hard for someone to get a good PhD thesis</p>
<p>out of it and they give up.</p>
<p>If we had richer libraries to begin with,</p>
<p>if you were evolving from systems</p>
<p>that had an rich innate structure to begin with,</p>
<p>then things might speed up.</p>
<p>Or more PhD students, if the evolutionary process</p>
<p>is indeed in a meta way runs away with good ideas,</p>
<p>you need to have a lot of ideas,</p>
<p>pool of ideas in order for it to discover one</p>
<p>that you can run away with.</p>
<p>And PhD students representing individual ideas as well.</p>
<p>Yeah, I mean, you could throw</p>
<p>a billion PhD students at it.</p>
<p>Yeah, the monkeys are typewriters with Shakespeare, yep.</p>
<p>Well, I mean, those aren&rsquo;t cumulative, right?</p>
<p>That&rsquo;s just random.</p>
<p>And part of the point that I&rsquo;m making</p>
<p>is that evolution is cumulative.</p>
<p>So if you have a billion monkeys independently,</p>
<p>you don&rsquo;t really get anywhere.</p>
<p>But if you have a billion monkeys,</p>
<p>and I think Dawkins made this point originally,</p>
<p>or probably other people, Dawkins made it very nice</p>
<p>and either a selfish gene or blind watchmaker.</p>
<p>If there is some sort of fitness function</p>
<p>that can drive you towards something,</p>
<p>I guess that&rsquo;s Dawkins point.</p>
<p>And my point, which is a variation on that,</p>
<p>is that if the evolution is cumulative,</p>
<p>I mean, the related points,</p>
<p>then you can start going faster.</p>
<p>Do you think something like the process of evolution</p>
<p>is required to build intelligent systems?</p>
<p>So if we&hellip; Not logically.</p>
<p>So all the stuff that evolution did,</p>
<p>a good engineer might be able to do.</p>
<p>So for example, evolution made quadrupeds,</p>
<p>which distribute the load across a horizontal surface.</p>
<p>A good engineer could come up with that idea.</p>
<p>I mean, sometimes good engineers come up with ideas</p>
<p>by looking at biology.</p>
<p>There&rsquo;s lots of ways to get your ideas.</p>
<p>Part of what I&rsquo;m suggesting</p>
<p>is we should look at biology a lot more.</p>
<p>We should look at the biology of thought and understanding</p>
<p>and the biology by which creatures intuitively reason</p>
<p>about physics or other agents,</p>
<p>or like how do dogs reason about people?</p>
<p>Like they&rsquo;re actually pretty good at it.</p>
<p>If we could understand, at my college we joked dognition,</p>
<p>if we could understand dognition well,</p>
<p>and how it was implemented, that might help us with our AI.</p>
<p>So do you think it&rsquo;s possible</p>
<p>that the kind of timescale that evolution took</p>
<p>is the kind of timescale that will be needed</p>
<p>to build intelligent systems?</p>
<p>Or can we significantly accelerate that process</p>
<p>inside a computer?</p>
<p>I mean, I think the way that we accelerate that process</p>
<p>is we borrow from biology, not slavishly,</p>
<p>but I think we look at how biology has solved problems</p>
<p>and we say, does that inspire</p>
<p>any engineering solutions here?</p>
<p>Try to mimic biological systems</p>
<p>and then therefore have a shortcut.</p>
<p>Yeah, I mean, there&rsquo;s a field called biomimicry</p>
<p>and people do that for like material science all the time.</p>
<p>We should be doing the analog of that for AI</p>
<p>and the analog for that for AI</p>
<p>is to look at cognitive science or the cognitive sciences,</p>
<p>which is psychology, maybe neuroscience, linguistics,</p>
<p>and so forth, look to those for insight.</p>
<p>What do you think is a good test of intelligence</p>
<p>in your view?</p>
<p>So I don&rsquo;t think there&rsquo;s one good test.</p>
<p>In fact, I tried to organize a movement</p>
<p>towards something called a Turing Olympics</p>
<p>and my hope is that Francois is actually gonna take,</p>
<p>Francois Chollet is gonna take over this.</p>
<p>I think he&rsquo;s interested and I don&rsquo;t,</p>
<p>I just don&rsquo;t have place in my busy life at this moment,</p>
<p>but the notion is that there&rsquo;d be many tests</p>
<p>and not just one because intelligence is multifaceted.</p>
<p>There can&rsquo;t really be a single measure of it</p>
<p>because it isn&rsquo;t a single thing.</p>
<p>Like just the crudest level,</p>
<p>the SAT has a verbal component and a math component</p>
<p>because they&rsquo;re not identical.</p>
<p>And Howard Gardner has talked about multiple intelligences</p>
<p>like kinesthetic intelligence</p>
<p>and verbal intelligence and so forth.</p>
<p>There are a lot of things that go into intelligence</p>
<p>and people can get good at one or the other.</p>
<p>I mean, in some sense, like every expert has developed</p>
<p>a very specific kind of intelligence</p>
<p>and then there are people that are generalists</p>
<p>and I think of myself as a generalist</p>
<p>with respect to cognitive science,</p>
<p>which doesn&rsquo;t mean I know anything about quantum mechanics,</p>
<p>but I know a lot about the different facets of the mind.</p>
<p>And there&rsquo;s a kind of intelligence</p>
<p>to thinking about intelligence.</p>
<p>I like to think that I have some of that,</p>
<p>but social intelligence, I&rsquo;m just okay.</p>
<p>There are people that are much better at that than I am.</p>
<p>Sure, but what would be really impressive to you?</p>
<p>I think the idea of a touring Olympics is really interesting</p>
<p>especially if somebody like Francois is running it,</p>
<p>but to you in general, not as a benchmark,</p>
<p>but if you saw an AI system being able to accomplish</p>
<p>something that would impress the heck out of you,</p>
<p>what would that thing be?</p>
<p>Would it be natural language conversation?</p>
<p>For me personally, I would like to see</p>
<p>a kind of comprehension that relates to what you just said.</p>
<p>So I wrote a piece in the New Yorker in I think 2015</p>
<p>right after Eugene Guestman, which was a software package,</p>
<p>won a version of the Turing test.</p>
<p>And the way that it did this is it be,</p>
<p>well, the way you win the Turing test,</p>
<p>so called win it, is the Turing test is you fool a person</p>
<p>into thinking that a machine is a person,</p>
<p>is you&rsquo;re evasive, you pretend to have limitations</p>
<p>so you don&rsquo;t have to answer certain questions and so forth.</p>
<p>So this particular system pretended to be a 13 year old boy</p>
<p>from Odessa who didn&rsquo;t understand English</p>
<p>and was kind of sarcastic</p>
<p>and wouldn&rsquo;t answer your questions and so forth.</p>
<p>And so judges got fooled into thinking briefly</p>
<p>with a very little exposure, it was a 13 year old boy,</p>
<p>and it docked all the questions</p>
<p>Turing was actually interested in,</p>
<p>which is like how do you make the machine</p>
<p>actually intelligent?</p>
<p>So that test itself is not that good.</p>
<p>And so in New Yorker, I proposed an alternative, I guess,</p>
<p>and the one that I proposed there</p>
<p>was a comprehension test.</p>
<p>And I must like Breaking Bad</p>
<p>because I&rsquo;ve already given you one Breaking Bad example</p>
<p>and in that article, I have one as well,</p>
<p>which was something like if Walter,</p>
<p>you should be able to watch an episode of Breaking Bad</p>
<p>or maybe you have to watch the whole series</p>
<p>to be able to answer the question and say,</p>
<p>if Walter White took a hit out on Jesse,</p>
<p>why did he do that?</p>
<p>So if you could answer kind of arbitrary questions</p>
<p>about characters motivations, I would be really impressed</p>
<p>with that and he built software to do that.</p>
<p>They could watch a film or there are different versions.</p>
<p>And so ultimately, I wrote this up with Praveen Paritosh</p>
<p>in a special issue of AI Magazine</p>
<p>that basically was about the Turing Olympics.</p>
<p>There were like 14 tests proposed.</p>
<p>The one that I was pushing was a comprehension challenge</p>
<p>and Praveen who&rsquo;s at Google was trying to figure out</p>
<p>like how we would actually run it</p>
<p>and so we wrote a paper together.</p>
<p>And you could have a text version too</p>
<p>or you could have an auditory podcast version,</p>
<p>you could have a written version.</p>
<p>But the point is that you win at this test</p>
<p>if you can do, let&rsquo;s say human level or better than humans</p>
<p>at answering kind of arbitrary questions.</p>
<p>Why did this person pick up the stone?</p>
<p>What were they thinking when they picked up the stone?</p>
<p>Were they trying to knock down glass?</p>
<p>And I mean, ideally these wouldn&rsquo;t be multiple choice either</p>
<p>because multiple choice is pretty easily gamed.</p>
<p>So if you could have relatively open ended questions</p>
<p>and you can answer why people are doing this stuff,</p>
<p>I would be very impressed.</p>
<p>And of course, humans can do this, right?</p>
<p>If you watch a well constructed movie</p>
<p>and somebody picks up a rock,</p>
<p>everybody watching the movie</p>
<p>knows why they picked up the rock, right?</p>
<p>They all know, oh my gosh,</p>
<p>he&rsquo;s gonna hit this character or whatever.</p>
<p>We have an example in the book about</p>
<p>when a whole bunch of people say, I am Spartacus,</p>
<p>you know, this famous scene.</p>
<p>The viewers understand,</p>
<p>first of all, that everybody or everybody minus one</p>
<p>has to be lying.</p>
<p>They can&rsquo;t all be Spartacus.</p>
<p>We have enough common sense knowledge</p>
<p>to know they couldn&rsquo;t all have the same name.</p>
<p>We know that they&rsquo;re lying</p>
<p>and we can infer why they&rsquo;re lying, right?</p>
<p>They&rsquo;re lying to protect someone</p>
<p>and to protect things they believe in.</p>
<p>You get a machine that can do that.</p>
<p>They can say, this is why these guys all got up</p>
<p>and said, I am Spartacus.</p>
<p>I will sit down and say, AI has really achieved a lot.</p>
<p>Thank you.</p>
<p>Without cheating any part of the system.</p>
<p>Yeah, I mean, if you do it,</p>
<p>there are lots of ways you could cheat.</p>
<p>You could build a Spartacus machine</p>
<p>that works on that film.</p>
<p>That&rsquo;s not what I&rsquo;m talking about.</p>
<p>I&rsquo;m talking about, you can do this</p>
<p>with essentially arbitrary films</p>
<p>or from a large set. Even beyond films</p>
<p>because it&rsquo;s possible such a system would discover</p>
<p>that the number of narrative arcs in film</p>
<p>is limited to 1930. Well, there&rsquo;s a famous thing</p>
<p>about the classic seven plots or whatever.</p>
<p>I don&rsquo;t care.</p>
<p>If you wanna build in the system,</p>
<p>boy meets girl, boy loses girl, boy finds girl.</p>
<p>That&rsquo;s fine.</p>
<p>I don&rsquo;t mind having some head stories on it.</p>
<p>And they acknowledge.</p>
<p>Okay, good.</p>
<p>I mean, you could build it in innately</p>
<p>or you could have your system watch a lot of films again.</p>
<p>If you can do this at all,</p>
<p>but with a wide range of films,</p>
<p>not just one film in one genre.</p>
<p>But even if you could do it for all Westerns,</p>
<p>I&rsquo;d be reasonably impressed.</p>
<p>Yeah.</p>
<p>So in terms of being impressed,</p>
<p>just for the fun of it,</p>
<p>because you&rsquo;ve put so many interesting ideas out there</p>
<p>in your book,</p>
<p>challenging the community for further steps.</p>
<p>Is it possible on the deep learning front</p>
<p>that you&rsquo;re wrong about its limitations?</p>
<p>That deep learning will unlock,</p>
<p>Yann LeCun next year will publish a paper</p>
<p>that achieves this comprehension.</p>
<p>So do you think that way often as a scientist?</p>
<p>Do you consider that your intuition</p>
<p>that deep learning could actually run away with it?</p>
<p>I&rsquo;m more worried about rebranding</p>
<p>as a kind of political thing.</p>
<p>So, I mean, what&rsquo;s gonna happen, I think,</p>
<p>is the deep learning is gonna start</p>
<p>to encompass symbol manipulation.</p>
<p>So I think Hinton&rsquo;s just wrong.</p>
<p>Hinton says we don&rsquo;t want hybrids.</p>
<p>I think people will work towards hybrids</p>
<p>and they will relabel their hybrids as deep learning.</p>
<p>We&rsquo;ve already seen some of that.</p>
<p>So AlphaGo is often described as a deep learning system,</p>
<p>but it&rsquo;s more correctly described as a system</p>
<p>that has deep learning, but also Monte Carlo tree search,</p>
<p>which is a classical AI technique.</p>
<p>And people will start to blur the lines</p>
<p>in the way that IBM blurred Watson.</p>
<p>First, Watson meant this particular system,</p>
<p>and then it was just anything that IBM built</p>
<p>in their cognitive division.</p>
<p>But purely, let me ask, for sure,</p>
<p>that&rsquo;s a branding question and that&rsquo;s like a giant mess.</p>
<p>I mean, purely, a single neural network</p>
<p>being able to accomplish reasonable comprehension.</p>
<p>I don&rsquo;t stay up at night worrying</p>
<p>that that&rsquo;s gonna happen.</p>
<p>And I&rsquo;ll just give you two examples.</p>
<p>One is a guy at DeepMind thought he had finally outfoxed me.</p>
<p>At Zergilord, I think is his Twitter handle.</p>
<p>And he said, he specifically made an example.</p>
<p>Marcus said that such and such.</p>
<p>He fed it into GP2, which is the AI system</p>
<p>that is so smart that OpenAI couldn&rsquo;t release it</p>
<p>because it would destroy the world, right?</p>
<p>You remember that a few months ago.</p>
<p>So he feeds it into GPT2, and my example</p>
<p>was something like a rose is a rose,</p>
<p>a tulip is a tulip, a lily is a blank.</p>
<p>And he got it to actually do that,</p>
<p>which was a little bit impressive.</p>
<p>And I wrote back and I said, that&rsquo;s impressive,</p>
<p>but can I ask you a few questions?</p>
<p>I said, was that just one example?</p>
<p>Can it do it generally?</p>
<p>And can it do it with novel words,</p>
<p>which was part of what I was talking about in 1998</p>
<p>when I first raised the example.</p>
<p>So a dax is a dax, right?</p>
<p>And he sheepishly wrote back about 20 minutes later.</p>
<p>And the answer was, well, it had some problems with those.</p>
<p>So I made some predictions 21 years ago that still hold.</p>
<p>In the world of computer science, that&rsquo;s amazing, right?</p>
<p>Because there&rsquo;s a thousand or a million times more memory</p>
<p>and computations a million times,</p>
<p>do million times more operations per second</p>
<p>spread across a cluster.</p>
<p>And there&rsquo;s been advances in replacing sigmoids</p>
<p>with other functions and so forth.</p>
<p>There&rsquo;s all kinds of advances,</p>
<p>but the fundamental architecture hasn&rsquo;t changed</p>
<p>and the fundamental limit hasn&rsquo;t changed.</p>
<p>And what I said then is kind of still true.</p>
<p>Then here&rsquo;s a second example.</p>
<p>I recently had a piece in Wired</p>
<p>that&rsquo;s adapted from the book.</p>
<p>And the book went to press before GP2 came out,</p>
<p>but we described this children&rsquo;s story</p>
<p>and all the inferences that you make in this story</p>
<p>about a boy finding a lost wallet.</p>
<p>And for fun, in the Wired piece, we ran it through GP2.</p>
<p>GPT2, something called talktotransformer.com,</p>
<p>and your viewers can try this experiment themselves.</p>
<p>Go to the Wired piece that has the link</p>
<p>and it has the story.</p>
<p>And the system made perfectly fluent text</p>
<p>that was totally inconsistent</p>
<p>with the conceptual underpinnings of the story, right?</p>
<p>This is what, again, I predicted in 1998.</p>
<p>And for that matter, Chomsky and Miller</p>
<p>made the same prediction in 1963.</p>
<p>I was just updating their claim for a slightly new text.</p>
<p>So those particular architectures</p>
<p>that don&rsquo;t have any built in knowledge,</p>
<p>they&rsquo;re basically just a bunch of layers</p>
<p>doing correlational stuff.</p>
<p>They&rsquo;re not gonna solve these problems.</p>
<p>So 20 years ago, you said the emperor has no clothes.</p>
<p>Today, the emperor still has no clothes.</p>
<p>The lighting&rsquo;s better though.</p>
<p>The lighting is better.</p>
<p>And I think you yourself are also, I mean.</p>
<p>And we found out some things to do with naked emperors.</p>
<p>I mean, it&rsquo;s not like stuff is worthless.</p>
<p>I mean, they&rsquo;re not really naked.</p>
<p>It&rsquo;s more like they&rsquo;re in their briefs</p>
<p>than everybody thinks they are.</p>
<p>And so like, I mean, they are great at speech recognition,</p>
<p>but the problems that I said were hard.</p>
<p>I didn&rsquo;t literally say the emperor has no clothes.</p>
<p>I said, this is a set of problems</p>
<p>that humans are really good at.</p>
<p>And it wasn&rsquo;t couched as AI.</p>
<p>It was couched as cognitive science.</p>
<p>But I said, if you wanna build a neural model</p>
<p>of how humans do certain class of things,</p>
<p>you&rsquo;re gonna have to change the architecture.</p>
<p>And I stand by those claims.</p>
<p>So, and I think people should understand</p>
<p>you&rsquo;re quite entertaining in your cynicism,</p>
<p>but you&rsquo;re also very optimistic and a dreamer</p>
<p>about the future of AI too.</p>
<p>So you&rsquo;re both, it&rsquo;s just.</p>
<p>There&rsquo;s a famous saying about being,</p>
<p>people overselling technology in the short run</p>
<p>and underselling it in the long run.</p>
<p>And so I actually end the book,</p>
<p>Ernie Davis and I end our book with an optimistic chapter,</p>
<p>which kind of killed Ernie</p>
<p>because he&rsquo;s even more pessimistic than I am.</p>
<p>He describes me as a contrarian and him as a pessimist.</p>
<p>But I persuaded him that we should end the book</p>
<p>with a look at what would happen</p>
<p>if AI really did incorporate, for example,</p>
<p>the common sense reasoning and the nativism</p>
<p>and so forth, the things that we counseled for.</p>
<p>And we wrote it and it&rsquo;s an optimistic chapter</p>
<p>that AI suitably reconstructed so that we could trust it,</p>
<p>which we can&rsquo;t now, could really be world changing.</p>
<p>So on that point, if you look at the future trajectories</p>
<p>of AI, people have worries about negative effects of AI,</p>
<p>whether it&rsquo;s at the large existential scale</p>
<p>or smaller short term scale of negative impact on society.</p>
<p>So you write about trustworthy AI,</p>
<p>how can we build AI systems that align with our values,</p>
<p>that make for a better world,</p>
<p>that we can interact with, that we can trust?</p>
<p>The first thing we have to do</p>
<p>is to replace deep learning with deep understanding.</p>
<p>So you can&rsquo;t have alignment with a system</p>
<p>that traffics only in correlations</p>
<p>and doesn&rsquo;t understand concepts like bottles or harm.</p>
<p>So Asimov talked about these famous laws</p>
<p>and the first one was first do no harm.</p>
<p>And you can quibble about the details of Asimov&rsquo;s laws,</p>
<p>but we have to, if we&rsquo;re gonna build real robots</p>
<p>in the real world, have something like that.</p>
<p>That means we have to program in a notion</p>
<p>that&rsquo;s at least something like harm.</p>
<p>That means we have to have these more abstract ideas</p>
<p>that deep learning is not particularly good at.</p>
<p>They have to be in the mix somewhere.</p>
<p>And you could do statistical analysis</p>
<p>about probabilities of given harms or whatever,</p>
<p>but you have to know what a harm is</p>
<p>in the same way that you have to understand</p>
<p>that a bottle isn&rsquo;t just a collection of pixels.</p>
<p>And also be able to, you&rsquo;re implying</p>
<p>that you need to also be able to communicate</p>
<p>that to humans so the AI systems would be able</p>
<p>to prove to humans that they understand</p>
<p>that they know what harm means.</p>
<p>I might run it in the reverse direction,</p>
<p>but roughly speaking, I agree with you.</p>
<p>So we probably need to have committees</p>
<p>of wise people, ethicists and so forth.</p>
<p>Think about what these rules ought to be</p>
<p>and we shouldn&rsquo;t just leave it to software engineers.</p>
<p>It shouldn&rsquo;t just be software engineers</p>
<p>and it shouldn&rsquo;t just be people</p>
<p>who own large mega corporations</p>
<p>that are good at technology, ethicists</p>
<p>and so forth should be involved.</p>
<p>But there should be some assembly of wise people</p>
<p>as I was putting it that tries to figure out</p>
<p>what the rules ought to be.</p>
<p>And those have to get translated into code.</p>
<p>You can argue or code or neural networks or something.</p>
<p>They have to be translated into something</p>
<p>that machines can work with.</p>
<p>And that means there has to be a way</p>
<p>of working the translation.</p>
<p>And right now we don&rsquo;t.</p>
<p>We don&rsquo;t have a way.</p>
<p>So let&rsquo;s say you and I were the committee</p>
<p>and we decide that Asimov&rsquo;s first law is actually right.</p>
<p>And let&rsquo;s say it&rsquo;s not just two white guys,</p>
<p>which would be kind of unfortunate that we have abroad.</p>
<p>And so we&rsquo;ve representative sample of the world</p>
<p>or however we wanna do this.</p>
<p>And the committee decides eventually,</p>
<p>okay, Asimov&rsquo;s first law is actually pretty good.</p>
<p>There are these exceptions to it.</p>
<p>We wanna program in these exceptions.</p>
<p>But let&rsquo;s start with just the first one</p>
<p>and then we&rsquo;ll get to the exceptions.</p>
<p>First one is first do no harm.</p>
<p>Well, somebody has to now actually turn that into</p>
<p>a computer program or a neural network or something.</p>
<p>And one way of taking the whole book,</p>
<p>the whole argument that I&rsquo;m making</p>
<p>is that we just don&rsquo;t have to do that yet.</p>
<p>And we&rsquo;re fooling ourselves</p>
<p>if we think that we can build trustworthy AI</p>
<p>if we can&rsquo;t even specify in any kind of,</p>
<p>we can&rsquo;t do it in Python and we can&rsquo;t do it in TensorFlow.</p>
<p>We&rsquo;re fooling ourselves in thinking</p>
<p>that we can make trustworthy AI</p>
<p>if we can&rsquo;t translate harm into something</p>
<p>that we can execute.</p>
<p>And if we can&rsquo;t, then we should be thinking really hard</p>
<p>how could we ever do such a thing?</p>
<p>Because if we&rsquo;re gonna use AI</p>
<p>in the ways that we wanna use it,</p>
<p>to make job interviews or to do surveillance,</p>
<p>not that I personally wanna do that or whatever.</p>
<p>I mean, if we&rsquo;re gonna use AI</p>
<p>in ways that have practical impact on people&rsquo;s lives</p>
<p>or medicine, it&rsquo;s gotta be able</p>
<p>to understand stuff like that.</p>
<p>So one of the things your book highlights</p>
<p>is that a lot of people in the deep learning community,</p>
<p>but also the general public, politicians,</p>
<p>just people in all general groups and walks of life</p>
<p>have different levels of misunderstanding of AI.</p>
<p>So when you talk about committees,</p>
<p>what&rsquo;s your advice to our society?</p>
<p>How do we grow, how do we learn about AI</p>
<p>such that such committees could emerge</p>
<p>where large groups of people could have</p>
<p>a productive discourse about</p>
<p>how to build successful AI systems?</p>
<p>Part of the reason we wrote the book</p>
<p>was to try to inform those committees.</p>
<p>So part of the reason we wrote the book</p>
<p>was to inspire a future generation of students</p>
<p>to solve what we think are the important problems.</p>
<p>So a lot of the book is trying to pinpoint</p>
<p>what we think are the hard problems</p>
<p>where we think effort would most be rewarded.</p>
<p>And part of it is to try to train people</p>
<p>who talk about AI, but aren&rsquo;t experts in the field</p>
<p>to understand what&rsquo;s realistic and what&rsquo;s not.</p>
<p>One of my favorite parts in the book</p>
<p>is the six questions you should ask</p>
<p>anytime you read a media account.</p>
<p>So like number one is if somebody talks about something,</p>
<p>look for the demo.</p>
<p>If there&rsquo;s no demo, don&rsquo;t believe it.</p>
<p>Like the demo that you can try.</p>
<p>If you can&rsquo;t try it at home,</p>
<p>maybe it doesn&rsquo;t really work that well yet.</p>
<p>So if, we don&rsquo;t have this example in the book,</p>
<p>but if Sundar Pinchai says we have this thing</p>
<p>that allows it to sound like human beings in conversation,</p>
<p>you should ask, can I try it?</p>
<p>And you should ask how general it is.</p>
<p>And it turns out at that time,</p>
<p>I&rsquo;m alluding to Google Duplex when it was announced,</p>
<p>it only worked on calling hairdressers,</p>
<p>restaurants and finding opening hours.</p>
<p>That&rsquo;s not very general, that&rsquo;s narrow AI.</p>
<p>And I&rsquo;m not gonna ask your thoughts about Sophia,</p>
<p>but yeah, I understand that&rsquo;s a really good question</p>
<p>to ask of any kind of hype top idea.</p>
<p>Sophia has very good material written for her,</p>
<p>but she doesn&rsquo;t understand the things that she&rsquo;s saying.</p>
<p>So a while ago you&rsquo;ve written a book</p>
<p>on the science of learning, which I think is fascinating,</p>
<p>but the learning case studies of playing guitar.</p>
<p>That&rsquo;s called Guitar Zero.</p>
<p>I love guitar myself, I&rsquo;ve been playing my whole life.</p>
<p>So let me ask a very important question.</p>
<p>What is your favorite song, rock song,</p>
<p>to listen to or try to play?</p>
<p>Well, those would be different,</p>
<p>but I&rsquo;ll say that my favorite rock song to listen to</p>
<p>is probably All Along the Watchtower,</p>
<p>The Jimi Hendrix version.</p>
<p>It feels magic to me.</p>
<p>I&rsquo;ve actually recently learned it, I love that song.</p>
<p>I&rsquo;ve been trying to put it on YouTube, myself singing.</p>
<p>Singing is the scary part.</p>
<p>If you could party with a rock star for a weekend,</p>
<p>living or dead, who would you choose?</p>
<p>And pick their mind, it&rsquo;s not necessarily about the partying.</p>
<p>Thanks for the clarification.</p>
<p>I guess John Lennon&rsquo;s such an intriguing person,</p>
<p>and I think a troubled person, but an intriguing one.</p>
<p>Beautiful.</p>
<p>Well, Imagine is one of my favorite songs.</p>
<p>Also one of my favorite songs.</p>
<p>That&rsquo;s a beautiful way to end it.</p>
<p>Gary, thank you so much for talking to me.</p>
<p>Thanks so much for having me.</p>

</section>


    <footer class="article-footer">
    
    <section class="article-tags">
        
            <a href="/tags/english/">English</a>
        
            <a href="/tags/podcast/">Podcast</a>
        
            <a href="/tags/lex-fridman-podcast/">Lex Fridman Podcast</a>
        
    </section>


    </footer>


    
</article>

    

    

<div>
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9206135835124064"
         crossorigin="anonymous"></script>
    <ins class="adsbygoogle"
         style="display:block; text-align:center;"
         data-ad-layout="in-article"
         data-ad-format="fluid"
         data-ad-client="ca-pub-9206135835124064"
         data-ad-slot="1055602464"></ins>
    <script>
         (adsbygoogle = window.adsbygoogle || []).push({});
    </script>
</div>
<aside class="related-content--wrapper">
    <h2 class="section-title">Related content</h2>
    <div class="related-content">
        <div class="flex article-list--tile">
            
                
<article class="">
    <a href="/en/1310500372/">
        
	
        
        <div class="article-image">
            
            <img src="/img/related-content.png" loading="lazy" 
            data-key="en/1310500372" data-hash="" 
            style="opacity: 0.3;"/>
        </div>
        
        <div class="article-details">
            <h2 class="article-title">Lex Fridman Podcast - #368 - Eliezer Yudkowsky: Dangers of AI and the End of Human Civilization</h2>
            
            <footer class="article-time">
                <time datetime=''>Mar 30, 2023</time>
            </footer>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/en/1310500371/">
        
	
        
        <div class="article-image">
            
            <img src="/img/related-content.png" loading="lazy" 
            data-key="en/1310500371" data-hash="" 
            style="opacity: 0.3;"/>
        </div>
        
        <div class="article-details">
            <h2 class="article-title">Lex Fridman Podcast - #367 - Sam Altman: OpenAI CEO on GPT-4, ChatGPT, and the Future of AI</h2>
            
            <footer class="article-time">
                <time datetime=''>Mar 26, 2023</time>
            </footer>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/en/1310500370/">
        
	
        
        <div class="article-image">
            
            <img src="/img/related-content.png" loading="lazy" 
            data-key="en/1310500370" data-hash="" 
            style="opacity: 0.3;"/>
        </div>
        
        <div class="article-details">
            <h2 class="article-title">Lex Fridman Podcast - #366 - Shannon Curry: Johnny Depp &amp; Amber Heard Trial, Marriage, Dating &amp; Love</h2>
            
            <footer class="article-time">
                <time datetime=''>Mar 22, 2023</time>
            </footer>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/en/1310500369/">
        
	
        
        <div class="article-image">
            
            <img src="/img/related-content.png" loading="lazy" 
            data-key="en/1310500369" data-hash="" 
            style="opacity: 0.3;"/>
        </div>
        
        <div class="article-details">
            <h2 class="article-title">Lex Fridman Podcast - #365 - Sam Harris: Trump, Pandemic, Twitter, Elon, Bret, IDW, Kanye, AI &amp; UFOs</h2>
            
            <footer class="article-time">
                <time datetime=''>Mar 15, 2023</time>
            </footer>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/en/1310500368/">
        
	
        
        <div class="article-image">
            
            <img src="/img/related-content.png" loading="lazy" 
            data-key="en/1310500368" data-hash="" 
            style="opacity: 0.3;"/>
        </div>
        
        <div class="article-details">
            <h2 class="article-title">Lex Fridman Podcast - #364 - Chris Voss: FBI Hostage Negotiator</h2>
            
            <footer class="article-time">
                <time datetime=''>Mar 11, 2023</time>
            </footer>
        </div>
    </a>
</article>

            
        </div>
    </div>
</aside>

     
    
        
    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
            2021 - 
        
        2023 SWIEST - Transcripts ¬∑ Screenplays ¬∑ Lyrics
    </section>
    
    <section class="powerby">
        

        As an Amazon Associate I earn from qualifying purchases üõí<br/>

        Built with <a href="https://swiest.com/" target="_blank" rel="noopener">(Ôæâ‚óï„ÉÆ‚óï)Ôæâü™Ñüíûüíñü•∞ across the glüåçüåèüåébe</a> <br />
        
        
    </section>
</footer>


    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo="crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU="crossorigin="anonymous"
                defer
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css"crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css"crossorigin="anonymous"
            >

            </main>
        </div>
        <script 
                src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js"integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z&#43;KMkF24hUW8WePSA9HM="crossorigin="anonymous"
                
                >
            </script><script type="text/javascript" src="/ts/main.js" defer></script>


<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Noto+Serif&family=Noto+Serif+Armenian&family=Noto+Serif+Bengali&family=Noto+Serif+Devanagari&family=Noto+Serif+Georgian&family=Noto+Serif+Gujarati&family=Noto+Serif+HK&family=Noto+Serif+Hebrew&family=Noto+Serif+JP&family=Noto+Serif+KR&family=Noto+Serif+Kannada&family=Noto+Serif+Khmer&family=Noto+Serif+Lao&family=Noto+Serif+Makasar&family=Noto+Serif+Malayalam&family=Noto+Serif+Myanmar&family=Noto+Serif+Oriya&family=Noto+Serif+SC&family=Noto+Serif+Sinhala&family=Noto+Serif+TC&family=Noto+Serif+Tamil&family=Noto+Serif+Telugu&family=Noto+Serif+Thai&family=Noto+Serif+Tibetan&display=swap" rel="stylesheet">

    </body>
</html>
