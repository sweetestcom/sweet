<!DOCTYPE html>
<html lang="en" dir="ltr">
    <head><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content='The following is a conversation with Peter Singer,
professor of bioethics at Princeton University,
best known for his 1975 book, Animal Liberation,
that makes an ethical case against eating meat.
He has written brilliantly from an ethical perspective
on extreme poverty, euthanasia, human genetic selection,
sports doping, the sale of kidneys,
and generally happiness, including in his books,
Ethics in the Real World, and The Life You Can Save.
He was a key popularizer of the effective altruism movement'>
<title>Lex Fridman Podcast - #107 ‚Äì Peter Singer: Suffering in Humans, Animals, and AI | SWIEST</title>

<link rel='canonical' href='https://swiest.com/en/1310500107/'>

<link rel="stylesheet" href="/scss/style.min.91b18679590f4ceed910ade4d64b1e7375cc0770ef5b8c1d822f42424f9ff2c8.css"><script>
    document.oncontextmenu = function(){ return false; };
    document.onselectstart = function(){ return false; };
    document.oncopy = function(){ return false; };
    document.oncut = function(){ return false; };
</script>

<script src="https://apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js"></script>


<script type="text/javascript">
    $(document).ready(function(){
     
     $("#back-to-top").hide();
     
     $(function () {
      $(window).scroll(function(){
       if ($(window).scrollTop()>600){
        $("#back-to-top").fadeIn(500);
       }else{
        $("#back-to-top").fadeOut(500);
       }
     });
     
     $("#back-to-top").click(function(){
      $('body,html').animate({scrollTop:0},500);
       return false;
      });
     });
    });
    </script><meta property='og:title' content='Lex Fridman Podcast - #107 ‚Äì Peter Singer: Suffering in Humans, Animals, and AI'>
<meta property='og:description' content='The following is a conversation with Peter Singer,
professor of bioethics at Princeton University,
best known for his 1975 book, Animal Liberation,
that makes an ethical case against eating meat.
He has written brilliantly from an ethical perspective
on extreme poverty, euthanasia, human genetic selection,
sports doping, the sale of kidneys,
and generally happiness, including in his books,
Ethics in the Real World, and The Life You Can Save.
He was a key popularizer of the effective altruism movement'>
<meta property='og:url' content='https://swiest.com/en/1310500107/'>
<meta property='og:site_name' content='SWIEST - Transcripts ¬∑ Screenplays ¬∑ Lyrics'>
<meta property='og:type' content='article'><meta property='article:section' content='Post' /><meta property='article:tag' content='English' /><meta property='article:tag' content='Podcast' /><meta property='article:tag' content='Lex Fridman Podcast' /><meta property='article:published_time' content='2022-06-15T17:00:00&#43;00:00'/><meta property='article:modified_time' content='2022-06-15T17:00:00&#43;00:00'/>
<meta name="twitter:title" content="Lex Fridman Podcast - #107 ‚Äì Peter Singer: Suffering in Humans, Animals, and AI">
<meta name="twitter:description" content="The following is a conversation with Peter Singer,
professor of bioethics at Princeton University,
best known for his 1975 book, Animal Liberation,
that makes an ethical case against eating meat.
He has written brilliantly from an ethical perspective
on extreme poverty, euthanasia, human genetic selection,
sports doping, the sale of kidneys,
and generally happiness, including in his books,
Ethics in the Real World, and The Life You Can Save.
He was a key popularizer of the effective altruism movement">
    <link rel="shortcut icon" href="/favicon.ico" />
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9206135835124064" crossorigin="anonymous"></script>
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    </head>
    <body class="
    article-page
    ">
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "dark");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky ">
    <button class="hamburger hamburger--spin" type="button" id="toggle-menu" aria-label="Toggle Menu">
        <span class="hamburger-box">
            <span class="hamburger-inner"></span>
        </span>
    </button>

    <header>
        
            
            <figure class="site-avatar">
                <a href="/">
                
                    
                    
                    
                        
                        <img src="/img/avatar_hu307e6a33fa6fd661ccda3b77024ef5c2_252345_300x0_resize_box_3.png" width="300"
                            height="300" class="site-logo" loading="lazy" alt="Avatar">
                    
                
                </a>
                
                    <span class="emoji">‚ú®</span>
                
            </figure>
            
        
        
        <div class="site-meta">
            <h1 class="site-name"><a href="/">SWIEST - Transcripts ¬∑ Screenplays ¬∑ Lyrics</a></h1>
            <h2 class="site-description">üåçüåèüåé</h2>
        </div>
    </header><ol class="menu" id="main-menu">
        
        
        
        <li >
            <a href='/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <polyline points="5 12 3 12 12 3 21 12 19 12" />
  <path d="M5 12v7a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-7" />
  <path d="M9 21v-6a2 2 0 0 1 2 -2h2a2 2 0 0 1 2 2v6" />
</svg>



                
                <span>Home</span>
            </a>
        </li>
        
        
        <li >
            <a href='/search/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="10" cy="10" r="7" />
  <line x1="21" y1="21" x2="15" y2="15" />
</svg>



                
                <span>Search</span>
            </a>
        </li>
        
        
        <li >
            <a href='/chart/podcastchart.html' target="_blank">
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-apple-podcast" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M18.364 18.364a9 9 0 1 0 -12.728 0" />
  <path d="M11.766 22h.468a2 2 0 0 0 1.985 -1.752l.5 -4a2 2 0 0 0 -1.985 -2.248h-1.468a2 2 0 0 0 -1.985 2.248l.5 4a2 2 0 0 0 1.985 1.752z" />
  <path d="M12 9m-2 0a2 2 0 1 0 4 0a2 2 0 1 0 -4 0" />
</svg>
                
                <span>Podcast Charts</span>
            </a>
        </li>
        


        <div class="menu-bottom-section">
                <li id="i18n-switch">  
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-language" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M4 5h7" />
  <path d="M9 3v2c0 4.418 -2.239 8 -5 8" />
  <path d="M5 9c-.003 2.144 2.952 3.908 6.7 4" />
  <path d="M12 20l4 -9l4 9" />
  <path d="M19.1 18h-6.2" />
</svg>



                    <select name="language" onchange="window.location.href = this.selectedOptions[0].value">
                        
                            <option value="https://swiest.com/" selected>English</option>
                        
                            <option value="https://swiest.com/af/" >Afrikaans</option>
                        
                            <option value="https://swiest.com/am/" >·ä†·àõ·à≠·äõ</option>
                        
                            <option value="https://swiest.com/ar/" >ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</option>
                        
                            <option value="https://swiest.com/az/" >Az…ôrbaycan</option>
                        
                            <option value="https://swiest.com/be/" >–±–µ–ª–∞—Ä—É—Å–∫—ñ</option>
                        
                            <option value="https://swiest.com/bg/" >–±—ä–ª–≥–∞—Ä—Å–∫–∏</option>
                        
                            <option value="https://swiest.com/bn/" >‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ</option>
                        
                            <option value="https://swiest.com/bo/" >‡Ωñ‡Ωº‡Ωë‡ºã‡Ω¶‡æê‡Ωë‡ºã</option>
                        
                            <option value="https://swiest.com/bs/" >Bosanski</option>
                        
                            <option value="https://swiest.com/ca/" >Catal√†</option>
                        
                            <option value="https://swiest.com/zh-hans/" >ÁÆÄ‰Ωì‰∏≠Êñá</option>
                        
                            <option value="https://swiest.com/zh-hant/" >ÁπÅÈ´î‰∏≠Êñá</option>
                        
                            <option value="https://swiest.com/cs/" >ƒåe≈°tina</option>
                        
                            <option value="https://swiest.com/el/" >ŒµŒªŒªŒ∑ŒΩŒπŒ∫Œ¨</option>
                        
                            <option value="https://swiest.com/cy/" >Cymraeg</option>
                        
                            <option value="https://swiest.com/da/" >Dansk</option>
                        
                            <option value="https://swiest.com/de/" >Deutsch</option>
                        
                            <option value="https://swiest.com/eo/" >Esperanto</option>
                        
                            <option value="https://swiest.com/es-es/" >Espa√±ol (Espa√±a)</option>
                        
                            <option value="https://swiest.com/es-419/" >Espa√±ol (Latinoam√©rica)</option>
                        
                            <option value="https://swiest.com/et/" >Eesti</option>
                        
                            <option value="https://swiest.com/eu/" >Euskara</option>
                        
                            <option value="https://swiest.com/haw/" > ª≈ålelo Hawai ªi</option>
                        
                            <option value="https://swiest.com/fa/" >ŸÅÿßÿ±ÿ≥€å</option>
                        
                            <option value="https://swiest.com/fi/" >Suomi</option>
                        
                            <option value="https://swiest.com/fo/" >F√∏royskt</option>
                        
                            <option value="https://swiest.com/fr/" >Fran√ßais</option>
                        
                            <option value="https://swiest.com/fy/" >Frysk</option>
                        
                            <option value="https://swiest.com/ga/" >Gaeilge</option>
                        
                            <option value="https://swiest.com/gl/" >Galego</option>
                        
                            <option value="https://swiest.com/gu/" >‡™ó‡´Å‡™ú‡™∞‡™æ‡™§‡´Ä</option>
                        
                            <option value="https://swiest.com/he/" >◊¢÷¥◊ë◊®÷¥◊ô◊™</option>
                        
                            <option value="https://swiest.com/km/" >·ûÄ·ûò·üí·ûñ·ûª·ûá·û∂·üî</option>
                        
                            <option value="https://swiest.com/hi/" >‡§π‡§ø‡§®‡•ç‡§¶‡•Ä</option>
                        
                            <option value="https://swiest.com/hr/" >Hrvatski</option>
                        
                            <option value="https://swiest.com/ht/" >Krey√≤l Ayisyen</option>
                        
                            <option value="https://swiest.com/hu/" >Magyar</option>
                        
                            <option value="https://swiest.com/hy/" >’Ä’°’µ’•÷Ä’•’∂</option>
                        
                            <option value="https://swiest.com/ig/" >√Ås·ª•ÃÄs·ª•ÃÅ √ågb√≤</option>
                        
                            <option value="https://swiest.com/id/" >Bahasa Indonesia</option>
                        
                            <option value="https://swiest.com/is/" >√çslenska</option>
                        
                            <option value="https://swiest.com/it/" >Italiano</option>
                        
                            <option value="https://swiest.com/ja/" >Êó•Êú¨Ë™û</option>
                        
                            <option value="https://swiest.com/jv/" >Basa Jawa</option>
                        
                            <option value="https://swiest.com/ka/" >·É•·Éê·É†·Éó·É£·Éö·Éò</option>
                        
                            <option value="https://swiest.com/kk/" >“ö–∞–∑–∞“õ—à–∞</option>
                        
                            <option value="https://swiest.com/kn/" >‡≤ï‡≤®‡≥ç‡≤®‡≤°</option>
                        
                            <option value="https://swiest.com/ko/" >ÌïúÍµ≠Ïñ¥</option>
                        
                            <option value="https://swiest.com/or/" >‡¨ì‡¨°‡¨º‡¨ø‡¨Ü</option>
                        
                            <option value="https://swiest.com/ckb/" >⁄©Ÿàÿ±ÿØ€å</option>
                        
                            <option value="https://swiest.com/ky/" >–ö—ã—Ä–≥—ã–∑—á–∞</option>
                        
                            <option value="https://swiest.com/la/" >Latina</option>
                        
                            <option value="https://swiest.com/lb/" >L√´tzebuergesch</option>
                        
                            <option value="https://swiest.com/lo/" >‡∫û‡∫≤‡∫™‡∫≤‡∫•‡∫≤‡∫ß</option>
                        
                            <option value="https://swiest.com/lt/" >Lietuvi≈≥</option>
                        
                            <option value="https://swiest.com/lv/" >Latvie≈°u</option>
                        
                            <option value="https://swiest.com/mk/" >–ú–∞–∫–µ–¥–æ–Ω—Å–∫–∏</option>
                        
                            <option value="https://swiest.com/ml/" >‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç</option>
                        
                            <option value="https://swiest.com/mn/" >–ú–æ–Ω–≥–æ–ª —Ö—ç–ª</option>
                        
                            <option value="https://swiest.com/mr/" >‡§Æ‡§∞‡§æ‡§†‡•Ä</option>
                        
                            <option value="https://swiest.com/sw/" >Kiswahili</option>
                        
                            <option value="https://swiest.com/ms/" >Bahasa Melayu</option>
                        
                            <option value="https://swiest.com/my/" >·Äô·Äº·Äî·Ä∫·Äô·Ä¨</option>
                        
                            <option value="https://swiest.com/ne/" >‡§®‡•á‡§™‡§æ‡§≤‡•Ä</option>
                        
                            <option value="https://swiest.com/nl/" >Nederlands</option>
                        
                            <option value="https://swiest.com/no/" >Norsk</option>
                        
                            <option value="https://swiest.com/pa/" >‡®™‡©∞‡®ú‡®æ‡®¨‡©Ä</option>
                        
                            <option value="https://swiest.com/pl/" >Polski</option>
                        
                            <option value="https://swiest.com/pt-br/" >Portugu√™s Brasil</option>
                        
                            <option value="https://swiest.com/pt-pt/" >Portugu√™s Europeu</option>
                        
                            <option value="https://swiest.com/ro/" >Rom√¢nƒÉ</option>
                        
                            <option value="https://swiest.com/ru/" >–†—É—Å—Å–∫–∏–π</option>
                        
                            <option value="https://swiest.com/rw/" >Kinyarwanda</option>
                        
                            <option value="https://swiest.com/si/" >‡∑É‡∑í‡∂Ç‡∑Ñ‡∂Ω</option>
                        
                            <option value="https://swiest.com/sk/" >Slovenƒçina</option>
                        
                            <option value="https://swiest.com/sl/" >Sloven≈°ƒçina</option>
                        
                            <option value="https://swiest.com/sq/" >Shqip</option>
                        
                            <option value="https://swiest.com/sr/" >–°—Ä–ø—Å–∫–∏ (Srpski)</option>
                        
                            <option value="https://swiest.com/su/" >Basa Sunda</option>
                        
                            <option value="https://swiest.com/sv/" >Svenska</option>
                        
                            <option value="https://swiest.com/ta/" >‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç</option>
                        
                            <option value="https://swiest.com/te/" >‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å</option>
                        
                            <option value="https://swiest.com/tg/" >–¢–æ“∑–∏–∫”£</option>
                        
                            <option value="https://swiest.com/th/" >‡πÑ‡∏ó‡∏¢</option>
                        
                            <option value="https://swiest.com/tl/" >Filipino</option>
                        
                            <option value="https://swiest.com/tr/" >T√ºrk√ße</option>
                        
                            <option value="https://swiest.com/uk/" >–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞</option>
                        
                            <option value="https://swiest.com/ur/" >ÿßÿ±ÿØŸà</option>
                        
                            <option value="https://swiest.com/uz/" >O&#39;zbekcha</option>
                        
                            <option value="https://swiest.com/vi/" >Ti·∫øng Vi·ªát</option>
                        
                            <option value="https://swiest.com/yi/" >◊ê◊ô◊ì◊ô◊©</option>
                        
                            <option value="https://swiest.com/zh-hk/" >Á≤µË™û</option>
                        
                            <option value="https://swiest.com/zu/" >IsiZulu</option>
                        
                    </select>
                </li>
            
            
            
                <li id="dark-mode-toggle">
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="8" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="16" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                    <span>Dark Mode</span>
                </li>
            
        </div>
    </ol>
</aside>

    

            <main class="main full-width">
    <article class="main-article">
    <header class="article-header">

    <div class="article-details">
    
    <header class="article-category">
        
            <a href="/categories/podcast/" >
                Podcast
            </a>
        
            <a href="/categories/lex-fridman-podcast/" >
                Lex Fridman Podcast
            </a>
        
    </header>
    

    <div class="article-title-wrapper">
        <h2 class="article-title">
            <a href="/en/1310500107/">Lex Fridman Podcast - #107 ‚Äì Peter Singer: Suffering in Humans, Animals, and AI</a>
        </h2>
    
        
    </div>

    
    
    
    
    <footer class="article-time">
        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M11.795 21h-6.795a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v4" />
  <circle cx="18" cy="18" r="4" />
  <path d="M15 3v4" />
  <path d="M7 3v4" />
  <path d="M3 11h16" />
  <path d="M18 16.496v1.504l1 1" />
</svg>
                <time class="article-time--published">2022-06-15</time>
            </div>
        

        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



                <time class="article-time--reading">
                    50 minute read
                </time>
            </div>
        
    </footer>
    

    
</div>

</header>
<div class="article-content">
    <p style="text-align:center">
       <a href="https://amzn.to/471i0jl" target="_blank">üéÅAmazon Prime</a>
       <a href="https://amzn.to/3Fulwaf" target="_blank">üíóThe Drop</a>
       <a href="https://amzn.to/3QDVlVf" target="_blank">üìñKindle Unlimited</a>
       <a href="https://amzn.to/3FqzNoB" target="_blank">üéßAudible Plus</a>
       <a href="https://amzn.to/3tMT3dm" target="_blank">üéµAmazon Music Unlimited</a>
       <a href="https://www.iherb.com/?rcode=EID1574" target="_blank">üåøiHerb</a>
       <a href="https://accounts.binance.com/register?ref=72302422" target="_blank">ü™ôBinance</a>
    </p>
</div>
<div>
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9206135835124064"
     crossorigin="anonymous"></script>
    
    <ins class="adsbygoogle"
         style="display:block"
         data-ad-client="ca-pub-9206135835124064"
         data-ad-slot="8754979142"
         data-ad-format="auto"
         data-full-width-responsive="true"></ins>
    <script>
         (adsbygoogle = window.adsbygoogle || []).push({});
    </script>
</div>


    <section class="article-content">
    
    
    <p>The following is a conversation with Peter Singer,</p>
<p>professor of bioethics at Princeton University,</p>
<p>best known for his 1975 book, Animal Liberation,</p>
<p>that makes an ethical case against eating meat.</p>
<p>He has written brilliantly from an ethical perspective</p>
<p>on extreme poverty, euthanasia, human genetic selection,</p>
<p>sports doping, the sale of kidneys,</p>
<p>and generally happiness, including in his books,</p>
<p>Ethics in the Real World, and The Life You Can Save.</p>
<p>He was a key popularizer of the effective altruism movement</p>
<p>and is generally considered one of the most influential</p>
<p>philosophers in the world.</p>
<p>Quick summary of the ads.</p>
<p>Two sponsors, Cash App and Masterclass.</p>
<p>Please consider supporting the podcast</p>
<p>by downloading Cash App and using code LexPodcast</p>
<p>and signing up at masterclass.com slash Lex.</p>
<p>Click the links, buy the stuff.</p>
<p>It really is the best way to support the podcast</p>
<p>and the journey I&rsquo;m on.</p>
<p>As you may know, I primarily eat a ketogenic or carnivore diet,</p>
<p>which means that most of my diet is made up of meat.</p>
<p>I do not hunt the food I eat, though one day I hope to.</p>
<p>I love fishing, for example.</p>
<p>Fishing and eating the fish I catch</p>
<p>has always felt much more honest than participating</p>
<p>in the supply chain of factory farming.</p>
<p>From an ethics perspective, this part of my life</p>
<p>has always had a cloud over it.</p>
<p>It makes me think.</p>
<p>I&rsquo;ve tried a few times in my life</p>
<p>to reduce the amount of meat I eat.</p>
<p>But for some reason, whatever the makeup of my body,</p>
<p>whatever the way I practice the dieting I have,</p>
<p>I get a lot of mental and physical energy</p>
<p>and performance from eating meat.</p>
<p>So both intellectually and physically,</p>
<p>it&rsquo;s a continued journey for me.</p>
<p>I return to Peter&rsquo;s work often to reevaluate the ethics</p>
<p>of how I live this aspect of my life.</p>
<p>Let me also say that you may be a vegan</p>
<p>or you may be a meat eater and may be upset by the words I say</p>
<p>or Peter says, but I ask for this podcast</p>
<p>and other episodes of this podcast</p>
<p>that you keep an open mind.</p>
<p>I may and probably will talk with people you disagree with.</p>
<p>Please try to really listen, especially</p>
<p>to people you disagree with.</p>
<p>And give me and the world the gift</p>
<p>of being a participant in a patient, intelligent,</p>
<p>and nuanced discourse.</p>
<p>If your instinct and desire is to be a voice of mockery</p>
<p>towards those you disagree with, please unsubscribe.</p>
<p>My source of joy and inspiration here</p>
<p>has been to be a part of a community that thinks deeply</p>
<p>and speaks with empathy and compassion.</p>
<p>That is what I hope to continue being a part of</p>
<p>and I hope you join as well.</p>
<p>If you enjoy this podcast, subscribe on YouTube,</p>
<p>review it with five stars on Apple Podcast,</p>
<p>follow on Spotify, support on Patreon,</p>
<p>or connect with me on Twitter at Lex Friedman.</p>
<p>As usual, I&rsquo;ll do a few minutes of ads now</p>
<p>and never any ads in the middle</p>
<p>that can break the flow of the conversation.</p>
<p>This show is presented by Cash App,</p>
<p>the number one finance app in the App Store.</p>
<p>When you get it, use code LEXPODCAST.</p>
<p>Cash App lets you send money to friends,</p>
<p>buy Bitcoin, and invest in the stock market</p>
<p>with as little as one dollar.</p>
<p>Since Cash App allows you to buy Bitcoin,</p>
<p>let me mention that cryptocurrency in the context</p>
<p>of the history of money is fascinating.</p>
<p>I recommend Ascent of Money</p>
<p>as a great book on this history.</p>
<p>Debits and credits on ledgers</p>
<p>started around 30,000 years ago.</p>
<p>The US dollar created over 200 years ago</p>
<p>and the first decentralized cryptocurrency</p>
<p>released just over 10 years ago.</p>
<p>So given that history, cryptocurrency is still very much</p>
<p>in its early days of development,</p>
<p>but it&rsquo;s still aiming to and just might</p>
<p>redefine the nature of money.</p>
<p>So again, if you get Cash App from the App Store</p>
<p>or Google Play and use the code LEXPODCAST,</p>
<p>you get $10 and Cash App will also donate $10 to FIRST,</p>
<p>an organization that is helping to advance</p>
<p>robotic system education for young people around the world.</p>
<p>This show is sponsored by Masterclass.</p>
<p>Sign up at masterclass.com slash LEX</p>
<p>to get a discount and to support this podcast.</p>
<p>When I first heard about Masterclass,</p>
<p>I thought it was too good to be true.</p>
<p>For $180 a year, you get an all access pass</p>
<p>to watch courses from, to list some of my favorites,</p>
<p>Chris Hadfield on space exploration,</p>
<p>Neil Gauss Tyson on scientific thinking and communication,</p>
<p>Will Wright, creator of SimCity and Sims on game design.</p>
<p>I promise I&rsquo;ll start streaming games at some point soon.</p>
<p>Carlos Santana on guitar, Gary Kasparov on chess,</p>
<p>Daniel Lagrano on poker and many more.</p>
<p>Chris Hadfield explaining how rockets work</p>
<p>and the experience of being launched into space alone</p>
<p>is worth the money.</p>
<p>By the way, you can watch it on basically any device.</p>
<p>Once again, sign up at masterclass.com slash LEX</p>
<p>to get a discount and to support this podcast.</p>
<p>And now, here&rsquo;s my conversation with Peter Singer.</p>
<p>When did you first become conscious of the fact</p>
<p>that there is much suffering in the world?</p>
<p>I think I was conscious of the fact</p>
<p>that there&rsquo;s a lot of suffering in the world</p>
<p>pretty much as soon as I was able to understand</p>
<p>anything about my family and its background</p>
<p>because I lost three of my four grandparents</p>
<p>in the Holocaust and obviously I knew</p>
<p>why I only had one grandparent</p>
<p>and she herself had been in the camps and survived,</p>
<p>so I think I knew a lot about that pretty early.</p>
<p>My entire family comes from the Soviet Union.</p>
<p>I was born in the Soviet Union.</p>
<p>World War II has deep roots in the culture</p>
<p>and the suffering that the war brought</p>
<p>the millions of people who died is in the music,</p>
<p>is in the literature, is in the culture.</p>
<p>What do you think was the impact</p>
<p>of the war broadly on our society?</p>
<p>The war had many impacts.</p>
<p>I think one of them, a beneficial impact,</p>
<p>is that it showed what racism</p>
<p>and authoritarian government can do</p>
<p>and at least as far as the West was concerned,</p>
<p>I think that meant that I grew up in an era</p>
<p>in which there wasn&rsquo;t the kind of overt racism</p>
<p>and antisemitism that had existed for my parents in Europe.</p>
<p>I was growing up in Australia</p>
<p>and certainly that was clearly seen</p>
<p>as something completely unacceptable.</p>
<p>There was also, though, a fear of a further outbreak of war</p>
<p>which this time we expected would be nuclear</p>
<p>because of the way the Second World War had ended,</p>
<p>so there was this overshadowing of my childhood</p>
<p>about the possibility that I would not live to grow up</p>
<p>and be an adult because of a catastrophic nuclear war.</p>
<p>The film On the Beach was made</p>
<p>in which the city that I was living,</p>
<p>Melbourne, was the last place on Earth</p>
<p>to have living human beings</p>
<p>because of the nuclear cloud</p>
<p>that was spreading from the North,</p>
<p>so that certainly gave us a bit of that sense.</p>
<p>There were many, there were clearly many other legacies</p>
<p>that we got of the war as well</p>
<p>and the whole setup of the world</p>
<p>and the Cold War that followed.</p>
<p>All of that has its roots in the Second World War.</p>
<p>There is much beauty that comes from war.</p>
<p>Sort of, I had a conversation with Eric Weinstein.</p>
<p>He said everything is great about war</p>
<p>except all the death and suffering.</p>
<p>Do you think there&rsquo;s something positive</p>
<p>that came from the war,</p>
<p>the mirror that it put to our society,</p>
<p>sort of the ripple effects on it, ethically speaking?</p>
<p>Do you think there are positive aspects to war?</p>
<p>I find it hard to see positive aspects in war</p>
<p>and some of the things that other people think of</p>
<p>as positive and beautiful may be questioning.</p>
<p>So there&rsquo;s a certain kind of patriotism.</p>
<p>People say during wartime, we all pull together,</p>
<p>we all work together against a common enemy</p>
<p>and that&rsquo;s true.</p>
<p>An outside enemy does unite a country</p>
<p>and in general, it&rsquo;s good for countries to be united</p>
<p>and have common purposes</p>
<p>but it also engenders a kind of a nationalism</p>
<p>and a patriotism that can&rsquo;t be questioned</p>
<p>and that I&rsquo;m more skeptical about.</p>
<p>What about the brotherhood</p>
<p>that people talk about from soldiers?</p>
<p>The sort of counterintuitive, sad idea</p>
<p>that the closest that people feel to each other</p>
<p>is in those moments of suffering,</p>
<p>of being at the sort of the edge</p>
<p>of seeing your comrades dying in your arms.</p>
<p>That somehow brings people extremely closely together.</p>
<p>Suffering brings people closer together.</p>
<p>How do you make sense of that?</p>
<p>It may bring people close together</p>
<p>but there are other ways of bonding</p>
<p>and being close to people I think</p>
<p>without the suffering and death that war entails.</p>
<p>Perhaps you could see, you could already hear</p>
<p>the romanticized Russian in me.</p>
<p>We tend to romanticize suffering just a little bit</p>
<p>in our literature and culture and so on.</p>
<p>Could you take a step back</p>
<p>and I apologize if it&rsquo;s a ridiculous question</p>
<p>but what is suffering?</p>
<p>If you would try to define what suffering is,</p>
<p>how would you go about it?</p>
<p>Suffering is a conscious state.</p>
<p>There can be no suffering for a being</p>
<p>who is completely unconscious</p>
<p>and it&rsquo;s distinguished from other conscious states</p>
<p>in terms of being one that considered just in itself.</p>
<p>We would rather be without.</p>
<p>It&rsquo;s a conscious state that we want to stop</p>
<p>if we&rsquo;re experiencing or we want to avoid having again</p>
<p>if we&rsquo;ve experienced it in the past.</p>
<p>And that&rsquo;s, as I say, emphasized for its own sake</p>
<p>because of course people will say,</p>
<p>well, suffering strengthens the spirit.</p>
<p>It has good consequences.</p>
<p>And sometimes it does have those consequences</p>
<p>and of course sometimes we might undergo suffering.</p>
<p>We set ourselves a challenge to run a marathon</p>
<p>or climb a mountain or even just to go to the dentist</p>
<p>so that the toothache doesn&rsquo;t get worse</p>
<p>even though we know the dentist is gonna hurt us</p>
<p>to some extent.</p>
<p>So I&rsquo;m not saying that we never choose suffering</p>
<p>but I am saying that other things being equal,</p>
<p>we would rather not be in that state of consciousness.</p>
<p>Is the ultimate goal sort of,</p>
<p>you have the new 10 year anniversary release</p>
<p>of the Life You Can Save book, really influential book.</p>
<p>We&rsquo;ll talk about it a bunch of times</p>
<p>throughout this conversation</p>
<p>but do you think it&rsquo;s possible</p>
<p>to eradicate suffering or is that the goal</p>
<p>or do we want to achieve a kind of minimum threshold</p>
<p>of suffering and then keeping a little drop of poison</p>
<p>to keep things interesting in the world?</p>
<p>In practice, I don&rsquo;t think we ever will eliminate suffering</p>
<p>so I think that little drop of poison as you put it</p>
<p>or if you like the contrasting dash of an unpleasant color</p>
<p>perhaps something like that</p>
<p>in a otherwise harmonious and beautiful composition,</p>
<p>that is gonna always be there.</p>
<p>If you ask me whether in theory</p>
<p>if we could get rid of it, we should.</p>
<p>I think the answer is whether in fact</p>
<p>we would be better off</p>
<p>or whether in terms of by eliminating the suffering</p>
<p>we would also eliminate some of the highs,</p>
<p>the positive highs and if that&rsquo;s so</p>
<p>then we might be prepared to say</p>
<p>it&rsquo;s worth having a minimum of suffering</p>
<p>in order to have the best possible experiences as well.</p>
<p>Is there a relative aspect to suffering?</p>
<p>So when you talk about eradicating poverty in the world,</p>
<p>is this the more you succeed,</p>
<p>the more the bar of what defines poverty raises</p>
<p>or is there at the basic human ethical level</p>
<p>a bar that&rsquo;s absolute that once you get above it</p>
<p>then we can morally converge</p>
<p>to feeling like we have eradicated poverty?</p>
<p>I think they&rsquo;re both and I think this is true for poverty</p>
<p>as well as suffering.</p>
<p>There&rsquo;s an objective level of suffering or of poverty</p>
<p>where we&rsquo;re talking about objective indicators</p>
<p>like you&rsquo;re constantly hungry,</p>
<p>you can&rsquo;t get enough food,</p>
<p>you&rsquo;re constantly cold, you can&rsquo;t get warm,</p>
<p>you have some physical pains that you&rsquo;re never rid of.</p>
<p>I think those things are objective</p>
<p>but it may also be true that if you do get rid of it</p>
<p>if you do get rid of that and you get to the stage</p>
<p>where all of those basic needs have been met,</p>
<p>there may still be then new forms of suffering that develop</p>
<p>and perhaps that&rsquo;s what we&rsquo;re seeing</p>
<p>in the affluent societies we have</p>
<p>that people get bored for example,</p>
<p>they don&rsquo;t need to spend so many hours a day earning money</p>
<p>to get enough to eat and shelter.</p>
<p>So now they&rsquo;re bored, they lack a sense of purpose.</p>
<p>That can happen.</p>
<p>And that then is a kind of a relative suffering</p>
<p>that is distinct from the objective forms of suffering.</p>
<p>But in your focus on eradicating suffering,</p>
<p>you don&rsquo;t think about that kind of,</p>
<p>the kind of interesting challenges and suffering</p>
<p>that emerges in affluent societies,</p>
<p>that&rsquo;s just not, in your ethical philosophical brain,</p>
<p>is that of interest at all?</p>
<p>It would be of interest to me if we had eliminated</p>
<p>all of the objective forms of suffering,</p>
<p>which I think of as generally more severe</p>
<p>and also perhaps easier at this stage anyway</p>
<p>to know how to eliminate.</p>
<p>So yes, in some future state when we&rsquo;ve eliminated</p>
<p>those objective forms of suffering,</p>
<p>I would be interested in trying to eliminate</p>
<p>the relative forms as well.</p>
<p>But that&rsquo;s not a practical need for me at the moment.</p>
<p>Sorry to linger on it because you kind of said it,</p>
<p>but just is elimination the goal for the affluent society?</p>
<p>So is there, do you see suffering as a creative force?</p>
<p>Suffering can be a creative force.</p>
<p>I think repeating what I said about the highs</p>
<p>and whether we need some of the lows</p>
<p>to experience the highs.</p>
<p>So it may be that suffering makes us more creative</p>
<p>and we regard that as worthwhile.</p>
<p>Maybe that brings some of those highs with it</p>
<p>that we would not have had if we&rsquo;d had no suffering.</p>
<p>I don&rsquo;t really know.</p>
<p>Many people have suggested that</p>
<p>and I certainly can&rsquo;t have no basis for denying it.</p>
<p>And if it&rsquo;s true, then I would not want</p>
<p>to eliminate suffering completely.</p>
<p>But the focus is on the absolute,</p>
<p>not to be cold, not to be hungry.</p>
<p>Yes, that&rsquo;s at the present stage</p>
<p>of where the world&rsquo;s population is, that&rsquo;s the focus.</p>
<p>Talking about human nature for a second,</p>
<p>do you think people are inherently good</p>
<p>or do we all have good and evil in us</p>
<p>that basically everyone is capable of evil</p>
<p>based on the environment?</p>
<p>Certainly most of us have potential for both good and evil.</p>
<p>I&rsquo;m not prepared to say that everyone is capable of evil.</p>
<p>Maybe some people who even in the worst of circumstances</p>
<p>would not be capable of it,</p>
<p>but most of us are very susceptible</p>
<p>to environmental influences.</p>
<p>So when we look at things</p>
<p>that we were talking about previously,</p>
<p>let&rsquo;s say what the Nazis did during the Holocaust,</p>
<p>I think it&rsquo;s quite difficult to say,</p>
<p>I know that I would not have done those things</p>
<p>even if I were in the same circumstances</p>
<p>as those who did them.</p>
<p>Even if let&rsquo;s say I had grown up under the Nazi regime</p>
<p>and had been indoctrinated with racist ideas,</p>
<p>had also had the idea that I must obey orders,</p>
<p>follow the commands of the Fuhrer,</p>
<p>plus of course perhaps the threat</p>
<p>that if I didn&rsquo;t do certain things,</p>
<p>I might get sent to the Russian front</p>
<p>and that would be a pretty grim fate.</p>
<p>I think it&rsquo;s really hard for anybody to say,</p>
<p>nevertheless, I know I would not have killed those Jews</p>
<p>or whatever else it was that they were.</p>
<p>Well, what&rsquo;s your intuition?</p>
<p>How many people will be able to say that?</p>
<p>Truly to be able to say it,</p>
<p>I think very few, less than 10%.</p>
<p>To me, it seems a very interesting</p>
<p>and powerful thing to meditate on.</p>
<p>So I&rsquo;ve read a lot about the war, World War II,</p>
<p>and I can&rsquo;t escape the thought</p>
<p>that I would have not been one of the 10%.</p>
<p>Right, I have to say, I simply don&rsquo;t know.</p>
<p>I would like to hope that I would have been one of the 10%,</p>
<p>but I don&rsquo;t really have any basis</p>
<p>for claiming that I would have been different</p>
<p>from the majority.</p>
<p>Is it a worthwhile thing to contemplate?</p>
<p>It would be interesting if we could find a way</p>
<p>of really finding these answers.</p>
<p>There obviously is quite a bit of research</p>
<p>on people during the Holocaust,</p>
<p>on how ordinary Germans got led to do terrible things,</p>
<p>and there are also studies of the resistance,</p>
<p>some heroic people in the White Rose group, for example,</p>
<p>who resisted even though they knew</p>
<p>they were likely to die for it.</p>
<p>But I don&rsquo;t know whether these studies</p>
<p>really can answer your larger question</p>
<p>of how many people would have been capable of doing that.</p>
<p>Well, sort of the reason I think is interesting</p>
<p>is in the world, as you described,</p>
<p>when there are things that you&rsquo;d like to do that are good,</p>
<p>that are objectively good,</p>
<p>it&rsquo;s useful to think about whether</p>
<p>I&rsquo;m not willing to do something,</p>
<p>or I&rsquo;m not willing to acknowledge something</p>
<p>as good and the right thing to do</p>
<p>because I&rsquo;m simply scared of putting my life,</p>
<p>of damaging my life in some kind of way.</p>
<p>And that kind of thought exercise is helpful</p>
<p>to understand what is the right thing</p>
<p>in my current skill set and the capacity to do.</p>
<p>Sort of there&rsquo;s things that are convenient,</p>
<p>and I wonder if there are things</p>
<p>that are highly inconvenient,</p>
<p>where I would have to experience derision,</p>
<p>or hatred, or death, or all those kinds of things,</p>
<p>but it&rsquo;s truly the right thing to do.</p>
<p>And that kind of balance is,</p>
<p>I feel like in America, we don&rsquo;t have,</p>
<p>it&rsquo;s difficult to think in the current times,</p>
<p>it seems easier to put yourself back in history,</p>
<p>where you can sort of objectively contemplate</p>
<p>whether, how willing you are to do the right thing</p>
<p>when the cost is high.</p>
<p>True, but I think we do face those challenges today,</p>
<p>and I think we can still ask ourselves those questions.</p>
<p>So one stand that I took more than 40 years ago now</p>
<p>was to stop eating meat, become a vegetarian at a time</p>
<p>when you hardly met anybody who was a vegetarian,</p>
<p>or if you did, they might&rsquo;ve been a Hindu,</p>
<p>or they might&rsquo;ve had some weird theories</p>
<p>about meat and health.</p>
<p>And I know thinking about making that decision,</p>
<p>I was convinced that it was the right thing to do,</p>
<p>but I still did have to think,</p>
<p>are all my friends gonna think that I&rsquo;m a crank</p>
<p>because I&rsquo;m now refusing to eat meat?</p>
<p>So I&rsquo;m not saying there were any terrible sanctions,</p>
<p>obviously, but I thought about that,</p>
<p>and I guess I decided,</p>
<p>well, I still think this is the right thing to do,</p>
<p>and I&rsquo;ll put up with that if it happens.</p>
<p>And one or two friends were clearly uncomfortable</p>
<p>with that decision, but that was pretty minor</p>
<p>compared to the historical examples</p>
<p>that we&rsquo;ve been talking about.</p>
<p>But other issues that we have around too,</p>
<p>like global poverty and what we ought to be doing about that</p>
<p>is another question where people, I think,</p>
<p>can have the opportunity to take a stand</p>
<p>on what&rsquo;s the right thing to do now.</p>
<p>Climate change would be a third question</p>
<p>where, again, people are taking a stand.</p>
<p>I can look at Greta Thunberg there and say,</p>
<p>well, I think it must&rsquo;ve taken a lot of courage</p>
<p>for a schoolgirl to say,</p>
<p>I&rsquo;m gonna go on strike about climate change</p>
<p>and see what happens.</p>
<p>Yeah, especially in this divisive world,</p>
<p>she gets exceptionally huge amounts of support</p>
<p>and hatred, both.</p>
<p>That&rsquo;s right.</p>
<p>Which is very difficult for a teenager to operate in.</p>
<p>In your book, Ethics in the Real World,</p>
<p>amazing book, people should check it out.</p>
<p>Very easy read.</p>
<p>82 brief essays on things that matter.</p>
<p>One of the essays asks, should robots have rights?</p>
<p>You&rsquo;ve written about this,</p>
<p>so let me ask, should robots have rights?</p>
<p>If we ever develop robots capable of consciousness,</p>
<p>capable of having their own internal perspective</p>
<p>on what&rsquo;s happening to them</p>
<p>so that their lives can go well or badly for them,</p>
<p>then robots should have rights.</p>
<p>Until that happens, they shouldn&rsquo;t.</p>
<p>So is consciousness essentially a prerequisite to suffering?</p>
<p>So everything that possesses consciousness</p>
<p>is capable of suffering, put another way.</p>
<p>And if so, what is consciousness?</p>
<p>I certainly think that consciousness</p>
<p>is a prerequisite for suffering.</p>
<p>You can&rsquo;t suffer if you&rsquo;re not conscious.</p>
<p>But is it true that every being that is conscious</p>
<p>will suffer or has to be capable of suffering?</p>
<p>I suppose you could imagine a kind of consciousness,</p>
<p>especially if we can construct it artificially,</p>
<p>that&rsquo;s capable of experiencing pleasure</p>
<p>but just automatically cuts out the consciousness</p>
<p>when they&rsquo;re suffering.</p>
<p>So they&rsquo;re like an instant anesthesia</p>
<p>as soon as something is gonna cause you suffering.</p>
<p>So that&rsquo;s possible.</p>
<p>But doesn&rsquo;t exist as far as we know on this planet yet.</p>
<p>You asked what is consciousness.</p>
<p>Philosophers often talk about it</p>
<p>as there being a subject of experiences.</p>
<p>So you and I and everybody listening to this</p>
<p>is a subject of experience.</p>
<p>There is a conscious subject who is taking things in,</p>
<p>responding to it in various ways,</p>
<p>feeling good about it, feeling bad about it.</p>
<p>And that&rsquo;s different from the kinds</p>
<p>of artificial intelligence we have now.</p>
<p>I take out my phone.</p>
<p>I ask Google directions to where I&rsquo;m going.</p>
<p>Google gives me the directions</p>
<p>and I choose to take a different way.</p>
<p>Google doesn&rsquo;t care.</p>
<p>It&rsquo;s not like I&rsquo;m offending Google or anything like that.</p>
<p>There is no subject of experiences there.</p>
<p>And I think that&rsquo;s the indication</p>
<p>that Google AI we have now is not conscious</p>
<p>or at least that level of AI is not conscious.</p>
<p>And that&rsquo;s the way to think about it.</p>
<p>Now, it may be difficult to tell, of course,</p>
<p>whether a certain AI is or isn&rsquo;t conscious.</p>
<p>It may mimic consciousness</p>
<p>and we can&rsquo;t tell if it&rsquo;s only mimicking it</p>
<p>or if it&rsquo;s the real thing.</p>
<p>But that&rsquo;s what we&rsquo;re looking for.</p>
<p>Is there a subject of experience,</p>
<p>a perspective on the world from which things can go well</p>
<p>or badly from that perspective?</p>
<p>So our idea of what suffering looks like</p>
<p>comes from just watching ourselves when we&rsquo;re in pain.</p>
<p>Or when we&rsquo;re experiencing pleasure, it&rsquo;s not only.</p>
<p>Pleasure and pain.</p>
<p>Yes, so and then you could actually,</p>
<p>you could push back on us, but I would say</p>
<p>that&rsquo;s how we kind of build an intuition about animals</p>
<p>is we can infer the similarities between humans and animals</p>
<p>and so infer that they&rsquo;re suffering or not</p>
<p>based on certain things and they&rsquo;re conscious or not.</p>
<p>So what if robots, you mentioned Google Maps</p>
<p>and I&rsquo;ve done this experiment.</p>
<p>So I work in robotics just for my own self</p>
<p>or I have several Roomba robots</p>
<p>and I play with different speech interaction,</p>
<p>voice based interaction.</p>
<p>And if the Roomba or the robot or Google Maps</p>
<p>shows any signs of pain, like screaming or moaning</p>
<p>or being displeased by something you&rsquo;ve done,</p>
<p>that in my mind, I can&rsquo;t help but immediately upgrade it.</p>
<p>And even when I myself programmed it in,</p>
<p>just having another entity that&rsquo;s now for the moment</p>
<p>disjoint from me showing signs of pain</p>
<p>makes me feel like it is conscious.</p>
<p>Like I immediately, then the whatever,</p>
<p>I immediately realize that it&rsquo;s not obviously,</p>
<p>but that feeling is there.</p>
<p>So sort of, I guess, what do you think about a world</p>
<p>where Google Maps and Roombas are pretending to be conscious</p>
<p>and we descendants of apes are not smart enough</p>
<p>to realize they&rsquo;re not or whatever, or that is conscious,</p>
<p>they appear to be conscious.</p>
<p>And so you then have to give them rights.</p>
<p>The reason I&rsquo;m asking that is that kind of capability</p>
<p>may be closer than we realize.</p>
<p>Yes, that kind of capability may be closer,</p>
<p>but I don&rsquo;t think it follows</p>
<p>that we have to give them rights.</p>
<p>I suppose the argument for saying that in those circumstances</p>
<p>we should give them rights is that if we don&rsquo;t,</p>
<p>we&rsquo;ll harden ourselves against other beings</p>
<p>who are not robots and who really do suffer.</p>
<p>That&rsquo;s a possibility that, you know,</p>
<p>if we get used to looking at a being suffering</p>
<p>and saying, yeah, we don&rsquo;t have to do anything about that,</p>
<p>that being doesn&rsquo;t have any rights,</p>
<p>maybe we&rsquo;ll feel the same about animals, for instance.</p>
<p>And interestingly, among philosophers and thinkers</p>
<p>who denied that we have any direct duties to animals,</p>
<p>and this includes people like Thomas Aquinas</p>
<p>and Immanuel Kant, they did say, yes,</p>
<p>but still it&rsquo;s better not to be cruel to them,</p>
<p>not because of the suffering we&rsquo;re inflicting</p>
<p>on the animals, but because if we are,</p>
<p>we may develop a cruel disposition</p>
<p>and this will be bad for humans, you know,</p>
<p>because we&rsquo;re more likely to be cruel to other humans</p>
<p>and that would be wrong.</p>
<p>So.</p>
<p>But you don&rsquo;t accept that kind of.</p>
<p>I don&rsquo;t accept that as the basis of the argument</p>
<p>for why we shouldn&rsquo;t be cruel to animals.</p>
<p>I think the basis of the argument</p>
<p>for why we shouldn&rsquo;t be cruel to animals</p>
<p>is just that we&rsquo;re inflicting suffering on them</p>
<p>and the suffering is a bad thing.</p>
<p>But possibly I might accept some sort of parallel</p>
<p>of that argument as a reason why you shouldn&rsquo;t be cruel</p>
<p>to these robots that mimic the symptoms of pain</p>
<p>if it&rsquo;s gonna be harder for us to distinguish.</p>
<p>I would venture to say, I&rsquo;d like to disagree with you</p>
<p>and with most people, I think,</p>
<p>at the risk of sounding crazy,</p>
<p>I would like to say that if that Roomba is dedicated</p>
<p>to faking the consciousness and the suffering,</p>
<p>I think it will be impossible for us.</p>
<p>I would like to apply the same argument</p>
<p>as with animals to robots,</p>
<p>that they deserve rights in that sense.</p>
<p>Now we might outlaw the addition</p>
<p>of those kinds of features into Roombas,</p>
<p>but once you do, I think I&rsquo;m quite surprised</p>
<p>by the upgrade in consciousness</p>
<p>that the display of suffering creates.</p>
<p>It&rsquo;s a totally open world,</p>
<p>but I&rsquo;d like to just sort of the difference</p>
<p>between animals and other humans is that in the robot case,</p>
<p>we&rsquo;ve added it in ourselves.</p>
<p>Therefore, we can say something about how real it is.</p>
<p>But I would like to say that the display of it</p>
<p>is what makes it real.</p>
<p>And I&rsquo;m not a philosopher, I&rsquo;m not making that argument,</p>
<p>but I&rsquo;d at least like to add that as a possibility.</p>
<p>And I&rsquo;ve been surprised by it</p>
<p>is all I&rsquo;m trying to sort of articulate poorly, I suppose.</p>
<p>So there is a philosophical view</p>
<p>has been held about humans,</p>
<p>which is rather like what you&rsquo;re talking about,</p>
<p>and that&rsquo;s behaviorism.</p>
<p>So behaviorism was employed both in psychology,</p>
<p>people like BF Skinner was a famous behaviorist,</p>
<p>but in psychology, it was more a kind of a,</p>
<p>what is it that makes this science?</p>
<p>Well, you need to have behavior</p>
<p>because that&rsquo;s what you can observe,</p>
<p>you can&rsquo;t observe consciousness.</p>
<p>But in philosophy, the view just defended</p>
<p>by people like Gilbert Ryle,</p>
<p>who was a professor of philosophy at Oxford,</p>
<p>wrote a book called The Concept of Mind,</p>
<p>in which in this kind of phase,</p>
<p>this is in the 40s of linguistic philosophy,</p>
<p>he said, well, the meaning of a term is its use,</p>
<p>and we use terms like so and so is in pain</p>
<p>when we see somebody writhing or screaming</p>
<p>or trying to escape some stimulus,</p>
<p>and that&rsquo;s the meaning of the term.</p>
<p>So that&rsquo;s what it is to be in pain,</p>
<p>and you point to the behavior.</p>
<p>And Norman Malcolm, who was another philosopher</p>
<p>in the school from Cornell, had the view that,</p>
<p>so what is it to dream?</p>
<p>After all, we can&rsquo;t see other people&rsquo;s dreams.</p>
<p>Well, when people wake up and say,</p>
<p>I&rsquo;ve just had a dream of, here I was,</p>
<p>undressed, walking down the main street</p>
<p>or whatever it is you&rsquo;ve dreamt,</p>
<p>that&rsquo;s what it is to have a dream.</p>
<p>It&rsquo;s basically to wake up and recall something.</p>
<p>So you could apply this to what you&rsquo;re talking about</p>
<p>and say, so what it is to be in pain</p>
<p>is to exhibit these symptoms of pain behavior,</p>
<p>and therefore, these robots are in pain.</p>
<p>That&rsquo;s what the word means.</p>
<p>But nowadays, not many people think</p>
<p>that Ryle&rsquo;s kind of philosophical behaviorism</p>
<p>is really very plausible,</p>
<p>so I think they would say the same about your view.</p>
<p>So, yes, I just spoke with Noam Chomsky,</p>
<p>who basically was part of dismantling</p>
<p>the behaviorist movement.</p>
<p>But, and I&rsquo;m with that 100% for studying human behavior,</p>
<p>but I am one of the few people in the world</p>
<p>who has made Roombas scream in pain.</p>
<p>And I just don&rsquo;t know what to do</p>
<p>with that empirical evidence,</p>
<p>because it&rsquo;s hard, sort of philosophically, I agree.</p>
<p>But the only reason I philosophically agree in that case</p>
<p>is because I was the programmer.</p>
<p>But if somebody else was a programmer,</p>
<p>I&rsquo;m not sure I would be able to interpret that well.</p>
<p>So I think it&rsquo;s a new world</p>
<p>that I was just curious what your thoughts are.</p>
<p>For now, you feel that the display</p>
<p>of what we can kind of intellectually say</p>
<p>is a fake display of suffering is not suffering.</p>
<p>That&rsquo;s right, that would be my view.</p>
<p>But that&rsquo;s consistent, of course,</p>
<p>with the idea that it&rsquo;s part of our nature</p>
<p>to respond to this display</p>
<p>if it&rsquo;s reasonably authentically done.</p>
<p>And therefore it&rsquo;s understandable</p>
<p>that people would feel this,</p>
<p>and maybe, as I said, it&rsquo;s even a good thing</p>
<p>that they do feel it,</p>
<p>and you wouldn&rsquo;t want to harden yourself against it</p>
<p>because then you might harden yourself</p>
<p>against being sort of really suffering.</p>
<p>But there&rsquo;s this line, so you said,</p>
<p>once artificial general intelligence system,</p>
<p>a human level intelligence system become conscious,</p>
<p>I guess if I could just linger on it,</p>
<p>now I&rsquo;ve wrote really dumb programs</p>
<p>that just say things that I told them to say,</p>
<p>but how do you know when a system like Alexa,</p>
<p>which is sufficiently complex</p>
<p>that you can&rsquo;t introspect to how it works,</p>
<p>starts giving you signs of consciousness</p>
<p>through natural language?</p>
<p>That there&rsquo;s a feeling,</p>
<p>there&rsquo;s another entity there that&rsquo;s self aware,</p>
<p>that has a fear of death, a mortality,</p>
<p>that has awareness of itself</p>
<p>that we kind of associate with other living creatures.</p>
<p>I guess I&rsquo;m sort of trying to do the slippery slope</p>
<p>from the very naive thing where I started</p>
<p>into something where it&rsquo;s sufficiently a black box</p>
<p>to where it&rsquo;s starting to feel like it&rsquo;s conscious.</p>
<p>Where&rsquo;s that threshold</p>
<p>where you would start getting uncomfortable</p>
<p>with the idea of robot suffering, do you think?</p>
<p>I don&rsquo;t know enough about the programming</p>
<p>that we&rsquo;re going to this really to answer this question.</p>
<p>But I presume that somebody who does know more about this</p>
<p>could look at the program</p>
<p>and see whether we can explain the behaviors</p>
<p>in a parsimonious way that doesn&rsquo;t require us</p>
<p>to suggest that some sort of consciousness has emerged.</p>
<p>Or alternatively, whether you&rsquo;re in a situation</p>
<p>where you say, I don&rsquo;t know how this is happening,</p>
<p>the program does generate a kind of artificial</p>
<p>general intelligence which is autonomous,</p>
<p>starts to do things itself and is autonomous</p>
<p>of the basics programming that set it up.</p>
<p>And so it&rsquo;s quite possible that actually</p>
<p>we have achieved consciousness</p>
<p>in a system of artificial intelligence.</p>
<p>Sort of the approach that I work with,</p>
<p>most of the community is really excited about now</p>
<p>is with learning methods, so machine learning.</p>
<p>And the learning methods are unfortunately</p>
<p>are not capable of revealing,</p>
<p>which is why somebody like Noam Chomsky criticizes them.</p>
<p>You create powerful systems that are able</p>
<p>to do certain things without understanding</p>
<p>the theory, the physics, the science of how it works.</p>
<p>And so it&rsquo;s possible if those are the kinds</p>
<p>of methods that succeed, we won&rsquo;t be able</p>
<p>to know exactly, sort of try to reduce,</p>
<p>try to find whether this thing is conscious or not,</p>
<p>this thing is intelligent or not.</p>
<p>It&rsquo;s simply giving, when we talk to it,</p>
<p>it displays wit and humor and cleverness</p>
<p>and emotion and fear, and then we won&rsquo;t be able</p>
<p>to say where in the billions of nodes,</p>
<p>neurons in this artificial neural network</p>
<p>is the fear coming from.</p>
<p>So in that case, that&rsquo;s a really interesting place</p>
<p>where we do now start to return to behaviorism and say.</p>
<p>Yeah, that is an interesting issue.</p>
<p>I would say that if we have serious doubts</p>
<p>and think it might be conscious,</p>
<p>then we ought to try to give it the benefit</p>
<p>of the doubt, just as I would say with animals.</p>
<p>I think we can be highly confident</p>
<p>that vertebrates are conscious,</p>
<p>but when we get down, and some invertebrates</p>
<p>like the octopus, but with insects,</p>
<p>it&rsquo;s much harder to be confident of that.</p>
<p>I think we should give them the benefit</p>
<p>of the doubt where we can, which means,</p>
<p>I think it would be wrong to torture an insect,</p>
<p>but it doesn&rsquo;t necessarily mean it&rsquo;s wrong</p>
<p>to slap a mosquito that&rsquo;s about to bite you</p>
<p>and stop you getting to sleep.</p>
<p>So I think you try to achieve some balance</p>
<p>in these circumstances of uncertainty.</p>
<p>If it&rsquo;s okay with you, if we can go back just briefly.</p>
<p>So 44 years ago, like you mentioned, 40 plus years ago,</p>
<p>you&rsquo;ve written Animal Liberation,</p>
<p>the classic book that started,</p>
<p>that launched, that was the foundation</p>
<p>of the movement of Animal Liberation.</p>
<p>Can you summarize the key set of ideas</p>
<p>that underpin that book?</p>
<p>Certainly, the key idea that underlies that book</p>
<p>is the concept of speciesism,</p>
<p>which I did not invent that term.</p>
<p>I took it from a man called Richard Rider,</p>
<p>who was in Oxford when I was,</p>
<p>and I saw a pamphlet that he&rsquo;d written</p>
<p>about experiments on chimpanzees that used that term.</p>
<p>But I think I contributed</p>
<p>to making it philosophically more precise</p>
<p>and to getting it into a broader audience.</p>
<p>And the idea is that we have a bias or a prejudice</p>
<p>against taking seriously the interests of beings</p>
<p>who are not members of our species.</p>
<p>Just as in the past, Europeans, for example,</p>
<p>had a bias against taking seriously</p>
<p>the interests of Africans, racism.</p>
<p>And men have had a bias against taking seriously</p>
<p>the interests of women, sexism.</p>
<p>So I think something analogous, not completely identical,</p>
<p>but something analogous goes on</p>
<p>and has gone on for a very long time</p>
<p>with the way humans see themselves vis a vis animals.</p>
<p>We see ourselves as more important.</p>
<p>We see animals as existing to serve our needs</p>
<p>in various ways.</p>
<p>And you&rsquo;re gonna find this very explicit</p>
<p>in earlier philosophers from Aristotle</p>
<p>through to Kant and others.</p>
<p>And either we don&rsquo;t need to take their interests</p>
<p>into account at all,</p>
<p>or we can discount it because they&rsquo;re not humans.</p>
<p>They can a little bit,</p>
<p>but they don&rsquo;t count nearly as much as humans do.</p>
<p>My book argues that that attitude is responsible</p>
<p>for a lot of the things that we do to animals</p>
<p>that are wrong, confining them indoors</p>
<p>in very crowded, cramped conditions in factory farms</p>
<p>to produce meat or eggs or milk more cheaply,</p>
<p>using them in some research that&rsquo;s by no means essential</p>
<p>for survival or wellbeing, and a whole lot,</p>
<p>some of the sports and things that we do to animals.</p>
<p>So I think that&rsquo;s unjustified</p>
<p>because I think the significance of pain and suffering</p>
<p>does not depend on the species of the being</p>
<p>who is in pain or suffering</p>
<p>any more than it depends on the race or sex of the being</p>
<p>who is in pain or suffering.</p>
<p>And I think we ought to rethink our treatment of animals</p>
<p>along the lines of saying,</p>
<p>if the pain is just as great in an animal,</p>
<p>then it&rsquo;s just as bad that it happens as if it were a human.</p>
<p>Maybe if I could ask, I apologize,</p>
<p>hopefully it&rsquo;s not a ridiculous question,</p>
<p>but so as far as we know,</p>
<p>we cannot communicate with animals through natural language,</p>
<p>but we would be able to communicate with robots.</p>
<p>So I&rsquo;m returning to sort of a small parallel</p>
<p>between perhaps animals and the future of AI.</p>
<p>If we do create an AGI system</p>
<p>or as we approach creating that AGI system,</p>
<p>what kind of questions would you ask her</p>
<p>to try to intuit whether there is consciousness</p>
<p>or more importantly, whether there&rsquo;s capacity to suffer?</p>
<p>I might ask the AGI what she was feeling</p>
<p>or does she have feelings?</p>
<p>And if she says yes, to describe those feelings,</p>
<p>to describe what they were like,</p>
<p>to see what the phenomenal account of consciousness is like.</p>
<p>That&rsquo;s one question.</p>
<p>I might also try to find out if the AGI</p>
<p>has a sense of itself.</p>
<p>So for example, the idea would you,</p>
<p>we often ask people,</p>
<p>so suppose you were in a car accident</p>
<p>and your brain were transplanted into someone else&rsquo;s body,</p>
<p>do you think you would survive</p>
<p>or would it be the person whose body was still surviving,</p>
<p>your body having been destroyed?</p>
<p>And most people say, I think I would,</p>
<p>if my brain was transplanted along with my memories</p>
<p>and so on, I would survive.</p>
<p>So we could ask AGI those kinds of questions.</p>
<p>If they were transferred to a different piece of hardware,</p>
<p>would they survive?</p>
<p>What would survive?</p>
<p>And get at that sort of concept.</p>
<p>Sort of on that line, another perhaps absurd question,</p>
<p>but do you think having a body</p>
<p>is necessary for consciousness?</p>
<p>So do you think digital beings can suffer?</p>
<p>Presumably digital beings need to be</p>
<p>running on some kind of hardware, right?</p>
<p>Yeah, that ultimately boils down to,</p>
<p>but this is exactly what you just said,</p>
<p>is moving the brain from one place to another.</p>
<p>So you could move it to a different kind of hardware.</p>
<p>And I could say, look, your hardware is getting worn out.</p>
<p>We&rsquo;re going to transfer you to a fresh piece of hardware.</p>
<p>So we&rsquo;re gonna shut you down for a time,</p>
<p>but don&rsquo;t worry, you&rsquo;ll be running very soon</p>
<p>on a nice fresh piece of hardware.</p>
<p>And you could imagine this conscious AGI saying,</p>
<p>that&rsquo;s fine, I don&rsquo;t mind having a little rest.</p>
<p>Just make sure you don&rsquo;t lose me or something like that.</p>
<p>Yeah, I mean, that&rsquo;s an interesting thought</p>
<p>that even with us humans, the suffering is in the software.</p>
<p>We right now don&rsquo;t know how to repair the hardware,</p>
<p>but we&rsquo;re getting better at it and better in the idea.</p>
<p>I mean, some people dream about one day being able</p>
<p>to transfer certain aspects of the software</p>
<p>to another piece of hardware.</p>
<p>What do you think, just on that topic,</p>
<p>there&rsquo;s been a lot of exciting innovation</p>
<p>in brain computer interfaces.</p>
<p>I don&rsquo;t know if you&rsquo;re familiar with the companies</p>
<p>like Neuralink, with Elon Musk,</p>
<p>communicating both ways from a computer,</p>
<p>being able to send, activate neurons</p>
<p>and being able to read spikes from neurons.</p>
<p>With the dream of being able to expand,</p>
<p>sort of increase the bandwidth at which your brain</p>
<p>can like look up articles on Wikipedia kind of thing,</p>
<p>sort of expand the knowledge capacity of the brain.</p>
<p>Do you think that notion, is that interesting to you</p>
<p>as the expansion of the human mind?</p>
<p>Yes, that&rsquo;s very interesting.</p>
<p>I&rsquo;d love to be able to have that increased bandwidth.</p>
<p>And I want better access to my memory, I have to say too,</p>
<p>as I get older, I talk to my wife about things</p>
<p>that we did 20 years ago or something.</p>
<p>Her memory is often better about particular events.</p>
<p>Where were we?</p>
<p>Who was at that event?</p>
<p>What did he or she wear even?</p>
<p>She may know and I have not the faintest idea about this,</p>
<p>but perhaps it&rsquo;s somewhere in my memory.</p>
<p>And if I had this extended memory,</p>
<p>I could search that particular year and rerun those things.</p>
<p>I think that would be great.</p>
<p>In some sense, we already have that</p>
<p>by storing so much of our data online,</p>
<p>like pictures of different events.</p>
<p>Yes, well, Gmail is fantastic for that</p>
<p>because people email me as if they know me well</p>
<p>and I haven&rsquo;t got a clue who they are,</p>
<p>but then I search for their name.</p>
<p>Ah yes, they emailed me in 2007</p>
<p>and I know who they are now.</p>
<p>Yeah, so we&rsquo;re taking the first steps already.</p>
<p>So on the flip side of AI,</p>
<p>people like Stuart Russell and others</p>
<p>focus on the control problem, value alignment in AI,</p>
<p>which is the problem of making sure we build systems</p>
<p>that align to our own values, our ethics.</p>
<p>Do you think sort of high level,</p>
<p>how do we go about building systems?</p>
<p>Do you think is it possible that align with our values,</p>
<p>align with our human ethics or living being ethics?</p>
<p>Presumably, it&rsquo;s possible to do that.</p>
<p>I know that a lot of people who think</p>
<p>that there&rsquo;s a real danger that we won&rsquo;t,</p>
<p>that we&rsquo;ll more or less accidentally lose control of AGI.</p>
<p>Do you have that fear yourself personally?</p>
<p>I&rsquo;m not quite sure what to think.</p>
<p>I talk to philosophers like Nick Bostrom and Toby Ord</p>
<p>and they think that this is a real problem</p>
<p>we need to worry about.</p>
<p>Then I talk to people who work for Microsoft</p>
<p>or DeepMind or somebody and they say,</p>
<p>no, we&rsquo;re not really that close to producing AGI,</p>
<p>super intelligence.</p>
<p>So if you look at Nick Bostrom,</p>
<p>sort of the arguments, it&rsquo;s very hard to defend.</p>
<p>So I&rsquo;m of course, I am a self engineer AI system,</p>
<p>so I&rsquo;m more with the DeepMind folks</p>
<p>where it seems that we&rsquo;re really far away,</p>
<p>but then the counter argument is,</p>
<p>is there any fundamental reason that we&rsquo;ll never achieve it?</p>
<p>And if not, then eventually there&rsquo;ll be</p>
<p>a dire existential risk.</p>
<p>So we should be concerned about it.</p>
<p>And do you find that argument at all appealing</p>
<p>in this domain or any domain that eventually</p>
<p>this will be a problem so we should be worried about it?</p>
<p>Yes, I think it&rsquo;s a problem.</p>
<p>I think that&rsquo;s a valid point.</p>
<p>Of course, when you say eventually,</p>
<p>that raises the question, how far off is that?</p>
<p>And is there something that we can do about it now?</p>
<p>Because if we&rsquo;re talking about</p>
<p>this is gonna be 100 years in the future</p>
<p>and you consider how rapidly our knowledge</p>
<p>of artificial intelligence has grown</p>
<p>in the last 10 or 20 years,</p>
<p>it seems unlikely that there&rsquo;s anything much</p>
<p>we could do now that would influence</p>
<p>whether this is going to happen 100 years in the future.</p>
<p>People in 80 years in the future</p>
<p>would be in a much better position to say,</p>
<p>this is what we need to do to prevent this happening</p>
<p>than we are now.</p>
<p>So to some extent I find that reassuring,</p>
<p>but I&rsquo;m all in favor of some people doing research</p>
<p>into this to see if indeed it is that far off</p>
<p>or if we are in a position to do something about it sooner.</p>
<p>I&rsquo;m very much of the view that extinction</p>
<p>is a terrible thing and therefore,</p>
<p>even if the risk of extinction is very small,</p>
<p>if we can reduce that risk,</p>
<p>that&rsquo;s something that we ought to do.</p>
<p>My disagreement with some of these people</p>
<p>who talk about longterm risks, extinction risks,</p>
<p>is only about how much priority that should have</p>
<p>as compared to present questions.</p>
<p>So essentially, if you look at the math of it</p>
<p>from a utilitarian perspective,</p>
<p>if it&rsquo;s existential risk, so everybody dies,</p>
<p>that it feels like an infinity in the math equation,</p>
<p>that that makes the math</p>
<p>with the priorities difficult to do.</p>
<p>That if we don&rsquo;t know the time scale</p>
<p>and you can legitimately argue</p>
<p>that it&rsquo;s nonzero probability that it&rsquo;ll happen tomorrow,</p>
<p>that how do you deal with these kinds of existential risks</p>
<p>like from nuclear war, from nuclear weapons,</p>
<p>from biological weapons, from,</p>
<p>I&rsquo;m not sure if global warming falls into that category</p>
<p>because global warming is a lot more gradual.</p>
<p>And people say it&rsquo;s not an existential risk</p>
<p>because there&rsquo;ll always be possibilities</p>
<p>of some humans existing, farming Antarctica</p>
<p>or northern Siberia or something of that sort, yeah.</p>
<p>But you don&rsquo;t find the complete existential risks</p>
<p>as a fundamental, like an overriding part</p>
<p>of the equations of ethics, of what we should do.</p>
<p>You know, certainly if you treat it as an infinity,</p>
<p>then it plays havoc with any calculations.</p>
<p>But arguably, we shouldn&rsquo;t.</p>
<p>I mean, one of the ethical assumptions that goes into this</p>
<p>is that the loss of future lives,</p>
<p>that is of merely possible lives of beings</p>
<p>who may never exist at all,</p>
<p>is in some way comparable to the sufferings or deaths</p>
<p>of people who do exist at some point.</p>
<p>And that&rsquo;s not clear to me.</p>
<p>I think there&rsquo;s a case for saying that,</p>
<p>but I also think there&rsquo;s a case for taking the other view.</p>
<p>So that has some impact on it.</p>
<p>Of course, you might say, ah, yes,</p>
<p>but still, if there&rsquo;s some uncertainty about this</p>
<p>and the costs of extinction are infinite,</p>
<p>then still, it&rsquo;s gonna overwhelm everything else.</p>
<p>But I suppose I&rsquo;m not convinced of that.</p>
<p>I&rsquo;m not convinced that it&rsquo;s really infinite here.</p>
<p>And even Nick Bostrom, in his discussion of this,</p>
<p>doesn&rsquo;t claim that there&rsquo;ll be</p>
<p>an infinite number of lives lived.</p>
<p>What is it, 10 to the 56th or something?</p>
<p>It&rsquo;s a vast number that I think he calculates.</p>
<p>This is assuming we can upload consciousness</p>
<p>onto these digital forms,</p>
<p>and therefore, they&rsquo;ll be much more energy efficient,</p>
<p>but he calculates the amount of energy in the universe</p>
<p>or something like that.</p>
<p>So the numbers are vast but not infinite,</p>
<p>which gives you some prospect maybe</p>
<p>of resisting some of the argument.</p>
<p>The beautiful thing with Nick&rsquo;s arguments</p>
<p>is he quickly jumps from the individual scale</p>
<p>to the universal scale,</p>
<p>which is just awe inspiring to think of</p>
<p>when you think about the entirety</p>
<p>of the span of time of the universe.</p>
<p>It&rsquo;s both interesting from a computer science perspective,</p>
<p>AI perspective, and from an ethical perspective,</p>
<p>the idea of utilitarianism.</p>
<p>Could you say what is utilitarianism?</p>
<p>Utilitarianism is the ethical view</p>
<p>that the right thing to do is the act</p>
<p>that has the greatest expected utility,</p>
<p>where what that means is it&rsquo;s the act</p>
<p>that will produce the best consequences,</p>
<p>discounted by the odds that you won&rsquo;t be able</p>
<p>to produce those consequences,</p>
<p>that something will go wrong.</p>
<p>But in simple case, let&rsquo;s assume we have certainty</p>
<p>about what the consequences of our actions will be,</p>
<p>then the right action is the action</p>
<p>that will produce the best consequences.</p>
<p>Is that always, and by the way,</p>
<p>there&rsquo;s a bunch of nuanced stuff</p>
<p>that you talk with Sam Harris on this podcast</p>
<p>on that people should go listen to.</p>
<p>It&rsquo;s great.</p>
<p>That&rsquo;s like two hours of moral philosophy discussion.</p>
<p>But is that an easy calculation?</p>
<p>No, it&rsquo;s a difficult calculation.</p>
<p>And actually, there&rsquo;s one thing that I need to add,</p>
<p>and that is utilitarians, certainly the classical</p>
<p>utilitarians, think that by best consequences,</p>
<p>we&rsquo;re talking about happiness</p>
<p>and the absence of pain and suffering.</p>
<p>There are other consequentialists</p>
<p>who are not really utilitarians who say</p>
<p>there are different things that could be good consequences.</p>
<p>Justice, freedom, human dignity,</p>
<p>knowledge, they all count as good consequences too.</p>
<p>And that makes the calculations even more difficult</p>
<p>because then you need to know</p>
<p>how to balance these things off.</p>
<p>If you are just talking about wellbeing,</p>
<p>using that term to express happiness</p>
<p>and the absence of suffering,</p>
<p>I think the calculation becomes more manageable</p>
<p>in a philosophical sense.</p>
<p>It&rsquo;s still in practice.</p>
<p>We don&rsquo;t know how to do it.</p>
<p>We don&rsquo;t know how to measure quantities</p>
<p>of happiness and misery.</p>
<p>We don&rsquo;t know how to calculate the probabilities</p>
<p>that different actions will produce, this or that.</p>
<p>So at best, we can use it as a rough guide</p>
<p>to different actions and one where we have to focus</p>
<p>on the short term consequences</p>
<p>because we just can&rsquo;t really predict</p>
<p>all of the longer term ramifications.</p>
<p>So what about the extreme suffering of very small groups?</p>
<p>Utilitarianism is focused on the overall aggregate, right?</p>
<p>Would you say you yourself are a utilitarian?</p>
<p>Yes, I&rsquo;m a utilitarian.</p>
<p>What do you make of the difficult, ethical,</p>
<p>maybe poetic suffering of very few individuals?</p>
<p>I think it&rsquo;s possible that that gets overridden</p>
<p>by benefits to very large numbers of individuals.</p>
<p>I think that can be the right answer.</p>
<p>But before we conclude that it is the right answer,</p>
<p>we have to know how severe the suffering is</p>
<p>and how that compares with the benefits.</p>
<p>So I tend to think that extreme suffering is worse than</p>
<p>or is further, if you like, below the neutral level</p>
<p>than extreme happiness or bliss is above it.</p>
<p>So when I think about the worst experiences possible</p>
<p>and the best experiences possible,</p>
<p>I don&rsquo;t think of them as equidistant from neutral.</p>
<p>So like it&rsquo;s a scale that goes from minus 100 through zero</p>
<p>as a neutral level to plus 100.</p>
<p>Because I know that I would not exchange an hour</p>
<p>of my most pleasurable experiences</p>
<p>for an hour of my most painful experiences,</p>
<p>even I wouldn&rsquo;t have an hour</p>
<p>of my most painful experiences even for two hours</p>
<p>or 10 hours of my most painful experiences.</p>
<p>Did I say that correctly?</p>
<p>Yeah, yeah, yeah, yeah.</p>
<p>Maybe 20 hours then, it&rsquo;s 21, what&rsquo;s the exchange rate?</p>
<p>So that&rsquo;s the question, what is the exchange rate?</p>
<p>But I think it can be quite high.</p>
<p>So that&rsquo;s why you shouldn&rsquo;t just assume that</p>
<p>it&rsquo;s okay to make one person suffer extremely</p>
<p>in order to make two people much better off.</p>
<p>It might be a much larger number.</p>
<p>But at some point I do think you should aggregate</p>
<p>and the result will be,</p>
<p>even though it violates our intuitions of justice</p>
<p>and fairness, whatever it might be,</p>
<p>giving priority to those who are worse off,</p>
<p>at some point I still think</p>
<p>that will be the right thing to do.</p>
<p>Yeah, it&rsquo;s some complicated nonlinear function.</p>
<p>Can I ask a sort of out there question is,</p>
<p>the more and more we put our data out there,</p>
<p>the more we&rsquo;re able to measure a bunch of factors</p>
<p>of each of our individual human lives.</p>
<p>And I could foresee the ability to estimate wellbeing</p>
<p>of whatever we together collectively agree</p>
<p>and is in a good objective function</p>
<p>from a utilitarian perspective.</p>
<p>Do you think it&rsquo;ll be possible</p>
<p>and is a good idea to push that kind of analysis</p>
<p>to make then public decisions perhaps with the help of AI</p>
<p>that here&rsquo;s a tax rate,</p>
<p>here&rsquo;s a tax rate at which wellbeing will be optimized.</p>
<p>Yeah, that would be great if we really knew that,</p>
<p>if we really could calculate that.</p>
<p>No, but do you think it&rsquo;s possible</p>
<p>to converge towards an agreement amongst humans,</p>
<p>towards an objective function</p>
<p>or is it just a hopeless pursuit?</p>
<p>I don&rsquo;t think it&rsquo;s hopeless.</p>
<p>I think it would be difficult</p>
<p>to get converged towards agreement, at least at present,</p>
<p>because some people would say,</p>
<p>I&rsquo;ve got different views about justice</p>
<p>and I think you ought to give priority</p>
<p>to those who are worse off,</p>
<p>even though I acknowledge that the gains</p>
<p>that the worst off are making are less than the gains</p>
<p>that those who are sort of medium badly off could be making.</p>
<p>So we still have all of these intuitions that we argue about.</p>
<p>So I don&rsquo;t think we would get agreement,</p>
<p>but the fact that we wouldn&rsquo;t get agreement</p>
<p>doesn&rsquo;t show that there isn&rsquo;t a right answer there.</p>
<p>Do you think, who gets to say what is right and wrong?</p>
<p>Do you think there&rsquo;s place for ethics oversight</p>
<p>from the government?</p>
<p>So I&rsquo;m thinking in the case of AI,</p>
<p>overseeing what kind of decisions AI can make or not,</p>
<p>but also if you look at animal rights</p>
<p>or rather not rights or perhaps rights,</p>
<p>but the ideas you&rsquo;ve explored in animal liberation,</p>
<p>who gets to, so you eloquently and beautifully write</p>
<p>in your book that this, you know, we shouldn&rsquo;t do this,</p>
<p>but is there some harder rules that should be imposed</p>
<p>or is this a collective thing we converse towards the society</p>
<p>and thereby make the better and better ethical decisions?</p>
<p>Politically, I&rsquo;m still a Democrat</p>
<p>despite looking at the flaws in democracy</p>
<p>and the way it doesn&rsquo;t work always very well.</p>
<p>So I don&rsquo;t see a better option</p>
<p>than allowing the public to vote for governments</p>
<p>in accordance with their policies.</p>
<p>And I hope that they will vote for policies</p>
<p>that reduce the suffering of animals</p>
<p>and reduce the suffering of distant humans,</p>
<p>whether geographically distant or distant</p>
<p>because they&rsquo;re future humans.</p>
<p>But I recognise that democracy</p>
<p>isn&rsquo;t really well set up to do that.</p>
<p>And in a sense, you could imagine a wise and benevolent,</p>
<p>you know, omnibenevolent leader</p>
<p>who would do that better than democracies could.</p>
<p>But in the world in which we live,</p>
<p>it&rsquo;s difficult to imagine that this leader</p>
<p>isn&rsquo;t gonna be corrupted by a variety of influences.</p>
<p>You know, we&rsquo;ve had so many examples</p>
<p>of people who&rsquo;ve taken power with good intentions</p>
<p>and then have ended up being corrupt</p>
<p>and favouring themselves.</p>
<p>So I don&rsquo;t know, you know, that&rsquo;s why, as I say,</p>
<p>I don&rsquo;t know that we have a better system</p>
<p>than democracy to make these decisions.</p>
<p>Well, so you also discuss effective altruism,</p>
<p>which is a mechanism for going around government</p>
<p>for putting the power in the hands of the people</p>
<p>to donate money towards causes to help, you know,</p>
<p>remove the middleman and give it directly</p>
<p>to the causes that they care about.</p>
<p>Sort of, maybe this is a good time to ask,</p>
<p>you&rsquo;ve, 10 years ago, wrote The Life You Can Save,</p>
<p>that&rsquo;s now, I think, available for free online?</p>
<p>That&rsquo;s right, you can download either the ebook</p>
<p>or the audiobook free from the lifeyoucansave.org.</p>
<p>And what are the key ideas that you present</p>
<p>in the book?</p>
<p>The main thing I wanna do in the book</p>
<p>is to make people realise that it&rsquo;s not difficult</p>
<p>to help people in extreme poverty,</p>
<p>that there are highly effective organisations now</p>
<p>that are doing this, that they&rsquo;ve been independently assessed</p>
<p>and verified by research teams that are expert in this area</p>
<p>and that it&rsquo;s a fulfilling thing to do</p>
<p>to, for at least part of your life, you know,</p>
<p>we can&rsquo;t all be saints, but at least one of your goals</p>
<p>should be to really make a positive contribution</p>
<p>to the world and to do something to help people</p>
<p>who through no fault of their own</p>
<p>are in very dire circumstances and living a life</p>
<p>that is barely or perhaps not at all</p>
<p>a decent life for a human being to live.</p>
<p>So you describe a minimum ethical standard of giving.</p>
<p>What advice would you give to people</p>
<p>that want to be effectively altruistic in their life,</p>
<p>like live an effective altruism life?</p>
<p>There are many different kinds of ways of living</p>
<p>as an effective altruist.</p>
<p>And if you&rsquo;re at the point where you&rsquo;re thinking</p>
<p>about your long term career, I&rsquo;d recommend you take a look</p>
<p>at a website called 80,000Hours, 80,000Hours.org,</p>
<p>which looks at ethical career choices.</p>
<p>And they range from, for example,</p>
<p>going to work on Wall Street</p>
<p>so that you can earn a huge amount of money</p>
<p>and then donate most of it to effective charities</p>
<p>to going to work for a really good nonprofit organization</p>
<p>so that you can directly use your skills and ability</p>
<p>and hard work to further a good cause,</p>
<p>or perhaps going into politics, maybe small chances,</p>
<p>but big payoffs in politics,</p>
<p>go to work in the public service</p>
<p>where if you&rsquo;re talented, you might rise to a high level</p>
<p>where you can influence decisions,</p>
<p>do research in an area where the payoffs could be great.</p>
<p>There are a lot of different opportunities,</p>
<p>but too few people are even thinking about those questions.</p>
<p>They&rsquo;re just going along in some sort of preordained rut</p>
<p>to particular careers.</p>
<p>Maybe they think they&rsquo;ll earn a lot of money</p>
<p>and have a comfortable life,</p>
<p>but they may not find that as fulfilling</p>
<p>as actually knowing that they&rsquo;re making</p>
<p>a positive difference to the world.</p>
<p>What about in terms of,</p>
<p>so that&rsquo;s like long term, 80,000 hours,</p>
<p>sort of shorter term giving part of,</p>
<p>well, actually it&rsquo;s a part of that.</p>
<p>You go to work at Wall Street,</p>
<p>if you would like to give a percentage of your income</p>
<p>that you talk about and life you can save that.</p>
<p>I mean, I was looking through, it&rsquo;s quite a compelling,</p>
<p>I mean, I&rsquo;m just a dumb engineer,</p>
<p>so I like, there&rsquo;s simple rules, there&rsquo;s a nice percentage.</p>
<p>Okay, so I do actually set out suggested levels of giving</p>
<p>because people often ask me about this.</p>
<p>A popular answer is give 10%, the traditional tithe</p>
<p>that&rsquo;s recommended in Christianity and also Judaism.</p>
<p>But why should it be the same percentage</p>
<p>irrespective of your income?</p>
<p>Tax scales reflect the idea that the more income you have,</p>
<p>the more you can pay tax.</p>
<p>And I think the same is true in what you can give.</p>
<p>So I do set out a progressive donor scale,</p>
<p>which starts out at 1% for people on modest incomes</p>
<p>and rises to 33 and a third percent</p>
<p>for people who are really earning a lot.</p>
<p>And my idea is that I don&rsquo;t think any of these amounts</p>
<p>really impose real hardship on people</p>
<p>because they are progressive and geared to income.</p>
<p>So I think anybody can do this</p>
<p>and can know that they&rsquo;re doing something significant</p>
<p>to play their part in reducing the huge gap</p>
<p>between people in extreme poverty in the world</p>
<p>and people living affluent lives.</p>
<p>And aside from it being an ethical life,</p>
<p>it&rsquo;s one that you find more fulfilling</p>
<p>because there&rsquo;s something about our human nature that,</p>
<p>or some of our human natures,</p>
<p>maybe most of our human nature that enjoys doing</p>
<p>the ethical thing.</p>
<p>Yes, I make both those arguments,</p>
<p>that it is an ethical requirement</p>
<p>in the kind of world we live in today</p>
<p>to help people in great need when we can easily do so,</p>
<p>but also that it is a rewarding thing</p>
<p>and there&rsquo;s good psychological research showing</p>
<p>that people who give more tend to be more satisfied</p>
<p>with their lives.</p>
<p>And I think this has something to do</p>
<p>with having a purpose that&rsquo;s larger than yourself</p>
<p>and therefore never being, if you like,</p>
<p>never being bored sitting around,</p>
<p>oh, you know, what will I do next?</p>
<p>I&rsquo;ve got nothing to do.</p>
<p>In a world like this, there are many good things</p>
<p>that you can do and enjoy doing them.</p>
<p>Plus you&rsquo;re working with other people</p>
<p>in the effective altruism movement</p>
<p>who are forming a community of other people</p>
<p>with similar ideas and they tend to be interesting,</p>
<p>thoughtful and good people as well.</p>
<p>And having friends of that sort is another big contribution</p>
<p>to having a good life.</p>
<p>So we talked about big things that are beyond ourselves,</p>
<p>but we&rsquo;re also just human and mortal.</p>
<p>Do you ponder your own mortality?</p>
<p>Is there insights about your philosophy,</p>
<p>the ethics that you gain from pondering your own mortality?</p>
<p>Clearly, you know, as you get into your 70s,</p>
<p>you can&rsquo;t help thinking about your own mortality.</p>
<p>Uh, but I don&rsquo;t know that I have great insights</p>
<p>into that from my philosophy.</p>
<p>I don&rsquo;t think there&rsquo;s anything after the death of my body,</p>
<p>you know, assuming that we won&rsquo;t be able to upload my mind</p>
<p>into anything at the time when I die.</p>
<p>So I don&rsquo;t think there&rsquo;s any afterlife</p>
<p>or anything to look forward to in that sense.</p>
<p>Do you fear death?</p>
<p>So if you look at Ernest Becker</p>
<p>and describing the motivating aspects</p>
<p>of our ability to be cognizant of our mortality,</p>
<p>do you have any of those elements</p>
<p>in your drive and your motivation in life?</p>
<p>I suppose the fact that you have only a limited time</p>
<p>to achieve the things that you want to achieve</p>
<p>gives you some sort of motivation</p>
<p>to get going and achieving them.</p>
<p>And if we thought we were immortal,</p>
<p>we might say, ah, you know,</p>
<p>I can put that off for another decade or two.</p>
<p>So there&rsquo;s that about it.</p>
<p>But otherwise, you know, no,</p>
<p>I&rsquo;d rather have more time to do more.</p>
<p>I&rsquo;d also like to be able to see how things go</p>
<p>that I&rsquo;m interested in, you know.</p>
<p>Is climate change gonna turn out to be as dire</p>
<p>as a lot of scientists say that it is going to be?</p>
<p>Will we somehow scrape through</p>
<p>with less damage than we thought?</p>
<p>I&rsquo;d really like to know the answers to those questions,</p>
<p>but I guess I&rsquo;m not going to.</p>
<p>Well, you said there&rsquo;s nothing afterwards.</p>
<p>So let me ask the even more absurd question.</p>
<p>What do you think is the meaning of it all?</p>
<p>I think the meaning of life is the meaning we give to it.</p>
<p>I don&rsquo;t think that we were brought into the universe</p>
<p>for any kind of larger purpose.</p>
<p>But given that we exist,</p>
<p>I think we can recognize that some things</p>
<p>are objectively bad.</p>
<p>Extreme suffering is an example,</p>
<p>and other things are objectively good,</p>
<p>like having a rich, fulfilling, enjoyable,</p>
<p>pleasurable life, and we can try to do our part</p>
<p>in reducing the bad things and increasing the good things.</p>
<p>So one way, the meaning is to do a little bit more</p>
<p>of the good things, objectively good things,</p>
<p>and a little bit less of the bad things.</p>
<p>Yes, so do as much of the good things as you can</p>
<p>and as little of the bad things.</p>
<p>You beautifully put, I don&rsquo;t think there&rsquo;s a better place</p>
<p>to end it, thank you so much for talking today.</p>
<p>Thanks very much, Lex.</p>
<p>It&rsquo;s been really interesting talking to you.</p>
<p>Thanks for listening to this conversation</p>
<p>with Peter Singer, and thank you to our sponsors,</p>
<p>Cash App and Masterclass.</p>
<p>Please consider supporting the podcast</p>
<p>by downloading Cash App and using the code LexPodcast,</p>
<p>and signing up at masterclass.com slash Lex.</p>
<p>Click the links, buy all the stuff.</p>
<p>It&rsquo;s the best way to support this podcast</p>
<p>and the journey I&rsquo;m on in my research and startup.</p>
<p>If you enjoy this thing, subscribe on YouTube,</p>
<p>review it with 5,000 Apple Podcast, support on Patreon,</p>
<p>or connect with me on Twitter at Lex Friedman,</p>
<p>spelled without the E, just F R I D M A N.</p>
<p>And now, let me leave you with some words</p>
<p>from Peter Singer, what one generation finds ridiculous,</p>
<p>the next accepts, and the third shudders</p>
<p>when looks back at what the first did.</p>
<p>Thank you for listening, and hope to see you next time.</p>

</section>


    <footer class="article-footer">
    
    <section class="article-tags">
        
            <a href="/tags/english/">English</a>
        
            <a href="/tags/podcast/">Podcast</a>
        
            <a href="/tags/lex-fridman-podcast/">Lex Fridman Podcast</a>
        
    </section>


    </footer>


    
</article>

    

    

<div>
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9206135835124064"
         crossorigin="anonymous"></script>
    <ins class="adsbygoogle"
         style="display:block; text-align:center;"
         data-ad-layout="in-article"
         data-ad-format="fluid"
         data-ad-client="ca-pub-9206135835124064"
         data-ad-slot="1055602464"></ins>
    <script>
         (adsbygoogle = window.adsbygoogle || []).push({});
    </script>
</div>
<aside class="related-content--wrapper">
    <h2 class="section-title">Related content</h2>
    <div class="related-content">
        <div class="flex article-list--tile">
            
                
<article class="">
    <a href="/en/1310500372/">
        
	
        
        <div class="article-image">
            
            <img src="/img/related-content.png" loading="lazy" 
            data-key="en/1310500372" data-hash="" 
            style="opacity: 0.3;"/>
        </div>
        
        <div class="article-details">
            <h2 class="article-title">Lex Fridman Podcast - #368 - Eliezer Yudkowsky: Dangers of AI and the End of Human Civilization</h2>
            
            <footer class="article-time">
                <time datetime=''>Mar 30, 2023</time>
            </footer>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/en/1310500371/">
        
	
        
        <div class="article-image">
            
            <img src="/img/related-content.png" loading="lazy" 
            data-key="en/1310500371" data-hash="" 
            style="opacity: 0.3;"/>
        </div>
        
        <div class="article-details">
            <h2 class="article-title">Lex Fridman Podcast - #367 - Sam Altman: OpenAI CEO on GPT-4, ChatGPT, and the Future of AI</h2>
            
            <footer class="article-time">
                <time datetime=''>Mar 26, 2023</time>
            </footer>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/en/1310500370/">
        
	
        
        <div class="article-image">
            
            <img src="/img/related-content.png" loading="lazy" 
            data-key="en/1310500370" data-hash="" 
            style="opacity: 0.3;"/>
        </div>
        
        <div class="article-details">
            <h2 class="article-title">Lex Fridman Podcast - #366 - Shannon Curry: Johnny Depp &amp; Amber Heard Trial, Marriage, Dating &amp; Love</h2>
            
            <footer class="article-time">
                <time datetime=''>Mar 22, 2023</time>
            </footer>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/en/1310500369/">
        
	
        
        <div class="article-image">
            
            <img src="/img/related-content.png" loading="lazy" 
            data-key="en/1310500369" data-hash="" 
            style="opacity: 0.3;"/>
        </div>
        
        <div class="article-details">
            <h2 class="article-title">Lex Fridman Podcast - #365 - Sam Harris: Trump, Pandemic, Twitter, Elon, Bret, IDW, Kanye, AI &amp; UFOs</h2>
            
            <footer class="article-time">
                <time datetime=''>Mar 15, 2023</time>
            </footer>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/en/1310500368/">
        
	
        
        <div class="article-image">
            
            <img src="/img/related-content.png" loading="lazy" 
            data-key="en/1310500368" data-hash="" 
            style="opacity: 0.3;"/>
        </div>
        
        <div class="article-details">
            <h2 class="article-title">Lex Fridman Podcast - #364 - Chris Voss: FBI Hostage Negotiator</h2>
            
            <footer class="article-time">
                <time datetime=''>Mar 11, 2023</time>
            </footer>
        </div>
    </a>
</article>

            
        </div>
    </div>
</aside>

     
    
        
    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
            2021 - 
        
        2023 SWIEST - Transcripts ¬∑ Screenplays ¬∑ Lyrics
    </section>
    
    <section class="powerby">
        

        As an Amazon Associate I earn from qualifying purchases üõí<br/>

        Built with <a href="https://swiest.com/" target="_blank" rel="noopener">(Ôæâ‚óï„ÉÆ‚óï)Ôæâü™Ñüíûüíñü•∞ across the glüåçüåèüåébe</a> <br />
        
        
    </section>
</footer>


    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo="crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU="crossorigin="anonymous"
                defer
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css"crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css"crossorigin="anonymous"
            >

            </main>
        </div>
        <script 
                src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js"integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z&#43;KMkF24hUW8WePSA9HM="crossorigin="anonymous"
                
                >
            </script><script type="text/javascript" src="/ts/main.js" defer></script>


<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Noto+Serif&family=Noto+Serif+Armenian&family=Noto+Serif+Bengali&family=Noto+Serif+Devanagari&family=Noto+Serif+Georgian&family=Noto+Serif+Gujarati&family=Noto+Serif+HK&family=Noto+Serif+Hebrew&family=Noto+Serif+JP&family=Noto+Serif+KR&family=Noto+Serif+Kannada&family=Noto+Serif+Khmer&family=Noto+Serif+Lao&family=Noto+Serif+Makasar&family=Noto+Serif+Malayalam&family=Noto+Serif+Myanmar&family=Noto+Serif+Oriya&family=Noto+Serif+SC&family=Noto+Serif+Sinhala&family=Noto+Serif+TC&family=Noto+Serif+Tamil&family=Noto+Serif+Telugu&family=Noto+Serif+Thai&family=Noto+Serif+Tibetan&display=swap" rel="stylesheet">

    </body>
</html>
