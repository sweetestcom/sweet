<!DOCTYPE html>
<html lang="en" dir="ltr">
    <head><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content='The following is a conversation with Greg Brockman.
He&amp;rsquo;s the cofounder and CTO of OpenAI,
a world class research organization
developing ideas in AI with a goal of eventually
creating a safe and friendly artificial general
intelligence, one that benefits and empowers humanity.
OpenAI is not only a source of publications, algorithms, tools,
and data sets.
Their mission is a catalyst for an important public discourse
about our future with both narrow and general intelligence'>
<title>Lex Fridman Podcast - #17 - Greg Brockman: OpenAI and AGI | SWIEST</title>

<link rel='canonical' href='https://swiest.com/en/1310500017/'>

<link rel="stylesheet" href="/scss/style.min.91b18679590f4ceed910ade4d64b1e7375cc0770ef5b8c1d822f42424f9ff2c8.css"><script>
    document.oncontextmenu = function(){ return false; };
    document.onselectstart = function(){ return false; };
    document.oncopy = function(){ return false; };
    document.oncut = function(){ return false; };
</script>

<script src="https://apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js"></script>


<script type="text/javascript">
    $(document).ready(function(){
     
     $("#back-to-top").hide();
     
     $(function () {
      $(window).scroll(function(){
       if ($(window).scrollTop()>600){
        $("#back-to-top").fadeIn(500);
       }else{
        $("#back-to-top").fadeOut(500);
       }
     });
     
     $("#back-to-top").click(function(){
      $('body,html').animate({scrollTop:0},500);
       return false;
      });
     });
    });
    </script><meta property='og:title' content='Lex Fridman Podcast - #17 - Greg Brockman: OpenAI and AGI'>
<meta property='og:description' content='The following is a conversation with Greg Brockman.
He&amp;rsquo;s the cofounder and CTO of OpenAI,
a world class research organization
developing ideas in AI with a goal of eventually
creating a safe and friendly artificial general
intelligence, one that benefits and empowers humanity.
OpenAI is not only a source of publications, algorithms, tools,
and data sets.
Their mission is a catalyst for an important public discourse
about our future with both narrow and general intelligence'>
<meta property='og:url' content='https://swiest.com/en/1310500017/'>
<meta property='og:site_name' content='SWIEST - Transcripts ¬∑ Screenplays ¬∑ Lyrics'>
<meta property='og:type' content='article'><meta property='article:section' content='Post' /><meta property='article:tag' content='English' /><meta property='article:tag' content='Podcast' /><meta property='article:tag' content='Lex Fridman Podcast' /><meta property='article:published_time' content='2022-03-17T17:00:00&#43;00:00'/><meta property='article:modified_time' content='2022-03-17T17:00:00&#43;00:00'/>
<meta name="twitter:title" content="Lex Fridman Podcast - #17 - Greg Brockman: OpenAI and AGI">
<meta name="twitter:description" content="The following is a conversation with Greg Brockman.
He&amp;rsquo;s the cofounder and CTO of OpenAI,
a world class research organization
developing ideas in AI with a goal of eventually
creating a safe and friendly artificial general
intelligence, one that benefits and empowers humanity.
OpenAI is not only a source of publications, algorithms, tools,
and data sets.
Their mission is a catalyst for an important public discourse
about our future with both narrow and general intelligence">
    <link rel="shortcut icon" href="/favicon.ico" />
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9206135835124064" crossorigin="anonymous"></script>
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    </head>
    <body class="
    article-page
    ">
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "dark");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky ">
    <button class="hamburger hamburger--spin" type="button" id="toggle-menu" aria-label="Toggle Menu">
        <span class="hamburger-box">
            <span class="hamburger-inner"></span>
        </span>
    </button>

    <header>
        
            
            <figure class="site-avatar">
                <a href="/">
                
                    
                    
                    
                        
                        <img src="/img/avatar_hu307e6a33fa6fd661ccda3b77024ef5c2_252345_300x0_resize_box_3.png" width="300"
                            height="300" class="site-logo" loading="lazy" alt="Avatar">
                    
                
                </a>
                
                    <span class="emoji">‚ú®</span>
                
            </figure>
            
        
        
        <div class="site-meta">
            <h1 class="site-name"><a href="/">SWIEST - Transcripts ¬∑ Screenplays ¬∑ Lyrics</a></h1>
            <h2 class="site-description">üåçüåèüåé</h2>
        </div>
    </header><ol class="menu" id="main-menu">
        
        
        
        <li >
            <a href='/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <polyline points="5 12 3 12 12 3 21 12 19 12" />
  <path d="M5 12v7a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-7" />
  <path d="M9 21v-6a2 2 0 0 1 2 -2h2a2 2 0 0 1 2 2v6" />
</svg>



                
                <span>Home</span>
            </a>
        </li>
        
        
        <li >
            <a href='/archives/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <rect x="3" y="4" width="18" height="4" rx="2" />
  <path d="M5 8v10a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-10" />
  <line x1="10" y1="12" x2="14" y2="12" />
</svg>



                
                <span>Archives</span>
            </a>
        </li>
        
        
        <li >
            <a href='/search/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="10" cy="10" r="7" />
  <line x1="21" y1="21" x2="15" y2="15" />
</svg>



                
                <span>Search</span>
            </a>
        </li>
        
        
        <li >
            <a href='/chart/podcastchart.html' target="_blank">
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-apple-podcast" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M18.364 18.364a9 9 0 1 0 -12.728 0" />
  <path d="M11.766 22h.468a2 2 0 0 0 1.985 -1.752l.5 -4a2 2 0 0 0 -1.985 -2.248h-1.468a2 2 0 0 0 -1.985 2.248l.5 4a2 2 0 0 0 1.985 1.752z" />
  <path d="M12 9m-2 0a2 2 0 1 0 4 0a2 2 0 1 0 -4 0" />
</svg>
                
                <span>Podcast Charts</span>
            </a>
        </li>
        

        <div>
            <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9206135835124064"
                crossorigin="anonymous"></script>
            
            <ins class="adsbygoogle"
                style="display:block"
                data-ad-client="ca-pub-9206135835124064"
                data-ad-slot="8754979142"
                data-ad-format="auto"
                data-full-width-responsive="true"></ins>
            <script>
                 (adsbygoogle = window.adsbygoogle || []).push({});
            </script>
        </div>

        <div class="menu-bottom-section">
                <li id="i18n-switch">  
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-language" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M4 5h7" />
  <path d="M9 3v2c0 4.418 -2.239 8 -5 8" />
  <path d="M5 9c-.003 2.144 2.952 3.908 6.7 4" />
  <path d="M12 20l4 -9l4 9" />
  <path d="M19.1 18h-6.2" />
</svg>



                    <select name="language" onchange="window.location.href = this.selectedOptions[0].value">
                        
                            <option value="https://swiest.com/" selected>English</option>
                        
                            <option value="https://swiest.com/af/" >Afrikaans</option>
                        
                            <option value="https://swiest.com/am/" >·ä†·àõ·à≠·äõ</option>
                        
                            <option value="https://swiest.com/ar/" >ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</option>
                        
                            <option value="https://swiest.com/az/" >Az…ôrbaycan</option>
                        
                            <option value="https://swiest.com/be/" >–±–µ–ª–∞—Ä—É—Å–∫—ñ</option>
                        
                            <option value="https://swiest.com/bg/" >–±—ä–ª–≥–∞—Ä—Å–∫–∏</option>
                        
                            <option value="https://swiest.com/bn/" >‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ</option>
                        
                            <option value="https://swiest.com/bo/" >‡Ωñ‡Ωº‡Ωë‡ºã‡Ω¶‡æê‡Ωë‡ºã</option>
                        
                            <option value="https://swiest.com/bs/" >Bosanski</option>
                        
                            <option value="https://swiest.com/ca/" >Catal√†</option>
                        
                            <option value="https://swiest.com/zh-hans/" >ÁÆÄ‰Ωì‰∏≠Êñá</option>
                        
                            <option value="https://swiest.com/zh-hant/" >ÁπÅÈ´î‰∏≠Êñá</option>
                        
                            <option value="https://swiest.com/cs/" >ƒåe≈°tina</option>
                        
                            <option value="https://swiest.com/el/" >ŒµŒªŒªŒ∑ŒΩŒπŒ∫Œ¨</option>
                        
                            <option value="https://swiest.com/cy/" >Cymraeg</option>
                        
                            <option value="https://swiest.com/da/" >Dansk</option>
                        
                            <option value="https://swiest.com/de/" >Deutsch</option>
                        
                            <option value="https://swiest.com/eo/" >Esperanto</option>
                        
                            <option value="https://swiest.com/es-es/" >Espa√±ol (Espa√±a)</option>
                        
                            <option value="https://swiest.com/es-419/" >Espa√±ol (Latinoam√©rica)</option>
                        
                            <option value="https://swiest.com/et/" >Eesti</option>
                        
                            <option value="https://swiest.com/eu/" >Euskara</option>
                        
                            <option value="https://swiest.com/haw/" > ª≈ålelo Hawai ªi</option>
                        
                            <option value="https://swiest.com/fa/" >ŸÅÿßÿ±ÿ≥€å</option>
                        
                            <option value="https://swiest.com/fi/" >Suomi</option>
                        
                            <option value="https://swiest.com/fo/" >F√∏royskt</option>
                        
                            <option value="https://swiest.com/fr/" >Fran√ßais</option>
                        
                            <option value="https://swiest.com/fy/" >Frysk</option>
                        
                            <option value="https://swiest.com/ga/" >Gaeilge</option>
                        
                            <option value="https://swiest.com/gl/" >Galego</option>
                        
                            <option value="https://swiest.com/gu/" >‡™ó‡´Å‡™ú‡™∞‡™æ‡™§‡´Ä</option>
                        
                            <option value="https://swiest.com/he/" >◊¢÷¥◊ë◊®÷¥◊ô◊™</option>
                        
                            <option value="https://swiest.com/km/" >·ûÄ·ûò·üí·ûñ·ûª·ûá·û∂·üî</option>
                        
                            <option value="https://swiest.com/hi/" >‡§π‡§ø‡§®‡•ç‡§¶‡•Ä</option>
                        
                            <option value="https://swiest.com/hr/" >Hrvatski</option>
                        
                            <option value="https://swiest.com/ht/" >Krey√≤l Ayisyen</option>
                        
                            <option value="https://swiest.com/hu/" >Magyar</option>
                        
                            <option value="https://swiest.com/hy/" >’Ä’°’µ’•÷Ä’•’∂</option>
                        
                            <option value="https://swiest.com/ig/" >√Ås·ª•ÃÄs·ª•ÃÅ √ågb√≤</option>
                        
                            <option value="https://swiest.com/id/" >Bahasa Indonesia</option>
                        
                            <option value="https://swiest.com/is/" >√çslenska</option>
                        
                            <option value="https://swiest.com/it/" >Italiano</option>
                        
                            <option value="https://swiest.com/ja/" >Êó•Êú¨Ë™û</option>
                        
                            <option value="https://swiest.com/jv/" >Basa Jawa</option>
                        
                            <option value="https://swiest.com/ka/" >·É•·Éê·É†·Éó·É£·Éö·Éò</option>
                        
                            <option value="https://swiest.com/kk/" >“ö–∞–∑–∞“õ—à–∞</option>
                        
                            <option value="https://swiest.com/kn/" >‡≤ï‡≤®‡≥ç‡≤®‡≤°</option>
                        
                            <option value="https://swiest.com/ko/" >ÌïúÍµ≠Ïñ¥</option>
                        
                            <option value="https://swiest.com/or/" >‡¨ì‡¨°‡¨º‡¨ø‡¨Ü</option>
                        
                            <option value="https://swiest.com/ckb/" >⁄©Ÿàÿ±ÿØ€å</option>
                        
                            <option value="https://swiest.com/ky/" >–ö—ã—Ä–≥—ã–∑—á–∞</option>
                        
                            <option value="https://swiest.com/la/" >Latina</option>
                        
                            <option value="https://swiest.com/lb/" >L√´tzebuergesch</option>
                        
                            <option value="https://swiest.com/lo/" >‡∫û‡∫≤‡∫™‡∫≤‡∫•‡∫≤‡∫ß</option>
                        
                            <option value="https://swiest.com/lt/" >Lietuvi≈≥</option>
                        
                            <option value="https://swiest.com/lv/" >Latvie≈°u</option>
                        
                            <option value="https://swiest.com/mk/" >–ú–∞–∫–µ–¥–æ–Ω—Å–∫–∏</option>
                        
                            <option value="https://swiest.com/ml/" >‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç</option>
                        
                            <option value="https://swiest.com/mn/" >–ú–æ–Ω–≥–æ–ª —Ö—ç–ª</option>
                        
                            <option value="https://swiest.com/mr/" >‡§Æ‡§∞‡§æ‡§†‡•Ä</option>
                        
                            <option value="https://swiest.com/sw/" >Kiswahili</option>
                        
                            <option value="https://swiest.com/ms/" >Bahasa Melayu</option>
                        
                            <option value="https://swiest.com/my/" >·Äô·Äº·Äî·Ä∫·Äô·Ä¨</option>
                        
                            <option value="https://swiest.com/ne/" >‡§®‡•á‡§™‡§æ‡§≤‡•Ä</option>
                        
                            <option value="https://swiest.com/nl/" >Nederlands</option>
                        
                            <option value="https://swiest.com/no/" >Norsk</option>
                        
                            <option value="https://swiest.com/pa/" >‡®™‡©∞‡®ú‡®æ‡®¨‡©Ä</option>
                        
                            <option value="https://swiest.com/pl/" >Polski</option>
                        
                            <option value="https://swiest.com/pt-br/" >Portugu√™s Brasil</option>
                        
                            <option value="https://swiest.com/pt-pt/" >Portugu√™s Europeu</option>
                        
                            <option value="https://swiest.com/ro/" >Rom√¢nƒÉ</option>
                        
                            <option value="https://swiest.com/ru/" >–†—É—Å—Å–∫–∏–π</option>
                        
                            <option value="https://swiest.com/rw/" >Kinyarwanda</option>
                        
                            <option value="https://swiest.com/si/" >‡∑É‡∑í‡∂Ç‡∑Ñ‡∂Ω</option>
                        
                            <option value="https://swiest.com/sk/" >Slovenƒçina</option>
                        
                            <option value="https://swiest.com/sl/" >Sloven≈°ƒçina</option>
                        
                            <option value="https://swiest.com/sq/" >Shqip</option>
                        
                            <option value="https://swiest.com/sr/" >–°—Ä–ø—Å–∫–∏ (Srpski)</option>
                        
                            <option value="https://swiest.com/su/" >Basa Sunda</option>
                        
                            <option value="https://swiest.com/sv/" >Svenska</option>
                        
                            <option value="https://swiest.com/ta/" >‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç</option>
                        
                            <option value="https://swiest.com/te/" >‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å</option>
                        
                            <option value="https://swiest.com/tg/" >–¢–æ“∑–∏–∫”£</option>
                        
                            <option value="https://swiest.com/th/" >‡πÑ‡∏ó‡∏¢</option>
                        
                            <option value="https://swiest.com/tl/" >Filipino</option>
                        
                            <option value="https://swiest.com/tr/" >T√ºrk√ße</option>
                        
                            <option value="https://swiest.com/uk/" >–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞</option>
                        
                            <option value="https://swiest.com/ur/" >ÿßÿ±ÿØŸà</option>
                        
                            <option value="https://swiest.com/uz/" >O&#39;zbekcha</option>
                        
                            <option value="https://swiest.com/vi/" >Ti·∫øng Vi·ªát</option>
                        
                            <option value="https://swiest.com/yi/" >◊ê◊ô◊ì◊ô◊©</option>
                        
                            <option value="https://swiest.com/zh-hk/" >Á≤µË™û</option>
                        
                            <option value="https://swiest.com/zu/" >IsiZulu</option>
                        
                    </select>
                </li>
            
            
            
                <li id="dark-mode-toggle">
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="8" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="16" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                    <span>Dark Mode</span>
                </li>
            
        </div>
    </ol>
</aside>

    

            <main class="main full-width">
    <article class="main-article">
    <header class="article-header">

    <div class="article-details">
    
    <header class="article-category">
        
            <a href="/categories/podcast/" >
                Podcast
            </a>
        
            <a href="/categories/lex-fridman-podcast/" >
                Lex Fridman Podcast
            </a>
        
    </header>
    

    <div class="article-title-wrapper">
        <h2 class="article-title">
            <a href="/en/1310500017/">Lex Fridman Podcast - #17 - Greg Brockman: OpenAI and AGI</a>
        </h2>
    
        
    </div>

    
    
    
    
    <footer class="article-time">
        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M11.795 21h-6.795a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v4" />
  <circle cx="18" cy="18" r="4" />
  <path d="M15 3v4" />
  <path d="M7 3v4" />
  <path d="M3 11h16" />
  <path d="M18 16.496v1.504l1 1" />
</svg>
                <time class="article-time--published">2022-03-17</time>
            </div>
        

        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



                <time class="article-time--reading">
                    77 minute read
                </time>
            </div>
        
    </footer>
    

    
</div>

</header>
<div>
    <ul>
       <a href="https://amzn.to/471i0jl" target="_blank">üéÅAmazon Prime</a>
       <a href="https://amzn.to/3QDVlVf" target="_blank">üìñKindle Unlimited</a>
       <a href="https://amzn.to/3FqzNoB" target="_blank">üéßAudible Plus</a>
       <a href="https://amzn.to/3tMT3dm" target="_blank">üéµAmazon Music Unlimited</a>
       <a href="https://www.iherb.com/?rcode=EID1574" target="_blank">üåøiHerb</a>
    </ul>
</div>
<div>
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9206135835124064"
     crossorigin="anonymous"></script>
    
    <ins class="adsbygoogle"
         style="display:block"
         data-ad-client="ca-pub-9206135835124064"
         data-ad-slot="8754979142"
         data-ad-format="auto"
         data-full-width-responsive="true"></ins>
    <script>
         (adsbygoogle = window.adsbygoogle || []).push({});
    </script>
</div>


    <section class="article-content">
    
    
    <p>The following is a conversation with Greg Brockman.</p>
<p>He&rsquo;s the cofounder and CTO of OpenAI,</p>
<p>a world class research organization</p>
<p>developing ideas in AI with a goal of eventually</p>
<p>creating a safe and friendly artificial general</p>
<p>intelligence, one that benefits and empowers humanity.</p>
<p>OpenAI is not only a source of publications, algorithms, tools,</p>
<p>and data sets.</p>
<p>Their mission is a catalyst for an important public discourse</p>
<p>about our future with both narrow and general intelligence</p>
<p>systems.</p>
<p>This conversation is part of the Artificial Intelligence</p>
<p>podcast at MIT and beyond.</p>
<p>If you enjoy it, subscribe on YouTube, iTunes,</p>
<p>or simply connect with me on Twitter at Lex Friedman,</p>
<p>spelled F R I D. And now, here&rsquo;s my conversation</p>
<p>with Greg Brockman.</p>
<p>So in high school, and right after you</p>
<p>wrote a draft of a chemistry textbook,</p>
<p>saw that that covers everything from basic structure</p>
<p>of the atom to quantum mechanics.</p>
<p>So it&rsquo;s clear you have an intuition and a passion</p>
<p>for both the physical world with chemistry and now robotics</p>
<p>to the digital world with AI, deep learning, reinforcement</p>
<p>learning, so on.</p>
<p>Do you see the physical world and the digital world</p>
<p>as different?</p>
<p>And what do you think is the gap?</p>
<p>A lot of it actually boils down to iteration speed.</p>
<p>I think that a lot of what really motivates me</p>
<p>is building things.</p>
<p>I think about mathematics, for example,</p>
<p>where you think really hard about a problem.</p>
<p>You understand it.</p>
<p>You write it down in this very obscure form</p>
<p>that we call a proof.</p>
<p>But then, this is in humanity&rsquo;s library.</p>
<p>It&rsquo;s there forever.</p>
<p>This is some truth that we&rsquo;ve discovered.</p>
<p>Maybe only five people in your field will ever read it.</p>
<p>But somehow, you&rsquo;ve kind of moved humanity forward.</p>
<p>And so I actually used to really think</p>
<p>that I was going to be a mathematician.</p>
<p>And then I actually started writing this chemistry</p>
<p>textbook.</p>
<p>One of my friends told me, you&rsquo;ll never publish it</p>
<p>because you don&rsquo;t have a PhD.</p>
<p>So instead, I decided to build a website</p>
<p>and try to promote my ideas that way.</p>
<p>And then I discovered programming.</p>
<p>And in programming, you think hard about a problem.</p>
<p>You understand it.</p>
<p>You write it down in a very obscure form</p>
<p>that we call a program.</p>
<p>But then once again, it&rsquo;s in humanity&rsquo;s library.</p>
<p>And anyone can get the benefit from it.</p>
<p>And the scalability is massive.</p>
<p>And so I think that the thing that really appeals</p>
<p>to me about the digital world is that you</p>
<p>can have this insane leverage.</p>
<p>A single individual with an idea is</p>
<p>able to affect the entire planet.</p>
<p>And that&rsquo;s something I think is really</p>
<p>hard to do if you&rsquo;re moving around physical atoms.</p>
<p>But you said mathematics.</p>
<p>So if you look at the wet thing over here, our mind,</p>
<p>do you ultimately see it as just math,</p>
<p>as just information processing?</p>
<p>Or is there some other magic, as you&rsquo;ve seen,</p>
<p>if you&rsquo;ve seen through biology and chemistry and so on?</p>
<p>Yeah, I think it&rsquo;s really interesting to think about</p>
<p>humans as just information processing systems.</p>
<p>And that seems like it&rsquo;s actually</p>
<p>a pretty good way of describing a lot of how the world works</p>
<p>or a lot of what we&rsquo;re capable of, to think that, again,</p>
<p>if you just look at technological innovations</p>
<p>over time, that in some ways, the most transformative</p>
<p>innovation that we&rsquo;ve had has been the computer.</p>
<p>In some ways, the internet, that what has the internet done?</p>
<p>The internet is not about these physical cables.</p>
<p>It&rsquo;s about the fact that I am suddenly</p>
<p>able to instantly communicate with any other human</p>
<p>on the planet.</p>
<p>I&rsquo;m able to retrieve any piece of knowledge</p>
<p>that in some ways the human race has ever had,</p>
<p>and that those are these insane transformations.</p>
<p>Do you see our society as a whole, the collective,</p>
<p>as another extension of the intelligence of the human being?</p>
<p>So if you look at the human being</p>
<p>as an information processing system,</p>
<p>you mentioned the internet, the networking.</p>
<p>Do you see us all together as a civilization</p>
<p>as a kind of intelligent system?</p>
<p>Yeah, I think this is actually</p>
<p>a really interesting perspective to take</p>
<p>and to think about, that you sort of have</p>
<p>this collective intelligence of all of society,</p>
<p>the economy itself is this superhuman machine</p>
<p>that is optimizing something, right?</p>
<p>And in some ways, a company has a will of its own, right?</p>
<p>That you have all these individuals</p>
<p>who are all pursuing their own individual goals</p>
<p>and thinking really hard</p>
<p>and thinking about the right things to do,</p>
<p>but somehow the company does something</p>
<p>that is this emergent thing</p>
<p>and that is a really useful abstraction.</p>
<p>And so I think that in some ways,</p>
<p>we think of ourselves as the most intelligent things</p>
<p>on the planet and the most powerful things on the planet,</p>
<p>but there are things that are bigger than us</p>
<p>that are the systems that we all contribute to.</p>
<p>And so I think actually, it&rsquo;s interesting to think about</p>
<p>if you&rsquo;ve read Isaac Asimov&rsquo;s foundation, right?</p>
<p>That there&rsquo;s this concept of psychohistory in there,</p>
<p>which is effectively this,</p>
<p>that if you have trillions or quadrillions of beings,</p>
<p>then maybe you could actually predict what that being,</p>
<p>that huge macro being will do</p>
<p>and almost independent of what the individuals want.</p>
<p>And I actually have a second angle on this</p>
<p>that I think is interesting,</p>
<p>which is thinking about technological determinism.</p>
<p>One thing that I actually think a lot about with OpenAI,</p>
<p>right, is that we&rsquo;re kind of coming on</p>
<p>to this insanely transformational technology</p>
<p>of general intelligence, right,</p>
<p>that will happen at some point.</p>
<p>And there&rsquo;s a question of how can you take actions</p>
<p>that will actually steer it to go better rather than worse.</p>
<p>And that I think one question you need to ask</p>
<p>is as a scientist, as an inventor, as a creator,</p>
<p>what impact can you have in general, right?</p>
<p>You look at things like the telephone</p>
<p>invented by two people on the same day.</p>
<p>Like, what does that mean?</p>
<p>Like, what does that mean about the shape of innovation?</p>
<p>And I think that what&rsquo;s going on</p>
<p>is everyone&rsquo;s building on the shoulders of the same giants.</p>
<p>And so you can kind of, you can&rsquo;t really hope</p>
<p>to create something no one else ever would.</p>
<p>You know, if Einstein wasn&rsquo;t born,</p>
<p>someone else would have come up with relativity.</p>
<p>You know, he changed the timeline a bit, right,</p>
<p>that maybe it would have taken another 20 years,</p>
<p>but it wouldn&rsquo;t be that fundamentally humanity</p>
<p>would never discover these fundamental truths.</p>
<p>So there&rsquo;s some kind of invisible momentum</p>
<p>that some people like Einstein or OpenAI is plugging into</p>
<p>that anybody else can also plug into</p>
<p>and ultimately that wave takes us into a certain direction.</p>
<p>That&rsquo;s what he means by digital.</p>
<p>That&rsquo;s right, that&rsquo;s right.</p>
<p>And you know, this kind of seems to play out</p>
<p>in a bunch of different ways,</p>
<p>that there&rsquo;s some exponential that is being written</p>
<p>and that the exponential itself, which one it is, changes.</p>
<p>Think about Moore&rsquo;s Law, an entire industry</p>
<p>set its clock to it for 50 years.</p>
<p>Like, how can that be, right?</p>
<p>How is that possible?</p>
<p>And yet somehow it happened.</p>
<p>And so I think you can&rsquo;t hope to ever invent something</p>
<p>that no one else will.</p>
<p>Maybe you can change the timeline a little bit.</p>
<p>But if you really want to make a difference,</p>
<p>I think that the thing that you really have to do,</p>
<p>the only real degree of freedom you have</p>
<p>is to set the initial conditions</p>
<p>under which a technology is born.</p>
<p>And so you think about the internet, right?</p>
<p>That there are lots of other competitors</p>
<p>trying to build similar things.</p>
<p>And the internet won.</p>
<p>And that the initial conditions</p>
<p>were that it was created by this group</p>
<p>that really valued people being able to be,</p>
<p>anyone being able to plug in</p>
<p>this very academic mindset of being open and connected.</p>
<p>And I think that the internet for the next 40 years</p>
<p>really played out that way.</p>
<p>You know, maybe today things are starting</p>
<p>to shift in a different direction.</p>
<p>But I think that those initial conditions</p>
<p>were really important to determine</p>
<p>the next 40 years worth of progress.</p>
<p>That&rsquo;s really beautifully put.</p>
<p>So another example that I think about,</p>
<p>you know, I recently looked at it.</p>
<p>I looked at Wikipedia, the formation of Wikipedia.</p>
<p>And I wondered what the internet would be like</p>
<p>if Wikipedia had ads.</p>
<p>You know, there&rsquo;s an interesting argument</p>
<p>that why they chose not to make it,</p>
<p>put advertisement on Wikipedia.</p>
<p>I think Wikipedia&rsquo;s one of the greatest resources</p>
<p>we have on the internet.</p>
<p>It&rsquo;s extremely surprising how well it works</p>
<p>and how well it was able to aggregate</p>
<p>all this kind of good information.</p>
<p>And essentially the creator of Wikipedia,</p>
<p>I don&rsquo;t know, there&rsquo;s probably some debates there,</p>
<p>but set the initial conditions.</p>
<p>And now it carried itself forward.</p>
<p>That&rsquo;s really interesting.</p>
<p>So the way you&rsquo;re thinking about AGI</p>
<p>or artificial intelligence is you&rsquo;re focused</p>
<p>on setting the initial conditions for the progress.</p>
<p>That&rsquo;s right.</p>
<p>That&rsquo;s powerful.</p>
<p>Okay, so looking to the future,</p>
<p>if you create an AGI system,</p>
<p>like one that can ace the Turing test, natural language,</p>
<p>what do you think would be the interactions</p>
<p>you would have with it?</p>
<p>What do you think are the questions you would ask?</p>
<p>Like what would be the first question you would ask?</p>
<p>It, her, him.</p>
<p>That&rsquo;s right.</p>
<p>I think that at that point,</p>
<p>if you&rsquo;ve really built a powerful system</p>
<p>that is capable of shaping the future of humanity,</p>
<p>the first question that you really should ask</p>
<p>is how do we make sure that this plays out well?</p>
<p>And so that&rsquo;s actually the first question</p>
<p>that I would ask a powerful AGI system is.</p>
<p>So you wouldn&rsquo;t ask your colleague,</p>
<p>you wouldn&rsquo;t ask like Ilya,</p>
<p>you would ask the AGI system.</p>
<p>Oh, we&rsquo;ve already had the conversation with Ilya, right?</p>
<p>And everyone here.</p>
<p>And so you want as many perspectives</p>
<p>and a piece of wisdom as you can</p>
<p>for answering this question.</p>
<p>So I don&rsquo;t think you necessarily defer</p>
<p>to whatever your powerful system tells you,</p>
<p>but you use it as one input</p>
<p>to try to figure out what to do.</p>
<p>But, and I guess fundamentally what it really comes down to</p>
<p>is if you built something really powerful</p>
<p>and you think about, for example,</p>
<p>the creation of shortly after</p>
<p>the creation of nuclear weapons, right?</p>
<p>The most important question in the world was</p>
<p>what&rsquo;s the world order going to be like?</p>
<p>How do we set ourselves up in a place</p>
<p>where we&rsquo;re going to be able to survive as a species?</p>
<p>With AGI, I think the question is slightly different, right?</p>
<p>That there is a question of how do we make sure</p>
<p>that we don&rsquo;t get the negative effects,</p>
<p>but there&rsquo;s also the positive side, right?</p>
<p>You imagine that, like what won&rsquo;t AGI be like?</p>
<p>Like what will it be capable of?</p>
<p>And I think that one of the core reasons</p>
<p>that an AGI can be powerful and transformative</p>
<p>is actually due to technological development, right?</p>
<p>If you have something that&rsquo;s capable as a human</p>
<p>and that it&rsquo;s much more scalable,</p>
<p>that you absolutely want that thing</p>
<p>to go read the whole scientific literature</p>
<p>and think about how to create cures for all the diseases,</p>
<p>right?</p>
<p>You want it to think about how to go</p>
<p>and build technologies to help us create material abundance</p>
<p>and to figure out societal problems</p>
<p>that we have trouble with.</p>
<p>Like how are we supposed to clean up the environment?</p>
<p>And maybe you want this to go and invent</p>
<p>a bunch of little robots that will go out</p>
<p>and be biodegradable and turn ocean debris</p>
<p>into harmless molecules.</p>
<p>And I think that that positive side</p>
<p>is something that I think people miss</p>
<p>sometimes when thinking about what an AGI will be like.</p>
<p>And so I think that if you have a system</p>
<p>that&rsquo;s capable of all of that,</p>
<p>you absolutely want its advice about how do I make sure</p>
<p>that we&rsquo;re using your capabilities</p>
<p>in a positive way for humanity.</p>
<p>So what do you think about that psychology</p>
<p>that looks at all the different possible trajectories</p>
<p>of an AGI system, many of which,</p>
<p>perhaps the majority of which are positive,</p>
<p>and nevertheless focuses on the negative trajectories?</p>
<p>I mean, you get to interact with folks,</p>
<p>you get to think about this, maybe within yourself as well.</p>
<p>You look at Sam Harris and so on.</p>
<p>It seems to be, sorry to put it this way,</p>
<p>but almost more fun to think about</p>
<p>the negative possibilities.</p>
<p>Whatever that&rsquo;s deep in our psychology,</p>
<p>what do you think about that?</p>
<p>And how do we deal with it?</p>
<p>Because we want AI to help us.</p>
<p>So I think there&rsquo;s kind of two problems</p>
<p>entailed in that question.</p>
<p>The first is more of the question of</p>
<p>how can you even picture what a world</p>
<p>with a new technology will be like?</p>
<p>Now imagine we&rsquo;re in 1950,</p>
<p>and I&rsquo;m trying to describe Uber to someone.</p>
<p>Apps and the internet.</p>
<p>Yeah, I mean, that&rsquo;s going to be extremely complicated.</p>
<p>But it&rsquo;s imaginable.</p>
<p>It&rsquo;s imaginable, right?</p>
<p>And now imagine being in 1950 and predicting Uber, right?</p>
<p>And you need to describe the internet,</p>
<p>you need to describe GPS,</p>
<p>you need to describe the fact that</p>
<p>everyone&rsquo;s going to have this phone in their pocket.</p>
<p>And so I think that just the first truth</p>
<p>is that it is hard to picture</p>
<p>how a transformative technology will play out in the world.</p>
<p>We&rsquo;ve seen that before with technologies</p>
<p>that are far less transformative than AGI will be.</p>
<p>And so I think that one piece is that</p>
<p>it&rsquo;s just even hard to imagine</p>
<p>and to really put yourself in a world</p>
<p>where you can predict what that positive vision</p>
<p>would be like.</p>
<p>And I think the second thing is that</p>
<p>I think it is always easier to support the negative side</p>
<p>than the positive side.</p>
<p>It&rsquo;s always easier to destroy than create.</p>
<p>And less in a physical sense</p>
<p>and more just in an intellectual sense, right?</p>
<p>Because I think that with creating something,</p>
<p>you need to just get a bunch of things right.</p>
<p>And to destroy, you just need to get one thing wrong.</p>
<p>And so I think that what that means</p>
<p>is that I think a lot of people&rsquo;s thinking dead ends</p>
<p>as soon as they see the negative story.</p>
<p>But that being said, I actually have some hope, right?</p>
<p>I think that the positive vision</p>
<p>is something that I think can be,</p>
<p>is something that we can talk about.</p>
<p>And I think that just simply saying this fact of,</p>
<p>yeah, there&rsquo;s positive, there&rsquo;s negatives,</p>
<p>everyone likes to dwell on the negative.</p>
<p>People actually respond well to that message and say,</p>
<p>huh, you&rsquo;re right, there&rsquo;s a part of this</p>
<p>that we&rsquo;re not talking about, not thinking about.</p>
<p>And that&rsquo;s actually something that&rsquo;s I think really</p>
<p>been a key part of how we think about AGI at OpenAI.</p>
<p>You can kind of look at it as like, okay,</p>
<p>OpenAI talks about the fact that there are risks</p>
<p>and yet they&rsquo;re trying to build this system.</p>
<p>How do you square those two facts?</p>
<p>So do you share the intuition that some people have,</p>
<p>I mean from Sam Harris to even Elon Musk himself,</p>
<p>that it&rsquo;s tricky as you develop AGI</p>
<p>to keep it from slipping into the existential threats,</p>
<p>into the negative?</p>
<p>What&rsquo;s your intuition about how hard is it</p>
<p>to keep AI development on the positive track?</p>
<p>What&rsquo;s your intuition there?</p>
<p>To answer that question, you can really look</p>
<p>at how we structure OpenAI.</p>
<p>So we really have three main arms.</p>
<p>We have capabilities, which is actually doing</p>
<p>the technical work and pushing forward</p>
<p>what these systems can do.</p>
<p>There&rsquo;s safety, which is working on technical mechanisms</p>
<p>to ensure that the systems we build</p>
<p>are aligned with human values.</p>
<p>And then there&rsquo;s policy, which is making sure</p>
<p>that we have governance mechanisms,</p>
<p>answering that question of, well, whose values?</p>
<p>And so I think that the technical safety one</p>
<p>is the one that people kind of talk about the most, right?</p>
<p>You talk about, like think about all of the dystopic AI</p>
<p>movies, a lot of that is about not having</p>
<p>good technical safety in place.</p>
<p>And what we&rsquo;ve been finding is that,</p>
<p>you know, I think that actually a lot of people</p>
<p>look at the technical safety problem</p>
<p>and think it&rsquo;s just intractable, right?</p>
<p>This question of what do humans want?</p>
<p>How am I supposed to write that down?</p>
<p>Can I even write down what I want?</p>
<p>No way.</p>
<p>And then they stop there.</p>
<p>But the thing is, we&rsquo;ve already built systems</p>
<p>that are able to learn things that humans can&rsquo;t specify.</p>
<p>You know, even the rules for how to recognize</p>
<p>if there&rsquo;s a cat or a dog in an image.</p>
<p>Turns out it&rsquo;s intractable to write that down,</p>
<p>and yet we&rsquo;re able to learn it.</p>
<p>And that what we&rsquo;re seeing with systems we build at OpenAI,</p>
<p>and they&rsquo;re still in early proof of concept stage,</p>
<p>is that you are able to learn human preferences.</p>
<p>You&rsquo;re able to learn what humans want from data.</p>
<p>And so that&rsquo;s kind of the core focus</p>
<p>for our technical safety team,</p>
<p>and I think that there actually,</p>
<p>we&rsquo;ve had some pretty encouraging updates</p>
<p>in terms of what we&rsquo;ve been able to make work.</p>
<p>So you have an intuition and a hope that from data,</p>
<p>you know, looking at the value alignment problem,</p>
<p>from data we can build systems that align</p>
<p>with the collective better angels of our nature.</p>
<p>So align with the ethics and the morals of human beings.</p>
<p>To even say this in a different way,</p>
<p>I mean, think about how do we align humans, right?</p>
<p>Think about like a human baby can grow up</p>
<p>to be an evil person or a great person.</p>
<p>And a lot of that is from learning from data, right?</p>
<p>That you have some feedback as a child is growing up,</p>
<p>they get to see positive examples.</p>
<p>And so I think that just like,</p>
<p>that the only example we have of a general intelligence</p>
<p>that is able to learn from data</p>
<p>to align with human values and to learn values,</p>
<p>I think we shouldn&rsquo;t be surprised</p>
<p>that we can do the same sorts of techniques</p>
<p>or whether the same sort of techniques</p>
<p>end up being how we solve value alignment for AGI&rsquo;s.</p>
<p>So let&rsquo;s go even higher.</p>
<p>I don&rsquo;t know if you&rsquo;ve read the book, Sapiens,</p>
<p>but there&rsquo;s an idea that, you know,</p>
<p>that as a collective, as us human beings,</p>
<p>we kind of develop together ideas that we hold.</p>
<p>There&rsquo;s no, in that context, objective truth.</p>
<p>We just kind of all agree to certain ideas</p>
<p>and hold them as a collective.</p>
<p>Did you have a sense that there is,</p>
<p>in the world of good and evil,</p>
<p>do you have a sense that to the first approximation,</p>
<p>there are some things that are good</p>
<p>and that you could teach systems to behave to be good?</p>
<p>So I think that this actually blends into our third team,</p>
<p>right, which is the policy team.</p>
<p>And this is the one, the aspect I think people</p>
<p>really talk about way less than they should, right?</p>
<p>Because imagine that we build super powerful systems</p>
<p>that we&rsquo;ve managed to figure out all the mechanisms</p>
<p>for these things to do whatever the operator wants.</p>
<p>The most important question becomes,</p>
<p>who&rsquo;s the operator, what do they want,</p>
<p>and how is that going to affect everyone else, right?</p>
<p>And I think that this question of what is good,</p>
<p>what are those values, I mean,</p>
<p>I think you don&rsquo;t even have to go to those,</p>
<p>those very grand existential places</p>
<p>to start to realize how hard this problem is.</p>
<p>You just look at different countries</p>
<p>and cultures across the world,</p>
<p>and that there&rsquo;s a very different conception</p>
<p>of how the world works and what kinds of ways</p>
<p>that society wants to operate.</p>
<p>And so I think that the really core question</p>
<p>is actually very concrete,</p>
<p>and I think it&rsquo;s not a question</p>
<p>that we have ready answers to, right?</p>
<p>It&rsquo;s how do you have a world</p>
<p>where all of the different countries that we have,</p>
<p>United States, China, Russia,</p>
<p>and the hundreds of other countries out there</p>
<p>are able to continue to not just operate</p>
<p>in the way that they see fit,</p>
<p>but in the world that emerges</p>
<p>where you have these very powerful systems</p>
<p>operating alongside humans,</p>
<p>ends up being something that empowers humans more,</p>
<p>that makes human existence be a more meaningful thing,</p>
<p>and that people are happier and wealthier,</p>
<p>and able to live more fulfilling lives.</p>
<p>It&rsquo;s not an obvious thing for how to design that world</p>
<p>once you have that very powerful system.</p>
<p>So if we take a little step back,</p>
<p>and we&rsquo;re having a fascinating conversation,</p>
<p>and OpenAI is in many ways a tech leader in the world,</p>
<p>and yet we&rsquo;re thinking about</p>
<p>these big existential questions,</p>
<p>which is fascinating, really important.</p>
<p>I think you&rsquo;re a leader in that space,</p>
<p>and that&rsquo;s a really important space</p>
<p>of just thinking how AI affects society</p>
<p>in a big picture view.</p>
<p>So Oscar Wilde said, we&rsquo;re all in the gutter,</p>
<p>but some of us are looking at the stars,</p>
<p>and I think OpenAI has a charter</p>
<p>that looks to the stars, I would say,</p>
<p>to create intelligence, to create general intelligence,</p>
<p>make it beneficial, safe, and collaborative.</p>
<p>So can you tell me how that came about,</p>
<p>how a mission like that and the path</p>
<p>to creating a mission like that at OpenAI was founded?</p>
<p>Yeah, so I think that in some ways</p>
<p>it really boils down to taking a look at the landscape.</p>
<p>So if you think about the history of AI,</p>
<p>that basically for the past 60 or 70 years,</p>
<p>people have thought about this goal</p>
<p>of what could happen if you could automate</p>
<p>human intellectual labor.</p>
<p>Imagine you could build a computer system</p>
<p>that could do that, what becomes possible?</p>
<p>We have a lot of sci fi that tells stories</p>
<p>of various dystopias, and increasingly you have movies</p>
<p>like Her that tell you a little bit about,</p>
<p>maybe more of a little bit utopic vision.</p>
<p>You think about the impacts that we&rsquo;ve seen</p>
<p>from being able to have bicycles for our minds</p>
<p>and computers, and I think that the impact</p>
<p>of computers and the internet has just far outstripped</p>
<p>what anyone really could have predicted.</p>
<p>And so I think that it&rsquo;s very clear</p>
<p>that if you can build an AGI,</p>
<p>it will be the most transformative technology</p>
<p>that humans will ever create.</p>
<p>And so what it boils down to then is a question of,</p>
<p>well, is there a path, is there hope,</p>
<p>is there a way to build such a system?</p>
<p>And I think that for 60 or 70 years,</p>
<p>that people got excited and that ended up</p>
<p>not being able to deliver on the hopes</p>
<p>that people had pinned on them.</p>
<p>And I think that then, that after two winters</p>
<p>of AI development, that people I think kind of</p>
<p>almost stopped daring to dream, right?</p>
<p>That really talking about AGI or thinking about AGI</p>
<p>became almost this taboo in the community.</p>
<p>But I actually think that people took the wrong lesson</p>
<p>from AI history.</p>
<p>And if you look back, starting in 1959</p>
<p>is when the Perceptron was released.</p>
<p>And this is basically one of the earliest neural networks.</p>
<p>It was released to what was perceived</p>
<p>as this massive overhype.</p>
<p>So in the New York Times in 1959,</p>
<p>you have this article saying that the Perceptron</p>
<p>will one day recognize people, call out their names,</p>
<p>instantly translate speech between languages.</p>
<p>And people at the time looked at this and said,</p>
<p>this is, your system can&rsquo;t do any of that.</p>
<p>And basically spent 10 years trying to discredit</p>
<p>the whole Perceptron direction and succeeded.</p>
<p>And all the funding dried up.</p>
<p>And people kind of went in other directions.</p>
<p>And in the 80s, there was this resurgence.</p>
<p>And I&rsquo;d always heard that the resurgence in the 80s</p>
<p>was due to the invention of backpropagation</p>
<p>and these algorithms that got people excited.</p>
<p>But actually the causality was due to people</p>
<p>building larger computers.</p>
<p>That you can find these articles from the 80s</p>
<p>saying that the democratization of computing power</p>
<p>suddenly meant that you could run</p>
<p>these larger neural networks.</p>
<p>And then people started to do all these amazing things.</p>
<p>Backpropagation algorithm was invented.</p>
<p>And the neural nets people were running</p>
<p>were these tiny little 20 neuron neural nets.</p>
<p>What are you supposed to learn with 20 neurons?</p>
<p>And so of course, they weren&rsquo;t able to get great results.</p>
<p>And it really wasn&rsquo;t until 2012 that this approach,</p>
<p>that&rsquo;s almost the most simple, natural approach</p>
<p>that people had come up with in the 50s,</p>
<p>in some ways even in the 40s before there were computers,</p>
<p>with the Pitts‚ÄìMcCullough neuron,</p>
<p>suddenly this became the best way of solving problems.</p>
<p>And I think there are three core properties</p>
<p>that deep learning has that I think</p>
<p>are very worth paying attention to.</p>
<p>The first is generality.</p>
<p>We have a very small number of deep learning tools.</p>
<p>SGD, deep neural net, maybe some RL.</p>
<p>And it solves this huge variety of problems.</p>
<p>Speech recognition, machine translation,</p>
<p>game playing, all of these problems, small set of tools.</p>
<p>So there&rsquo;s the generality.</p>
<p>There&rsquo;s a second piece, which is the competence.</p>
<p>You want to solve any of those problems?</p>
<p>Throw up 40 years worth of normal computer vision research,</p>
<p>replace it with a deep neural net,</p>
<p>it&rsquo;s going to work better.</p>
<p>And there&rsquo;s a third piece, which is the scalability.</p>
<p>One thing that has been shown time and time again</p>
<p>is that if you have a larger neural network,</p>
<p>throw more compute, more data at it, it will work better.</p>
<p>Those three properties together feel like essential parts</p>
<p>of building a general intelligence.</p>
<p>Now it doesn&rsquo;t just mean that if we scale up what we have,</p>
<p>that we will have an AGI, right?</p>
<p>There are clearly missing pieces.</p>
<p>There are missing ideas.</p>
<p>We need to have answers for reasoning.</p>
<p>But I think that the core here is that for the first time,</p>
<p>it feels that we have a paradigm that gives us hope</p>
<p>that general intelligence can be achievable.</p>
<p>And so as soon as you believe that,</p>
<p>everything else comes into focus, right?</p>
<p>If you imagine that you may be able to,</p>
<p>and you know that the timeline I think remains uncertain,</p>
<p>but I think that certainly within our lifetimes</p>
<p>and possibly within a much shorter period of time</p>
<p>than people would expect,</p>
<p>if you can really build the most transformative technology</p>
<p>that will ever exist,</p>
<p>you stop thinking about yourself so much, right?</p>
<p>You start thinking about just like,</p>
<p>how do you have a world where this goes well?</p>
<p>And that you need to think about the practicalities</p>
<p>of how do you build an organization</p>
<p>and get together a bunch of people and resources</p>
<p>and to make sure that people feel motivated</p>
<p>and ready to do it.</p>
<p>But I think that then you start thinking about,</p>
<p>well, what if we succeed?</p>
<p>And how do we make sure that when we succeed,</p>
<p>that the world is actually the place</p>
<p>that we want ourselves to exist in?</p>
<p>And almost in the Rawlsian Veil sense of the word.</p>
<p>And so that&rsquo;s kind of the broader landscape.</p>
<p>And OpenAI was really formed in 2015</p>
<p>with that high level picture of AGI might be possible</p>
<p>sooner than people think,</p>
<p>and that we need to try to do our best</p>
<p>to make sure it&rsquo;s going to go well.</p>
<p>And then we spent the next couple of years</p>
<p>really trying to figure out what does that mean?</p>
<p>How do we do it?</p>
<p>And I think that typically with a company,</p>
<p>you start out very small, see you in a co founder,</p>
<p>and you build a product, you get some users,</p>
<p>you get a product market fit.</p>
<p>Then at some point you raise some money,</p>
<p>you hire people, you scale, and then down the road,</p>
<p>then the big companies realize you exist</p>
<p>and try to kill you.</p>
<p>And for OpenAI, it was basically everything</p>
<p>in exactly the opposite order.</p>
<p>Let me just pause for a second, you said a lot of things.</p>
<p>And let me just admire the jarring aspect</p>
<p>of what OpenAI stands for, which is daring to dream.</p>
<p>I mean, you said it&rsquo;s pretty powerful.</p>
<p>It caught me off guard because I think that&rsquo;s very true.</p>
<p>The step of just daring to dream about the possibilities</p>
<p>of creating intelligence in a positive, in a safe way,</p>
<p>but just even creating intelligence is a very powerful</p>
<p>is a much needed refreshing catalyst for the AI community.</p>
<p>So that&rsquo;s the starting point.</p>
<p>Okay, so then formation of OpenAI, what&rsquo;s that?</p>
<p>I would just say that when we were starting OpenAI,</p>
<p>that kind of the first question that we had is,</p>
<p>is it too late to start a lab</p>
<p>with a bunch of the best people?</p>
<p>Right, is that even possible? Wow, okay.</p>
<p>That was an actual question?</p>
<p>That was the core question of,</p>
<p>we had this dinner in July of 2015,</p>
<p>and that was really what we spent the whole time</p>
<p>talking about.</p>
<p>And, you know, because you think about kind of where AI was</p>
<p>is that it had transitioned from being an academic pursuit</p>
<p>to an industrial pursuit.</p>
<p>And so a lot of the best people were in these big</p>
<p>research labs and that we wanted to start our own one</p>
<p>that no matter how much resources we could accumulate</p>
<p>would be pale in comparison to the big tech companies.</p>
<p>And we knew that.</p>
<p>And it was a question of, are we going to be actually</p>
<p>able to get this thing off the ground?</p>
<p>You need critical mass.</p>
<p>You can&rsquo;t just do you and a cofounder build a product.</p>
<p>You really need to have a group of five to 10 people.</p>
<p>And we kind of concluded it wasn&rsquo;t obviously impossible.</p>
<p>So it seemed worth trying.</p>
<p>Well, you&rsquo;re also a dreamer, so who knows, right?</p>
<p>That&rsquo;s right.</p>
<p>Okay, so speaking of that, competing with the big players,</p>
<p>let&rsquo;s talk about some of the tricky things</p>
<p>as you think through this process of growing,</p>
<p>of seeing how you can develop these systems</p>
<p>at a scale that competes.</p>
<p>So you recently formed OpenAI LP,</p>
<p>a new cap profit company that now carries the name OpenAI.</p>
<p>So OpenAI is now this official company.</p>
<p>The original nonprofit company still exists</p>
<p>and carries the OpenAI nonprofit name.</p>
<p>So can you explain what this company is,</p>
<p>what the purpose of this creation is,</p>
<p>and how did you arrive at the decision to create it?</p>
<p>OpenAI, the whole entity and OpenAI LP as a vehicle</p>
<p>is trying to accomplish the mission</p>
<p>of ensuring that artificial general intelligence</p>
<p>benefits everyone.</p>
<p>And the main way that we&rsquo;re trying to do that</p>
<p>is by actually trying to build general intelligence</p>
<p>ourselves and make sure the benefits</p>
<p>are distributed to the world.</p>
<p>That&rsquo;s the primary way.</p>
<p>We&rsquo;re also fine if someone else does this, right?</p>
<p>Doesn&rsquo;t have to be us.</p>
<p>If someone else is going to build an AGI</p>
<p>and make sure that the benefits don&rsquo;t get locked up</p>
<p>in one company or with one set of people,</p>
<p>like we&rsquo;re actually fine with that.</p>
<p>And so those ideas are baked into our charter,</p>
<p>which is kind of the foundational document</p>
<p>that describes kind of our values and how we operate.</p>
<p>But it&rsquo;s also really baked into the structure of OpenAI LP.</p>
<p>And so the way that we&rsquo;ve set up OpenAI LP</p>
<p>is that in the case where we succeed, right?</p>
<p>If we actually build what we&rsquo;re trying to build,</p>
<p>then investors are able to get a return,</p>
<p>but that return is something that is capped.</p>
<p>And so if you think of AGI in terms of the value</p>
<p>that you could really create,</p>
<p>you&rsquo;re talking about the most transformative technology</p>
<p>ever created, it&rsquo;s going to create orders of magnitude</p>
<p>more value than any existing company.</p>
<p>And that all of that value will be owned by the world,</p>
<p>like legally titled to the nonprofit</p>
<p>to fulfill that mission.</p>
<p>And so that&rsquo;s the structure.</p>
<p>So the mission is a powerful one,</p>
<p>and it&rsquo;s one that I think most people would agree with.</p>
<p>It&rsquo;s how we would hope AI progresses.</p>
<p>And so how do you tie yourself to that mission?</p>
<p>How do you make sure you do not deviate from that mission,</p>
<p>that other incentives that are profit driven</p>
<p>don&rsquo;t interfere with the mission?</p>
<p>So this was actually a really core question for us</p>
<p>for the past couple of years,</p>
<p>because I&rsquo;d say that like the way that our history went</p>
<p>was that for the first year,</p>
<p>we were getting off the ground, right?</p>
<p>We had this high level picture,</p>
<p>but we didn&rsquo;t know exactly how we wanted to accomplish it.</p>
<p>And really two years ago is when we first started realizing</p>
<p>in order to build AGI,</p>
<p>we&rsquo;re just going to need to raise way more money</p>
<p>than we can as a nonprofit.</p>
<p>And we&rsquo;re talking many billions of dollars.</p>
<p>And so the first question is how are you supposed to do that</p>
<p>and stay true to this mission?</p>
<p>And we looked at every legal structure out there</p>
<p>and concluded none of them were quite right</p>
<p>for what we wanted to do.</p>
<p>And I guess it shouldn&rsquo;t be too surprising</p>
<p>if you&rsquo;re gonna do some like crazy unprecedented technology</p>
<p>that you&rsquo;re gonna have to come with</p>
<p>some crazy unprecedented structure to do it in.</p>
<p>And a lot of our conversation was with people at OpenAI,</p>
<p>the people who really joined</p>
<p>because they believe so much in this mission</p>
<p>and thinking about how do we actually</p>
<p>raise the resources to do it</p>
<p>and also stay true to what we stand for.</p>
<p>And the place you gotta start is to really align</p>
<p>on what is it that we stand for, right?</p>
<p>What are those values?</p>
<p>What&rsquo;s really important to us?</p>
<p>And so I&rsquo;d say that we spent about a year</p>
<p>really compiling the OpenAI charter</p>
<p>and that determines,</p>
<p>and if you even look at the first line item in there,</p>
<p>it says that, look, we expect we&rsquo;re gonna have to marshal</p>
<p>huge amounts of resources,</p>
<p>but we&rsquo;re going to make sure that we minimize</p>
<p>conflict of interest with the mission.</p>
<p>And that kind of aligning on all of those pieces</p>
<p>was the most important step towards figuring out</p>
<p>how do we structure a company</p>
<p>that can actually raise the resources</p>
<p>to do what we need to do.</p>
<p>I imagine OpenAI, the decision to create OpenAI LP</p>
<p>was a really difficult one.</p>
<p>And there was a lot of discussions,</p>
<p>as you mentioned, for a year,</p>
<p>and there was different ideas,</p>
<p>perhaps detractors within OpenAI,</p>
<p>sort of different paths that you could have taken.</p>
<p>What were those concerns?</p>
<p>What were the different paths considered?</p>
<p>What was that process of making that decision like?</p>
<p>Yep, so if you look actually at the OpenAI charter,</p>
<p>there&rsquo;s almost two paths embedded within it.</p>
<p>There is, we are primarily trying to build AGI ourselves,</p>
<p>but we&rsquo;re also okay if someone else does it.</p>
<p>And this is a weird thing for a company.</p>
<p>It&rsquo;s really interesting, actually.</p>
<p>There is an element of competition</p>
<p>that you do wanna be the one that does it,</p>
<p>but at the same time, you&rsquo;re okay if somebody else doesn&rsquo;t.</p>
<p>We&rsquo;ll talk about that a little bit, that trade off,</p>
<p>that dance that&rsquo;s really interesting.</p>
<p>And I think this was the core tension</p>
<p>as we were designing OpenAI LP,</p>
<p>and really the OpenAI strategy,</p>
<p>is how do you make sure that both you have a shot</p>
<p>at being a primary actor,</p>
<p>which really requires building an organization,</p>
<p>raising massive resources,</p>
<p>and really having the will to go</p>
<p>and execute on some really, really hard vision, right?</p>
<p>You need to really sign up for a long period</p>
<p>to go and take on a lot of pain and a lot of risk.</p>
<p>And to do that, normally you just import</p>
<p>the startup mindset, right?</p>
<p>And that you think about, okay,</p>
<p>like how do we out execute everyone?</p>
<p>You have this very competitive angle.</p>
<p>But you also have the second angle of saying that,</p>
<p>well, the true mission isn&rsquo;t for OpenAI to build AGI.</p>
<p>The true mission is for AGI to go well for humanity.</p>
<p>And so how do you take all of those first actions</p>
<p>and make sure you don&rsquo;t close the door on outcomes</p>
<p>that would actually be positive and fulfill the mission?</p>
<p>And so I think it&rsquo;s a very delicate balance, right?</p>
<p>And I think that going 100% one direction or the other</p>
<p>is clearly not the correct answer.</p>
<p>And so I think that even in terms of just how we talk</p>
<p>about OpenAI and think about it,</p>
<p>there&rsquo;s just like one thing that&rsquo;s always in the back</p>
<p>of my mind is to make sure that we&rsquo;re not just saying</p>
<p>OpenAI&rsquo;s goal is to build AGI, right?</p>
<p>That it&rsquo;s actually much broader than that, right?</p>
<p>That first of all, it&rsquo;s not just AGI,</p>
<p>it&rsquo;s safe AGI that&rsquo;s very important.</p>
<p>But secondly, our goal isn&rsquo;t to be the ones to build it.</p>
<p>Our goal is to make sure it goes well for the world.</p>
<p>And so I think that figuring out</p>
<p>how do you balance all of those</p>
<p>and to get people to really come to the table</p>
<p>and compile a single document that encompasses all of that</p>
<p>wasn&rsquo;t trivial.</p>
<p>So part of the challenge here is your mission is,</p>
<p>I would say, beautiful, empowering,</p>
<p>and a beacon of hope for people in the research community</p>
<p>and just people thinking about AI.</p>
<p>So your decisions are scrutinized more than,</p>
<p>I think, a regular profit driven company.</p>
<p>Do you feel the burden of this</p>
<p>in the creation of the charter</p>
<p>and just in the way you operate?</p>
<p>Yes.</p>
<p>So why do you lean into the burden</p>
<p>by creating such a charter?</p>
<p>Why not keep it quiet?</p>
<p>I mean, it just boils down to the mission, right?</p>
<p>Like I&rsquo;m here and everyone else is here</p>
<p>because we think this is the most important mission.</p>
<p>Dare to dream.</p>
<p>All right, so do you think you can be good for the world</p>
<p>or create an AGI system that&rsquo;s good</p>
<p>when you&rsquo;re a for profit company?</p>
<p>From my perspective, I don&rsquo;t understand</p>
<p>why profit interferes with positive impact on society.</p>
<p>I don&rsquo;t understand why Google,</p>
<p>that makes most of its money from ads,</p>
<p>can&rsquo;t also do good for the world</p>
<p>or other companies, Facebook, anything.</p>
<p>I don&rsquo;t understand why those have to interfere.</p>
<p>You know, profit isn&rsquo;t the thing, in my view,</p>
<p>that affects the impact of a company.</p>
<p>What affects the impact of the company is the charter,</p>
<p>is the culture, is the people inside,</p>
<p>and profit is the thing that just fuels those people.</p>
<p>So what are your views there?</p>
<p>Yeah, so I think that&rsquo;s a really good question</p>
<p>and there&rsquo;s some real longstanding debates</p>
<p>in human society that are wrapped up in it.</p>
<p>The way that I think about it is just think about</p>
<p>what are the most impactful non profits in the world?</p>
<p>What are the most impactful for profits in the world?</p>
<p>Right, it&rsquo;s much easier to list the for profits.</p>
<p>That&rsquo;s right, and I think that there&rsquo;s some real truth here</p>
<p>that the system that we set up,</p>
<p>the system for kind of how today&rsquo;s world is organized,</p>
<p>is one that really allows for huge impact.</p>
<p>And that kind of part of that is that you need to be,</p>
<p>that for profits are self sustaining</p>
<p>and able to kind of build on their own momentum.</p>
<p>And I think that&rsquo;s a really powerful thing.</p>
<p>It&rsquo;s something that when it turns out</p>
<p>that we haven&rsquo;t set the guardrails correctly,</p>
<p>causes problems, right?</p>
<p>Think about logging companies that go into forest,</p>
<p>the rainforest, that&rsquo;s really bad, we don&rsquo;t want that.</p>
<p>And it&rsquo;s actually really interesting to me</p>
<p>that kind of this question of how do you get</p>
<p>positive benefits out of a for profit company,</p>
<p>it&rsquo;s actually very similar to how do you get</p>
<p>positive benefits out of an AGI, right?</p>
<p>That you have this like very powerful system,</p>
<p>it&rsquo;s more powerful than any human,</p>
<p>and is kind of autonomous in some ways,</p>
<p>it&rsquo;s superhuman in a lot of axes,</p>
<p>and somehow you have to set the guardrails</p>
<p>to get good things to happen.</p>
<p>But when you do, the benefits are massive.</p>
<p>And so I think that when I think about</p>
<p>nonprofit versus for profit,</p>
<p>I think just not enough happens in nonprofits,</p>
<p>they&rsquo;re very pure, but it&rsquo;s just kind of,</p>
<p>it&rsquo;s just hard to do things there.</p>
<p>In for profits in some ways, like too much happens,</p>
<p>but if kind of shaped in the right way,</p>
<p>it can actually be very positive.</p>
<p>And so with OpenAI LP, we&rsquo;re picking a road in between.</p>
<p>Now the thing that I think is really important to recognize</p>
<p>is that the way that we think about OpenAI LP</p>
<p>is that in the world where AGI actually happens, right,</p>
<p>in a world where we are successful,</p>
<p>we build the most transformative technology ever,</p>
<p>the amount of value we&rsquo;re gonna create will be astronomical.</p>
<p>And so then in that case, that the cap that we have</p>
<p>will be a small fraction of the value we create,</p>
<p>and the amount of value that goes back to investors</p>
<p>and employees looks pretty similar to what would happen</p>
<p>in a pretty successful startup.</p>
<p>And that&rsquo;s really the case that we&rsquo;re optimizing for, right?</p>
<p>That we&rsquo;re thinking about in the success case,</p>
<p>making sure that the value we create doesn&rsquo;t get locked up.</p>
<p>And I expect that in other for profit companies</p>
<p>that it&rsquo;s possible to do something like that.</p>
<p>I think it&rsquo;s not obvious how to do it, right?</p>
<p>I think that as a for profit company,</p>
<p>you have a lot of fiduciary duty to your shareholders</p>
<p>and that there are certain decisions</p>
<p>that you just cannot make.</p>
<p>In our structure, we&rsquo;ve set it up</p>
<p>so that we have a fiduciary duty to the charter,</p>
<p>that we always get to make the decision</p>
<p>that is right for the charter rather than,</p>
<p>even if it comes at the expense of our own stakeholders.</p>
<p>And so I think that when I think about</p>
<p>what&rsquo;s really important,</p>
<p>it&rsquo;s not really about nonprofit versus for profit,</p>
<p>it&rsquo;s really a question of if you build AGI</p>
<p>and you kind of, humanity&rsquo;s now in this new age,</p>
<p>who benefits, whose lives are better?</p>
<p>And I think that what&rsquo;s really important</p>
<p>is to have an answer that is everyone.</p>
<p>Yeah, which is one of the core aspects of the charter.</p>
<p>So one concern people have, not just with OpenAI,</p>
<p>but with Google, Facebook, Amazon,</p>
<p>anybody really that&rsquo;s creating impact at scale</p>
<p>is how do we avoid, as your charter says,</p>
<p>avoid enabling the use of AI or AGI</p>
<p>to unduly concentrate power?</p>
<p>Why would not a company like OpenAI</p>
<p>keep all the power of an AGI system to itself?</p>
<p>The charter.</p>
<p>So how does the charter</p>
<p>actualize itself in day to day?</p>
<p>So I think that first, to zoom out,</p>
<p>that the way that we structure the company</p>
<p>is so that the power for sort of dictating the actions</p>
<p>that OpenAI takes ultimately rests with the board,</p>
<p>the board of the nonprofit.</p>
<p>And the board is set up in certain ways</p>
<p>with certain restrictions that you can read about</p>
<p>in the OpenAI LP blog post.</p>
<p>But effectively the board is the governing body</p>
<p>for OpenAI LP.</p>
<p>And the board has a duty to fulfill the mission</p>
<p>of the nonprofit.</p>
<p>And so that&rsquo;s kind of how we tie,</p>
<p>how we thread all these things together.</p>
<p>Now there&rsquo;s a question of, so day to day,</p>
<p>how do people, the individuals,</p>
<p>who in some ways are the most empowered ones, right?</p>
<p>Now the board sort of gets to call the shots</p>
<p>at the high level, but the people</p>
<p>who are actually executing are the employees, right?</p>
<p>People here on a day to day basis</p>
<p>who have the keys to the technical whole kingdom.</p>
<p>And there I think that the answer looks a lot like,</p>
<p>well, how does any company&rsquo;s values get actualized, right?</p>
<p>And I think that a lot of that comes down to</p>
<p>that you need people who are here</p>
<p>because they really believe in that mission</p>
<p>and they believe in the charter</p>
<p>and that they are willing to take actions</p>
<p>that maybe are worse for them,</p>
<p>but are better for the charter.</p>
<p>And that&rsquo;s something that&rsquo;s really baked into the culture.</p>
<p>And honestly, I think it&rsquo;s, you know,</p>
<p>I think that that&rsquo;s one of the things</p>
<p>that we really have to work to preserve as time goes on.</p>
<p>And that&rsquo;s a really important part</p>
<p>of how we think about hiring people</p>
<p>and bringing people into OpenAI.</p>
<p>So there&rsquo;s people here, there&rsquo;s people here</p>
<p>who could speak up and say, like, hold on a second,</p>
<p>this is totally against what we stand for, culture wise.</p>
<p>Yeah, yeah, for sure.</p>
<p>I mean, I think that we actually have,</p>
<p>I think that&rsquo;s like a pretty important part</p>
<p>of how we operate and how we have,</p>
<p>even again with designing the charter</p>
<p>and designing OpenAI LP in the first place,</p>
<p>that there has been a lot of conversation</p>
<p>with employees here and a lot of times</p>
<p>where employees said, wait a second,</p>
<p>this seems like it&rsquo;s going in the wrong direction</p>
<p>and let&rsquo;s talk about it.</p>
<p>And so I think one thing that&rsquo;s I think a really,</p>
<p>and you know, here&rsquo;s actually one thing</p>
<p>that I think is very unique about us as a small company,</p>
<p>is that if you&rsquo;re at a massive tech giant,</p>
<p>that&rsquo;s a little bit hard for someone</p>
<p>who&rsquo;s a line employee to go and talk to the CEO</p>
<p>and say, I think that we&rsquo;re doing this wrong.</p>
<p>And you know, you&rsquo;ll get companies like Google</p>
<p>that have had some collective action from employees</p>
<p>to make ethical change around things like Maven.</p>
<p>And so maybe there are mechanisms</p>
<p>at other companies that work.</p>
<p>But here, super easy for anyone to pull me aside,</p>
<p>to pull Sam aside, to pull Ilya aside,</p>
<p>and people do it all the time.</p>
<p>One of the interesting things in the charter</p>
<p>is this idea that it&rsquo;d be great</p>
<p>if you could try to describe or untangle</p>
<p>switching from competition to collaboration</p>
<p>in late stage AGI development.</p>
<p>It&rsquo;s really interesting,</p>
<p>this dance between competition and collaboration.</p>
<p>How do you think about that?</p>
<p>Yeah, assuming that you can actually do</p>
<p>the technical side of AGI development,</p>
<p>I think there&rsquo;s going to be two key problems</p>
<p>with figuring out how do you actually deploy it,</p>
<p>make it go well.</p>
<p>The first one of these is the run up</p>
<p>to building the first AGI.</p>
<p>You look at how self driving cars are being developed,</p>
<p>and it&rsquo;s a competitive race.</p>
<p>And the thing that always happens in competitive race</p>
<p>is that you have huge amounts of pressure</p>
<p>to get rid of safety.</p>
<p>And so that&rsquo;s one thing we&rsquo;re very concerned about,</p>
<p>is that people, multiple teams figuring out</p>
<p>we can actually get there,</p>
<p>but if we took the slower path</p>
<p>that is more guaranteed to be safe, we will lose.</p>
<p>And so we&rsquo;re going to take the fast path.</p>
<p>And so the more that we can both ourselves</p>
<p>be in a position where we don&rsquo;t generate</p>
<p>that competitive race, where we say,</p>
<p>if the race is being run and that someone else</p>
<p>is further ahead than we are,</p>
<p>we&rsquo;re not going to try to leapfrog.</p>
<p>We&rsquo;re going to actually work with them, right?</p>
<p>We will help them succeed.</p>
<p>As long as what they&rsquo;re trying to do</p>
<p>is to fulfill our mission, then we&rsquo;re good.</p>
<p>We don&rsquo;t have to build AGI ourselves.</p>
<p>And I think that&rsquo;s a really important commitment from us,</p>
<p>but it can&rsquo;t just be unilateral, right?</p>
<p>I think that it&rsquo;s really important that other players</p>
<p>who are serious about building AGI</p>
<p>make similar commitments, right?</p>
<p>I think that, again, to the extent that everyone believes</p>
<p>that AGI should be something to benefit everyone,</p>
<p>then it actually really shouldn&rsquo;t matter</p>
<p>which company builds it.</p>
<p>And we should all be concerned about the case</p>
<p>where we just race so hard to get there</p>
<p>that something goes wrong.</p>
<p>So what role do you think government,</p>
<p>our favorite entity, has in setting policy and rules</p>
<p>about this domain, from research to the development</p>
<p>to early stage to late stage AI and AGI development?</p>
<p>So I think that, first of all,</p>
<p>it&rsquo;s really important that government&rsquo;s in there, right?</p>
<p>In some way, shape, or form.</p>
<p>At the end of the day, we&rsquo;re talking about</p>
<p>building technology that will shape how the world operates,</p>
<p>and that there needs to be government</p>
<p>as part of that answer.</p>
<p>And so that&rsquo;s why we&rsquo;ve done a number</p>
<p>of different congressional testimonies,</p>
<p>we interact with a number of different lawmakers,</p>
<p>and that right now, a lot of our message to them</p>
<p>is that it&rsquo;s not the time for regulation,</p>
<p>it is the time for measurement, right?</p>
<p>That our main policy recommendation is that people,</p>
<p>and the government does this all the time</p>
<p>with bodies like NIST, spend time trying to figure out</p>
<p>just where the technology is, how fast it&rsquo;s moving,</p>
<p>and can really become literate and up to speed</p>
<p>with respect to what to expect.</p>
<p>So I think that today, the answer really</p>
<p>is about measurement, and I think that there will be a time</p>
<p>and place where that will change.</p>
<p>And I think it&rsquo;s a little bit hard to predict</p>
<p>exactly what exactly that trajectory should look like.</p>
<p>So there will be a point at which regulation,</p>
<p>federal in the United States, the government steps in</p>
<p>and helps be the, I don&rsquo;t wanna say the adult in the room,</p>
<p>to make sure that there is strict rules,</p>
<p>maybe conservative rules that nobody can cross.</p>
<p>Well, I think there&rsquo;s kind of maybe two angles to it.</p>
<p>So today, with narrow AI applications</p>
<p>that I think there are already existing bodies</p>
<p>that are responsible and should be responsible</p>
<p>for regulation, you think about, for example,</p>
<p>with self driving cars, that you want the national highway.</p>
<p>Netsa.</p>
<p>Yeah, exactly, to be regulating that.</p>
<p>That makes sense, right, that basically what we&rsquo;re saying</p>
<p>is that we&rsquo;re going to have these technological systems</p>
<p>that are going to be performing applications</p>
<p>that humans already do, great.</p>
<p>We already have ways of thinking about standards</p>
<p>and safety for those.</p>
<p>So I think actually empowering those regulators today</p>
<p>is also pretty important.</p>
<p>And then I think for AGI, that there&rsquo;s going to be a point</p>
<p>where we&rsquo;ll have better answers.</p>
<p>And I think that maybe a similar approach</p>
<p>of first measurement and start thinking about</p>
<p>what the rules should be.</p>
<p>I think it&rsquo;s really important</p>
<p>that we don&rsquo;t prematurely squash progress.</p>
<p>I think it&rsquo;s very easy to kind of smother a budding field.</p>
<p>And I think that&rsquo;s something to really avoid.</p>
<p>But I don&rsquo;t think that the right way of doing it</p>
<p>is to say, let&rsquo;s just try to blaze ahead</p>
<p>and not involve all these other stakeholders.</p>
<p>So you recently released a paper on GPT2 language modeling,</p>
<p>but did not release the full model</p>
<p>because you had concerns about the possible</p>
<p>negative effects of the availability of such model.</p>
<p>It&rsquo;s outside of just that decision,</p>
<p>it&rsquo;s super interesting because of the discussion</p>
<p>at a societal level, the discourse it creates.</p>
<p>So it&rsquo;s fascinating in that aspect.</p>
<p>But if you think that&rsquo;s the specifics here at first,</p>
<p>what are some negative effects that you envisioned?</p>
<p>And of course, what are some of the positive effects?</p>
<p>Yeah, so again, I think to zoom out,</p>
<p>the way that we thought about GPT2</p>
<p>is that with language modeling,</p>
<p>we are clearly on a trajectory right now</p>
<p>where we scale up our models</p>
<p>and we get qualitatively better performance.</p>
<p>GPT2 itself was actually just a scale up</p>
<p>of a model that we&rsquo;ve released in the previous June.</p>
<p>We just ran it at much larger scale</p>
<p>and we got these results where</p>
<p>suddenly starting to write coherent pros,</p>
<p>which was not something we&rsquo;d seen previously.</p>
<p>And what are we doing now?</p>
<p>Well, we&rsquo;re gonna scale up GPT2 by 10x, by 100x, by 1000x,</p>
<p>and we don&rsquo;t know what we&rsquo;re gonna get.</p>
<p>And so it&rsquo;s very clear that the model</p>
<p>that we released last June,</p>
<p>I think it&rsquo;s kind of like, it&rsquo;s a good academic toy.</p>
<p>It&rsquo;s not something that we think is something</p>
<p>that can really have negative applications</p>
<p>or to the extent that it can,</p>
<p>that the positive of people being able to play with it</p>
<p>is far outweighs the possible harms.</p>
<p>You fast forward to not GPT2, but GPT20,</p>
<p>and you think about what that&rsquo;s gonna be like.</p>
<p>And I think that the capabilities are going to be substantive.</p>
<p>And so there needs to be a point in between the two</p>
<p>where you say, this is something</p>
<p>where we are drawing the line</p>
<p>and that we need to start thinking about the safety aspects.</p>
<p>And I think for GPT2, we could have gone either way.</p>
<p>And in fact, when we had conversations internally</p>
<p>that we had a bunch of pros and cons,</p>
<p>and it wasn&rsquo;t clear which one outweighed the other.</p>
<p>And I think that when we announced that,</p>
<p>hey, we decide not to release this model,</p>
<p>then there was a bunch of conversation</p>
<p>where various people said,</p>
<p>it&rsquo;s so obvious that you should have just released it.</p>
<p>There are other people said,</p>
<p>it&rsquo;s so obvious you should not have released it.</p>
<p>And I think that that almost definitionally means</p>
<p>that holding it back was the correct decision.</p>
<p>Right, if it&rsquo;s not obvious</p>
<p>whether something is beneficial or not,</p>
<p>you should probably default to caution.</p>
<p>And so I think that the overall landscape</p>
<p>for how we think about it</p>
<p>is that this decision could have gone either way.</p>
<p>There are great arguments in both directions,</p>
<p>but for future models down the road</p>
<p>and possibly sooner than you&rsquo;d expect,</p>
<p>because scaling these things up</p>
<p>doesn&rsquo;t actually take that long,</p>
<p>those ones you&rsquo;re definitely not going to want</p>
<p>to release into the wild.</p>
<p>And so I think that we almost view this as a test case</p>
<p>and to see, can we even design,</p>
<p>you know, how do you have a society</p>
<p>or how do you have a system</p>
<p>that goes from having no concept</p>
<p>of responsible disclosure,</p>
<p>where the mere idea of not releasing something</p>
<p>for safety reasons is unfamiliar</p>
<p>to a world where you say, okay, we have a powerful model,</p>
<p>let&rsquo;s at least think about it,</p>
<p>let&rsquo;s go through some process.</p>
<p>And you think about the security community,</p>
<p>it took them a long time</p>
<p>to design responsible disclosure, right?</p>
<p>You know, you think about this question of,</p>
<p>well, I have a security exploit,</p>
<p>I send it to the company,</p>
<p>the company is like, tries to prosecute me</p>
<p>or just sit, just ignores it, what do I do, right?</p>
<p>And so, you know, the alternatives of,</p>
<p>oh, I just always publish your exploits,</p>
<p>that doesn&rsquo;t seem good either, right?</p>
<p>And so it really took a long time</p>
<p>and took this, it was bigger than any individual, right?</p>
<p>It&rsquo;s really about building a whole community</p>
<p>that believe that, okay, we&rsquo;ll have this process</p>
<p>where you send it to the company, you know,</p>
<p>if they don&rsquo;t act in a certain time,</p>
<p>then you can go public and you&rsquo;re not a bad person,</p>
<p>you&rsquo;ve done the right thing.</p>
<p>And I think that in AI,</p>
<p>part of the response at GPT2 just proves</p>
<p>that we don&rsquo;t have any concept of this.</p>
<p>So that&rsquo;s the high level picture.</p>
<p>And so I think that,</p>
<p>I think this was a really important move to make</p>
<p>and we could have maybe delayed it for GPT3,</p>
<p>but I&rsquo;m really glad we did it for GPT2.</p>
<p>And so now you look at GPT2 itself</p>
<p>and you think about the substance of, okay,</p>
<p>what are potential negative applications?</p>
<p>So you have this model that&rsquo;s been trained on the internet,</p>
<p>which, you know, it&rsquo;s also going to be</p>
<p>a bunch of very biased data,</p>
<p>a bunch of, you know, very offensive content in there,</p>
<p>and you can ask it to generate content for you</p>
<p>on basically any topic, right?</p>
<p>You just give it a prompt and it&rsquo;ll just start writing</p>
<p>and it writes content like you see on the internet,</p>
<p>you know, even down to like saying advertisement</p>
<p>in the middle of some of its generations.</p>
<p>And you think about the possibilities</p>
<p>for generating fake news or abusive content.</p>
<p>And, you know, it&rsquo;s interesting seeing</p>
<p>what people have done with, you know,</p>
<p>we released a smaller version of GPT2</p>
<p>and the people have done things like try to generate,</p>
<p>you know, take my own Facebook message history</p>
<p>and generate more Facebook messages like me</p>
<p>and people generating fake politician content</p>
<p>or, you know, there&rsquo;s a bunch of things there</p>
<p>where you at least have to think,</p>
<p>is this going to be good for the world?</p>
<p>There&rsquo;s the flip side, which is I think</p>
<p>that there&rsquo;s a lot of awesome applications</p>
<p>that we really want to see,</p>
<p>like creative applications in terms of</p>
<p>if you have sci fi authors that can work with this tool</p>
<p>and come up with cool ideas, like that seems awesome</p>
<p>if we can write better sci fi through the use of these tools</p>
<p>and we&rsquo;ve actually had a bunch of people write into us</p>
<p>asking, hey, can we use it for, you know,</p>
<p>a variety of different creative applications?</p>
<p>So the positive are actually pretty easy to imagine.</p>
<p>They&rsquo;re, you know, the usual NLP applications</p>
<p>are really interesting, but let&rsquo;s go there.</p>
<p>It&rsquo;s kind of interesting to think about a world</p>
<p>where, look at Twitter, where not just fake news,</p>
<p>but smarter and smarter bots being able to spread</p>
<p>in an interesting, complex, networking way information</p>
<p>that just floods out us regular human beings</p>
<p>with our original thoughts.</p>
<p>So what are your views of this world with GPT20, right?</p>
<p>How do we think about it?</p>
<p>Again, it&rsquo;s like one of those things about in the 50s</p>
<p>trying to describe the internet or the smartphone.</p>
<p>What do you think about that world,</p>
<p>the nature of information?</p>
<p>One possibility is that we&rsquo;ll always try to design systems</p>
<p>that identify robot versus human</p>
<p>and we&rsquo;ll do so successfully and so we&rsquo;ll authenticate</p>
<p>that we&rsquo;re still human and the other world is that</p>
<p>we just accept the fact that we&rsquo;re swimming in a sea</p>
<p>of fake news and just learn to swim there.</p>
<p>Well, have you ever seen the popular meme of robot</p>
<p>with a physical arm and pen clicking the</p>
<p>I&rsquo;m not a robot button?</p>
<p>Yeah.</p>
<p>I think the truth is that really trying to distinguish</p>
<p>between robot and human is a losing battle.</p>
<p>Ultimately, you think it&rsquo;s a losing battle?</p>
<p>I think it&rsquo;s a losing battle ultimately, right?</p>
<p>I think that that is, in terms of the content,</p>
<p>in terms of the actions that you can take.</p>
<p>I mean, think about how captures have gone, right?</p>
<p>The captures used to be a very nice, simple,</p>
<p>you just have this image, all of our OCR is terrible,</p>
<p>you put a couple of artifacts in it,</p>
<p>humans are gonna be able to tell what it is.</p>
<p>An AI system wouldn&rsquo;t be able to.</p>
<p>Today, I could barely do captures.</p>
<p>And I think that this is just kind of where we&rsquo;re going.</p>
<p>I think captures were a moment in time thing</p>
<p>and as AI systems become more powerful,</p>
<p>that there being human capabilities that can be measured</p>
<p>in a very easy, automated way that AIs</p>
<p>will not be capable of.</p>
<p>I think that&rsquo;s just like,</p>
<p>it&rsquo;s just an increasingly hard technical battle.</p>
<p>But it&rsquo;s not that all hope is lost, right?</p>
<p>You think about how do we already authenticate ourselves,</p>
<p>right, that we have systems, we have social security numbers</p>
<p>if you&rsquo;re in the US or you have ways of identifying</p>
<p>individual people and having real world identity</p>
<p>tied to digital identity seems like a step</p>
<p>towards authenticating the source of content</p>
<p>rather than the content itself.</p>
<p>Now, there are problems with that.</p>
<p>How can you have privacy and anonymity</p>
<p>in a world where the only content you can really trust is,</p>
<p>or the only way you can trust content</p>
<p>is by looking at where it comes from?</p>
<p>And so I think that building out good reputation networks</p>
<p>may be one possible solution.</p>
<p>But yeah, I think that this question is not an obvious one.</p>
<p>And I think that we, maybe sooner than we think,</p>
<p>will be in a world where today I often will read a tweet</p>
<p>and be like, hmm, do I feel like a real human wrote this?</p>
<p>Or do I feel like this is genuine?</p>
<p>I feel like I can kind of judge the content a little bit.</p>
<p>And I think in the future, it just won&rsquo;t be the case.</p>
<p>You look at, for example, the FCC comments on net neutrality.</p>
<p>It came out later that millions of those were auto generated</p>
<p>and that the researchers were able to do</p>
<p>various statistical techniques to do that.</p>
<p>What do you do in a world</p>
<p>where those statistical techniques don&rsquo;t exist?</p>
<p>It&rsquo;s just impossible to tell the difference</p>
<p>between humans and AIs.</p>
<p>And in fact, the most persuasive arguments</p>
<p>are written by AI.</p>
<p>All that stuff, it&rsquo;s not sci fi anymore.</p>
<p>You look at GPT2 making a great argument</p>
<p>for why recycling is bad for the world.</p>
<p>You gotta read that and be like, huh, you&rsquo;re right.</p>
<p>We are addressing just the symptoms.</p>
<p>Yeah, that&rsquo;s quite interesting.</p>
<p>I mean, ultimately it boils down to the physical world</p>
<p>being the last frontier of proving,</p>
<p>so you said like basically networks of people,</p>
<p>humans vouching for humans in the physical world.</p>
<p>And somehow the authentication ends there.</p>
<p>I mean, if I had to ask you,</p>
<p>I mean, you&rsquo;re way too eloquent for a human.</p>
<p>So if I had to ask you to authenticate,</p>
<p>like prove how do I know you&rsquo;re not a robot</p>
<p>and how do you know I&rsquo;m not a robot?</p>
<p>Yeah.</p>
<p>I think that&rsquo;s so far where in this space,</p>
<p>this conversation we just had,</p>
<p>the physical movements we did,</p>
<p>is the biggest gap between us and AI systems</p>
<p>is the physical manipulation.</p>
<p>So maybe that&rsquo;s the last frontier.</p>
<p>Well, here&rsquo;s another question is why is,</p>
<p>why is solving this problem important, right?</p>
<p>Like what aspects are really important to us?</p>
<p>And I think that probably where we&rsquo;ll end up</p>
<p>is we&rsquo;ll hone in on what do we really want</p>
<p>out of knowing if we&rsquo;re talking to a human.</p>
<p>And I think that, again, this comes down to identity.</p>
<p>And so I think that the internet of the future,</p>
<p>I expect to be one that will have lots of agents out there</p>
<p>that will interact with you.</p>
<p>But I think that the question of is this</p>
<p>flesh, real flesh and blood human</p>
<p>or is this an automated system,</p>
<p>may actually just be less important.</p>
<p>Let&rsquo;s actually go there.</p>
<p>It&rsquo;s GPT2 is impressive and let&rsquo;s look at GPT20.</p>
<p>Why is it so bad that all my friends are GPT20?</p>
<p>Why is it so important on the internet,</p>
<p>do you think, to interact with only human beings?</p>
<p>Why can&rsquo;t we live in a world where ideas can come</p>
<p>from models trained on human data?</p>
<p>Yeah, I think this is actually</p>
<p>a really interesting question.</p>
<p>This comes back to the how do you even picture a world</p>
<p>with some new technology?</p>
<p>And I think that one thing that I think is important</p>
<p>is, you know, let&rsquo;s say honesty.</p>
<p>And I think that if you have almost in the Turing test</p>
<p>style sense of technology, you have AIs that are pretending</p>
<p>to be humans and deceiving you.</p>
<p>I think that feels like a bad thing, right?</p>
<p>I think that it&rsquo;s really important that we feel like</p>
<p>we&rsquo;re in control of our environment, right?</p>
<p>That we understand who we&rsquo;re interacting with.</p>
<p>And if it&rsquo;s an AI or a human, that&rsquo;s not something</p>
<p>that we&rsquo;re being deceived about.</p>
<p>But I think that the flip side of can I have as meaningful</p>
<p>of an interaction with an AI as I can with a human?</p>
<p>Well, I actually think here you can turn to sci fi.</p>
<p>And her I think is a great example of asking</p>
<p>this very question, right?</p>
<p>One thing I really love about her is it really starts out</p>
<p>almost by asking how meaningful</p>
<p>are human virtual relationships, right?</p>
<p>And then you have a human who has a relationship with an AI</p>
<p>and that you really start to be drawn into that, right?</p>
<p>That all of your emotional buttons get triggered</p>
<p>in the same way as if there was a real human</p>
<p>that was on the other side of that phone.</p>
<p>And so I think that this is one way of thinking about it</p>
<p>is that I think that we can have meaningful interactions</p>
<p>and that if there&rsquo;s a funny joke,</p>
<p>some sense it doesn&rsquo;t really matter</p>
<p>if it was written by a human or an AI.</p>
<p>But what you don&rsquo;t want and why I think</p>
<p>we should really draw hard lines is deception.</p>
<p>And I think that as long as we&rsquo;re in a world</p>
<p>where why do we build AI systems at all, right?</p>
<p>The reason we want to build them is to enhance human lives,</p>
<p>to make humans be able to do more things,</p>
<p>to have humans feel more fulfilled.</p>
<p>And if we can build AI systems that do that, sign me up.</p>
<p>So the process of language modeling,</p>
<p>how far do you think it&rsquo;d take us?</p>
<p>Let&rsquo;s look at movie Her.</p>
<p>Do you think a dialogue, natural language conversation</p>
<p>is formulated by the Turing test, for example,</p>
<p>do you think that process could be achieved</p>
<p>through this kind of unsupervised language modeling?</p>
<p>So I think the Turing test in its real form</p>
<p>isn&rsquo;t just about language, right?</p>
<p>It&rsquo;s really about reasoning too, right?</p>
<p>To really pass the Turing test,</p>
<p>I should be able to teach calculus</p>
<p>to whoever&rsquo;s on the other side</p>
<p>and have it really understand calculus</p>
<p>and be able to go and solve new calculus problems.</p>
<p>And so I think that to really solve the Turing test,</p>
<p>we need more than what we&rsquo;re seeing with language models.</p>
<p>We need some way of plugging in reasoning.</p>
<p>Now, how different will that be from what we already do?</p>
<p>That&rsquo;s an open question, right?</p>
<p>Might be that we need some sequence</p>
<p>of totally radical new ideas,</p>
<p>or it might be that we just need to kind of shape</p>
<p>our existing systems in a slightly different way.</p>
<p>But I think that in terms of how far language modeling</p>
<p>will go, it&rsquo;s already gone way further</p>
<p>than many people would have expected, right?</p>
<p>I think that things like,</p>
<p>and I think there&rsquo;s a lot of really interesting angles</p>
<p>to poke in terms of how much does GPT2</p>
<p>understand physical world?</p>
<p>Like, you read a little bit about fire underwater in GPT2.</p>
<p>So it&rsquo;s like, okay, maybe it doesn&rsquo;t quite understand</p>
<p>what these things are, but at the same time,</p>
<p>I think that you also see various things</p>
<p>like smoke coming from flame,</p>
<p>and a bunch of these things that GPT2,</p>
<p>it has no body, it has no physical experience,</p>
<p>it&rsquo;s just statically read data.</p>
<p>And I think that the answer is like, we don&rsquo;t know yet.</p>
<p>These questions, though, we&rsquo;re starting to be able</p>
<p>to actually ask them to physical systems,</p>
<p>to real systems that exist, and that&rsquo;s very exciting.</p>
<p>Do you think, what&rsquo;s your intuition?</p>
<p>Do you think if you just scale language modeling,</p>
<p>like significantly scale,</p>
<p>that reasoning can emerge from the same exact mechanisms?</p>
<p>I think it&rsquo;s unlikely that if we just scale GPT2</p>
<p>that we&rsquo;ll have reasoning in the full fledged way.</p>
<p>And I think that there&rsquo;s like,</p>
<p>the type signature&rsquo;s a little bit wrong, right?</p>
<p>That like, there&rsquo;s something we do with,</p>
<p>that we call thinking, right?</p>
<p>Where we spend a lot of compute,</p>
<p>like a variable amount of compute,</p>
<p>to get to better answers, right?</p>
<p>I think a little bit harder, I get a better answer.</p>
<p>And that that kind of type signature</p>
<p>isn&rsquo;t quite encoded in a GPT, right?</p>
<p>GPT will kind of like, it&rsquo;s been a long time,</p>
<p>and it&rsquo;s like evolutionary history,</p>
<p>baking in all this information,</p>
<p>getting very, very good at this predictive process.</p>
<p>And then at runtime, I just kind of do one forward pass,</p>
<p>and I&rsquo;m able to generate stuff.</p>
<p>And so, you know, there might be small tweaks</p>
<p>to what we do in order to get the type signature, right?</p>
<p>For example, well, you know,</p>
<p>it&rsquo;s not really one forward pass, right?</p>
<p>You know, you generate symbol by symbol,</p>
<p>and so maybe you generate like a whole sequence</p>
<p>of thoughts, and you only keep like the last bit</p>
<p>or something.</p>
<p>But I think that at the very least,</p>
<p>I would expect you have to make changes like that.</p>
<p>Yeah, just exactly how we, you said, think,</p>
<p>is the process of generating thought by thought</p>
<p>in the same kind of way, like you said,</p>
<p>keep the last bit, the thing that we converge towards.</p>
<p>Yep.</p>
<p>And I think there&rsquo;s another piece which is interesting,</p>
<p>which is this out of distribution generalization, right?</p>
<p>That like thinking somehow lets us do that, right?</p>
<p>That we haven&rsquo;t experienced a thing, and yet somehow</p>
<p>we just kind of keep refining our mental model of it.</p>
<p>This is, again, something that feels tied</p>
<p>to whatever reasoning is, and maybe it&rsquo;s a small tweak</p>
<p>to what we do, maybe it&rsquo;s many ideas,</p>
<p>and we&rsquo;ll take as many decades.</p>
<p>Yeah, so the assumption there,</p>
<p>generalization out of distribution,</p>
<p>is that it&rsquo;s possible to create new ideas.</p>
<p>Mm hmm.</p>
<p>You know, it&rsquo;s possible that nobody&rsquo;s ever created</p>
<p>any new ideas, and then with scaling GPT2 to GPT20,</p>
<p>you would essentially generalize to all possible thoughts</p>
<p>that us humans could have.</p>
<p>I mean.</p>
<p>Just to play devil&rsquo;s advocate.</p>
<p>Right, right, right, I mean, how many new story ideas</p>
<p>have we come up with since Shakespeare, right?</p>
<p>Yeah, exactly.</p>
<p>It&rsquo;s just all different forms of love and drama and so on.</p>
<p>Okay.</p>
<p>Not sure if you read Bitter Lesson,</p>
<p>a recent blog post by Rich Sutton.</p>
<p>Yep, I have.</p>
<p>He basically says something that echoes some of the ideas</p>
<p>that you&rsquo;ve been talking about, which is,</p>
<p>he says the biggest lesson that can be read</p>
<p>from 70 years of AI research is that general methods</p>
<p>that leverage computation are ultimately going to,</p>
<p>ultimately win out.</p>
<p>Do you agree with this?</p>
<p>So basically, and OpenAI in general,</p>
<p>but the ideas you&rsquo;re exploring about coming up with methods,</p>
<p>whether it&rsquo;s GPT2 modeling or whether it&rsquo;s OpenAI 5</p>
<p>playing Dota, or a general method is better</p>
<p>than a more fine tuned, expert tuned method.</p>
<p>Yeah, so I think that, well one thing that I think</p>
<p>was really interesting about the reaction</p>
<p>to that blog post was that a lot of people have read this</p>
<p>as saying that compute is all that matters.</p>
<p>And that&rsquo;s a very threatening idea, right?</p>
<p>And I don&rsquo;t think it&rsquo;s a true idea either.</p>
<p>Right, it&rsquo;s very clear that we have algorithmic ideas</p>
<p>that have been very important for making progress</p>
<p>and to really build AGI.</p>
<p>You wanna push as far as you can on the computational scale</p>
<p>and you wanna push as far as you can on human ingenuity.</p>
<p>And so I think you need both.</p>
<p>But I think the way that you phrased the question</p>
<p>is actually very good, right?</p>
<p>That it&rsquo;s really about what kind of ideas</p>
<p>should we be striving for?</p>
<p>And absolutely, if you can find a scalable idea,</p>
<p>you pour more compute into it, you pour more data into it,</p>
<p>it gets better, like that&rsquo;s the real holy grail.</p>
<p>And so I think that the answer to the question,</p>
<p>I think, is yes, that that&rsquo;s really how we think about it</p>
<p>and that part of why we&rsquo;re excited about the power</p>
<p>of deep learning, the potential for building AGI</p>
<p>is because we look at the systems that exist</p>
<p>in the most successful AI systems</p>
<p>and we realize that you scale those up,</p>
<p>they&rsquo;re gonna work better.</p>
<p>And I think that that scalability</p>
<p>is something that really gives us hope</p>
<p>for being able to build transformative systems.</p>
<p>So I&rsquo;ll tell you, this is partially an emotional,</p>
<p>a response that people often have,</p>
<p>if compute is so important for state of the art performance,</p>
<p>individual developers, maybe a 13 year old</p>
<p>sitting somewhere in Kansas or something like that,</p>
<p>they&rsquo;re sitting, they might not even have a GPU</p>
<p>or may have a single GPU, a 1080 or something like that,</p>
<p>and there&rsquo;s this feeling like, well,</p>
<p>how can I possibly compete or contribute</p>
<p>to this world of AI if scale is so important?</p>
<p>So if you can comment on that and in general,</p>
<p>do you think we need to also in the future</p>
<p>focus on democratizing compute resources more</p>
<p>or as much as we democratize the algorithms?</p>
<p>Well, so the way that I think about it</p>
<p>is that there&rsquo;s this space of possible progress, right?</p>
<p>There&rsquo;s a space of ideas and sort of systems</p>
<p>that will work that will move us forward</p>
<p>and there&rsquo;s a portion of that space</p>
<p>and to some extent, an increasingly significant portion</p>
<p>of that space that does just require</p>
<p>massive compute resources.</p>
<p>And for that, I think that the answer is kind of clear</p>
<p>and that part of why we have the structure that we do</p>
<p>is because we think it&rsquo;s really important</p>
<p>to be pushing the scale and to be building</p>
<p>these large clusters and systems.</p>
<p>But there&rsquo;s another portion of the space</p>
<p>that isn&rsquo;t about the large scale compute</p>
<p>that are these ideas that, and again,</p>
<p>I think that for the ideas to really be impactful</p>
<p>and really shine, that they should be ideas</p>
<p>that if you scale them up, would work way better</p>
<p>than they do at small scale.</p>
<p>But that you can discover them</p>
<p>without massive computational resources.</p>
<p>And if you look at the history of recent developments,</p>
<p>you think about things like the GAN or the VAE,</p>
<p>that these are ones that I think you could come up with them</p>
<p>without having, and in practice,</p>
<p>people did come up with them without having</p>
<p>massive, massive computational resources.</p>
<p>Right, I just talked to Ian Goodfellow,</p>
<p>but the thing is the initial GAN</p>
<p>produced pretty terrible results, right?</p>
<p>So only because it was in a very specific,</p>
<p>it was only because they&rsquo;re smart enough</p>
<p>to know that this is quite surprising</p>
<p>it can generate anything that they know.</p>
<p>Do you see a world, or is that too optimistic and dreamer</p>
<p>like to imagine that the compute resources</p>
<p>are something that&rsquo;s owned by governments</p>
<p>and provided as utility?</p>
<p>Actually, to some extent, this question reminds me</p>
<p>of a blog post from one of my former professors at Harvard,</p>
<p>this guy Matt Welsh, who was a systems professor.</p>
<p>I remember sitting in his tenure talk, right,</p>
<p>and that he had literally just gotten tenure.</p>
<p>He went to Google for the summer</p>
<p>and then decided he wasn&rsquo;t going back to academia, right?</p>
<p>And kind of in his blog post, he makes this point that,</p>
<p>look, as a systems researcher,</p>
<p>that I come up with these cool system ideas, right,</p>
<p>and I kind of build a little proof of concept,</p>
<p>and the best thing I can hope for</p>
<p>is that the people at Google or Yahoo,</p>
<p>which was around at the time,</p>
<p>will implement it and actually make it work at scale, right?</p>
<p>That&rsquo;s like the dream for me, right?</p>
<p>I build the little thing,</p>
<p>and they turn it into the big thing that&rsquo;s actually working.</p>
<p>And for him, he said, I&rsquo;m done with that.</p>
<p>I want to be the person who&rsquo;s actually doing building</p>
<p>and deploying.</p>
<p>And I think that there&rsquo;s a similar dichotomy here, right?</p>
<p>I think that there are people who really actually find value,</p>
<p>and I think it is a valuable thing to do</p>
<p>to be the person who produces those ideas, right,</p>
<p>who builds the proof of concept.</p>
<p>And yeah, you don&rsquo;t get to generate</p>
<p>the coolest possible GAN images,</p>
<p>but you invented the GAN, right?</p>
<p>And so there&rsquo;s a real trade off there,</p>
<p>and I think that that&rsquo;s a very personal choice,</p>
<p>but I think there&rsquo;s value in both sides.</p>
<p>So do you think creating AGI or some new models,</p>
<p>we would see echoes of the brilliance</p>
<p>even at the prototype level?</p>
<p>So you would be able to develop those ideas without scale,</p>
<p>the initial seeds.</p>
<p>So take a look at, you know,</p>
<p>I always like to look at examples that exist, right?</p>
<p>Look at real precedent.</p>
<p>And so take a look at the June 2018 model that we released,</p>
<p>that we scaled up to turn into GPT2.</p>
<p>And you can see that at small scale,</p>
<p>it set some records, right?</p>
<p>This was the original GPT.</p>
<p>We actually had some cool generations.</p>
<p>They weren&rsquo;t nearly as amazing and really stunning</p>
<p>as the GPT2 ones, but it was promising.</p>
<p>It was interesting.</p>
<p>And so I think it is the case</p>
<p>that with a lot of these ideas,</p>
<p>that you see promise at small scale.</p>
<p>But there is an asterisk here, a very big asterisk,</p>
<p>which is sometimes we see behaviors that emerge</p>
<p>that are qualitatively different</p>
<p>from anything we saw at small scale.</p>
<p>And that the original inventor of whatever algorithm</p>
<p>looks at and says, I didn&rsquo;t think it could do that.</p>
<p>This is what we saw in Dota, right?</p>
<p>So PPO was created by John Shulman,</p>
<p>who&rsquo;s a researcher here.</p>
<p>And with Dota, we basically just ran PPO</p>
<p>at massive, massive scale.</p>
<p>And there&rsquo;s some tweaks in order to make it work,</p>
<p>but fundamentally, it&rsquo;s PPO at the core.</p>
<p>And we were able to get this long term planning,</p>
<p>these behaviors to really play out on a time scale</p>
<p>that we just thought was not possible.</p>
<p>And John looked at that and was like,</p>
<p>I didn&rsquo;t think it could do that.</p>
<p>That&rsquo;s what happens when you&rsquo;re at three orders</p>
<p>of magnitude more scale than you tested at.</p>
<p>Yeah, but it still has the same flavors of,</p>
<p>you know, at least echoes of the expected billions.</p>
<p>Although I suspect with GPT scaled more and more,</p>
<p>you might get surprising things.</p>
<p>So yeah, you&rsquo;re right, it&rsquo;s interesting.</p>
<p>It&rsquo;s difficult to see how far an idea will go</p>
<p>when it&rsquo;s scaled.</p>
<p>It&rsquo;s an open question.</p>
<p>Well, so to that point with Dota and PPO,</p>
<p>like, I mean, here&rsquo;s a very concrete one, right?</p>
<p>It&rsquo;s like, it&rsquo;s actually one thing</p>
<p>that&rsquo;s very surprising about Dota</p>
<p>that I think people don&rsquo;t really pay that much attention to</p>
<p>is the decree of generalization</p>
<p>out of distribution that happens, right?</p>
<p>That you have this AI that&rsquo;s trained against other bots</p>
<p>for its entirety, the entirety of its existence.</p>
<p>Sorry to take a step back.</p>
<p>Can you talk through, you know, a story of Dota,</p>
<p>a story of leading up to opening I5 and that past,</p>
<p>and what was the process of self play</p>
<p>and so on of training on this?</p>
<p>Yeah, yeah, yeah.</p>
<p>So with Dota.</p>
<p>What is Dota?</p>
<p>Yeah, Dota is a complex video game</p>
<p>and we started trying to solve Dota</p>
<p>because we felt like this was a step towards the real world</p>
<p>relative to other games like chess or Go, right?</p>
<p>Those very cerebral games</p>
<p>where you just kind of have this board,</p>
<p>very discreet moves.</p>
<p>Dota starts to be much more continuous time</p>
<p>that you have this huge variety of different actions</p>
<p>that you have a 45 minute game</p>
<p>with all these different units</p>
<p>and it&rsquo;s got a lot of messiness to it</p>
<p>that really hasn&rsquo;t been captured by previous games.</p>
<p>And famously, all of the hard coded bots for Dota</p>
<p>were terrible, right?</p>
<p>It&rsquo;s just impossible to write anything good for it</p>
<p>because it&rsquo;s so complex.</p>
<p>And so this seemed like a really good place</p>
<p>to push what&rsquo;s the state of the art</p>
<p>in reinforcement learning.</p>
<p>And so we started by focusing</p>
<p>on the one versus one version of the game</p>
<p>and we&rsquo;re able to solve that.</p>
<p>We&rsquo;re able to beat the world champions</p>
<p>and the skill curve was this crazy exponential, right?</p>
<p>And it was like constantly we were just scaling up</p>
<p>that we were fixing bugs</p>
<p>and that you look at the skill curve</p>
<p>and it was really a very, very smooth one.</p>
<p>This is actually really interesting</p>
<p>to see how that human iteration loop</p>
<p>yielded very steady exponential progress.</p>
<p>And to one side note, first of all,</p>
<p>it&rsquo;s an exceptionally popular video game.</p>
<p>The side effect is that there&rsquo;s a lot of incredible</p>
<p>human experts at that video game.</p>
<p>So the benchmark that you&rsquo;re trying to reach is very high.</p>
<p>And the other, can you talk about the approach</p>
<p>that was used initially and throughout</p>
<p>training these agents to play this game?</p>
<p>Yep, and so the approach that we used is self play.</p>
<p>And so you have two agents that don&rsquo;t know anything.</p>
<p>They battle each other,</p>
<p>they discover something a little bit good</p>
<p>and now they both know it.</p>
<p>And they just get better and better and better</p>
<p>without bound.</p>
<p>And that&rsquo;s a really powerful idea, right?</p>
<p>That we then went from the one versus one version</p>
<p>of the game and scaled up to five versus five, right?</p>
<p>So you think about kind of like with basketball</p>
<p>where you have this like team sport</p>
<p>and you need to do all this coordination</p>
<p>and we were able to push the same idea,</p>
<p>the same self play to really get to the professional level</p>
<p>at the full five versus five version of the game.</p>
<p>And the things I think are really interesting here</p>
<p>is that these agents, in some ways,</p>
<p>they&rsquo;re almost like an insect like intelligence, right?</p>
<p>Where they have a lot in common</p>
<p>with how an insect is trained, right?</p>
<p>An insect kind of lives in this environment</p>
<p>for a very long time or the ancestors of this insect</p>
<p>have been around for a long time</p>
<p>and had a lot of experience that gets baked into this agent.</p>
<p>And it&rsquo;s not really smart in the sense of a human, right?</p>
<p>It&rsquo;s not able to go and learn calculus,</p>
<p>but it&rsquo;s able to navigate its environment extremely well.</p>
<p>And it&rsquo;s able to handle unexpected things</p>
<p>in the environment that it&rsquo;s never seen before pretty well.</p>
<p>And we see the same sort of thing with our Dota bots, right?</p>
<p>That they&rsquo;re able to, within this game,</p>
<p>they&rsquo;re able to play against humans,</p>
<p>which is something that never existed</p>
<p>in its evolutionary environment,</p>
<p>totally different play styles from humans versus the bots.</p>
<p>And yet it&rsquo;s able to handle it extremely well.</p>
<p>And that&rsquo;s something that I think was very surprising to us,</p>
<p>was something that doesn&rsquo;t really emerge</p>
<p>from what we&rsquo;ve seen with PPO at smaller scale, right?</p>
<p>And the kind of scale we&rsquo;re running this stuff at was,</p>
<p>I could say like 100,000 CPU cores</p>
<p>running with like hundreds of GPUs.</p>
<p>It was probably about something like hundreds</p>
<p>of years of experience going into this bot</p>
<p>every single real day.</p>
<p>And so that scale is massive</p>
<p>and we start to see very different kinds of behaviors</p>
<p>out of the algorithms that we all know and love.</p>
<p>Dota, you mentioned, beat the world expert one v one.</p>
<p>And then you weren&rsquo;t able to win five v five this year.</p>
<p>Yeah.</p>
<p>At the best players in the world.</p>
<p>So what&rsquo;s the comeback story?</p>
<p>First of all, talk through that.</p>
<p>That was an exceptionally exciting event.</p>
<p>And what&rsquo;s the following months and this year look like?</p>
<p>Yeah, yeah, so one thing that&rsquo;s interesting</p>
<p>is that we lose all the time.</p>
<p>Because we play.</p>
<p>Who&rsquo;s we here?</p>
<p>The Dota team at OpenAI.</p>
<p>We play the bot against better players</p>
<p>than our system all the time.</p>
<p>Or at least we used to, right?</p>
<p>Like the first time we lost publicly</p>
<p>was we went up on stage at the international</p>
<p>and we played against some of the best teams in the world</p>
<p>and we ended up losing both games,</p>
<p>but we gave them a run for their money, right?</p>
<p>That both games were kind of 30 minutes, 25 minutes</p>
<p>and they went back and forth, back and forth,</p>
<p>back and forth.</p>
<p>And so I think that really shows</p>
<p>that we&rsquo;re at the professional level</p>
<p>and that kind of looking at those games,</p>
<p>we think that the coin could have gone a different direction</p>
<p>and we could have had some wins.</p>
<p>That was actually very encouraging for us.</p>
<p>And it&rsquo;s interesting because the international</p>
<p>was at a fixed time, right?</p>
<p>So we knew exactly what day we were going to be playing</p>
<p>and we pushed as far as we could, as fast as we could.</p>
<p>Two weeks later, we had a bot that had an 80% win rate</p>
<p>versus the one that played at TI.</p>
<p>So the march of progress, you should think of it</p>
<p>as a snapshot rather than as an end state.</p>
<p>And so in fact, we&rsquo;ll be announcing our finals pretty soon.</p>
<p>I actually think that we&rsquo;ll announce our final match</p>
<p>prior to this podcast being released.</p>
<p>So we&rsquo;ll be playing against the world champions.</p>
<p>And for us, it&rsquo;s really less about,</p>
<p>like the way that we think about what&rsquo;s upcoming</p>
<p>is the final milestone, the final competitive milestone</p>
<p>for the project, right?</p>
<p>That our goal in all of this</p>
<p>isn&rsquo;t really about beating humans at Dota.</p>
<p>Our goal is to push the state of the art</p>
<p>in reinforcement learning.</p>
<p>And we&rsquo;ve done that, right?</p>
<p>And we&rsquo;ve actually learned a lot from our system</p>
<p>and that we have, I think, a lot of exciting next steps</p>
<p>that we want to take.</p>
<p>And so kind of as a final showcase of what we built,</p>
<p>we&rsquo;re going to do this match.</p>
<p>But for us, it&rsquo;s not really the success or failure</p>
<p>to see do we have the coin flip go in our direction</p>
<p>or against.</p>
<p>Where do you see the field of deep learning</p>
<p>heading in the next few years?</p>
<p>Where do you see the work and reinforcement learning</p>
<p>perhaps heading, and more specifically with OpenAI,</p>
<p>all the exciting projects that you&rsquo;re working on,</p>
<p>what does 2019 hold for you?</p>
<p>Massive scale.</p>
<p>Scale.</p>
<p>I will put an asterisk on that and just say,</p>
<p>I think that it&rsquo;s about ideas plus scale.</p>
<p>You need both.</p>
<p>So that&rsquo;s a really good point.</p>
<p>So the question, in terms of ideas,</p>
<p>you have a lot of projects</p>
<p>that are exploring different areas of intelligence.</p>
<p>And the question is, when you think of scale,</p>
<p>do you think about growing the scale</p>
<p>of those individual projects</p>
<p>or do you think about adding new projects?</p>
<p>And sorry to, and if you&rsquo;re thinking about</p>
<p>adding new projects, or if you look at the past,</p>
<p>what&rsquo;s the process of coming up with new projects</p>
<p>and new ideas?</p>
<p>Yep.</p>
<p>So we really have a life cycle of project here.</p>
<p>So we start with a few people</p>
<p>just working on a small scale idea.</p>
<p>And language is actually a very good example of this.</p>
<p>That it was really one person here</p>
<p>who was pushing on language for a long time.</p>
<p>I mean, then you get signs of life, right?</p>
<p>And so this is like, let&rsquo;s say,</p>
<p>with the original GPT, we had something that was interesting</p>
<p>and we said, okay, it&rsquo;s time to scale this, right?</p>
<p>It&rsquo;s time to put more people on it,</p>
<p>put more computational resources behind it.</p>
<p>And then we just kind of keep pushing and keep pushing.</p>
<p>And the end state is something</p>
<p>that looks like Dota or robotics,</p>
<p>where you have a large team of 10 or 15 people</p>
<p>that are running things at very large scale</p>
<p>and that you&rsquo;re able to really have material engineering</p>
<p>and sort of machine learning science coming together</p>
<p>to make systems that work and get material results</p>
<p>that just would have been impossible otherwise.</p>
<p>So we do that whole life cycle.</p>
<p>We&rsquo;ve done it a number of times, typically end to end.</p>
<p>It&rsquo;s probably two years or so to do it.</p>
<p>The organization has been around for three years,</p>
<p>so maybe we&rsquo;ll find that we also have</p>
<p>longer life cycle projects, but we&rsquo;ll work up to those.</p>
<p>So one team that we were actually just starting,</p>
<p>Ilya and I are kicking off a new team</p>
<p>called the Reasoning Team,</p>
<p>and that this is to really try to tackle</p>
<p>how do you get neural networks to reason?</p>
<p>And we think that this will be a long term project.</p>
<p>It&rsquo;s one that we&rsquo;re very excited about.</p>
<p>In terms of reasoning, super exciting topic,</p>
<p>what kind of benchmarks, what kind of tests of reasoning</p>
<p>do you envision?</p>
<p>What would, if you sat back with whatever drink</p>
<p>and you would be impressed that this system</p>
<p>is able to do something, what would that look like?</p>
<p>Theorem proving.</p>
<p>So some kind of logic, and especially mathematical logic.</p>
<p>I think so.</p>
<p>I think that there&rsquo;s other problems that are dual</p>
<p>to theorem proving in particular.</p>
<p>You think about programming, you think about</p>
<p>even security analysis of code,</p>
<p>that these all kind of capture the same sorts</p>
<p>of core reasoning and being able to do</p>
<p>some out of distribution generalization.</p>
<p>So it would be quite exciting if OpenAI Reasoning Team</p>
<p>was able to prove that P equals NP.</p>
<p>That would be very nice.</p>
<p>It would be very, very, very exciting, especially.</p>
<p>If it turns out that P equals NP,</p>
<p>that&rsquo;ll be interesting too.</p>
<p>It would be ironic and humorous.</p>
<p>So what problem stands out to you</p>
<p>as the most exciting and challenging and impactful</p>
<p>to the work for us as a community in general</p>
<p>and for OpenAI this year?</p>
<p>You mentioned reasoning.</p>
<p>I think that&rsquo;s a heck of a problem.</p>
<p>Yeah, so I think reasoning&rsquo;s an important one.</p>
<p>I think it&rsquo;s gonna be hard to get good results in 2019.</p>
<p>Again, just like we think about the life cycle, takes time.</p>
<p>I think for 2019, language modeling seems to be</p>
<p>kind of on that ramp.</p>
<p>It&rsquo;s at the point that we have a technique that works.</p>
<p>We wanna scale 100x, 1,000x, see what happens.</p>
<p>Awesome.</p>
<p>Do you think we&rsquo;re living in a simulation?</p>
<p>I think it&rsquo;s hard to have a real opinion about it.</p>
<p>It&rsquo;s actually interesting.</p>
<p>I separate out things that I think can have like,</p>
<p>yield materially different predictions about the world</p>
<p>from ones that are just kind of fun to speculate about.</p>
<p>I kind of view simulation as more like,</p>
<p>is there a flying teapot between Mars and Jupiter?</p>
<p>Like, maybe, but it&rsquo;s a little bit hard to know</p>
<p>what that would mean for my life.</p>
<p>So there is something actionable.</p>
<p>So some of the best work OpenAI has done</p>
<p>is in the field of reinforcement learning.</p>
<p>And some of the success of reinforcement learning</p>
<p>come from being able to simulate</p>
<p>the problem you&rsquo;re trying to solve.</p>
<p>So do you have a hope for reinforcement,</p>
<p>for the future of reinforcement learning</p>
<p>and for the future of simulation?</p>
<p>Like whether it&rsquo;s, we&rsquo;re talking about autonomous vehicles</p>
<p>or any kind of system.</p>
<p>Do you see that scaling to where we&rsquo;ll be able</p>
<p>to simulate systems and hence,</p>
<p>be able to create a simulator that echoes our real world</p>
<p>and proving once and for all,</p>
<p>even though you&rsquo;re denying it,</p>
<p>that we&rsquo;re living in a simulation?</p>
<p>I feel like it&rsquo;s two separate questions, right?</p>
<p>So kind of at the core there of like,</p>
<p>can we use simulation for self driving cars?</p>
<p>Take a look at our robotic system, Dactyl, right?</p>
<p>That was trained in simulation using the Dota system,</p>
<p>in fact, and it transfers to a physical robot.</p>
<p>And I think everyone looks at our Dota system,</p>
<p>they&rsquo;re like, okay, it&rsquo;s just a game.</p>
<p>How are you ever gonna escape to the real world?</p>
<p>And the answer is, well, we did it with a physical robot</p>
<p>that no one could program.</p>
<p>And so I think the answer is simulation</p>
<p>goes a lot further than you think</p>
<p>if you apply the right techniques to it.</p>
<p>Now, there&rsquo;s a question of,</p>
<p>are the beings in that simulation gonna wake up</p>
<p>and have consciousness?</p>
<p>I think that one seems a lot harder to, again,</p>
<p>reason about.</p>
<p>I think that you really should think about</p>
<p>where exactly does human consciousness come from</p>
<p>in our own self awareness?</p>
<p>And is it just that once you have a complicated enough</p>
<p>neural net, you have to worry about</p>
<p>the agents feeling pain?</p>
<p>And I think there&rsquo;s interesting speculation to do there,</p>
<p>but again, I think it&rsquo;s a little bit hard to know for sure.</p>
<p>Well, let me just keep with the speculation.</p>
<p>Do you think to create intelligence, general intelligence,</p>
<p>you need, one, consciousness, and two, a body?</p>
<p>Do you think any of those elements are needed,</p>
<p>or is intelligence something that&rsquo;s orthogonal to those?</p>
<p>I&rsquo;ll stick to the non grand answer first, right?</p>
<p>So the non grand answer is just to look at,</p>
<p>what are we already making work?</p>
<p>You look at GPT2, a lot of people would have said</p>
<p>that to even get these kinds of results,</p>
<p>you need real world experience.</p>
<p>You need a body, you need grounding.</p>
<p>How are you supposed to reason about any of these things?</p>
<p>How are you supposed to like even kind of know</p>
<p>about smoke and fire and those things</p>
<p>if you&rsquo;ve never experienced them?</p>
<p>And GPT2 shows that you can actually go way further</p>
<p>than that kind of reasoning would predict.</p>
<p>So I think that in terms of, do we need consciousness?</p>
<p>Do we need a body?</p>
<p>It seems the answer is probably not, right?</p>
<p>That we could probably just continue to push</p>
<p>kind of the systems we have.</p>
<p>They already feel general.</p>
<p>They&rsquo;re not as competent or as general</p>
<p>or able to learn as quickly as an AGI would,</p>
<p>but they&rsquo;re at least like kind of proto AGI in some way,</p>
<p>and they don&rsquo;t need any of those things.</p>
<p>Now let&rsquo;s move to the grand answer,</p>
<p>which is, are our neural nets conscious already?</p>
<p>Would we ever know?</p>
<p>How can we tell, right?</p>
<p>And here&rsquo;s where the speculation starts to become</p>
<p>at least interesting or fun</p>
<p>and maybe a little bit disturbing</p>
<p>depending on where you take it.</p>
<p>But it certainly seems that when we think about animals,</p>
<p>that there&rsquo;s some continuum of consciousness.</p>
<p>You know, my cat I think is conscious in some way, right?</p>
<p>Not as conscious as a human.</p>
<p>And you could imagine that you could build</p>
<p>a little consciousness meter, right?</p>
<p>You point at a cat, it gives you a little reading.</p>
<p>Point at a human, it gives you much bigger reading.</p>
<p>What would happen if you pointed one of those</p>
<p>at a donor neural net?</p>
<p>And if you&rsquo;re training in this massive simulation,</p>
<p>do the neural nets feel pain?</p>
<p>You know, it becomes pretty hard to know</p>
<p>that the answer is no.</p>
<p>And it becomes pretty hard to really think about</p>
<p>what that would mean if the answer were yes.</p>
<p>And it&rsquo;s very possible, you know, for example,</p>
<p>you could imagine that maybe the reason</p>
<p>that humans have consciousness</p>
<p>is because it&rsquo;s a convenient computational shortcut, right?</p>
<p>If you think about it, if you have a being</p>
<p>that wants to avoid pain,</p>
<p>which seems pretty important to survive in this environment</p>
<p>and wants to like, you know, eat food,</p>
<p>then that maybe the best way of doing it</p>
<p>is to have a being that&rsquo;s conscious, right?</p>
<p>That, you know, in order to succeed in the environment,</p>
<p>you need to have those properties</p>
<p>and how are you supposed to implement them</p>
<p>and maybe this consciousness&rsquo;s way of doing that.</p>
<p>If that&rsquo;s true, then actually maybe we should expect</p>
<p>that really competent reinforcement learning agents</p>
<p>will also have consciousness.</p>
<p>But you know, that&rsquo;s a big if.</p>
<p>And I think there are a lot of other arguments</p>
<p>they can make in other directions.</p>
<p>I think that&rsquo;s a really interesting idea</p>
<p>that even GPT2 has some degree of consciousness.</p>
<p>That&rsquo;s something, it&rsquo;s actually not as crazy</p>
<p>to think about, it&rsquo;s useful to think about</p>
<p>as we think about what it means</p>
<p>to create intelligence of a dog, intelligence of a cat,</p>
<p>and the intelligence of a human.</p>
<p>So last question, do you think</p>
<p>we will ever fall in love, like in the movie Her,</p>
<p>with an artificial intelligence system</p>
<p>or an artificial intelligence system</p>
<p>falling in love with a human?</p>
<p>I hope so.</p>
<p>If there&rsquo;s any better way to end it is on love.</p>
<p>So Greg, thanks so much for talking today.</p>
<p>Thank you for having me.</p>

</section>


    <footer class="article-footer">
    
    <section class="article-tags">
        
            <a href="/tags/english/">English</a>
        
            <a href="/tags/podcast/">Podcast</a>
        
            <a href="/tags/lex-fridman-podcast/">Lex Fridman Podcast</a>
        
    </section>


    </footer>


    
</article>

    

    

<div>
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9206135835124064"
         crossorigin="anonymous"></script>
    <ins class="adsbygoogle"
         style="display:block; text-align:center;"
         data-ad-layout="in-article"
         data-ad-format="fluid"
         data-ad-client="ca-pub-9206135835124064"
         data-ad-slot="1055602464"></ins>
    <script>
         (adsbygoogle = window.adsbygoogle || []).push({});
    </script>
</div>
<aside class="related-content--wrapper">
    <h2 class="section-title">Related content</h2>
    <div class="related-content">
        <div class="flex article-list--tile">
            
                
<article class="">
    <a href="/en/1310500372/">
        
	
        
        <div class="article-image">
            
            <img src="/img/related-content.png" loading="lazy" 
            data-key="en/1310500372" data-hash="" 
            style="opacity: 0.3;"/>
        </div>
        
        <div class="article-details">
            <h2 class="article-title">Lex Fridman Podcast - #368 - Eliezer Yudkowsky: Dangers of AI and the End of Human Civilization</h2>
            
            <footer class="article-time">
                <time datetime=''>Mar 30, 2023</time>
            </footer>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/en/1310500371/">
        
	
        
        <div class="article-image">
            
            <img src="/img/related-content.png" loading="lazy" 
            data-key="en/1310500371" data-hash="" 
            style="opacity: 0.3;"/>
        </div>
        
        <div class="article-details">
            <h2 class="article-title">Lex Fridman Podcast - #367 - Sam Altman: OpenAI CEO on GPT-4, ChatGPT, and the Future of AI</h2>
            
            <footer class="article-time">
                <time datetime=''>Mar 26, 2023</time>
            </footer>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/en/1310500370/">
        
	
        
        <div class="article-image">
            
            <img src="/img/related-content.png" loading="lazy" 
            data-key="en/1310500370" data-hash="" 
            style="opacity: 0.3;"/>
        </div>
        
        <div class="article-details">
            <h2 class="article-title">Lex Fridman Podcast - #366 - Shannon Curry: Johnny Depp &amp; Amber Heard Trial, Marriage, Dating &amp; Love</h2>
            
            <footer class="article-time">
                <time datetime=''>Mar 22, 2023</time>
            </footer>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/en/1310500369/">
        
	
        
        <div class="article-image">
            
            <img src="/img/related-content.png" loading="lazy" 
            data-key="en/1310500369" data-hash="" 
            style="opacity: 0.3;"/>
        </div>
        
        <div class="article-details">
            <h2 class="article-title">Lex Fridman Podcast - #365 - Sam Harris: Trump, Pandemic, Twitter, Elon, Bret, IDW, Kanye, AI &amp; UFOs</h2>
            
            <footer class="article-time">
                <time datetime=''>Mar 15, 2023</time>
            </footer>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/en/1310500368/">
        
	
        
        <div class="article-image">
            
            <img src="/img/related-content.png" loading="lazy" 
            data-key="en/1310500368" data-hash="" 
            style="opacity: 0.3;"/>
        </div>
        
        <div class="article-details">
            <h2 class="article-title">Lex Fridman Podcast - #364 - Chris Voss: FBI Hostage Negotiator</h2>
            
            <footer class="article-time">
                <time datetime=''>Mar 11, 2023</time>
            </footer>
        </div>
    </a>
</article>

            
        </div>
    </div>
</aside>

     
    
        
    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
            2021 - 
        
        2023 SWIEST - Transcripts ¬∑ Screenplays ¬∑ Lyrics
    </section>
    
    <section class="powerby">
        

        As an Amazon Associate I earn from qualifying purchases üõí<br/>

        Built with <a href="https://swiest.com/" target="_blank" rel="noopener">(Ôæâ‚óï„ÉÆ‚óï)Ôæâü™Ñüíûüíñü•∞ across the glüåçüåèüåébe</a> <br />
        
        
    </section>
</footer>


    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo="crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU="crossorigin="anonymous"
                defer
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css"crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css"crossorigin="anonymous"
            >

            </main>
        </div>
        <script 
                src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js"integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z&#43;KMkF24hUW8WePSA9HM="crossorigin="anonymous"
                
                >
            </script><script type="text/javascript" src="/ts/main.js" defer></script>


<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Noto+Serif&family=Noto+Serif+Armenian&family=Noto+Serif+Bengali&family=Noto+Serif+Devanagari&family=Noto+Serif+Georgian&family=Noto+Serif+Gujarati&family=Noto+Serif+HK&family=Noto+Serif+Hebrew&family=Noto+Serif+JP&family=Noto+Serif+KR&family=Noto+Serif+Kannada&family=Noto+Serif+Khmer&family=Noto+Serif+Lao&family=Noto+Serif+Makasar&family=Noto+Serif+Malayalam&family=Noto+Serif+Myanmar&family=Noto+Serif+Oriya&family=Noto+Serif+SC&family=Noto+Serif+Sinhala&family=Noto+Serif+TC&family=Noto+Serif+Tamil&family=Noto+Serif+Telugu&family=Noto+Serif+Thai&family=Noto+Serif+Tibetan&display=swap" rel="stylesheet">

    </body>
</html>
