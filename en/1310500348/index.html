<!DOCTYPE html>
<html lang="en" dir="ltr">
    <head><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content='The following is a conversation with Noel Brown,
research scientist at FAIR,
Facebook AI research group at Meta AI.
He co-created the first AI system
that achieved superhuman level performance
in no limit Texas Hold&amp;rsquo;em,
both heads up and multiplayer.
And now, recently, he co-created an AI system
that can strategically out-negotiate humans
using natural language
in a popular board game called Diplomacy,
which is a war game that emphasizes negotiation.'>
<title>Lex Fridman Podcast - #344 - Noam Brown: AI vs Humans in Poker and Games of Strategic Negotiation | SWIEST</title>

<link rel='canonical' href='https://swiest.com/en/1310500348/'>

<link rel="stylesheet" href="/scss/style.min.91b18679590f4ceed910ade4d64b1e7375cc0770ef5b8c1d822f42424f9ff2c8.css"><script>
    document.oncontextmenu = function(){ return false; };
    document.onselectstart = function(){ return false; };
    document.oncopy = function(){ return false; };
    document.oncut = function(){ return false; };
</script>

<script src="https://apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js"></script>


<script type="text/javascript">
    $(document).ready(function(){
     
     $("#back-to-top").hide();
     
     $(function () {
      $(window).scroll(function(){
       if ($(window).scrollTop()>600){
        $("#back-to-top").fadeIn(500);
       }else{
        $("#back-to-top").fadeOut(500);
       }
     });
     
     $("#back-to-top").click(function(){
      $('body,html').animate({scrollTop:0},500);
       return false;
      });
     });
    });
    </script><meta property='og:title' content='Lex Fridman Podcast - #344 - Noam Brown: AI vs Humans in Poker and Games of Strategic Negotiation'>
<meta property='og:description' content='The following is a conversation with Noel Brown,
research scientist at FAIR,
Facebook AI research group at Meta AI.
He co-created the first AI system
that achieved superhuman level performance
in no limit Texas Hold&amp;rsquo;em,
both heads up and multiplayer.
And now, recently, he co-created an AI system
that can strategically out-negotiate humans
using natural language
in a popular board game called Diplomacy,
which is a war game that emphasizes negotiation.'>
<meta property='og:url' content='https://swiest.com/en/1310500348/'>
<meta property='og:site_name' content='SWIEST - Transcripts ¬∑ Screenplays ¬∑ Lyrics'>
<meta property='og:type' content='article'><meta property='article:section' content='Post' /><meta property='article:tag' content='English' /><meta property='article:tag' content='Podcast' /><meta property='article:tag' content='Lex Fridman Podcast' /><meta property='article:published_time' content='2023-02-11T09:00:00&#43;00:00'/><meta property='article:modified_time' content='2023-02-11T09:00:00&#43;00:00'/>
<meta name="twitter:title" content="Lex Fridman Podcast - #344 - Noam Brown: AI vs Humans in Poker and Games of Strategic Negotiation">
<meta name="twitter:description" content="The following is a conversation with Noel Brown,
research scientist at FAIR,
Facebook AI research group at Meta AI.
He co-created the first AI system
that achieved superhuman level performance
in no limit Texas Hold&amp;rsquo;em,
both heads up and multiplayer.
And now, recently, he co-created an AI system
that can strategically out-negotiate humans
using natural language
in a popular board game called Diplomacy,
which is a war game that emphasizes negotiation.">
    <link rel="shortcut icon" href="/favicon.ico" />
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9206135835124064" crossorigin="anonymous"></script>
<script type="text/javascript">amzn_assoc_ad_type = "link_enhancement_widget";amzn_assoc_tracking_id = "swiest00-20";amzn_assoc_linkid = "b583d47a9f44ec47064a228dad7fb822";amzn_assoc_placement = "";amzn_assoc_marketplace = "amazon";amzn_assoc_region = "US";</script><script src="//ws-na.amazon-adsystem.com/widgets/q?ServiceVersion=20070822&Operation=GetScript&ID=OneJS&WS=1&MarketPlace=US"></script>
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    </head>
    <body class="
    article-page
    ">
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "dark");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky ">
    <button class="hamburger hamburger--spin" type="button" id="toggle-menu" aria-label="Toggle Menu">
        <span class="hamburger-box">
            <span class="hamburger-inner"></span>
        </span>
    </button>

    <header>
        
            
            <figure class="site-avatar">
                <a href="/">
                
                    
                    
                    
                        
                        <img src="/img/avatar_hu307e6a33fa6fd661ccda3b77024ef5c2_252345_300x0_resize_box_3.png" width="300"
                            height="300" class="site-logo" loading="lazy" alt="Avatar">
                    
                
                </a>
                
                    <span class="emoji">‚ú®</span>
                
            </figure>
            
        
        
        <div class="site-meta">
            <h1 class="site-name"><a href="/">SWIEST - Transcripts ¬∑ Screenplays ¬∑ Lyrics</a></h1>
            <h2 class="site-description">üåçüåèüåé</h2>
        </div>
    </header><ol class="menu" id="main-menu">
        
        
        
        <li >
            <a href='/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <polyline points="5 12 3 12 12 3 21 12 19 12" />
  <path d="M5 12v7a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-7" />
  <path d="M9 21v-6a2 2 0 0 1 2 -2h2a2 2 0 0 1 2 2v6" />
</svg>



                
                <span>Home</span>
            </a>
        </li>
        
        
        <li >
            <a href='/archives/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <rect x="3" y="4" width="18" height="4" rx="2" />
  <path d="M5 8v10a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-10" />
  <line x1="10" y1="12" x2="14" y2="12" />
</svg>



                
                <span>Archives</span>
            </a>
        </li>
        
        
        <li >
            <a href='/search/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="10" cy="10" r="7" />
  <line x1="21" y1="21" x2="15" y2="15" />
</svg>



                
                <span>Search</span>
            </a>
        </li>
        
        
        <li >
            <a href='/chart/podcastchart.html' target="_blank">
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-apple-podcast" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="#ffffff" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M18.364 18.364a9 9 0 1 0 -12.728 0" />
  <path d="M11.766 22h.468a2 2 0 0 0 1.985 -1.752l.5 -4a2 2 0 0 0 -1.985 -2.248h-1.468a2 2 0 0 0 -1.985 2.248l.5 4a2 2 0 0 0 1.985 1.752z" />
  <path d="M12 9m-2 0a2 2 0 1 0 4 0a2 2 0 1 0 -4 0" />
</svg>
                
                <span>Podcast Charts</span>
            </a>
        </li>
        

        <div class="menu-bottom-section">
                <li id="i18n-switch">  
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-language" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M4 5h7" />
  <path d="M9 3v2c0 4.418 -2.239 8 -5 8" />
  <path d="M5 9c-.003 2.144 2.952 3.908 6.7 4" />
  <path d="M12 20l4 -9l4 9" />
  <path d="M19.1 18h-6.2" />
</svg>



                    <select name="language" onchange="window.location.href = this.selectedOptions[0].value">
                        
                            <option value="https://swiest.com/" selected>English</option>
                        
                            <option value="https://swiest.com/af/" >Afrikaans</option>
                        
                            <option value="https://swiest.com/am/" >·ä†·àõ·à≠·äõ</option>
                        
                            <option value="https://swiest.com/ar/" >ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</option>
                        
                            <option value="https://swiest.com/az/" >Az…ôrbaycan</option>
                        
                            <option value="https://swiest.com/be/" >–±–µ–ª–∞—Ä—É—Å–∫—ñ</option>
                        
                            <option value="https://swiest.com/bg/" >–±—ä–ª–≥–∞—Ä—Å–∫–∏</option>
                        
                            <option value="https://swiest.com/bn/" >‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ</option>
                        
                            <option value="https://swiest.com/bo/" >‡Ωñ‡Ωº‡Ωë‡ºã‡Ω¶‡æê‡Ωë‡ºã</option>
                        
                            <option value="https://swiest.com/bs/" >Bosanski</option>
                        
                            <option value="https://swiest.com/ca/" >Catal√†</option>
                        
                            <option value="https://swiest.com/zh-hans/" >ÁÆÄ‰Ωì‰∏≠Êñá</option>
                        
                            <option value="https://swiest.com/zh-hant/" >ÁπÅÈ´î‰∏≠Êñá</option>
                        
                            <option value="https://swiest.com/cs/" >ƒåe≈°tina</option>
                        
                            <option value="https://swiest.com/el/" >ŒµŒªŒªŒ∑ŒΩŒπŒ∫Œ¨</option>
                        
                            <option value="https://swiest.com/cy/" >Cymraeg</option>
                        
                            <option value="https://swiest.com/da/" >Dansk</option>
                        
                            <option value="https://swiest.com/de/" >Deutsch</option>
                        
                            <option value="https://swiest.com/eo/" >Esperanto</option>
                        
                            <option value="https://swiest.com/es-es/" >Espa√±ol (Espa√±a)</option>
                        
                            <option value="https://swiest.com/es-419/" >Espa√±ol (Latinoam√©rica)</option>
                        
                            <option value="https://swiest.com/et/" >Eesti</option>
                        
                            <option value="https://swiest.com/eu/" >Euskara</option>
                        
                            <option value="https://swiest.com/haw/" > ª≈ålelo Hawai ªi</option>
                        
                            <option value="https://swiest.com/fa/" >ŸÅÿßÿ±ÿ≥€å</option>
                        
                            <option value="https://swiest.com/fi/" >Suomi</option>
                        
                            <option value="https://swiest.com/fo/" >F√∏royskt</option>
                        
                            <option value="https://swiest.com/fr/" >Fran√ßais</option>
                        
                            <option value="https://swiest.com/fy/" >Frysk</option>
                        
                            <option value="https://swiest.com/ga/" >Gaeilge</option>
                        
                            <option value="https://swiest.com/gl/" >Galego</option>
                        
                            <option value="https://swiest.com/gu/" >‡™ó‡´Å‡™ú‡™∞‡™æ‡™§‡´Ä</option>
                        
                            <option value="https://swiest.com/he/" >◊¢÷¥◊ë◊®÷¥◊ô◊™</option>
                        
                            <option value="https://swiest.com/km/" >·ûÄ·ûò·üí·ûñ·ûª·ûá·û∂·üî</option>
                        
                            <option value="https://swiest.com/hi/" >‡§π‡§ø‡§®‡•ç‡§¶‡•Ä</option>
                        
                            <option value="https://swiest.com/hr/" >Hrvatski</option>
                        
                            <option value="https://swiest.com/ht/" >Krey√≤l Ayisyen</option>
                        
                            <option value="https://swiest.com/hu/" >Magyar</option>
                        
                            <option value="https://swiest.com/hy/" >’Ä’°’µ’•÷Ä’•’∂</option>
                        
                            <option value="https://swiest.com/ig/" >√Ås·ª•ÃÄs·ª•ÃÅ √ågb√≤</option>
                        
                            <option value="https://swiest.com/id/" >Bahasa Indonesia</option>
                        
                            <option value="https://swiest.com/is/" >√çslenska</option>
                        
                            <option value="https://swiest.com/it/" >Italiano</option>
                        
                            <option value="https://swiest.com/ja/" >Êó•Êú¨Ë™û</option>
                        
                            <option value="https://swiest.com/jv/" >Basa Jawa</option>
                        
                            <option value="https://swiest.com/ka/" >·É•·Éê·É†·Éó·É£·Éö·Éò</option>
                        
                            <option value="https://swiest.com/kk/" >“ö–∞–∑–∞“õ—à–∞</option>
                        
                            <option value="https://swiest.com/kn/" >‡≤ï‡≤®‡≥ç‡≤®‡≤°</option>
                        
                            <option value="https://swiest.com/ko/" >ÌïúÍµ≠Ïñ¥</option>
                        
                            <option value="https://swiest.com/or/" >‡¨ì‡¨°‡¨º‡¨ø‡¨Ü</option>
                        
                            <option value="https://swiest.com/ckb/" >⁄©Ÿàÿ±ÿØ€å</option>
                        
                            <option value="https://swiest.com/ky/" >–ö—ã—Ä–≥—ã–∑—á–∞</option>
                        
                            <option value="https://swiest.com/la/" >Latina</option>
                        
                            <option value="https://swiest.com/lb/" >L√´tzebuergesch</option>
                        
                            <option value="https://swiest.com/lo/" >‡∫û‡∫≤‡∫™‡∫≤‡∫•‡∫≤‡∫ß</option>
                        
                            <option value="https://swiest.com/lt/" >Lietuvi≈≥</option>
                        
                            <option value="https://swiest.com/lv/" >Latvie≈°u</option>
                        
                            <option value="https://swiest.com/mk/" >–ú–∞–∫–µ–¥–æ–Ω—Å–∫–∏</option>
                        
                            <option value="https://swiest.com/ml/" >‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç</option>
                        
                            <option value="https://swiest.com/mn/" >–ú–æ–Ω–≥–æ–ª —Ö—ç–ª</option>
                        
                            <option value="https://swiest.com/mr/" >‡§Æ‡§∞‡§æ‡§†‡•Ä</option>
                        
                            <option value="https://swiest.com/sw/" >Kiswahili</option>
                        
                            <option value="https://swiest.com/ms/" >Bahasa Melayu</option>
                        
                            <option value="https://swiest.com/my/" >·Äô·Äº·Äî·Ä∫·Äô·Ä¨</option>
                        
                            <option value="https://swiest.com/ne/" >‡§®‡•á‡§™‡§æ‡§≤‡•Ä</option>
                        
                            <option value="https://swiest.com/nl/" >Nederlands</option>
                        
                            <option value="https://swiest.com/no/" >Norsk</option>
                        
                            <option value="https://swiest.com/pa/" >‡®™‡©∞‡®ú‡®æ‡®¨‡©Ä</option>
                        
                            <option value="https://swiest.com/pl/" >Polski</option>
                        
                            <option value="https://swiest.com/pt-br/" >Portugu√™s Brasil</option>
                        
                            <option value="https://swiest.com/pt-pt/" >Portugu√™s Europeu</option>
                        
                            <option value="https://swiest.com/ro/" >Rom√¢nƒÉ</option>
                        
                            <option value="https://swiest.com/ru/" >–†—É—Å—Å–∫–∏–π</option>
                        
                            <option value="https://swiest.com/rw/" >Kinyarwanda</option>
                        
                            <option value="https://swiest.com/si/" >‡∑É‡∑í‡∂Ç‡∑Ñ‡∂Ω</option>
                        
                            <option value="https://swiest.com/sk/" >Slovenƒçina</option>
                        
                            <option value="https://swiest.com/sl/" >Sloven≈°ƒçina</option>
                        
                            <option value="https://swiest.com/sq/" >Shqip</option>
                        
                            <option value="https://swiest.com/sr/" >–°—Ä–ø—Å–∫–∏ (Srpski)</option>
                        
                            <option value="https://swiest.com/su/" >Basa Sunda</option>
                        
                            <option value="https://swiest.com/sv/" >Svenska</option>
                        
                            <option value="https://swiest.com/ta/" >‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç</option>
                        
                            <option value="https://swiest.com/te/" >‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å</option>
                        
                            <option value="https://swiest.com/tg/" >–¢–æ“∑–∏–∫”£</option>
                        
                            <option value="https://swiest.com/th/" >‡πÑ‡∏ó‡∏¢</option>
                        
                            <option value="https://swiest.com/tl/" >Filipino</option>
                        
                            <option value="https://swiest.com/tr/" >T√ºrk√ße</option>
                        
                            <option value="https://swiest.com/uk/" >–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞</option>
                        
                            <option value="https://swiest.com/ur/" >ÿßÿ±ÿØŸà</option>
                        
                            <option value="https://swiest.com/uz/" >O&#39;zbekcha</option>
                        
                            <option value="https://swiest.com/vi/" >Ti·∫øng Vi·ªát</option>
                        
                            <option value="https://swiest.com/yi/" >◊ê◊ô◊ì◊ô◊©</option>
                        
                            <option value="https://swiest.com/zh-hk/" >Á≤µË™û</option>
                        
                            <option value="https://swiest.com/zu/" >IsiZulu</option>
                        
                    </select>
                </li>
            
            
            
                <li id="dark-mode-toggle">
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="8" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="16" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                    <span>Dark Mode</span>
                </li>
            
        </div>
    </ol>
</aside>

    

            <main class="main full-width">
    <article class="main-article">
    <header class="article-header">

    <div class="article-details">
    
    <header class="article-category">
        
            <a href="/categories/podcast/" >
                Podcast
            </a>
        
            <a href="/categories/lex-fridman-podcast/" >
                Lex Fridman Podcast
            </a>
        
    </header>
    

    <div class="article-title-wrapper">
        <h2 class="article-title">
            <a href="/en/1310500348/">Lex Fridman Podcast - #344 - Noam Brown: AI vs Humans in Poker and Games of Strategic Negotiation</a>
        </h2>
    
        
    </div>

    
    
    
    
    <footer class="article-time">
        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M11.795 21h-6.795a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v4" />
  <circle cx="18" cy="18" r="4" />
  <path d="M15 3v4" />
  <path d="M7 3v4" />
  <path d="M3 11h16" />
  <path d="M18 16.496v1.504l1 1" />
</svg>
                <time class="article-time--published">2023-02-11</time>
            </div>
        

        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



                <time class="article-time--reading">
                    132 minute read
                </time>
            </div>
        
    </footer>
    

    
</div>

</header>
<div>
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9206135835124064"
         crossorigin="anonymous"></script>
    <ins class="adsbygoogle"
         style="display:block; text-align:center;"
         data-ad-layout="in-article"
         data-ad-format="fluid"
         data-ad-client="ca-pub-9206135835124064"
         data-ad-slot="1055602464"></ins>
    <script>
         (adsbygoogle = window.adsbygoogle || []).push({});
    </script>
</div>

    <section class="article-content">
    
    
    <p>The following is a conversation with Noel Brown,</p>
<p>research scientist at FAIR,</p>
<p>Facebook AI research group at Meta AI.</p>
<p>He co-created the first AI system</p>
<p>that achieved superhuman level performance</p>
<p>in no limit Texas Hold&rsquo;em,</p>
<p>both heads up and multiplayer.</p>
<p>And now, recently, he co-created an AI system</p>
<p>that can strategically out-negotiate humans</p>
<p>using natural language</p>
<p>in a popular board game called Diplomacy,</p>
<p>which is a war game that emphasizes negotiation.</p>
<p>And now, a quick few second mention of each sponsor.</p>
<p>Check them out in the description.</p>
<p>It&rsquo;s the best way to support this podcast.</p>
<p>We got True Classic Tees for shirts,</p>
<p>Audible for audiobooks,</p>
<p>Insight Tracker for bio-monitoring,</p>
<p>and ExpressVPN for ISP privacy.</p>
<p>Choose wisely, my friends.</p>
<p>And now, onto the full ad reads.</p>
<p>As always, no ads in the middle.</p>
<p>I try to make these interesting,</p>
<p>but if you skip them,</p>
<p>please still check out the sponsors.</p>
<p>I enjoy their stuff.</p>
<p>Maybe you will too.</p>
<p>This show is brought to you by True Classic Tees.</p>
<p>High quality, soft, slim-fitted t-shirts for men.</p>
<p>They also make all the other menswear staples</p>
<p>like polos, workout shirts, and boxers.</p>
<p>I mostly wear their black t-shirt.</p>
<p>And that&rsquo;s what I&rsquo;m wearing right now.</p>
<p>I have a ton of them.</p>
<p>I enjoy how it feels.</p>
<p>I enjoy how it looks.</p>
<p>That&rsquo;s like the standard default look</p>
<p>of the guy behind the keyboard.</p>
<p>I guess programmer.</p>
<p>I wonder when the t-shirt was created.</p>
<p>Looking up on a wiki,</p>
<p>the t-shirt evolved from undergarments</p>
<p>used in the 19th century</p>
<p>and in the mid 20th century transitioned</p>
<p>from undergarments to general use casual clothing.</p>
<p>Okay, wonderful.</p>
<p>Anyway, go to trueclassic.com</p>
<p>and enter code LEX to get 25% off.</p>
<p>This episode is brought to you by Audible,</p>
<p>an audio book service that has given me hundreds,</p>
<p>if not thousands of hours of education</p>
<p>to listening to audio books.</p>
<p>I&rsquo;m currently re-listening for the,</p>
<p>I don&rsquo;t know how many times I&rsquo;ve re-listened to this book,</p>
<p>how many times I&rsquo;ve read it,</p>
<p>by George Orwell&rsquo;s 1984.</p>
<p>Not nearly as many times as Animal Farm.</p>
<p>I don&rsquo;t know why exactly,</p>
<p>but Animal Farm just is a story.</p>
<p>Just connects with me.</p>
<p>A basic fable of creatures being not so good to each other</p>
<p>and being greedy and also being good to each other</p>
<p>and having personalities and just in the simple way that</p>
<p>sort of, whenever animals are made in a children-like story,</p>
<p>it&rsquo;s simple, but it can still get to the profound.</p>
<p>I think I like to think of life in those terms.</p>
<p>Anyway, I&rsquo;m currently listening to 1984.</p>
<p>It&rsquo;s really well sort of spoken,</p>
<p>voiced or whatever on Audible.</p>
<p>So I highly recommend it.</p>
<p>New members can try free for 30 days</p>
<p>at audible.com slash Lex or text Lex to 500 500.</p>
<p>This show is also brought to you by InsideTracker,</p>
<p>a service I use to track biological data.</p>
<p>Did you know there&rsquo;s 1.2 to 1.5 gallons of blood</p>
<p>in a human being?</p>
<p>It&rsquo;s approximately 10% of adults weight.</p>
<p>I remember like reading some insane stats</p>
<p>on the volume of blood pumped a day through the human body.</p>
<p>It&rsquo;s kind of, it&rsquo;s just incredible</p>
<p>sort of this whole machinery that interacts with oxygen.</p>
<p>I mean, just with the chemistry of earth,</p>
<p>interacts with it, it uses energy,</p>
<p>ultimately from the sun and the photosynthesis is involved</p>
<p>with the plants.</p>
<p>The whole system is just freaking incredible</p>
<p>and it&rsquo;s just so full of data.</p>
<p>Like imagine being able to measure all of that</p>
<p>about life on earth.</p>
<p>Yeah, so InsideTracker is like early steps</p>
<p>in being able to measure directly from the human body.</p>
<p>Get $200 off InsideTracker&rsquo;s ultimate plan</p>
<p>or 34% off the entire store</p>
<p>when you go to InsideTracker.com slash Lex.</p>
<p>This show is also brought to you by ExpressVPN.</p>
<p>I use them to protect my privacy on the internet.</p>
<p>I&rsquo;ve used them for many, many years.</p>
<p>Through thick and thin.</p>
<p>When I was lost in this too big world of ours</p>
<p>and looking for the truth out there</p>
<p>and protecting my privacy all along,</p>
<p>I remember being really excited</p>
<p>to learn that it can work on Android,</p>
<p>that it can work on Linux.</p>
<p>So it works on any operating system</p>
<p>and it just doesn&rsquo;t feel like it&rsquo;s there.</p>
<p>Everything is super fast,</p>
<p>whether you have the VPN or not.</p>
<p>It&rsquo;s kind of incredible.</p>
<p>It&rsquo;s incredible how this technology works</p>
<p>and it conceals your location</p>
<p>from the perspective of the website</p>
<p>or service that you&rsquo;re using online.</p>
<p>It&rsquo;s an incredible tool.</p>
<p>Should be the first layer of protection</p>
<p>of your privacy on the internet.</p>
<p>Go to ExpressVPN.com slash LexPod</p>
<p>for an extra three months free.</p>
<p>This is the Lex Friedman Podcast.</p>
<p>To support it,</p>
<p>please check out our sponsors in the description.</p>
<p>And now dear friends,</p>
<p>here&rsquo;s Noam Brown.</p>
<p>You&rsquo;ve been a lead on three amazing AI projects.</p>
<p>So we&rsquo;ve got Libratus that solved</p>
<p>or at least achieved human level performance</p>
<p>on No Limit Texas Hold&rsquo;em Poker</p>
<p>with two players, heads up.</p>
<p>You got Pluribus that solved No Limit Texas Hold&rsquo;em Poker</p>
<p>with six players.</p>
<p>And just now you have Cicero.</p>
<p>These are all names of systems</p>
<p>that solved or achieved human level performance</p>
<p>on the game of Diplomacy,</p>
<p>which for people who don&rsquo;t know</p>
<p>is a popular strategy board game.</p>
<p>It was loved by JFK, John F. Kennedy and Henry Kissinger</p>
<p>and many other big famous people in the decades since.</p>
<p>So let&rsquo;s talk about poker and diplomacy today.</p>
<p>First poker, what is the game of No Limit Texas Hold&rsquo;em?</p>
<p>And how is it different from chess?</p>
<p>Well, No Limit Texas Hold&rsquo;em Poker</p>
<p>is the most popular variant of poker in the world.</p>
<p>So, you know, you go to a casino,</p>
<p>you play, sit down at the poker table.</p>
<p>The game that you&rsquo;re playing is No Limit Texas Hold&rsquo;em.</p>
<p>If you watch movies about poker,</p>
<p>like Casino Royale or Rounders,</p>
<p>the game that they&rsquo;re playing</p>
<p>is No Limit Texas Hold&rsquo;em Poker.</p>
<p>Now it&rsquo;s very different from Limit Hold&rsquo;em</p>
<p>in that you can bet any amount of chips that you want.</p>
<p>And so the stakes escalate really quickly.</p>
<p>You start out with like one or $2 in the pot.</p>
<p>And then by the end of the hand,</p>
<p>you&rsquo;ve got like $1,000 in there maybe.</p>
<p>So the option to increase the number very aggressively</p>
<p>and very quickly is always there.</p>
<p>Right.</p>
<p>The No Limit aspect is there&rsquo;s no limits</p>
<p>to how much you can bet.</p>
<p>In Limit Hold&rsquo;em, there&rsquo;s like $2 in the pot.</p>
<p>You can only bet like $2.</p>
<p>But if you got $10,000 in front of you,</p>
<p>you&rsquo;re always welcome to put $10,000 into the pot.</p>
<p>So I got a chance to hang out with Phil Helmuth</p>
<p>who plays all these different variants of poker.</p>
<p>And correct me if I&rsquo;m wrong,</p>
<p>but it seems like No Limit rewards crazy</p>
<p>versus the other ones rewards</p>
<p>more kind of calculated strategy.</p>
<p>Or no, because you&rsquo;re sort of looking</p>
<p>from an analytic perspective,</p>
<p>is strategy also rewarded in No Limit Texas Hold&rsquo;em?</p>
<p>I think both variants reward strategy.</p>
<p>But I think what&rsquo;s different about No Limit Hold&rsquo;em</p>
<p>is it&rsquo;s much easier to get jumpy.</p>
<p>You go in there thinking you&rsquo;re gonna play</p>
<p>for like $100 or something.</p>
<p>And suddenly there&rsquo;s like $1,000 in the pot.</p>
<p>A lot of people can&rsquo;t handle that.</p>
<p>Can you define jumpy?</p>
<p>When you&rsquo;re playing poker,</p>
<p>you always want to choose the action</p>
<p>that&rsquo;s going to maximize your expected value.</p>
<p>It&rsquo;s kind of like with investing, right?</p>
<p>Like if you&rsquo;re ever in a situation</p>
<p>where the amount of money that&rsquo;s at stake</p>
<p>is going to have a material impact on your life,</p>
<p>then you&rsquo;re gonna play in a more risk averse style.</p>
<p>You know, if somebody makes a huge bet,</p>
<p>you&rsquo;re gonna, if you&rsquo;re playing No Limit Hold&rsquo;em</p>
<p>and somebody makes a huge bet,</p>
<p>there might come a point where you&rsquo;re like,</p>
<p>this is too much money for me to handle.</p>
<p>Like I can&rsquo;t risk this amount.</p>
<p>And that&rsquo;s what throws a lot of people off.</p>
<p>So that&rsquo;s the big difference, I think,</p>
<p>between No Limit and Limit.</p>
<p>What about on the action side</p>
<p>when you&rsquo;re actually making that big bet?</p>
<p>That&rsquo;s what I mean by crazy.</p>
<p>I was trying to refer to the technical term of crazy,</p>
<p>meaning use the big jump in the bet</p>
<p>to completely throw off the other person</p>
<p>in terms of their ability to reason optimally.</p>
<p>I think that&rsquo;s right.</p>
<p>I think one of the key strategies in poker</p>
<p>is to put the other person into an uncomfortable position.</p>
<p>And if you&rsquo;re doing that, then you&rsquo;re playing poker well.</p>
<p>And there&rsquo;s a lot of opportunities to do that</p>
<p>in No Limit Hold&rsquo;em.</p>
<p>You know, you can have like $50 in there,</p>
<p>you throw in $1,000 bet.</p>
<p>And you know, that&rsquo;s sometimes if you do it right,</p>
<p>it puts the other person in a really tough spot.</p>
<p>Now, it&rsquo;s also possible that you make huge mistakes</p>
<p>that way.</p>
<p>And so it&rsquo;s really easy to lose a lot of money</p>
<p>in No Limit Hold&rsquo;em if you don&rsquo;t know what you&rsquo;re doing.</p>
<p>But there&rsquo;s a lot of upside potential too.</p>
<p>So when you build systems,</p>
<p>AI systems that play these games,</p>
<p>we&rsquo;ll talk about poker, we&rsquo;ll talk about diplomacy.</p>
<p>Are you drawn in in part by the beauty of the game itself,</p>
<p>AI aside?</p>
<p>Or is it to you primarily a fascinating problem set</p>
<p>for the AI to solve?</p>
<p>I&rsquo;m drawn in by the beauty of the game.</p>
<p>When I, I started playing poker when I was in high school.</p>
<p>And the idea to me that there is a correct,</p>
<p>an objectively correct way of playing poker.</p>
<p>And if you could figure out what that is,</p>
<p>then you&rsquo;re, you know,</p>
<p>you&rsquo;re making unlimited money basically.</p>
<p>That&rsquo;s like a really fascinating concept to me.</p>
<p>And so I was fascinated by the strategy of poker,</p>
<p>even when I was like 16 years old.</p>
<p>It wasn&rsquo;t until like much later</p>
<p>that I actually worked on poker AIs.</p>
<p>So there was a sense that you can solve poker,</p>
<p>like in the way you can solve chess, for example,</p>
<p>or checkers, I believe checkers got solved, right?</p>
<p>Yeah, checkers is completely solved.</p>
<p>Optimal strategy.</p>
<p>Optimal strategy, it&rsquo;s impossible to beat the AI.</p>
<p>Yeah, and so in that same way,</p>
<p>you could technically solve chess.</p>
<p>You could solve chess, you could solve poker.</p>
<p>You could solve poker.</p>
<p>So this is, this gets into the concept of a Nash equilibrium.</p>
<p>So it is a Nash equilibrium.</p>
<p>Okay, so in any finite two player zero sum game,</p>
<p>there is an optimal strategy that if you play it,</p>
<p>you are guaranteed to not lose an expectation</p>
<p>no matter what your opponent does.</p>
<p>And this is kind of a radical concept to a lot of people,</p>
<p>but it&rsquo;s true in chess, it&rsquo;s true in poker,</p>
<p>it&rsquo;s true in any finite two player zero sum game.</p>
<p>And to give some intuition for this,</p>
<p>you can think of rock, paper, scissors.</p>
<p>In rock, paper, scissors, if you randomly choose</p>
<p>between throwing rock, paper, and scissors</p>
<p>with equal probability,</p>
<p>then no matter what your opponent does,</p>
<p>you are not going to lose an expectation.</p>
<p>You&rsquo;re not going to lose an expectation in the long run.</p>
<p>Now, the same is true for poker.</p>
<p>There exists some strategy,</p>
<p>some really complicated strategy that if you play that,</p>
<p>you are guaranteed to not lose money in the long run.</p>
<p>And I should say, this is for two player poker.</p>
<p>Six player poker is a different story.</p>
<p>Yeah, it&rsquo;s a beautiful giant mess.</p>
<p>When you say in expectation,</p>
<p>you&rsquo;re guaranteed not to lose in expectation.</p>
<p>What does in expectation mean?</p>
<p>Poker is a very high variance game.</p>
<p>So you&rsquo;re going to have hands where you win,</p>
<p>you&rsquo;re going to have hands with your lose.</p>
<p>Even if you&rsquo;re playing the perfect strategy,</p>
<p>you can&rsquo;t guarantee that you&rsquo;re going to win</p>
<p>every single hand.</p>
<p>But if you play for long enough,</p>
<p>then you are guaranteed to at least break even</p>
<p>and in practice, probably win.</p>
<p>So that&rsquo;s an expectation,</p>
<p>the size of your stack, generally speaking.</p>
<p>Now that doesn&rsquo;t include anything about</p>
<p>the fact that you can go broke.</p>
<p>It doesn&rsquo;t include any of those kinds of normal</p>
<p>real world limitations.</p>
<p>You&rsquo;re talking in a theoretical world.</p>
<p>What about the zero sum aspect?</p>
<p>How big of a constraint is that?</p>
<p>How big of a constraint is finite?</p>
<p>So finite&rsquo;s not a huge constraint.</p>
<p>So I mean, most games that you play are finite in size.</p>
<p>It&rsquo;s also true actually that there exists</p>
<p>this perfect strategy in many infinite games as well.</p>
<p>Technically, the game has to be compact.</p>
<p>There are some edge cases where you don&rsquo;t have</p>
<p>a Nash equilibrium in a two player zero sum game.</p>
<p>So you can think of a game where you&rsquo;re like,</p>
<p>if we&rsquo;re playing a game where whoever names</p>
<p>the bigger number is the winner,</p>
<p>there&rsquo;s no Nash equilibrium to that game.</p>
<p>17, okay.</p>
<p>18, I thought you beat.</p>
<p>You win again.</p>
<p>You&rsquo;re good at this.</p>
<p>I&rsquo;ve played a lot of games.</p>
<p>Okay, so that&rsquo;s, and then the zero sum aspect.</p>
<p>The zero sum.</p>
<p>The zero sum aspect.</p>
<p>There exists a Nash equilibrium</p>
<p>in non two player zero sum games as well.</p>
<p>And by the way, just to clarify what I mean</p>
<p>by two player zero sum, I mean there&rsquo;s two players</p>
<p>and whatever one player wins, the other player loses.</p>
<p>So if we&rsquo;re playing poker and I win $50,</p>
<p>that means that you&rsquo;re losing $50.</p>
<p>Now, outside of two player zero sum games,</p>
<p>there still exists Nash equilibria,</p>
<p>but they&rsquo;re not as meaningful.</p>
<p>Because you can think of a game like Risk.</p>
<p>If everybody else on the board decides to team up</p>
<p>against you and take you out,</p>
<p>there&rsquo;s no perfect strategy you can play</p>
<p>that&rsquo;s gonna guarantee that you win there.</p>
<p>There&rsquo;s just nothing you can do.</p>
<p>So outside of two player zero sum games,</p>
<p>there&rsquo;s no guarantee that you&rsquo;re going to win</p>
<p>by playing a Nash equilibrium.</p>
<p>Have you ever tried to model in the other aspects</p>
<p>of the game, which is like the pleasure you draw</p>
<p>from playing the game?</p>
<p>And then if you&rsquo;re a professional poker player,</p>
<p>if you&rsquo;re exciting, even if you lose,</p>
<p>you know, the money you would get from the attention</p>
<p>you get to the sponsors and all that kind of stuff,</p>
<p>is that, that&rsquo;d be a fun thing to model in.</p>
<p>Or is that make it sort of super complex</p>
<p>to include the human factor in this full complexity?</p>
<p>I think you bring up a couple of good points there.</p>
<p>So I think a lot of professional poker players,</p>
<p>I mean, they get a huge amount of money,</p>
<p>not from actually playing poker, but from the sponsorships</p>
<p>and having a personality that people want to tune in</p>
<p>and watch, that&rsquo;s a big way to make a name</p>
<p>for yourself in poker.</p>
<p>I just wonder from an AI perspective,</p>
<p>if you create, and we&rsquo;ll talk about this more,</p>
<p>maybe AI system that also talks trash</p>
<p>and all that kind of stuff,</p>
<p>that that becomes part of the function to maximize.</p>
<p>So it&rsquo;s not just optimal poker play.</p>
<p>Maybe sometimes you want to be chaotic.</p>
<p>Maybe sometimes you want to be suboptimal</p>
<p>and you lose the chaos.</p>
<p>And maybe sometimes you want to be overly aggressive</p>
<p>because the audience loves that.</p>
<p>That&rsquo;d be fascinating.</p>
<p>I think what you&rsquo;re getting at here</p>
<p>is that there&rsquo;s a difference between making an AI</p>
<p>that wins a game and an AI that&rsquo;s fun to play with.</p>
<p>Yeah.</p>
<p>Yeah.</p>
<p>Or fun to watch.</p>
<p>So those are all different things,</p>
<p>fun to play with and fun to watch.</p>
<p>Yeah.</p>
<p>And I think, I&rsquo;ve heard talks from game designers</p>
<p>and they say, people that work on AI</p>
<p>for actual recreational games that people play,</p>
<p>and they say, yeah, there&rsquo;s a big difference</p>
<p>between trying to make an AI that actually wins.</p>
<p>And you look at a game like Civilization,</p>
<p>the way that the AIs play is not optimal</p>
<p>for trying to win.</p>
<p>They&rsquo;re playing a different game.</p>
<p>They&rsquo;re trying to have personalities.</p>
<p>They&rsquo;re trying to be fun and engaging.</p>
<p>And that makes for a better game.</p>
<p>Yeah.</p>
<p>And we also talk about NPCs.</p>
<p>I just talked to Todd Howard,</p>
<p>who is the creator of Fallout and the Elder Scrolls series</p>
<p>and Starfield, the new game coming out.</p>
<p>And the creator, what I think is the greatest game</p>
<p>of all time, which is Skyrim and the NPCs there.</p>
<p>The AI that governs that whole game is very interesting,</p>
<p>but the NPCs also are super interesting.</p>
<p>And considering what language models might do</p>
<p>to NPCs in an open world RPG role-playing game</p>
<p>is super exciting.</p>
<p>Yeah.</p>
<p>Honestly, I think this is one of the first applications</p>
<p>where we&rsquo;re gonna see real consumer interaction</p>
<p>with large language models.</p>
<p>I guess Elder Scrolls VI is in development now.</p>
<p>They&rsquo;re probably pretty close to finishing it,</p>
<p>but I would not be surprised at all</p>
<p>if Elder Scrolls VII was using large language models</p>
<p>for their NPCs.</p>
<p>I mean, I&rsquo;m not saying anything, I&rsquo;m not saying anything.</p>
<p>Okay, this is me speculating, not you.</p>
<p>No, but they&rsquo;re just releasing the Starfield game.</p>
<p>They do one game at a time.</p>
<p>Yeah.</p>
<p>And so whatever it is, whenever the date is,</p>
<p>I don&rsquo;t know what the date is, calm down,</p>
<p>but it would be, I don&rsquo;t know, like 2024, 25, 26.</p>
<p>So it&rsquo;s actually very possible</p>
<p>they would include language models.</p>
<p>I was listening to this talk by a gaming executive</p>
<p>when I was in grad school.</p>
<p>And one of the questions that a person in the audience asked</p>
<p>is why are all these games so focused</p>
<p>on fighting and killing?</p>
<p>And the person responded that it&rsquo;s just so much harder</p>
<p>to make an AI that can talk with you and cooperate with you</p>
<p>than it is to make an AI that can fight you.</p>
<p>And I think once this technology develops further</p>
<p>and you can reach a point where like</p>
<p>not every single line of dialogue has to be scripted,</p>
<p>it unlocks a lot of potential for new kinds of games,</p>
<p>like much more like positive interactions</p>
<p>that are not so focused on fighting.</p>
<p>And I&rsquo;m really looking forward to that.</p>
<p>It might not be positive, it might be just drama.</p>
<p>So you&rsquo;ll be in like a call of duty game</p>
<p>and instead of doing the shooting,</p>
<p>you&rsquo;ll just be hanging out and like arguing with an AI</p>
<p>about like passive aggressive.</p>
<p>And then you won&rsquo;t be able to sleep that night.</p>
<p>You have to return or continue the argument</p>
<p>that you were emotionally hurt.</p>
<p>I mean, yeah, I think that&rsquo;s actually an exciting world.</p>
<p>Whatever is the drama, the chaos that we love,</p>
<p>the push and pull of human connection,</p>
<p>I think it&rsquo;s possible to do that in the video game world.</p>
<p>And I think you could be messier</p>
<p>and make more mistakes in a video game world,</p>
<p>which is why it would be a nice place.</p>
<p>And also it doesn&rsquo;t have a deep of a,</p>
<p>as deep of a real psychological impact</p>
<p>because inside video games,</p>
<p>it&rsquo;s kind of understood that you&rsquo;re in a not a real world.</p>
<p>So whatever crazy stuff AI does,</p>
<p>we have some flexibility to play.</p>
<p>Just like with a game of diplomacy, it&rsquo;s a game.</p>
<p>This is not real geopolitics, not real war, it&rsquo;s a game.</p>
<p>So you can have a little bit of fun, a little bit of chaos.</p>
<p>Okay, back to Nash equilibrium.</p>
<p>How do we find the Nash equilibrium?</p>
<p>All right, so there&rsquo;s different ways</p>
<p>to find a Nash equilibrium.</p>
<p>So the way that we do it</p>
<p>is with this process called self-play.</p>
<p>Basically we have this algorithm</p>
<p>that starts by playing totally randomly</p>
<p>and it learns how to play the game by playing against itself.</p>
<p>So it will start playing the game totally randomly.</p>
<p>And then if it&rsquo;s playing poker,</p>
<p>it&rsquo;ll eventually get to the end of the game and make $50.</p>
<p>And then it will review all of the decisions</p>
<p>that it made along the way and say,</p>
<p>what would have happened</p>
<p>if I had chosen this other action instead?</p>
<p>If I had raised here instead of called,</p>
<p>what would the other player have done?</p>
<p>And because it&rsquo;s playing against a copy of itself,</p>
<p>it&rsquo;s able to do that counterfactual reasoning.</p>
<p>So it can say, okay, well, if I took this action</p>
<p>and the other person takes this action</p>
<p>and then I take this action</p>
<p>and eventually I make $150 instead of 50.</p>
<p>And so it updates the regret value for that action.</p>
<p>Regret is basically like how much does it regret</p>
<p>having not played that action in the past?</p>
<p>And when it encounters that same situation again,</p>
<p>it&rsquo;s going to pick actions that have higher regret</p>
<p>with higher probability.</p>
<p>Now, it&rsquo;ll just keep simulating the games this way.</p>
<p>It&rsquo;ll keep accumulating regrets for different situations.</p>
<p>And in the long run,</p>
<p>if you pick actions that have higher regret</p>
<p>with higher probability in the correct way,</p>
<p>it&rsquo;s proven to converge to a Nash equilibrium.</p>
<p>Even for super complex games?</p>
<p>Even for imperfect information games?</p>
<p>It&rsquo;s true for all games.</p>
<p>It&rsquo;s true for chess.</p>
<p>It&rsquo;s true for poker.</p>
<p>It&rsquo;s particularly useful for poker.</p>
<p>So this is the method</p>
<p>of counterfactual regret minimization?</p>
<p>This is counterfactual regret minimization.</p>
<p>That doesn&rsquo;t have to do with self-play,</p>
<p>it has to do with just any,</p>
<p>if you follow this kind of process, self-play or not,</p>
<p>you will be able to arrive at an optimal set of actions.</p>
<p>So this counterfactual regret minimization</p>
<p>is a kind of self-play.</p>
<p>It&rsquo;s a principled kind of self-play</p>
<p>that&rsquo;s proven to converge to Nash equilibria,</p>
<p>even in imperfect information games.</p>
<p>Now you can have other forms of self-play</p>
<p>and people use other forms of self-play</p>
<p>for perfect information games,</p>
<p>where you have more flexibility,</p>
<p>the algorithm doesn&rsquo;t have to be as theoretically sound</p>
<p>in order to converge to that class of games</p>
<p>because it&rsquo;s a simpler setting.</p>
<p>Sure, so I kind of, in my brain,</p>
<p>the word self-play has mapped to neural networks,</p>
<p>but we&rsquo;re speaking something bigger</p>
<p>than just neural networks.</p>
<p>It could be anything.</p>
<p>The self-play mechanism</p>
<p>is just the mechanism of a system playing itself.</p>
<p>Exactly, yeah.</p>
<p>Self-play is not tied specifically to neural nets.</p>
<p>It&rsquo;s a kind of reinforcement learning, basically.</p>
<p>And I would also say this process of trying to reason,</p>
<p>oh, what would the value have been</p>
<p>if I had taken this other action instead?</p>
<p>This is very similar to how humans learn</p>
<p>to play a game like poker.</p>
<p>You probably played poker before,</p>
<p>and with your friends, you probably ask,</p>
<p>oh, what do you have called me if I raise there?</p>
<p>And that&rsquo;s a person trying to do the same kind of</p>
<p>learning from a counterfactual that the AI is doing.</p>
<p>Okay, and if you do that at scale,</p>
<p>you&rsquo;re gonna be able to learn an optimal policy.</p>
<p>Yeah, now where the neural nets come in,</p>
<p>I said, okay, if it&rsquo;s in that situation again,</p>
<p>then it will choose the action that has high regret.</p>
<p>Now, the problem is that poker is such a huge game.</p>
<p>I think No Limit Texas Hold&rsquo;em,</p>
<p>the version that we were playing,</p>
<p>has 10 to the 161 different decision points,</p>
<p>which is more than the number of atoms</p>
<p>in the universe squared.</p>
<p>That&rsquo;s heads up?</p>
<p>That&rsquo;s heads up, yeah.</p>
<p>10 to the 161, you said?</p>
<p>Yeah, I mean, it depends on the number of chips</p>
<p>that you have, the stacks and everything,</p>
<p>but the version that we were playing was 10 to the 161.</p>
<p>Which I assume would be a somewhat simplified version anyway</p>
<p>because I bet there&rsquo;s some step function</p>
<p>you had for bets.</p>
<p>Oh, no, no, no.</p>
<p>I&rsquo;m saying we played the full game.</p>
<p>You can bet whatever amount you want.</p>
<p>Now, the bot maybe was constrained</p>
<p>in what it considered for bet sizes,</p>
<p>but the person on the other side</p>
<p>could bet whatever they wanted.</p>
<p>Yeah, I mean, 161 plus or minus 10, doesn&rsquo;t matter.</p>
<p>And so the way neural nets help out here</p>
<p>is you don&rsquo;t have to run into the same exact situation</p>
<p>because that&rsquo;s never gonna happen again.</p>
<p>The odds of you running into the same exact situation</p>
<p>are pretty slim, but if you run into a similar situation,</p>
<p>then you can generalize from other states</p>
<p>that you&rsquo;ve been in that kind of look like that one,</p>
<p>and you can say like, well, these other situations,</p>
<p>I had high regret for this action,</p>
<p>and so maybe I should play that action here as well.</p>
<p>Which is the more complex game, chess or poker,</p>
<p>or go or poker, do you know?</p>
<p>That is a controversial question.</p>
<p>Okay.</p>
<p>I&rsquo;m gonna-</p>
<p>It&rsquo;s like somebody&rsquo;s screaming on Reddit right now.</p>
<p>It depends on which subreddit you&rsquo;re on.</p>
<p>Is it chess or is it poker?</p>
<p>I&rsquo;m sure David Silver&rsquo;s gonna get really angry at me.</p>
<p>I&rsquo;ll say, I&rsquo;m gonna say poker actually,</p>
<p>and I think for a couple of reasons.</p>
<p>They&rsquo;re not here to defend themselves.</p>
<p>So first of all,</p>
<p>you have the imperfect information aspect,</p>
<p>and so it&rsquo;s, we can go into that,</p>
<p>but like once you introduce imperfect information,</p>
<p>things get much more complicated.</p>
<p>So we should say, maybe you can describe</p>
<p>what is seen to the players,</p>
<p>what is not seen in the game of Texas Hold&rsquo;em.</p>
<p>Yeah, so Texas Hold&rsquo;em,</p>
<p>you get two cards face down that only you see.</p>
<p>And so that&rsquo;s the hidden information of the game.</p>
<p>The other players also all get two cards face down</p>
<p>that only they see.</p>
<p>And so you have to kind of, as you&rsquo;re playing,</p>
<p>reason about like, okay, what do they think I have?</p>
<p>What do they have?</p>
<p>What do they think I think they have?</p>
<p>That kind of stuff.</p>
<p>And that&rsquo;s kind of where bluffing comes into play, right?</p>
<p>Because the fact that you can bluff,</p>
<p>the fact that you can bet with a bad hand and still win</p>
<p>is because they don&rsquo;t know what your cards are.</p>
<p>And that&rsquo;s the key difference</p>
<p>between a perfect information game like chess and go</p>
<p>and imperfect information games like poker.</p>
<p>This is what trash talk looks like.</p>
<p>The implied statement is the game I solved is much tougher.</p>
<p>But yeah, so when you&rsquo;re playing,</p>
<p>I&rsquo;m just gonna do random questions here.</p>
<p>So when you&rsquo;re playing your opponent</p>
<p>under imperfect information,</p>
<p>is there some degree to which you&rsquo;re trying</p>
<p>to estimate the range of hands that they have?</p>
<p>Or is that not part of the algorithm?</p>
<p>So what are the different approaches</p>
<p>to the imperfect information game?</p>
<p>So the key thing to understand</p>
<p>about why imperfect information makes things difficult</p>
<p>is that you have to worry</p>
<p>not just about which actions to play,</p>
<p>but the probability that you&rsquo;re gonna play those actions.</p>
<p>So you think about Rock, Paper, Scissors, for example.</p>
<p>Rock, Paper, Scissors is an imperfect information game.</p>
<p>Because you don&rsquo;t know what I&rsquo;m about to throw.</p>
<p>I do, but yeah, usually not, yeah.</p>
<p>And so you can&rsquo;t just say like,</p>
<p>oh, I&rsquo;m just gonna throw a rock every single time</p>
<p>because the other person&rsquo;s gonna figure that out</p>
<p>and notice a pattern</p>
<p>and then suddenly you&rsquo;re gonna start losing.</p>
<p>And so you don&rsquo;t just have to figure out</p>
<p>like which action to play,</p>
<p>you have to figure out the probability that you play it.</p>
<p>And really importantly, the value of an action</p>
<p>depends on the probability that you&rsquo;re gonna play it.</p>
<p>So if you&rsquo;re playing Rock every single time,</p>
<p>that value is really low.</p>
<p>But if you&rsquo;re never playing Rock,</p>
<p>you play Rock like 1% of the time,</p>
<p>then suddenly the other person</p>
<p>is probably gonna be throwing scissors.</p>
<p>And when you throw a rock,</p>
<p>the value of that action is gonna be really high.</p>
<p>Now you take that to poker,</p>
<p>what that means is the value of bluffing, for example.</p>
<p>If you&rsquo;re the kind of person that never bluffs</p>
<p>and you have this reputation as somebody that never bluffs,</p>
<p>and suddenly you bluff,</p>
<p>there&rsquo;s a really good chance that that bluff is gonna work</p>
<p>and you&rsquo;re gonna make a lot of money.</p>
<p>On the other hand, if you got a reputation,</p>
<p>like if they&rsquo;ve seen you play for a long time</p>
<p>and they see, oh, you&rsquo;re the kind of person</p>
<p>that&rsquo;s bluffing all the time,</p>
<p>when you bluff, they&rsquo;re not gonna buy it</p>
<p>and they&rsquo;re gonna call you down</p>
<p>and you&rsquo;re gonna lose a lot of money.</p>
<p>And that, finding that balance</p>
<p>of how often you should be bluffing</p>
<p>is the key challenge of a game of poker.</p>
<p>And you contrast that with a game like chess.</p>
<p>It doesn&rsquo;t matter if you&rsquo;re opening with the Queen&rsquo;s Gambit</p>
<p>10% of the time or 100% of the time.</p>
<p>The value, the expected value is the same.</p>
<p>So, that&rsquo;s why we need these algorithms</p>
<p>that understand not just we have to figure out</p>
<p>what actions are good, but the probabilities.</p>
<p>We need to get the exact probabilities correct.</p>
<p>And that&rsquo;s actually, when we created the bot Libratus,</p>
<p>Libratus means balanced</p>
<p>because the algorithm that we designed</p>
<p>was designed to find that right balance</p>
<p>of how often it should play each action.</p>
<p>The balance of how often in the key sort of branching</p>
<p>is the bluff or not the bluff.</p>
<p>Is that a good crude simplification</p>
<p>of the major decision in poker?</p>
<p>It&rsquo;s a good simplification.</p>
<p>I think that&rsquo;s like the main tension,</p>
<p>but it&rsquo;s not just how often to bluff or not to bluff.</p>
<p>It&rsquo;s like, how often should you bet in general?</p>
<p>How often should you, what kind of bet should you make?</p>
<p>Should you bet big or should you bet small?</p>
<p>And with which hands?</p>
<p>And so, this is where the idea of a range comes from.</p>
<p>Because when you&rsquo;re bluffing with a particular hand</p>
<p>in a particular spot, you don&rsquo;t want there to be a pattern</p>
<p>for the other person to pick up on.</p>
<p>You don&rsquo;t want them to figure out,</p>
<p>oh, whenever this person is in this spot,</p>
<p>they&rsquo;re always bluffing.</p>
<p>And so, you have to reason about,</p>
<p>okay, would I also bet with a good hand in this spot?</p>
<p>You wanna be unpredictable.</p>
<p>So, you have to think about,</p>
<p>what would I do if I had this different set of cards?</p>
<p>Is there explicit estimation of like a theory of mind</p>
<p>that the other person has about you?</p>
<p>Or is that just a emergent thing that happens?</p>
<p>The way that the bots handle it, that are really successful,</p>
<p>they have an explicit theory of mind.</p>
<p>So, they&rsquo;re explicitly reasoning about what are,</p>
<p>what&rsquo;s the common knowledge belief?</p>
<p>What do you think I have?</p>
<p>What do I think you have?</p>
<p>What do you think I think you have?</p>
<p>It&rsquo;s explicitly reasoning about that.</p>
<p>Is there multiple yous there?</p>
<p>So, maybe that&rsquo;s jumping ahead to six players,</p>
<p>but is there a stickiness to the person?</p>
<p>So, it&rsquo;s an iterative game.</p>
<p>You&rsquo;re playing the same person.</p>
<p>There&rsquo;s a stickiness to that, right?</p>
<p>You&rsquo;re gathering information as you play.</p>
<p>It&rsquo;s not every hand is a new hand.</p>
<p>Is there a continuation in terms of estimating</p>
<p>what kind of player I&rsquo;m facing here?</p>
<p>That&rsquo;s a good question.</p>
<p>So, you could approach the game that way.</p>
<p>The way that the bots do it, they don&rsquo;t,</p>
<p>and the way that humans approach it also,</p>
<p>expert human players, the way they approach it</p>
<p>is to basically assume that you know my strategy.</p>
<p>So, I&rsquo;m going to try to pick a strategy</p>
<p>where even if I were to play it for 10,000 hands</p>
<p>and you could figure out exactly what it was,</p>
<p>you still wouldn&rsquo;t be able to beat it.</p>
<p>Basically, what that means is I&rsquo;m trying</p>
<p>to approximate the Nash equilibrium.</p>
<p>I&rsquo;m trying to be perfectly balanced</p>
<p>because if I&rsquo;m playing the Nash equilibrium,</p>
<p>even if you know what my strategy is,</p>
<p>like I said, I&rsquo;m still unbeatable in expectation.</p>
<p>So, that&rsquo;s what the bot aims for.</p>
<p>That&rsquo;s actually what a lot</p>
<p>of expert poker players aim for as well,</p>
<p>to start by playing the Nash equilibrium,</p>
<p>and then maybe if they spot weaknesses</p>
<p>in the way you&rsquo;re playing,</p>
<p>then they can deviate a little bit</p>
<p>to take advantage of that.</p>
<p>They aim to be unbeatable in expectation.</p>
<p>Okay, so who&rsquo;s the greatest poker player of all time</p>
<p>and why is it Phil Hellmuth?</p>
<p>So, this is for Phil.</p>
<p>So, he&rsquo;s known, at least in part,</p>
<p>for maybe playing suboptimally,</p>
<p>and he still wins a lot.</p>
<p>It&rsquo;s a bit chaotic.</p>
<p>So, maybe, can you speak from an AI perspective</p>
<p>about the genius of his madness</p>
<p>or the madness of his genius?</p>
<p>So, playing suboptimally, playing chaotically</p>
<p>as a way to make you hard to pin down</p>
<p>about what your strategy is.</p>
<p>So, okay, the thing that I should explain first of all</p>
<p>with Nash equilibrium,</p>
<p>it doesn&rsquo;t mean that it&rsquo;s predictable.</p>
<p>The whole point of it is</p>
<p>that you&rsquo;re trying to be unpredictable.</p>
<p>Now, I think when somebody like Phil Hellmuth</p>
<p>might be really successful</p>
<p>is not in being unpredictable,</p>
<p>but in being able to take advantage of the other player</p>
<p>and figure out where they&rsquo;re being predictable</p>
<p>or guiding the other player into thinking</p>
<p>that you have certain weaknesses</p>
<p>and then understanding how they&rsquo;re going</p>
<p>to change their behavior.</p>
<p>They&rsquo;re gonna deviate from a Nash equilibrium style of play</p>
<p>to try to take advantage of those perceived weaknesses</p>
<p>and then counter exploit them.</p>
<p>So, you kind of get into the mind games there.</p>
<p>So, you think about these heads up poker</p>
<p>as a dance between two agents.</p>
<p>I guess, are you playing the cards</p>
<p>or are you playing the player?</p>
<p>So, this gets down to a big argument</p>
<p>in the poker community and the academic community.</p>
<p>For a long time, there was this debate of like</p>
<p>what&rsquo;s called GTO, game theory optimal poker,</p>
<p>or exploitative play.</p>
<p>And up until about like 2017,</p>
<p>when we did the Labradors match,</p>
<p>I think actually exploitative play had the advantage.</p>
<p>A lot of people were saying like,</p>
<p>oh, this whole idea of game theory, it&rsquo;s just nonsense.</p>
<p>And if you really wanna make money,</p>
<p>you gotta like look into the other person&rsquo;s eyes</p>
<p>and read their soul and figure out what cards they have.</p>
<p>But what happened was people started adopting</p>
<p>the game theory optimal strategy</p>
<p>and they were making good money.</p>
<p>And they weren&rsquo;t trying to adapt so much to the other player.</p>
<p>They were just trying to play the Nash equilibrium.</p>
<p>And then what really solidified it, I think,</p>
<p>was the Labradors match,</p>
<p>where we played our bot against four top heads up,</p>
<p>no limit Hold&rsquo;em poker players.</p>
<p>And the bot wasn&rsquo;t trying to adapt to them.</p>
<p>It wasn&rsquo;t trying to exploit them.</p>
<p>It wasn&rsquo;t trying to do these mind games.</p>
<p>It was just trying to approximate the Nash equilibrium</p>
<p>and it crushed them.</p>
<p>I think, you know, we were playing for $50, $100 blinds.</p>
<p>And over the course of about 120,000 hands,</p>
<p>it made close to $2 million.</p>
<p>120,000 hands.</p>
<p>120,000 hands.</p>
<p>Against humans.</p>
<p>Yeah, and this was fake money to be clear.</p>
<p>So there was real money at stake.</p>
<p>There was $200,000.</p>
<p>First of all, all money is fake.</p>
<p>But that&rsquo;s a different conversation.</p>
<p>We give it meaning.</p>
<p>It&rsquo;s a phenomenon that gets meaning</p>
<p>from our complex psychology as a human civilization.</p>
<p>It&rsquo;s emerging from the collective intelligence</p>
<p>of the human species.</p>
<p>But that&rsquo;s not what you mean.</p>
<p>You mean like there&rsquo;s literally,</p>
<p>you can&rsquo;t buy stuff with it.</p>
<p>Okay, can you actually step back</p>
<p>and take me through that competition?</p>
<p>Yeah, okay.</p>
<p>So when I was in grad school,</p>
<p>there was this thing called</p>
<p>the Annual Computer Poker Competition,</p>
<p>where every year all the different research labs</p>
<p>that were working on AI for poker would get together.</p>
<p>They would make a bot.</p>
<p>They would play them against each other.</p>
<p>And we made a bot that actually won</p>
<p>the 2014 competition, the 2016 competition.</p>
<p>And so we decided we&rsquo;re gonna take this bot, build on it,</p>
<p>and play against real top professional</p>
<p>heads up no limit Texas Hold&rsquo;em poker players.</p>
<p>So we invited four of the world&rsquo;s best players</p>
<p>in this specialty.</p>
<p>And we challenged them to 120,000 hands of poker</p>
<p>over the course of 20 days.</p>
<p>And we had $200,000 in prize money at stake,</p>
<p>where it would basically be divided among them</p>
<p>depending on how well they did relative to each other.</p>
<p>So we wanted to have some incentive</p>
<p>for them to play their best.</p>
<p>Did you have a confidence, 2014, 16,</p>
<p>that this is even possible?</p>
<p>How much doubt was there?</p>
<p>We did a competition actually in 2015</p>
<p>where we also played against professional poker players</p>
<p>and the bot lost by a pretty sizable margin actually.</p>
<p>Now there were some big improvements from 2015 to 2017.</p>
<p>And so-</p>
<p>Can you speak to the improvements?</p>
<p>Is it computational in nature?</p>
<p>Is it the algorithm, the methods?</p>
<p>It was really an algorithmic approach.</p>
<p>That was the difference.</p>
<p>So 2015, it was much more focused</p>
<p>on trying to come up with a strategy upfront,</p>
<p>like trying to solve the entire game of poker</p>
<p>and then just have a lookup table</p>
<p>where you&rsquo;re saying like,</p>
<p>oh, I&rsquo;m in this situation, what&rsquo;s the strategy?</p>
<p>The approach that we took in 2017</p>
<p>was much more search-based.</p>
<p>It was trying to say, okay, well,</p>
<p>let me in real time try to compute a much better strategy</p>
<p>than what I had pre-computed</p>
<p>by playing against myself during self-play.</p>
<p>What is the search space for poker?</p>
<p>What are you searching over?</p>
<p>What&rsquo;s that look like?</p>
<p>There&rsquo;s different actions like raising, calling.</p>
<p>Yeah, what are the actions?</p>
<p>Is it just a search over actions?</p>
<p>So in a game like chess, the search is like,</p>
<p>okay, I&rsquo;m in this chess position</p>
<p>and I can move these different pieces</p>
<p>and see where things end up.</p>
<p>In poker, what you&rsquo;re searching over</p>
<p>is the actions that you can take for your hand,</p>
<p>the probabilities that you take those actions,</p>
<p>and then also the probabilities</p>
<p>that you take other actions</p>
<p>with other hands that you might have.</p>
<p>And that&rsquo;s hard to wrap your head around.</p>
<p>Why are you searching over these other hands</p>
<p>that you might have and trying to figure out</p>
<p>what you would do with those hands?</p>
<p>And the idea is, again,</p>
<p>you wanna always be balanced and unpredictable.</p>
<p>And so if your search algorithm is saying,</p>
<p>oh, I want to raise with this hand,</p>
<p>well, in order to know whether that&rsquo;s a good action,</p>
<p>let&rsquo;s say it&rsquo;s a bluff.</p>
<p>Let&rsquo;s say you have a bad hand and you&rsquo;re saying,</p>
<p>oh, I think I should be betting here</p>
<p>with this really bad hand and bluffing.</p>
<p>Well, that&rsquo;s only a good action</p>
<p>if you&rsquo;re also betting with a strong hand.</p>
<p>Otherwise, it&rsquo;s an obvious bluff.</p>
<p>So if your action in some sense</p>
<p>maximizes your unpredictability,</p>
<p>so that action could be mapped by your opponent</p>
<p>to a lot of different hands,</p>
<p>then that&rsquo;s a good action.</p>
<p>Basically, what you wanna do</p>
<p>is put your opponent into a tough spot.</p>
<p>So you want them to always have some doubt,</p>
<p>like, should I call here?</p>
<p>Should I fold here?</p>
<p>And if you are raising in the appropriate balance</p>
<p>between bluffs and good hands,</p>
<p>then you&rsquo;re putting them into that tough spot.</p>
<p>And so that&rsquo;s what we&rsquo;re trying to do.</p>
<p>We&rsquo;re always trying to search for a strategy</p>
<p>that would put the opponent into a difficult position.</p>
<p>Can you give a metric</p>
<p>that you&rsquo;re trying to maximize or minimize?</p>
<p>Does this have to do with the regret thing</p>
<p>that we&rsquo;re talking about</p>
<p>in terms of putting your opponent in a maximally tough spot?</p>
<p>Yeah, ultimately what you&rsquo;re trying to maximize</p>
<p>is your expected winnings, like your expected value,</p>
<p>the amount of money that you&rsquo;re gonna walk away from,</p>
<p>assuming that your opponent</p>
<p>was playing optimally in response.</p>
<p>So you&rsquo;re gonna assume that your opponent</p>
<p>is also playing as well as possible</p>
<p>a Nash equilibrium approach,</p>
<p>because if they&rsquo;re not,</p>
<p>then you&rsquo;re just gonna make more money, right?</p>
<p>Like anything that deviates,</p>
<p>like by definition, the Nash equilibrium</p>
<p>is the strategy that does the best in expectation.</p>
<p>And so if you&rsquo;re deviating from that,</p>
<p>then you&rsquo;re just, they&rsquo;re gonna lose money.</p>
<p>And since it&rsquo;s a two-player zero-sum game,</p>
<p>that means you&rsquo;re gonna make money.</p>
<p>So there&rsquo;s not an explicit, like objective function</p>
<p>that maximizes the toughness of the spot they&rsquo;re put in.</p>
<p>You&rsquo;re always, this is from like</p>
<p>a self-play reinforcement learning perspective.</p>
<p>You&rsquo;re just trying to maximize winnings.</p>
<p>And the rest is implicit.</p>
<p>That&rsquo;s right, yeah.</p>
<p>So what we&rsquo;re actually trying to maximize</p>
<p>is the expected value,</p>
<p>given that the opponent is playing optimally</p>
<p>in response to us.</p>
<p>Now in practice, what that ends up looking like</p>
<p>is it&rsquo;s putting the opponent into difficult situations</p>
<p>where there&rsquo;s no obvious decision to be made.</p>
<p>So the system doesn&rsquo;t know anything</p>
<p>about the difficulty of the situation?</p>
<p>Not at all, doesn&rsquo;t care.</p>
<p>Okay.</p>
<p>In my head, it was getting excited</p>
<p>whenever I was making the opponent sweat.</p>
<p>Okay, so you&rsquo;re, in 2015, you didn&rsquo;t do as well.</p>
<p>So what&rsquo;s the journey from that to a system</p>
<p>that in your mind could have a chance?</p>
<p>So 2015, we got, we beat pretty badly.</p>
<p>And we actually learned a lot from that competition.</p>
<p>And in particular, what became clear to me</p>
<p>is that the way the humans were approaching the game</p>
<p>was very different from how the bot</p>
<p>was approaching the game.</p>
<p>The bot would not be doing search.</p>
<p>It would just be trying to compute,</p>
<p>it would do like months of self-play.</p>
<p>It would just be playing against itself for months,</p>
<p>but then when it&rsquo;s actually playing the game,</p>
<p>it would just act instantly.</p>
<p>And the humans, when they&rsquo;re in a tough spot,</p>
<p>they would sit there and think</p>
<p>for sometimes even like five minutes</p>
<p>about whether they&rsquo;re gonna call or fold a hand.</p>
<p>And it became clear to me that that&rsquo;s,</p>
<p>there&rsquo;s a good chance that that&rsquo;s what&rsquo;s missing</p>
<p>from our bot.</p>
<p>So I actually did some initial experiments</p>
<p>to try to figure out how much of a difference</p>
<p>does this actually make?</p>
<p>And the difference was huge.</p>
<p>As a signal to the human player,</p>
<p>how long you took to think?</p>
<p>No, no, no, I&rsquo;m not saying that there were any timing tells.</p>
<p>I was saying when the human,</p>
<p>like the bot would always act instantly.</p>
<p>It wouldn&rsquo;t try to come up with a better strategy</p>
<p>in real time over what it had pre-computed during training.</p>
<p>Whereas the human, like they have all this intuition</p>
<p>about how to play, but they&rsquo;re also in real time</p>
<p>leveraging their ability to think, to search, to plan,</p>
<p>and coming up with an even better strategy</p>
<p>than what their intuition would say.</p>
<p>So you&rsquo;re saying that there&rsquo;s,</p>
<p>you&rsquo;re doing, that&rsquo;s what you mean by</p>
<p>you&rsquo;re doing search also.</p>
<p>You have an intuition and search on top of that</p>
<p>looking for a better solution.</p>
<p>Yeah, that&rsquo;s what I mean by search,</p>
<p>that instead of acting instantly,</p>
<p>a neural net usually gives you a response</p>
<p>in like 100 milliseconds or something.</p>
<p>It depends on the size of the net.</p>
<p>But if you can leverage extra computational resources,</p>
<p>you can possibly get a much better outcome.</p>
<p>And we did some experiments</p>
<p>in small-scale versions of poker.</p>
<p>And what we found was that if you do a little bit of search,</p>
<p>even just a little bit,</p>
<p>it was the equivalent of making your pre-computed strategy,</p>
<p>like you can kind of think of it as your neural net,</p>
<p>a thousand times bigger,</p>
<p>with just a little bit of search.</p>
<p>And it just like blew away all of the research</p>
<p>that we had been working on</p>
<p>and trying to like scale up this like pre-computed solution.</p>
<p>It was dwarfed by the benefit that we got from search.</p>
<p>Can you just linger on what you mean by search here?</p>
<p>You&rsquo;re searching over a space of actions</p>
<p>for your hand and for other hands.</p>
<p>How are you selecting the other hands to search over?</p>
<p>Is it randomly?</p>
<p>No, it&rsquo;s all the other hands that you could have.</p>
<p>So when you&rsquo;re playing No Limit Texas Hold&rsquo;em,</p>
<p>you&rsquo;ve got two face down cards.</p>
<p>And so that&rsquo;s 52 choose two, 1,326 different combinations.</p>
<p>Now that&rsquo;s actually a little bit lower</p>
<p>because there&rsquo;s face up cards in the middle</p>
<p>and so you can eliminate those as well.</p>
<p>But you&rsquo;re looking at like around a thousand</p>
<p>different possible hands that you can have.</p>
<p>And so when we&rsquo;re doing, when the bot&rsquo;s doing search,</p>
<p>it&rsquo;s thinking explicitly,</p>
<p>there are these thousand different hands that I could have.</p>
<p>There are these thousand different hands that you could have.</p>
<p>Let me try to figure out what would be a better strategy</p>
<p>than what I&rsquo;ve pre-computed for these hands and your hands.</p>
<p>Okay, so that search,</p>
<p>how do you fuse that with what the neural net is telling you</p>
<p>or what the train system is telling you?</p>
<p>Yeah, so you kind of like where the train system comes in</p>
<p>is the value at the end.</p>
<p>So there&rsquo;s, you only look so far ahead.</p>
<p>You look like maybe one round ahead.</p>
<p>So if you&rsquo;re on the flop,</p>
<p>you&rsquo;re looking to the start of the turn.</p>
<p>And at that point you can use the pre-computed solution</p>
<p>to figure out what&rsquo;s the value here of this strategy.</p>
<p>Is it of a single action essentially in that spot?</p>
<p>You&rsquo;re getting a value</p>
<p>or is it the value of the entire series of actions?</p>
<p>Well, it&rsquo;s kind of both</p>
<p>because you&rsquo;re trying to maximize the value</p>
<p>for the hand that you have.</p>
<p>But in the process,</p>
<p>in order to maximize the value of the hand that you have,</p>
<p>you have to figure out what would I be doing</p>
<p>with all these other hands as well.</p>
<p>Okay, but are you in the search</p>
<p>or was going to the end of the game?</p>
<p>In Libratus, we did.</p>
<p>So we only use search starting on the turn.</p>
<p>And then we searched all the way to the end of the game.</p>
<p>The turn, the river.</p>
<p>Can we take it through the terminology?</p>
<p>Yeah, there&rsquo;s four rounds of poker.</p>
<p>So there&rsquo;s the pre-flop, the flop, the turn and the river.</p>
<p>And so we would start doing search halfway through the game.</p>
<p>Now the first half of the game, that was all pre-computed.</p>
<p>It would just act instantly.</p>
<p>And then when it got to the halfway point,</p>
<p>then it would always search to the end of the game.</p>
<p>Now we later improved this.</p>
<p>So it wouldn&rsquo;t have to search all the way</p>
<p>to the end of the game.</p>
<p>It would actually search just a few moves ahead.</p>
<p>But that came later and that drastically reduced</p>
<p>the amount of computational resources that we needed.</p>
<p>But the moves,</p>
<p>because you can keep betting on top of each other.</p>
<p>That&rsquo;s what you mean by moves.</p>
<p>So like that&rsquo;s where you don&rsquo;t just get one bet</p>
<p>per turn of poker.</p>
<p>You can have multiple arbitrary number of bets, right?</p>
<p>I&rsquo;m trying to think like I&rsquo;m going to bet.</p>
<p>And then what are you going to do in response?</p>
<p>Are you going to raise me?</p>
<p>Are you going to call?</p>
<p>And then if you raise, what should I do?</p>
<p>So it&rsquo;s reasoning about that whole process</p>
<p>up until the end of the game in the case of Libratus.</p>
<p>So for Libratus,</p>
<p>what&rsquo;s the most number of re-raises have you ever seen?</p>
<p>You probably cap out at like five or something</p>
<p>because at that point you&rsquo;re basically all in.</p>
<p>I mean, is there like interesting patterns like that</p>
<p>that you&rsquo;ve seen that the game does?</p>
<p>You&rsquo;ll have like AlphaZero doing way more sacrifices</p>
<p>than humans usually do.</p>
<p>Is there something like Libratus was constantly re-raising</p>
<p>or something like that that you&rsquo;ve noticed?</p>
<p>There was something really interesting</p>
<p>that we observed with Libratus.</p>
<p>So humans, when they&rsquo;re playing poker,</p>
<p>they usually size their bets relative</p>
<p>to the size of the pot.</p>
<p>So if the pot has $100 in there,</p>
<p>maybe you bet like $75 or somewhere around there,</p>
<p>somewhere between like 50 and $100.</p>
<p>And with Libratus,</p>
<p>we gave it the option to basically bet whatever it wanted.</p>
<p>It was actually really easy for us to say like,</p>
<p>oh, if you want, you can bet like 10 times the pot.</p>
<p>And we didn&rsquo;t think it would actually do that.</p>
<p>It was just like, why not give it the option?</p>
<p>And then during the competition,</p>
<p>it actually started doing this.</p>
<p>And by the way, this is like a very last minute decision</p>
<p>on our part to add this option.</p>
<p>And so we did not think the bot would do this.</p>
<p>And I was actually kind of worried</p>
<p>when it did start to do this, like, oh, is this a problem?</p>
<p>Like humans don&rsquo;t do this.</p>
<p>Like, is it screwing up?</p>
<p>But it would put the humans into really difficult spots</p>
<p>when it would do that.</p>
<p>Because, you know, you could imagine like,</p>
<p>you have the second best hand that&rsquo;s possible</p>
<p>given the board and you&rsquo;re thinking like,</p>
<p>oh, you&rsquo;re in a really great spot here.</p>
<p>And suddenly the bot bets $20,000 into a $1,000 pot.</p>
<p>And it&rsquo;s basically saying like,</p>
<p>I have the best hand or I&rsquo;m bluffing.</p>
<p>And you having the second best hand,</p>
<p>like now you get a really tough choice to make.</p>
<p>And so the humans would sometimes think like</p>
<p>five or 10 minutes about like, what do you do?</p>
<p>Should I call?</p>
<p>Should I fold?</p>
<p>And when I saw the humans like really struggling</p>
<p>with that decision, like that&rsquo;s when I realized like,</p>
<p>oh, actually this is maybe a good thing to do after all.</p>
<p>And of course the system doesn&rsquo;t know that it&rsquo;s making,</p>
<p>again, like we said, that it&rsquo;s putting them in a tough spot.</p>
<p>It&rsquo;s just, that&rsquo;s part of the optimal,</p>
<p>the game theory optimal.</p>
<p>Right, from the bot&rsquo;s perspective,</p>
<p>it&rsquo;s just doing the thing</p>
<p>that&rsquo;s going to make it the most money.</p>
<p>And the fact that it&rsquo;s putting the humans</p>
<p>in a difficult spot,</p>
<p>like that&rsquo;s just a side effect of that.</p>
<p>And this was, I think the one thing,</p>
<p>I mean, there were a few things</p>
<p>that the humans walked away from,</p>
<p>but this was the number one thing</p>
<p>that the humans walked away from the competition saying like,</p>
<p>we need to start doing this.</p>
<p>And now these over bets, what are called over bets,</p>
<p>have become really common in high-level poker play.</p>
<p>Have you ever talked to somebody like Daniel Negreanu</p>
<p>about this?</p>
<p>He seems to be a student of the game.</p>
<p>I did actually have a conversation</p>
<p>with Daniel Negreanu once, yeah.</p>
<p>I was visiting the Isle of Man</p>
<p>to talk to poker stars about AI.</p>
<p>And Daniel Negreanu was there</p>
<p>when we had dinner together with some other people.</p>
<p>And yeah, he was really interested in it.</p>
<p>He mentioned that he was excited</p>
<p>about learning from these AIs.</p>
<p>So he wasn&rsquo;t scared, he was excited.</p>
<p>He was excited.</p>
<p>And he honestly, he wanted to play against the bot.</p>
<p>He thought he had a decent chance of beating it.</p>
<p>I think this was several years ago</p>
<p>when I think it was not as clear to everybody</p>
<p>that the AIs were taking over.</p>
<p>I think now people recognize that</p>
<p>if you&rsquo;re playing against a bot,</p>
<p>there&rsquo;s no chance that you have in a game like poker.</p>
<p>So consistently the bots will win.</p>
<p>The bots have heads up and in other variants too.</p>
<p>So six-player Texas Hold&rsquo;em,</p>
<p>no-limit Texas Hold&rsquo;em, the bots win?</p>
<p>Yeah, that&rsquo;s the case.</p>
<p>So I think there&rsquo;s some debate about like,</p>
<p>is it true for every single variant of poker?</p>
<p>I think for every single variant of poker,</p>
<p>if somebody really put in the effort,</p>
<p>they can make an AI that would beat all humans at it.</p>
<p>We&rsquo;ve focused on the most popular variants.</p>
<p>So heads up, no-limit Texas Hold&rsquo;em.</p>
<p>And then we followed that up with six-player poker as well,</p>
<p>where we managed to make a bot</p>
<p>that beat expert human players.</p>
<p>And I think even there now,</p>
<p>it&rsquo;s pretty clear that humans don&rsquo;t stand a chance.</p>
<p>See, I would love to hook up an AI system</p>
<p>that looks at EEG,</p>
<p>like how, like actually tries to optimize</p>
<p>the toughness of the spot it puts a human in.</p>
<p>And I would love to see how different is that</p>
<p>from the game theory optimal.</p>
<p>So you try to maximize the heart rate of the human player,</p>
<p>like the freaking out over a long period of time.</p>
<p>I wonder if there&rsquo;s going to be different strategies</p>
<p>that emerge that are close in terms of effectiveness.</p>
<p>Because something tells me you could still be,</p>
<p>achieve superhuman level performance</p>
<p>by just making people sweat.</p>
<p>I feel like that there&rsquo;s a good chance that that is the case.</p>
<p>Yeah, if you&rsquo;re able to see like,</p>
<p>that it&rsquo;s like a decent proxy for score, right?</p>
<p>And this is actually like the common poker wisdom</p>
<p>where they&rsquo;re teaching players, before there were bots,</p>
<p>and they were trying to teach people how to play poker.</p>
<p>They would say like, the key to the game</p>
<p>is to put your opponent into difficult spots.</p>
<p>It&rsquo;s a good estimate for</p>
<p>if you&rsquo;re making the right decision.</p>
<p>So what else can you say about</p>
<p>the fundamental role of search in poker?</p>
<p>And maybe if you can also relate it to chess and go</p>
<p>in these games.</p>
<p>What&rsquo;s the role of search to solving these games?</p>
<p>Yeah, I think a lot of people under,</p>
<p>this is true for the general public.</p>
<p>And I think it&rsquo;s true for the AI community.</p>
<p>A lot of people underestimate the importance of search</p>
<p>for these kinds of game AI results.</p>
<p>An example of this is TD Gammon that came out in 1992.</p>
<p>This was the first real instance of a neural net</p>
<p>being used in a game AI.</p>
<p>It&rsquo;s a landmark achievement.</p>
<p>It was actually the inspiration for AlphaZero.</p>
<p>And it used search.</p>
<p>It used two-ply search to figure out its next move.</p>
<p>You got Deep Blue.</p>
<p>There, it was very heavily focused on search,</p>
<p>looking many, many moves ahead,</p>
<p>farther than any human could.</p>
<p>And that was key for why it won.</p>
<p>And then even with something like AlphaGo,</p>
<p>I mean, AlphaGo is commonly hailed</p>
<p>as a landmark achievement for neural nets.</p>
<p>And it is, but there&rsquo;s also this huge component of search,</p>
<p>Monte Carlo tree search to AlphaGo,</p>
<p>that was key, absolutely essential</p>
<p>for the AI to be able to beat top humans.</p>
<p>I think a good example of this is,</p>
<p>you look at the latest versions of AlphaGo,</p>
<p>like it was called AlphaZero.</p>
<p>And there&rsquo;s this metric called ELO rating,</p>
<p>where you can compare different humans</p>
<p>and you can compare bots to humans.</p>
<p>Now, a top human player is around 3,600 ELO,</p>
<p>maybe a little bit higher now.</p>
<p>AlphaZero, the strongest version, is around 5,200 ELO.</p>
<p>But if you take out the search that&rsquo;s being done</p>
<p>at test time, and by the way,</p>
<p>what I mean by search is the planning ahead,</p>
<p>the thinking of like, oh, if I move my,</p>
<p>if I place this stone here and then he does this,</p>
<p>and then you look like five moves ahead</p>
<p>and you see like what the board state looks like,</p>
<p>that&rsquo;s what I mean by search.</p>
<p>If you take out the search that&rsquo;s done during the game,</p>
<p>the ELO rating drops to around 3,000.</p>
<p>So even today, what, seven years after AlphaGo,</p>
<p>if you take out the Monte Carlo tree search</p>
<p>that&rsquo;s being done at, when playing against the human,</p>
<p>the bots are not superhuman.</p>
<p>Nobody has made a raw neural net that is superhuman in Go.</p>
<p>That&rsquo;s worth lingering on.</p>
<p>That&rsquo;s quite profound.</p>
<p>So without search, that just means looking at the next move</p>
<p>and saying, this is the best move.</p>
<p>So having a function that estimates accurately</p>
<p>what the best move is.</p>
<p>That&rsquo;s right.</p>
<p>Without search.</p>
<p>Yeah, and all these bots,</p>
<p>they have what&rsquo;s called a policy network,</p>
<p>where it will tell you,</p>
<p>this is what the neural net thinks is the next best move.</p>
<p>And it&rsquo;s kind of like the intuition that a human has.</p>
<p>You know, the human looks at the board</p>
<p>and any Go or chess master will be able to tell you like,</p>
<p>oh, instantly, here&rsquo;s what I think the right move is.</p>
<p>And the bot is able to do the same thing.</p>
<p>But just like how a human grandmaster</p>
<p>can make a better decision if they have more time to think,</p>
<p>when you add on this Monte Carlo tree search,</p>
<p>the bot is able to make a better decision.</p>
<p>Yeah, I mean, of course a human</p>
<p>is doing something like search in their brain,</p>
<p>but it&rsquo;s not, I hesitate to draw a hard line,</p>
<p>but it&rsquo;s not like a Monte Carlo tree search.</p>
<p>It&rsquo;s more like sequential language model generation.</p>
<p>So it&rsquo;s like a different,</p>
<p>the neural network is doing the searching.</p>
<p>I wonder what the human brain is doing in terms of searching.</p>
<p>Because you&rsquo;re doing that like computation.</p>
<p>A human is computing.</p>
<p>They have intuition, they have gut.</p>
<p>They have a really strong ability to estimate,</p>
<p>amongst the top players of what is good and not position</p>
<p>without calculating all the details.</p>
<p>But they&rsquo;re still doing search in their head,</p>
<p>but it&rsquo;s a different kind of search.</p>
<p>Have you ever thought about like,</p>
<p>what is the difference between the human,</p>
<p>the search that the human is performing</p>
<p>versus what computers are doing?</p>
<p>I have thought a lot about that</p>
<p>and I think it&rsquo;s a really important question.</p>
<p>So the AI in Alpha and Alphas in AlphaGo</p>
<p>or any of these Go AIs,</p>
<p>they&rsquo;re all doing Monte Carlo tree search,</p>
<p>which is a particular kind of search.</p>
<p>And it&rsquo;s actually a symbolic tabular search.</p>
<p>It uses the neural net to guide its search,</p>
<p>but it isn&rsquo;t actually like full on neural net.</p>
<p>Now that kind of search is very successful</p>
<p>in these kinds of like perfect information board games</p>
<p>like chess and Go.</p>
<p>But if you take it to a game like poker, for example,</p>
<p>it doesn&rsquo;t work.</p>
<p>It can&rsquo;t understand the concept of hidden information.</p>
<p>It doesn&rsquo;t understand the balance that you have to strike</p>
<p>between like the amount that you&rsquo;re raising</p>
<p>versus the amount that you&rsquo;re calling.</p>
<p>And in every one of these games,</p>
<p>you see a different kind of search.</p>
<p>And the human brain is able to plan</p>
<p>for all these different games in a very general way.</p>
<p>Now, I think that&rsquo;s one thing</p>
<p>that we&rsquo;re missing from AI today.</p>
<p>And I think it&rsquo;s a really important missing piece.</p>
<p>The ability to plan and reason more generally</p>
<p>across a wide variety of different settings.</p>
<p>In a way where the general reasoning</p>
<p>makes you better at each one of the games, not worse.</p>
<p>Yeah, so you can kind of think of it</p>
<p>as like neural nets today,</p>
<p>they&rsquo;ll give you like transformers, for example,</p>
<p>are super general.</p>
<p>But they&rsquo;ll give you,</p>
<p>it&rsquo;ll output an answer in like 100 milliseconds.</p>
<p>And if you tell it like,</p>
<p>oh, you&rsquo;ve got five minutes to give you a decision,</p>
<p>feel free to take more time to make a better decision.</p>
<p>It&rsquo;s not gonna know what to do with that.</p>
<p>But a human, if you&rsquo;re playing a game like chess,</p>
<p>they&rsquo;re gonna give you a very different answer</p>
<p>depending on if you say,</p>
<p>oh, you&rsquo;ve got 100 milliseconds</p>
<p>or you&rsquo;ve got five minutes.</p>
<p>Yeah, I mean, people have started using</p>
<p>transformers and language models</p>
<p>like in an iterative way that does improve the answer</p>
<p>or like showing the work kind of idea.</p>
<p>Yeah, they got this thing called chain of thought reasoning.</p>
<p>And that&rsquo;s, I think-</p>
<p>Super promising, right?</p>
<p>Yeah, and I think it&rsquo;s a good step in the right direction.</p>
<p>I would kind of like say it&rsquo;s similar</p>
<p>to Monte Carlo rollouts in a game like chess.</p>
<p>There&rsquo;s a kind of search that you can do</p>
<p>where you&rsquo;re saying like,</p>
<p>I&rsquo;m gonna roll out my intuition</p>
<p>and see like without really thinking,</p>
<p>what are the better decisions I can make</p>
<p>farther down the path?</p>
<p>What would I do if I just acted according to intuition</p>
<p>for the next 10 moves?</p>
<p>And that gets you an improvement.</p>
<p>But I think that there&rsquo;s much richer kinds of planning</p>
<p>that we could do.</p>
<p>So when the Broadus actually beat the poker players,</p>
<p>what did that feel like?</p>
<p>What was that?</p>
<p>I mean, actually on that day,</p>
<p>what were you feeling like?</p>
<p>Were you nervous?</p>
<p>I mean, poker was one of the games that you thought</p>
<p>like is not gonna be solvable</p>
<p>because it&rsquo;s the human factor.</p>
<p>So at least in the narratives,</p>
<p>we&rsquo;ll tell ourselves the human factor</p>
<p>is so fundamental to the game of poker.</p>
<p>Yeah, the Libratus competition was super stressful for me.</p>
<p>Also, I mean, I was working on this</p>
<p>like basically continuously for a year</p>
<p>leading up to the competition.</p>
<p>I mean, for me, it became like very clear,</p>
<p>like, okay, this is the search technique.</p>
<p>This is the approach that we need.</p>
<p>And then I spent a year working on this</p>
<p>pretty much like nonstop.</p>
<p>Can we actually get into details?</p>
<p>Like what programming languages is it written in?</p>
<p>What&rsquo;s some interesting implementation details</p>
<p>that are like fun slash painful?</p>
<p>Yeah, so one of the interesting things about Libratus</p>
<p>is that we had no idea what the bar was</p>
<p>to actually beat top humans.</p>
<p>We could play against like our prior bots</p>
<p>and that kind of gives us some sense of like,</p>
<p>are we making progress?</p>
<p>Are we going in the right direction?</p>
<p>But we had no idea like what the bar actually was.</p>
<p>And so we threw a huge amount of resources</p>
<p>at trying to make the strongest bot possible.</p>
<p>So we use C++.</p>
<p>It was parallelized.</p>
<p>We were using, I think like a thousand CPUs,</p>
<p>maybe more actually.</p>
<p>And today that sounds like nothing,</p>
<p>but for a grad student back in 2016,</p>
<p>that was a huge amount of resources.</p>
<p>Well, it&rsquo;s still a lot for even any grad student today.</p>
<p>It&rsquo;s still tough to get,</p>
<p>or even to allow yourself to think in that,</p>
<p>in terms of scale at CMU, at MIT,</p>
<p>anything like that.</p>
<p>Yeah.</p>
<p>And, you know, talking about terabytes of memory.</p>
<p>So it was a very parallelized</p>
<p>and it had to be very fast too,</p>
<p>because the more games that you could simulate,</p>
<p>the stronger the bot would be.</p>
<p>So is there some like John Carmack style,</p>
<p>like efficiencies you had to come up with,</p>
<p>like an efficient way to represent the hand,</p>
<p>all that kind of stuff?</p>
<p>There are all sorts of optimizations that I had to make</p>
<p>to try to get this thing to run as fast as possible.</p>
<p>They were like, how do you minimize the latency?</p>
<p>How do you package things together</p>
<p>so that you minimize the amount of communication</p>
<p>between the different nodes?</p>
<p>How do you optimize the algorithms</p>
<p>so that you can try to squeeze out more and more</p>
<p>from the game that you&rsquo;re actually playing?</p>
<p>All these kinds of different decisions</p>
<p>that I had to make.</p>
<p>Just a fun question.</p>
<p>What IDE did you use for C++ at the time?</p>
<p>I think I used Visual Studio actually.</p>
<p>Okay.</p>
<p>Is that still carried through to today?</p>
<p>VS Code is what I use today.</p>
<p>It seems like it&rsquo;s pretty popular.</p>
<p>It&rsquo;s the community, basically conversion on.</p>
<p>Okay, cool.</p>
<p>So you got this super optimized C++ system</p>
<p>and then you show up to the day of competition.</p>
<p>Yeah.</p>
<p>Humans versus machine.</p>
<p>How did it feel throughout the day?</p>
<p>Super stressful.</p>
<p>I mean, I thought going into it</p>
<p>that we had like a 50-50 chance.</p>
<p>Because basically I thought if they play</p>
<p>in a totally normal style,</p>
<p>I think we&rsquo;ll squeak out a win.</p>
<p>But there&rsquo;s always a chance</p>
<p>that they can find some weakness in the bot.</p>
<p>And if they do, and we&rsquo;re playing like for 20 days,</p>
<p>120,000 hands of poker.</p>
<p>They have a lot of time to find weaknesses in the system.</p>
<p>And if they do, we&rsquo;re gonna get crushed.</p>
<p>And that&rsquo;s actually what happened</p>
<p>in the previous competition.</p>
<p>The humans, they started out,</p>
<p>it wasn&rsquo;t like they were winning from the start.</p>
<p>But then they found these weaknesses</p>
<p>that they could take advantage of.</p>
<p>And for the next 10 days,</p>
<p>they were just crushing the bot, stealing money from it.</p>
<p>What were the weaknesses they found?</p>
<p>Like maybe overbetting was effective,</p>
<p>that kind of stuff.</p>
<p>So certain betting strategies worked.</p>
<p>What they found is, yeah, overbetting,</p>
<p>like betting certain amounts,</p>
<p>the bot would have a lot of trouble</p>
<p>dealing with those sizes.</p>
<p>And then also when the bot got</p>
<p>into really difficult all-in situations,</p>
<p>it wasn&rsquo;t able to, because it wasn&rsquo;t doing search,</p>
<p>it had to clump different hands together</p>
<p>and it would treat them identically.</p>
<p>And so it wouldn&rsquo;t be able to distinguish</p>
<p>having a king high flush versus an ace high flush.</p>
<p>And in some situations, that really matters a lot.</p>
<p>And so they could put the bot into those situations</p>
<p>and then the bot would just bleed money.</p>
<p>Clever humans.</p>
<p>Okay, so I didn&rsquo;t realize it was over 20 days.</p>
<p>So what were the humans like over those 20 days?</p>
<p>And what was the bot like?</p>
<p>So we had set up the competition.</p>
<p>Like I said, there was $200,000 in prize money</p>
<p>and they would get paid a fraction of that</p>
<p>depending on how well they did relative to each other.</p>
<p>So I was kind of hoping that they wouldn&rsquo;t work together</p>
<p>to try to find weaknesses in the bot,</p>
<p>but they entered the competition</p>
<p>with their number one objective being to beat the bot.</p>
<p>And they didn&rsquo;t care about individual glory.</p>
<p>They were like, we&rsquo;re all gonna work as a team</p>
<p>to try to take down this bot.</p>
<p>And so they immediately started comparing notes.</p>
<p>What they would do is they would coordinate</p>
<p>looking at different parts of the strategy</p>
<p>to try to find out weaknesses.</p>
<p>And then at the end of the day,</p>
<p>we actually sent them a log</p>
<p>of all the hands that were played</p>
<p>and what cards the bot had on each of those hands.</p>
<p>Oh, wow.</p>
<p>Yeah, yeah.</p>
<p>That&rsquo;s gutsy.</p>
<p>Yeah, it was honestly,</p>
<p>and I&rsquo;m not sure why we did that in retrospect,</p>
<p>but I mean, I&rsquo;m glad we did it</p>
<p>because we ended up winning anyway,</p>
<p>but that if you&rsquo;ve ever played poker before,</p>
<p>like that is golden information.</p>
<p>I mean, to know, usually when you play poker,</p>
<p>you see about a third of the hands to show down</p>
<p>and to just hand them all the cards</p>
<p>that the bot had on every single hand,</p>
<p>that was just a goldmine for them.</p>
<p>And so then they would review the hands</p>
<p>and try to see like,</p>
<p>okay, could they find patterns in the bot weaknesses?</p>
<p>And could they, then they would coordinate</p>
<p>and study together and try to figure out,</p>
<p>okay, now this person&rsquo;s gonna explore</p>
<p>this part of the strategy for weaknesses.</p>
<p>This person is gonna explore</p>
<p>this part of the strategy for weaknesses.</p>
<p>It&rsquo;s a kind of psychological warfare</p>
<p>showing them the hands.</p>
<p>Yeah.</p>
<p>I mean, I&rsquo;m sure you didn&rsquo;t think of it that way,</p>
<p>but like doing that means you&rsquo;re confident</p>
<p>in the bot&rsquo;s ability to win.</p>
<p>Well, that&rsquo;s one way of putting it.</p>
<p>I wasn&rsquo;t super confident.</p>
<p>Yeah.</p>
<p>So, you know, going in, like I said,</p>
<p>I think I had like 50-50 odds on us winning the,</p>
<p>when we actually, when we announced the competition,</p>
<p>the poker community decided to gamble on who would win</p>
<p>and their initial odds against us were like four to one.</p>
<p>They were really convinced</p>
<p>that the humans were gonna pull out a win.</p>
<p>The bot ended up winning for three days straight.</p>
<p>And even then after three days,</p>
<p>the betting odds were still just 50-50.</p>
<p>And then at that point,</p>
<p>it started to look like the humans were coming back.</p>
<p>They started to like, you know,</p>
<p>but poker is a very high variance game.</p>
<p>And I think what happened is like,</p>
<p>they thought that they spotted some weaknesses</p>
<p>that weren&rsquo;t actually there.</p>
<p>And then around day eight,</p>
<p>it was just very clear</p>
<p>that they were getting absolutely crushed.</p>
<p>And from that point, I mean, for a while there,</p>
<p>I was super stressed out thinking like,</p>
<p>oh my God, the humans are coming back</p>
<p>and we&rsquo;re just, they&rsquo;ve found weaknesses</p>
<p>and now we&rsquo;re just gonna lose the whole thing.</p>
<p>But no, it ended up going in the other direction</p>
<p>and the bot ended up like crushing them in the long run.</p>
<p>How did it feel at the end?</p>
<p>Like as a human being, what did,</p>
<p>as a person who loves,</p>
<p>appreciates the beauty of the game of poker</p>
<p>and as a person who appreciates the beauty of AI,</p>
<p>is there, did you feel a certain kind of way about it?</p>
<p>I felt a lot of things, man.</p>
<p>I mean, at that point in my life,</p>
<p>I had spent five years working on this project</p>
<p>and it was a huge sense of accomplishment.</p>
<p>I mean, to spend five years working on something</p>
<p>and finally see it succeed.</p>
<p>Yeah, I wouldn&rsquo;t trade that for anything in the world.</p>
<p>Yeah, because that&rsquo;s a real benchmark.</p>
<p>It&rsquo;s not like getting some percent accuracy in a dataset.</p>
<p>This is like real, this is real world.</p>
<p>It&rsquo;s just a game, but it&rsquo;s also a game</p>
<p>that means a lot to a lot of people.</p>
<p>And this is humans doing their best to beat the machine.</p>
<p>So this is a real benchmark, unlike anything else.</p>
<p>Yeah, and I mean, this is what I have been dreaming about</p>
<p>since I was like 16 playing poker,</p>
<p>you know, with my friends in high school.</p>
<p>The idea that you could find a strategy,</p>
<p>you know, approximate the Nash equilibrium,</p>
<p>be able to beat all the poker players in the world with it.</p>
<p>You know, so to actually see that come to fruition</p>
<p>and be realized, that was, it&rsquo;s kind of magical.</p>
<p>Yeah, especially money is on the line too.</p>
<p>It&rsquo;s different than chess.</p>
<p>And that aspect, like people get,</p>
<p>that&rsquo;s why you want to look at betting markets</p>
<p>if you want to actually understand</p>
<p>what people really think.</p>
<p>And in the same sense, poker, it&rsquo;s really high stakes</p>
<p>because it&rsquo;s money.</p>
<p>And to solve that game, that&rsquo;s an amazing accomplishment.</p>
<p>So the leap from that to multi-way six-player poker,</p>
<p>what&rsquo;s, how difficult is that jump?</p>
<p>And what are some interesting differences</p>
<p>between heads up poker and multi-way poker?</p>
<p>Yeah, so I mentioned, you know,</p>
<p>Nash equilibrium in two-player zero-sum games.</p>
<p>If you play that strategy,</p>
<p>you are guaranteed to not lose an expectation</p>
<p>no matter what your opponent does.</p>
<p>Now, once you go to six-player poker,</p>
<p>you&rsquo;re no longer playing a two-player zero-sum game.</p>
<p>And so there was a lot of debate</p>
<p>among the academic community and among the poker community</p>
<p>about how well these techniques would extend</p>
<p>beyond just two-player heads up poker.</p>
<p>Now, what I had come to realize is that</p>
<p>the techniques actually, I thought,</p>
<p>really would extend to six-player poker.</p>
<p>Because even though in theory,</p>
<p>they don&rsquo;t give you these guarantees</p>
<p>outside of two-player zero-sum games,</p>
<p>in practice, it still gives you a really strong strategy.</p>
<p>Now, there were a lot of complications</p>
<p>that would come up with six-player poker</p>
<p>besides the game-theoretic aspect.</p>
<p>I mean, for one, the game is just exponentially larger.</p>
<p>So the main thing that allowed us</p>
<p>to go from two-player to six-player</p>
<p>was the idea of depth-limited search.</p>
<p>So I said before, like, you know,</p>
<p>we would do search, we would plan out,</p>
<p>the bot would plan out what it&rsquo;s going to do next</p>
<p>and for the next several moves.</p>
<p>And in Libratus, that search was done</p>
<p>extending all the way to the end of the game.</p>
<p>So it would have to start from the turn onwards,</p>
<p>like looking maybe 10 moves ahead,</p>
<p>it would have to figure out</p>
<p>what it was doing for all those moves.</p>
<p>Now, when you get to six-player poker,</p>
<p>it can&rsquo;t do that exhaustive search anymore</p>
<p>because the game is just way too large.</p>
<p>But by only having to look a few moves ahead</p>
<p>and then stopping there and substituting a value estimate</p>
<p>of, like, how good is that strategy at that point,</p>
<p>then we&rsquo;re able to do a much more scalable</p>
<p>form of search.</p>
<p>Is there something cool,</p>
<p>looking at the paper right now,</p>
<p>is there something cool in the paper in terms of graphics?</p>
<p>A game tree traversal via Monte Carlo.</p>
<p>I think if you go down a bit.</p>
<p>Figure one, an example of equilibrium selection problem.</p>
<p>Ooh, so yeah.</p>
<p>What do we know about equilibria</p>
<p>when there&rsquo;s multiple players?</p>
<p>So when you go outside of two players, you&rsquo;re a sum.</p>
<p>So a Nash equilibrium is a set of strategies,</p>
<p>like one strategy for each player,</p>
<p>where no player has an incentive</p>
<p>to switch to a different strategy.</p>
<p>And so you can kind of think of it as, like,</p>
<p>imagine you have a game where there&rsquo;s a ring.</p>
<p>That&rsquo;s actually the visual here.</p>
<p>You got a ring, and the object of the game</p>
<p>is to be as far away from the other players as possible.</p>
<p>There&rsquo;s, a Nash equilibrium is for all the players</p>
<p>to be spaced equally apart around this ring.</p>
<p>But there&rsquo;s infinitely many different Nash equilibria,</p>
<p>right, there&rsquo;s infinitely many ways</p>
<p>to space four dots along a ring.</p>
<p>And if every single player independently computes</p>
<p>a Nash equilibrium, then there&rsquo;s no guarantee</p>
<p>that the joint strategy that they&rsquo;re all playing</p>
<p>is going to be a Nash equilibrium.</p>
<p>They&rsquo;re just going to be like random dots</p>
<p>scattered along this ring,</p>
<p>rather than four coordinated dots</p>
<p>being equally spaced apart.</p>
<p>Is it possible to sort of optimally do this kind of selection</p>
<p>to do the selection of the equilibria you&rsquo;re chasing?</p>
<p>So is there like a meta problem to be solved here?</p>
<p>So the meta problem is, in some sense,</p>
<p>how do you understand the Nash equilibria</p>
<p>that the other players are going to play?</p>
<p>And even if you do that, again,</p>
<p>there&rsquo;s no guarantee that you&rsquo;re going to win.</p>
<p>So, you know, if you&rsquo;re playing risk, like I said,</p>
<p>and all the other players decide to team up against you,</p>
<p>you&rsquo;re going to lose.</p>
<p>Nash equilibrium doesn&rsquo;t help you there.</p>
<p>And so there was this big debate</p>
<p>about whether Nash equilibrium</p>
<p>and all these techniques that compute it</p>
<p>are even useful once you go outside</p>
<p>of two-player zero-sum games.</p>
<p>Now, I think for many games,</p>
<p>there is a valid criticism here.</p>
<p>And I think when we talk about,</p>
<p>when we go to something like diplomacy,</p>
<p>we run into this issue that the approach</p>
<p>of trying to approximate a Nash equilibrium</p>
<p>doesn&rsquo;t really work anymore.</p>
<p>But it turns out that in six-player poker,</p>
<p>because six-player poker is such an adversarial game,</p>
<p>where none of the players</p>
<p>really try to work with each other,</p>
<p>the techniques that were used in two-player poker</p>
<p>to try to approximate an equilibrium,</p>
<p>those still end up working in practice</p>
<p>in six-player poker as well.</p>
<p>There&rsquo;s some deep way in which six-player poker</p>
<p>is just a bunch of heads-up poker, like games in one.</p>
<p>It&rsquo;s like embedded in it.</p>
<p>So the competitiveness is more fundamental to poker</p>
<p>than the cooperation.</p>
<p>Right, yeah.</p>
<p>Poker is just such an adversarial game.</p>
<p>There&rsquo;s no real cooperation.</p>
<p>In fact, you&rsquo;re not even allowed to cooperate in poker.</p>
<p>It&rsquo;s considered collusion.</p>
<p>It&rsquo;s against the rules.</p>
<p>And so for that reason,</p>
<p>the techniques end up working really well.</p>
<p>And I think that&rsquo;s true more broadly</p>
<p>in extremely adversarial games in general.</p>
<p>But that&rsquo;s sort of in practice</p>
<p>versus being able to prove something.</p>
<p>That&rsquo;s right.</p>
<p>Nobody has a proof that that&rsquo;s the case.</p>
<p>And it could be that six-player poker</p>
<p>belongs to some class of games</p>
<p>where approximating a Nash equilibrium</p>
<p>through self-play provably works well.</p>
<p>And there are other classes of games</p>
<p>beyond just two-player zero-sum</p>
<p>where this is proven to work well.</p>
<p>So there are these kinds of games called potential games,</p>
<p>which I won&rsquo;t go into.</p>
<p>It&rsquo;s kind of like a complicated concept.</p>
<p>But there are classes of games</p>
<p>where this approach to approximating a Nash equilibrium</p>
<p>is proven to work well.</p>
<p>Now, six-player poker is not known</p>
<p>to belong to one of those classes,</p>
<p>but it is possible that there is some classic games</p>
<p>where it either provably performs well</p>
<p>or provably performs not that badly.</p>
<p>So what are some interesting things about Pluribus</p>
<p>that was able to achieve human-level performance</p>
<p>on this or superhuman-level performance</p>
<p>on the six-player version of poker?</p>
<p>Personally, I think the most interesting thing</p>
<p>about Pluribus is that it was so much cheaper than Libratus.</p>
<p>I mean, Libratus, if you had to put a price tag</p>
<p>on the computational resources that went into it,</p>
<p>I would say the final training run took about $100,000.</p>
<p>You go to Pluribus, the final training run</p>
<p>would cost less than $150 on AWS.</p>
<p>Is this normalized to computational inflation?</p>
<p>So meaning, does this just have to do with the fact</p>
<p>that Pluribus was trained like a year later?</p>
<p>No, no, no, it&rsquo;s not.</p>
<p>I mean, first of all, yeah,</p>
<p>computing resources are getting cheaper every day,</p>
<p>but you&rsquo;re not gonna see a thousand-fold decrease</p>
<p>in the computational resources over two years,</p>
<p>or even anywhere close to that.</p>
<p>The real improvement was algorithmic improvements,</p>
<p>and in particular, the ability to do depth-limited search.</p>
<p>So does depth-limited search also work for Libratus?</p>
<p>Yeah, yes.</p>
<p>So where this depth-limited search came from</p>
<p>is I developed this technique</p>
<p>and ran it on two-player poker first,</p>
<p>and that reduced the computational resources</p>
<p>needed to make an AI that was superhuman</p>
<p>from $100,000 for Libratus</p>
<p>to something you could train on your laptop.</p>
<p>What do you learn from that, from that discovery?</p>
<p>What I would take away from that</p>
<p>is that algorithmic improvements really do matter.</p>
<p>How would you describe the more general case</p>
<p>of limited depth search?</p>
<p>So it&rsquo;s basically constraining the scale,</p>
<p>temporal or in some other way</p>
<p>of the computation you&rsquo;re doing, in some clever way.</p>
<p>So how else can you significantly</p>
<p>constrain computation, right?</p>
<p>Well, I think the idea is that</p>
<p>we want to be able to leverage search as much as possible,</p>
<p>and the way that we were doing it in Libratus</p>
<p>required us to search all the way to the end of the game.</p>
<p>Now, if you&rsquo;re playing a game like chess,</p>
<p>the idea that you&rsquo;re gonna search always</p>
<p>to the end of the game is kind of unimaginable, right?</p>
<p>Like there&rsquo;s just so many situations</p>
<p>where you just won&rsquo;t be able to use search in that case,</p>
<p>or the cost would be prohibitive.</p>
<p>And this technique allowed us to leverage search,</p>
<p>and without having to pay</p>
<p>such a huge computational cost for it,</p>
<p>and be able to apply it more broadly.</p>
<p>So to what degree did you use neural nets</p>
<p>for Libratus and Pluribus?</p>
<p>And more generally, what role do neural nets have to play</p>
<p>in superhuman level performance in poker?</p>
<p>So we actually did not use neural nets at all</p>
<p>for Libratus or Pluribus.</p>
<p>And a lot of people found this surprising back in 2017,</p>
<p>I think they find it surprising today,</p>
<p>that we were able to do this without using any neural nets.</p>
<p>And I think the reason for that,</p>
<p>I mean, I think neural nets are incredibly powerful,</p>
<p>and the techniques that are used today,</p>
<p>even for poker AIs, do rely quite heavily on neural nets.</p>
<p>But it wasn&rsquo;t the main challenge for poker.</p>
<p>Like I think what neural nets are really good for,</p>
<p>if you&rsquo;re in a situation where finding features</p>
<p>for a value function is really difficult,</p>
<p>then neural nets are really powerful.</p>
<p>And this was the problem in Go, right?</p>
<p>Like the problem in Go was that,</p>
<p>or the final problem in Go at least,</p>
<p>was that nobody had a good way of looking at a board</p>
<p>and figuring out who was winning or losing,</p>
<p>and describing through a simple algorithm</p>
<p>who was winning or losing.</p>
<p>And so there neural nets were super helpful</p>
<p>because you could just feed in</p>
<p>a ton of different board positions into this neural net,</p>
<p>and it would be able to predict then</p>
<p>who was winning or losing.</p>
<p>But in poker, the features weren&rsquo;t the challenge.</p>
<p>The challenge was, how do you design a scalable algorithm</p>
<p>that would allow you to find this balanced strategy,</p>
<p>that would understand that you have to bluff</p>
<p>with the right probability?</p>
<p>So can that be somehow incorporated</p>
<p>into the value function?</p>
<p>This, the complexity of poker that you&rsquo;ve described?</p>
<p>Yeah, so the way the value functions work in poker,</p>
<p>like the latest and greatest poker AIs,</p>
<p>they do use neural nets for the value function.</p>
<p>The way it&rsquo;s done is very different</p>
<p>from how it&rsquo;s done in a game like chess or Go,</p>
<p>because in poker, you have to reason about beliefs.</p>
<p>And so the value of a state</p>
<p>depends on the beliefs that players have</p>
<p>about what the different cards are.</p>
<p>Like if you have pocket aces,</p>
<p>then whether that&rsquo;s a really, really good hand</p>
<p>or just an okay hand,</p>
<p>depends on whether you know I have pocket aces.</p>
<p>Right, like if you know that I have pocket aces,</p>
<p>then if I bet, you&rsquo;re gonna fold immediately.</p>
<p>But if you think that I have a really bad hand,</p>
<p>then I could bet with pocket aces and make a ton of money.</p>
<p>So the value function in poker these days</p>
<p>takes the beliefs as an input,</p>
<p>which is very different from like how chess</p>
<p>and Go AIs work.</p>
<p>So as a person who appreciates the game,</p>
<p>who do you think is the greatest poker player of all time?</p>
<p>That&rsquo;s a tough question.</p>
<p>Can AI help answer that question?</p>
<p>Can you actually analyze the quality of play, right?</p>
<p>So the chess engines can give estimates</p>
<p>of the quality of play, right?</p>
<p>I wonder if there&rsquo;s a,</p>
<p>is there an ELO rating type of system for poker?</p>
<p>I suppose you could, but there&rsquo;s just not enough,</p>
<p>you would have to play a lot of games, right?</p>
<p>A very large number of games,</p>
<p>like more than you would in chess.</p>
<p>The deterministic game makes it easier to estimate ELO,</p>
<p>I think.</p>
<p>I think it is much harder to estimate</p>
<p>something like ELO rating in poker.</p>
<p>I think it&rsquo;s doable.</p>
<p>The problem is that the game is very high variance.</p>
<p>So you could play, you could be profitable in poker</p>
<p>for a year and you could actually be a bad player</p>
<p>just because the variance is so high.</p>
<p>I mean, you&rsquo;ve got top professional poker players</p>
<p>that would lose for a year</p>
<p>just because they&rsquo;re on a really bad streak.</p>
<p>So yeah, so for ELO,</p>
<p>you have to have a nice clean way of saying</p>
<p>if player A played player B and A beats B,</p>
<p>that says something, that&rsquo;s a signal.</p>
<p>In poker, that&rsquo;s a very noisy signal.</p>
<p>It&rsquo;s a very noisy signal.</p>
<p>Now there is a signal there.</p>
<p>And so you could do this calculation,</p>
<p>it would just be much harder.</p>
<p>But the same way that AIs have now taken over chess</p>
<p>and all the top professional chess players</p>
<p>train with AIs, the same is true for poker.</p>
<p>The game has become a very computational,</p>
<p>people train with AIs to try to find out</p>
<p>where they&rsquo;re making mistakes,</p>
<p>try to learn from the AIs to improve their strategy.</p>
<p>So now, yeah, so the game has been revolutionized</p>
<p>in the past five years by the development of AI</p>
<p>in this sport.</p>
<p>The skill with which you avoided the question</p>
<p>of the greatest of all time was impressive.</p>
<p>So my feeling is that it&rsquo;s a difficult question</p>
<p>because just like in chess,</p>
<p>where you can&rsquo;t really compare Magnus Carlsen today</p>
<p>to Garry Kasparov because the game has evolved so much.</p>
<p>The poker players today are so far beyond the skills</p>
<p>of people that were playing even 10 or 20 years ago.</p>
<p>So you look at the kinds of all-stars that were on ESPN</p>
<p>at the height of the poker boom,</p>
<p>pretty much all those players are actually not that good</p>
<p>at the game today, at least the strategy aspect.</p>
<p>I mean, they might still be good at reading the player</p>
<p>at the other side of the table and trying to figure out</p>
<p>are they bluffing or not?</p>
<p>But in terms of the actual computational strategy</p>
<p>of the game, a lot of them have really struggled</p>
<p>to keep up with that development.</p>
<p>Now, so for that reason, I&rsquo;ll give an answer</p>
<p>and I&rsquo;m gonna say Daniel Legranio,</p>
<p>who you actually had on the podcast recently,</p>
<p>I saw it was a great episode.</p>
<p>I&rsquo;m gonna love this so much.</p>
<p>And Phil&rsquo;s gonna hate this so much.</p>
<p>And I&rsquo;m gonna give him credit</p>
<p>because he is one of the few old school,</p>
<p>really strong players that have kept up</p>
<p>with the development of AI.</p>
<p>So he is trying to, he&rsquo;s constantly studying</p>
<p>the game theory optimal way of playing.</p>
<p>Exactly, yeah.</p>
<p>And I think a lot of the old school poker players</p>
<p>have just kind of given up on that aspect</p>
<p>and I gotta give Daniel Legranio credit</p>
<p>for keeping up with all the developments</p>
<p>that are happening in the sport.</p>
<p>Yeah, it&rsquo;s fascinating to watch.</p>
<p>It&rsquo;s fascinating to watch where it&rsquo;s headed.</p>
<p>Yeah, so there you go.</p>
<p>Some love for Daniel.</p>
<p>Quick pause, bathroom break?</p>
<p>Yeah, let&rsquo;s do it.</p>
<p>Let&rsquo;s go from poker to diplomacy.</p>
<p>What is, at a high level, the game of diplomacy?</p>
<p>Yeah, so I talked a lot about two-player zero-sum games</p>
<p>and what&rsquo;s interesting about diplomacy</p>
<p>is that it&rsquo;s very different from these adversarial games</p>
<p>like chess, go, poker, even Starcraft and Dota.</p>
<p>Diplomacy has a much bigger cooperative element to it.</p>
<p>It&rsquo;s a seven-player game.</p>
<p>It was actually created in the 50s</p>
<p>and it takes place before World War I.</p>
<p>It&rsquo;s like a map of Europe with seven great powers</p>
<p>and they&rsquo;re all trying to form alliances with each other.</p>
<p>There&rsquo;s a lot of negotiation going on.</p>
<p>And so the whole focus of the game</p>
<p>is on forming alliances with the other players</p>
<p>to take on the other players.</p>
<p>England, Germany, Russia, Turkey,</p>
<p>Austria, Hungary, Italy, and France.</p>
<p>That&rsquo;s right, yeah.</p>
<p>So the way the game works is on each turn,</p>
<p>you spend about five to 15 minutes</p>
<p>talking to the other players in private</p>
<p>and you make all sorts of deals with them.</p>
<p>You say like, hey, let&rsquo;s work together.</p>
<p>Let&rsquo;s team up against this other player</p>
<p>because the only way that you can make progress</p>
<p>is by working with somebody else against the others.</p>
<p>And then after that negotiation period is done,</p>
<p>all the players simultaneously submit their moves</p>
<p>and they&rsquo;re all executed at the same time.</p>
<p>And so you can tell people like,</p>
<p>hey, I&rsquo;m gonna support you this turn,</p>
<p>but then you don&rsquo;t follow through with it.</p>
<p>And they&rsquo;re only gonna figure that out</p>
<p>once they see the moves being read off.</p>
<p>How much of it is natural language,</p>
<p>like written, actual text?</p>
<p>How much is like,</p>
<p>you&rsquo;re actually saying phrases that are structured?</p>
<p>So there&rsquo;s different ways to play the game.</p>
<p>You can play it in person</p>
<p>and in that case, it&rsquo;s all natural language.</p>
<p>Free form communication,</p>
<p>there&rsquo;s no constraints on the kinds of deals</p>
<p>that you can make,</p>
<p>the kinds of things that you can discuss.</p>
<p>You can also play it online.</p>
<p>So you can send long emails back and forth.</p>
<p>You can play it like live online or over voice chats.</p>
<p>But the focus, the important thing to understand</p>
<p>is that this is unstructured communication.</p>
<p>You can say whatever you want.</p>
<p>You can make any sorts of deals that you want</p>
<p>and everything is done privately.</p>
<p>So it&rsquo;s not like you&rsquo;re all around the board together,</p>
<p>having a conversation.</p>
<p>You&rsquo;re grabbing somebody going off into a corner</p>
<p>and conspiring behind everybody else&rsquo;s back</p>
<p>about what you&rsquo;re planning.</p>
<p>And there&rsquo;s no limit in theory to the conversation</p>
<p>you can have directly with one person.</p>
<p>That&rsquo;s right.</p>
<p>You can make all sorts of,</p>
<p>you can talk about anything.</p>
<p>You could say like,</p>
<p>hey, let&rsquo;s have a long-term alliance against this guy.</p>
<p>You can say like,</p>
<p>hey, can you support me this turn?</p>
<p>And in return, I&rsquo;ll do this other thing for you next turn.</p>
<p>Or, you know, yeah,</p>
<p>just, you can talk about like what you talked about</p>
<p>with somebody else</p>
<p>and gossip about like what they&rsquo;re planning.</p>
<p>The way that I would describe the game</p>
<p>is that it&rsquo;s kind of like a mix between risk,</p>
<p>poker, and the TV show Survivor.</p>
<p>There&rsquo;s like this big element of like trying to,</p>
<p>yeah, there&rsquo;s a big social element.</p>
<p>And the best way that I would describe the game</p>
<p>is that it&rsquo;s really a game about people</p>
<p>rather than the pieces.</p>
<p>So risk, because it is a map,</p>
<p>it&rsquo;s kind of war game-like.</p>
<p>Poker, because there&rsquo;s a game theory component</p>
<p>that&rsquo;s very kind of strategic.</p>
<p>So you could convert it</p>
<p>into an artificial intelligence problem.</p>
<p>And then Survivor, because of the social component.</p>
<p>That&rsquo;s a strong social component.</p>
<p>I saw that somebody said online</p>
<p>that the internet version of the game</p>
<p>has this quality of,</p>
<p>that it&rsquo;s easier to almost to do like role-playing.</p>
<p>As opposed to being yourself,</p>
<p>you can actually like be the,</p>
<p>like really imagine yourself as the leader of France</p>
<p>or Russia and so on.</p>
<p>Like really pretend to be that person.</p>
<p>It&rsquo;s actually fun to really lean into being that leader.</p>
<p>Yeah, so some players do go this route</p>
<p>where they just like kind of view it as a strategy game,</p>
<p>but also a role-playing game where they can like act out</p>
<p>like what would I be like if I was,</p>
<p>you know, a leader of France in 1900?</p>
<p>A forfeit right away.</p>
<p>No, I&rsquo;m just kidding.</p>
<p>And they sometimes use like the old-timey language</p>
<p>to like, or how they imagined the elites would talk</p>
<p>at that time.</p>
<p>Anyway, so what are the different turns of the game?</p>
<p>Like what are the rounds?</p>
<p>Yeah, so on every turn,</p>
<p>you got like a bunch of different units</p>
<p>that you start out with.</p>
<p>So you start out controlling like just a few units</p>
<p>and the object of the game is to gain control</p>
<p>of a majority of the map.</p>
<p>If you&rsquo;re able to do that, then you&rsquo;ve won the game.</p>
<p>But like I said, the only way that you&rsquo;re able to do that</p>
<p>is by working with other players.</p>
<p>So on every turn, you can issue a move order.</p>
<p>So for each of your units,</p>
<p>you can move them to an adjacent territory</p>
<p>or you can keep them where they are,</p>
<p>or you can support a move or hold of a different unit.</p>
<p>So-</p>
<p>What are the territories?</p>
<p>Well, how is the map divided up?</p>
<p>It&rsquo;s kind of like risk where the map is divided up</p>
<p>into like 50 different territories.</p>
<p>Now you can enter a territory</p>
<p>if you&rsquo;re moving into that territory with more supports</p>
<p>than the person that&rsquo;s in there</p>
<p>or the person that&rsquo;s trying to move in there.</p>
<p>So if you&rsquo;re moving in and there&rsquo;s somebody already there,</p>
<p>then if neither of you have support, it&rsquo;s a one versus one</p>
<p>and you&rsquo;ll bounce back and neither of you will make progress.</p>
<p>If you have a unit that&rsquo;s supporting</p>
<p>that move into the territory, then it&rsquo;s a two versus one</p>
<p>and you&rsquo;ll kick them out</p>
<p>and they&rsquo;ll have to retreat somewhere.</p>
<p>What does support mean?</p>
<p>Support is like, it&rsquo;s an action</p>
<p>that you can issue in the game.</p>
<p>So you can say this unit, you write down,</p>
<p>this unit is supporting this other unit into this territory.</p>
<p>Are these units from opposing forces?</p>
<p>It could be, they could be.</p>
<p>And this is where the interesting aspect</p>
<p>of the game comes in</p>
<p>because you can support your own units into territory,</p>
<p>but you can also support other people&rsquo;s units</p>
<p>into territories.</p>
<p>And so that&rsquo;s what the negotiations really revolve around.</p>
<p>But you don&rsquo;t have to do the thing you say</p>
<p>you&rsquo;re going to do, right?</p>
<p>Yeah.</p>
<p>So you can say, I&rsquo;m gonna support you,</p>
<p>but then backstab the person.</p>
<p>Yeah, that&rsquo;s absolutely right.</p>
<p>And that tension is core to the game?</p>
<p>That tension is absolutely core to the game.</p>
<p>The fact that you can make all sorts of promises,</p>
<p>but you have to reason about the fact that like,</p>
<p>hey, they might not trust you</p>
<p>if you say you&rsquo;re gonna do something,</p>
<p>or they might be lying to you</p>
<p>when they say that they&rsquo;re gonna support you.</p>
<p>So maybe just to jump back,</p>
<p>what&rsquo;s the history of the game in general?</p>
<p>Is it true that Henry Kissinger loved the game?</p>
<p>And JFK and all those,</p>
<p>I&rsquo;ve heard like a bunch of different people that,</p>
<p>or is that just one of those things</p>
<p>that the cool kids say they do,</p>
<p>but they don&rsquo;t actually play?</p>
<p>So the game was created in the 50s.</p>
<p>Yeah.</p>
<p>And from what I understand,</p>
<p>it was JFK&rsquo;s, it was played in like the JFK White House,</p>
<p>Henry Kissinger&rsquo;s favorite game.</p>
<p>I don&rsquo;t know if it&rsquo;s true,</p>
<p>but that&rsquo;s definitely what I&rsquo;ve heard.</p>
<p>It&rsquo;s interesting that they went with World War I</p>
<p>when it was created after World War II.</p>
<p>So the story that I&rsquo;ve heard for the creation of the game</p>
<p>is it was created by somebody that had looked</p>
<p>at the history of the 20th century,</p>
<p>and they saw World War I as a failure of diplomacy.</p>
<p>So they saw the fact that this war broke out</p>
<p>as like the diplomats of all these countries</p>
<p>like really failed to prevent a war.</p>
<p>And he wanted to create a game</p>
<p>that would basically teach people about diplomacy.</p>
<p>And it&rsquo;s really fascinating that like in his ideal version</p>
<p>of the game of diplomacy, nobody actually wins the game.</p>
<p>Because the whole point is that if somebody is about to win,</p>
<p>then the other players should be able to work together</p>
<p>to stop that person from winning.</p>
<p>And so the ideal version of the game is just one</p>
<p>where nobody actually wins.</p>
<p>And it&rsquo;s kind of has a nice like wholesome take home message</p>
<p>then that war is ultimately futile.</p>
<p>And-</p>
<p>And that optimal,</p>
<p>that futile optimal could be achieved</p>
<p>through great diplomacy.</p>
<p>Yep.</p>
<p>So is there some asymmetry in terms of</p>
<p>which is more powerful, Russia versus Germany</p>
<p>versus France and so on?</p>
<p>So I think the general consensus is that France</p>
<p>is the strongest power in the game, but-</p>
<p>The beautiful thing about diplomacy</p>
<p>is that it&rsquo;s self-balancing, right?</p>
<p>So the fact that France has an inherited advantage</p>
<p>from the beginning means that the other players</p>
<p>are less likely to work with it.</p>
<p>I saw that Russia has four units or four of something</p>
<p>that the others have three of something.</p>
<p>That&rsquo;s true, yeah.</p>
<p>So Russia starts off with four units</p>
<p>while all the other players start with three.</p>
<p>But Russia is also in a much more vulnerable position</p>
<p>because they have to like,</p>
<p>they have a lot more neighbors as well.</p>
<p>Got it.</p>
<p>Larger territory, more, yeah, right.</p>
<p>More border to defend.</p>
<p>Okay, what else is important to know about the rules?</p>
<p>So how many rounds are there?</p>
<p>Like, is this iterative game?</p>
<p>Is it finite, do you just keep going indefinitely?</p>
<p>Usually the game lasts, I would say about 15 or 20 turns.</p>
<p>There&rsquo;s in theory, no limit.</p>
<p>It could last longer, but at some point,</p>
<p>I mean, if you&rsquo;re playing a house game with friends,</p>
<p>at some point you just get tired and you all agree like,</p>
<p>okay, we&rsquo;re going to end the game here and call it a draw.</p>
<p>If you&rsquo;re playing online,</p>
<p>there&rsquo;s usually like set limits</p>
<p>on when the game will actually end.</p>
<p>And what&rsquo;s the end, what&rsquo;s the termination condition?</p>
<p>Like, does one country have to conquer everything else?</p>
<p>So if somebody is able to actually gain control</p>
<p>of a majority of the map, then they&rsquo;ve won the game.</p>
<p>And that is a solo victory as it&rsquo;s called.</p>
<p>Now that pretty rarely happens,</p>
<p>especially with strong players, because like I said,</p>
<p>the game is designed to incentivize the other players</p>
<p>to put a stop to that.</p>
<p>And they&rsquo;ll all work together to stop the superpower.</p>
<p>Usually what ends up happening is that, you know,</p>
<p>all the players agree to a draw.</p>
<p>And then the score,</p>
<p>the win is divided among the remaining players.</p>
<p>There&rsquo;s a lot of different scoring systems.</p>
<p>The one that we used in our research</p>
<p>basically gives a score relative</p>
<p>to how much control you have of the map.</p>
<p>So the more that you control, the higher your score.</p>
<p>What&rsquo;s the history of using this game</p>
<p>as a benchmark for AI research?</p>
<p>Do people use it?</p>
<p>Yeah, so people have been working on AI for diplomacy</p>
<p>since about the 80s.</p>
<p>There was some really exciting research back then,</p>
<p>but the approach that was taken</p>
<p>was very different from what we see today.</p>
<p>I mean, the research in the 80s</p>
<p>was a very rule-based approach,</p>
<p>kind of a heuristic approach.</p>
<p>It was very in line with the kind of research</p>
<p>that was being done in the 80s.</p>
<p>You know, basically trying to encode human knowledge</p>
<p>into the strategy of the AI.</p>
<p>Sure.</p>
<p>And, you know, it&rsquo;s understandable.</p>
<p>I mean, the game is so incredibly different</p>
<p>and so much more complicated</p>
<p>than the kinds of games that people were working on</p>
<p>like chess and go and poker</p>
<p>that it was honestly even hard</p>
<p>to like start making any progress in diplomacy.</p>
<p>Can you just formulate what is the problem</p>
<p>from an AI perspective and why is it hard?</p>
<p>Why is it a challenging game to solve?</p>
<p>So there&rsquo;s a lot of aspects in diplomacy</p>
<p>that make it a huge challenge.</p>
<p>First of all, you have the natural language components.</p>
<p>And I think this really is what makes it</p>
<p>arguably the most difficult game</p>
<p>among like the major benchmarks.</p>
<p>The fact that you have to,</p>
<p>it&rsquo;s not about moving pieces on the board.</p>
<p>Your action space is basically all the different sentences</p>
<p>that you could communicate to somebody else in this game.</p>
<p>And-</p>
<p>Is there, can we just like linger on that?</p>
<p>So is part of it like the ambiguity in the language?</p>
<p>If it was like very strict,</p>
<p>if you narrowed the set of possible sentences</p>
<p>you could do it,</p>
<p>would that simplify the game significantly?</p>
<p>The real difficulty is the breadth of things</p>
<p>that you can talk about.</p>
<p>You can have natural language in other games</p>
<p>like Settlers of Catan, for example,</p>
<p>like you could have a natural language,</p>
<p>Settlers of Catan AI.</p>
<p>But the things that you&rsquo;re gonna talk about</p>
<p>are basically like, am I trading you two sheep for a wood</p>
<p>or three sheep for a wood?</p>
<p>Whereas in a game like Diplomacy,</p>
<p>the breadth of conversations that you&rsquo;re going to have</p>
<p>are like, am I going to support you?</p>
<p>Are you gonna support me in return?</p>
<p>Which units are gonna do what?</p>
<p>What did this other person promise you?</p>
<p>They&rsquo;re lying because they told this other person</p>
<p>that they&rsquo;re gonna do this instead.</p>
<p>If you help me out this turn,</p>
<p>then in the future I&rsquo;ll do these things</p>
<p>that will help you out.</p>
<p>The depth and breadth of these conversations</p>
<p>is really complicated.</p>
<p>And it&rsquo;s all being done in natural language.</p>
<p>Now you could approach it,</p>
<p>and we actually considered doing this,</p>
<p>like having a simplified language</p>
<p>to make this complexity smaller.</p>
<p>But ultimately we thought the most impactful way</p>
<p>of doing this research would be to address</p>
<p>the natural language component head on</p>
<p>and just try to go for the full game upfront.</p>
<p>Just looking at sample games</p>
<p>and what the conversations look like.</p>
<p>Greetings, England.</p>
<p>This should prove to be a fun game</p>
<p>since all the private press</p>
<p>is going to be made public at the end.</p>
<p>At the least, it will be interesting to see</p>
<p>if the press changes because of that.</p>
<p>Anyway, good.</p>
<p>Okay, so there&rsquo;s like a-</p>
<p>Yeah, that&rsquo;s just kind of like the generic greetings</p>
<p>at the beginning of the game.</p>
<p>I think that the meat comes a little bit later</p>
<p>when you&rsquo;re starting to talk about</p>
<p>specific strategy and stuff.</p>
<p>I agree there are a lot of advantages</p>
<p>to the two of us keeping in touch</p>
<p>and our nations make strong natural allies</p>
<p>in the middle game.</p>
<p>So that kind of stuff.</p>
<p>Making friends, making enemies.</p>
<p>Yeah, or like if you look at the next line,</p>
<p>so the person saying like,</p>
<p>I&rsquo;ve heard bits about a Lepanto and an octopus opening</p>
<p>and basically telling Austria like,</p>
<p>hey, just a heads up.</p>
<p>You know, I&rsquo;ve heard these whispers</p>
<p>about like what might be going on behind your back.</p>
<p>Yeah, so there&rsquo;s all kinds of complexities</p>
<p>in the language of that, right?</p>
<p>Like to interpret what the heck that means.</p>
<p>It&rsquo;s hard for us humans, but for AI, it&rsquo;s even harder</p>
<p>because you have to understand like at every level,</p>
<p>the semantics of that.</p>
<p>Right, I mean, there&rsquo;s a complexity in understanding</p>
<p>when somebody is saying this to me, what does that mean?</p>
<p>And then there&rsquo;s also the complexity of like,</p>
<p>should I be telling this person this?</p>
<p>Like I&rsquo;ve overheard these whispers.</p>
<p>Should I be telling this person that like,</p>
<p>hey, you might be getting attacked by this other power?</p>
<p>Okay, so how are we supposed to think about?</p>
<p>Okay, so that&rsquo;s the natural language.</p>
<p>How do you even begin trying to solve this game?</p>
<p>It seems like the Turing test on steroids.</p>
<p>Yeah, and I mean, there&rsquo;s the natural language aspect.</p>
<p>And then even besides the natural language aspect,</p>
<p>you also have the cooperative elements of the game.</p>
<p>And I think this is actually something</p>
<p>that I find really interesting.</p>
<p>If you look at all the previous game AI breakthroughs,</p>
<p>they&rsquo;ve all happened in these purely adversarial games</p>
<p>where you don&rsquo;t actually need to understand</p>
<p>how humans play the game.</p>
<p>It&rsquo;s all just AI versus AI, right?</p>
<p>Like you look at checkers, chess, Go, poker,</p>
<p>Starcraft, Dota 2.</p>
<p>Like in some of those cases, they leveraged human data,</p>
<p>but they never needed to.</p>
<p>They were always just trying to have a scalable algorithm</p>
<p>that then they could throw</p>
<p>a lot of computational resources at, a lot of memory at.</p>
<p>And then eventually it would converge</p>
<p>to an approximation of a Nash equilibrium.</p>
<p>This perfect strategy that in a two-player zero-sum game</p>
<p>guarantees that they&rsquo;re going to be able</p>
<p>to not lose to any opponents.</p>
<p>So you can&rsquo;t leverage self-play to solve this game.</p>
<p>You can leverage self-play,</p>
<p>but it&rsquo;s no longer sufficient to beat humans.</p>
<p>So how do you integrate the human into the loop of this?</p>
<p>So what you have to do is incorporate human data.</p>
<p>And to kind of give you some intuition</p>
<p>for why this is the case,</p>
<p>like imagine you&rsquo;re playing a negotiation game,</p>
<p>like diplomacy,</p>
<p>but you&rsquo;re training completely from scratch</p>
<p>without any human data.</p>
<p>The AI is not going to suddenly like</p>
<p>figure out how to communicate in English.</p>
<p>It&rsquo;s going to figure out some weird robot language</p>
<p>that only it will understand.</p>
<p>And then when you stick that in a game</p>
<p>with six other humans,</p>
<p>they&rsquo;re going to think this person&rsquo;s talking gibberish</p>
<p>and they&rsquo;re just going to ally with each other</p>
<p>and team up against the bot.</p>
<p>Or not even team up against the bot,</p>
<p>but just not work with the bot.</p>
<p>And so in order to be able to play this game with humans,</p>
<p>it has to understand the human way of playing the game,</p>
<p>not this machine way of playing the game.</p>
<p>Yeah.</p>
<p>Yeah, that&rsquo;s fascinating.</p>
<p>So, right.</p>
<p>That&rsquo;s a nuanced thing to understand</p>
<p>because a chess playing program</p>
<p>doesn&rsquo;t need to play like a human to beat a human.</p>
<p>Exactly.</p>
<p>But here you have to play like a human</p>
<p>in order to beat them.</p>
<p>Or at least you have to understand</p>
<p>how humans play the game</p>
<p>so that you can understand how to work with them.</p>
<p>If they have certain expectations</p>
<p>about what does it mean to be a good ally,</p>
<p>what does it mean to have like a reciprocal relationship</p>
<p>where we&rsquo;re working together?</p>
<p>You have to abide by those conventions.</p>
<p>And if you don&rsquo;t,</p>
<p>they&rsquo;re just going to work with somebody else instead.</p>
<p>Do you think of this as a clean,</p>
<p>in some deep sense of the spirit of the Turing test</p>
<p>as formulated by Alan Turing?</p>
<p>Is it, in some sense,</p>
<p>this is what the Turing test actually looks like?</p>
<p>So, because of open-ended natural language conversation</p>
<p>it seems like very difficult to evaluate.</p>
<p>Like here at a high stakes</p>
<p>where humans are trying to win a game,</p>
<p>that seems like how you actually perform the Turing test.</p>
<p>I think it&rsquo;s different from the Turing test.</p>
<p>Like the way that the Turing test is formulated,</p>
<p>it&rsquo;s about trying to distinguish a human from a machine</p>
<p>and seeing, oh, could the machine successfully pass</p>
<p>as a human in this adversarial setting</p>
<p>where the player is trying to figure out</p>
<p>whether it&rsquo;s a machine or a human.</p>
<p>Whereas in diplomacy,</p>
<p>it&rsquo;s not about trying to figure out</p>
<p>whether this player is a human or a machine.</p>
<p>It&rsquo;s ultimately about whether I can work with this player</p>
<p>regardless of whether they are a human or a machine.</p>
<p>And can the machine do that better than a human can?</p>
<p>Yeah, I&rsquo;m gonna have to think about that,</p>
<p>but that just feels like the implied requirement for that</p>
<p>is for the machine to be human-like.</p>
<p>I think that&rsquo;s true,</p>
<p>that if you&rsquo;re going to play in this human game,</p>
<p>you have to somehow adapt to the human surroundings</p>
<p>and the human play style.</p>
<p>And to win, you have to adapt.</p>
<p>So you can&rsquo;t, if you&rsquo;re the outsider,</p>
<p>if you&rsquo;re not human-like,</p>
<p>I feel like that&rsquo;s a losing strategy.</p>
<p>I think that&rsquo;s correct, yeah.</p>
<p>Yeah, so, okay.</p>
<p>What are the complexities here?</p>
<p>What was your approach to it?</p>
<p>Before I get to that,</p>
<p>one thing I should explain</p>
<p>why we decided to work on Diplomacy.</p>
<p>So basically what happened is in 2019,</p>
<p>I was wrapping up the work on six-player poker on Pluribus</p>
<p>and was trying to think about what to work on next.</p>
<p>And I had been seeing all these other breakthroughs</p>
<p>happening in AI.</p>
<p>I mean, like 2019, you have StarCraft,</p>
<p>you have AlphaStar beating humans in StarCraft.</p>
<p>You&rsquo;ve got the Dota 2 stuff happening at OpenAI.</p>
<p>You have GPT-2 or GPT-3,</p>
<p>I think it was GPT-2 at the time.</p>
<p>And it became clear that AI was progressing</p>
<p>really, really rapidly.</p>
<p>And people were throwing out these other games</p>
<p>about what should be the next challenge for multi-agent AI.</p>
<p>And I just felt like we had to aim bigger.</p>
<p>If you look at a game like chess or a game like Go,</p>
<p>they took decades for researchers</p>
<p>to ultimately reach superhuman performance at.</p>
<p>I mean, chess took 40 years of AI research,</p>
<p>Go took another 20 years.</p>
<p>And we thought that diplomacy</p>
<p>would be this incredibly difficult challenge</p>
<p>that could easily take a decade</p>
<p>to make an AI that could play competently.</p>
<p>But we felt like that was a goal worth aiming for.</p>
<p>And so honestly, I was kind of reluctant</p>
<p>to work on it at first,</p>
<p>because I thought it was like too far</p>
<p>out of the realm of possibility.</p>
<p>But I was talking to a coworker of mine, Adam Lear,</p>
<p>and he was basically saying like,</p>
<p>eh, why not aim for it?</p>
<p>We&rsquo;ll learn some interesting things along the way,</p>
<p>and maybe it&rsquo;ll be possible.</p>
<p>And so we decided to go for it.</p>
<p>And I think it was the right choice</p>
<p>considering just how much progress there was in AI.</p>
<p>And that progress has continued in the years since.</p>
<p>So winning in diplomacy, what does that really look like?</p>
<p>It means talking to six other players,</p>
<p>six other entities, agents,</p>
<p>and convincing them of stuff</p>
<p>that you want them to be convinced of.</p>
<p>Like what exactly, I&rsquo;m trying to get like,</p>
<p>to deeply understand what the problem is.</p>
<p>Ultimately, the problem is, it&rsquo;s simple to quantify, right?</p>
<p>Like you&rsquo;re going to play this game with humans,</p>
<p>and you want your score on average</p>
<p>to be as high as possible.</p>
<p>You know, if you can say like,</p>
<p>I am winning more than any human alive,</p>
<p>then you&rsquo;re a champion diplomacy player.</p>
<p>Now, ultimately, we didn&rsquo;t reach that.</p>
<p>We got to human level performance.</p>
<p>We actually, so we played about 40 games</p>
<p>with real humans online.</p>
<p>The bot came in second out of all players</p>
<p>that played five or more games.</p>
<p>And so not like number one, but way, way higher than-</p>
<p>What was the expertise level?</p>
<p>Are they beginners?</p>
<p>Are they intermediate players, advanced players?</p>
<p>Do you have a sense?</p>
<p>That&rsquo;s a great question.</p>
<p>And so I think this kind of goes into</p>
<p>how do you measure the performance in diplomacy?</p>
<p>And I would argue that when you&rsquo;re measuring performance</p>
<p>in a game like this, you don&rsquo;t actually want to measure it</p>
<p>in games with all expert players.</p>
<p>It&rsquo;s kind of like, if you&rsquo;re developing a self-driving car,</p>
<p>you don&rsquo;t want to measure that car on the road</p>
<p>with a bunch of expert stunt drivers.</p>
<p>You want to put it on a road of like an actual American city</p>
<p>and see, is this car crashing less often</p>
<p>than an expert driver would?</p>
<p>So that&rsquo;s the metric that we&rsquo;ve used.</p>
<p>We&rsquo;re saying like, we&rsquo;re going to stick this game,</p>
<p>we&rsquo;re going to stick this bot in games</p>
<p>with a wide variety of skill levels.</p>
<p>And then are we doing better than a strong</p>
<p>or expert human player would in the same situation?</p>
<p>That&rsquo;s quite brilliant.</p>
<p>Because I played a lot of sports in my life,</p>
<p>like I did tennis, judo, whatever.</p>
<p>And it&rsquo;s somehow almost easier to go against experts</p>
<p>almost always.</p>
<p>I don&rsquo;t know.</p>
<p>I think they&rsquo;re more predictable in the quality of play.</p>
<p>The space of strategies you&rsquo;re operating under</p>
<p>is narrower against the experts.</p>
<p>It&rsquo;s more fun.</p>
<p>It&rsquo;s really frustrating to go against beginners.</p>
<p>Also, because beginners talk trash to you</p>
<p>when they somehow do beat you.</p>
<p>So that&rsquo;s a human thing that they add</p>
<p>is not to be worried about that.</p>
<p>But yeah, the variance in strategies is greater,</p>
<p>especially with natural language.</p>
<p>It&rsquo;s just all over the place then.</p>
<p>True.</p>
<p>Yeah, and honestly, when you look at</p>
<p>what makes a good human diplomacy player,</p>
<p>obviously they&rsquo;re able to handle themselves</p>
<p>in games with other expert humans,</p>
<p>but where they really shine is when they&rsquo;re playing</p>
<p>with these weak players.</p>
<p>And they know how to take advantage</p>
<p>of the fact that they&rsquo;re a weak player,</p>
<p>that they won&rsquo;t be able to pull off a stab as well,</p>
<p>or that they have certain tendencies</p>
<p>and they can take them under their wing</p>
<p>and persuade them to do things</p>
<p>that might not even be in their interest.</p>
<p>The really good diplomacy players are able</p>
<p>to take advantage of the fact</p>
<p>that there are some weak players in the game.</p>
<p>Okay, so if you have to incorporate human play data,</p>
<p>how do you do that?</p>
<p>How do you do that in order to train an AI system</p>
<p>to play diplomacy?</p>
<p>Yeah, so that&rsquo;s really the crux of the problem.</p>
<p>How do we leverage the benefits of self-play</p>
<p>that have been so successful</p>
<p>in all these other previous games</p>
<p>while keeping the strategy as human compatible as possible?</p>
<p>And so what we did is we first trained a language model</p>
<p>and then we made that language model controllable</p>
<p>on a set of intents, what we call intents,</p>
<p>which are basically like an action that we want to play</p>
<p>and an action that we would like the other player to play.</p>
<p>And so this gives us a way to generate dialogue</p>
<p>that&rsquo;s not just trying to imitate the human style,</p>
<p>whatever a human would say in this situation,</p>
<p>but to actually give it an intent,</p>
<p>a purpose in its communication.</p>
<p>We can talk about a specific move</p>
<p>or we can make a specific request.</p>
<p>And the determination of what that move is</p>
<p>that we&rsquo;re discussing comes from a strategic reasoning model</p>
<p>that uses reinforcement learning and planning.</p>
<p>So computing the intents for all the players,</p>
<p>how is that done?</p>
<p>Just as a starting point,</p>
<p>is that with reinforcement learning</p>
<p>or is that just optimal,</p>
<p>determining what the optimal is for intents?</p>
<p>It&rsquo;s a combination of reinforcement learning and planning.</p>
<p>Actually very similar to how we approached poker</p>
<p>and how people approached chess and go as well.</p>
<p>We&rsquo;re using self-play and search</p>
<p>to try to figure out what is an optimal move for us</p>
<p>and what is a desirable move</p>
<p>that we would like this other player to play.</p>
<p>Now, the difference between the way</p>
<p>that we approached reinforcement learning and search</p>
<p>in this game versus those previous games</p>
<p>is that we have to keep it human compatible.</p>
<p>We have to understand how the other person</p>
<p>is likely to play rather than just assuming</p>
<p>that they&rsquo;re gonna play like a machine.</p>
<p>And how language gets them to play</p>
<p>in a way that maximize the chance of following the intent</p>
<p>you want them to follow.</p>
<p>Okay, how do you do that?</p>
<p>How do you connect language to intent?</p>
<p>So the way that RL and planning is done</p>
<p>is actually not using language.</p>
<p>So we&rsquo;re coming up with this plan for the action</p>
<p>that we&rsquo;re gonna play and the other person&rsquo;s gonna play</p>
<p>and then we feed that action into the dialogue model</p>
<p>that will then send a message according to those plans.</p>
<p>So the language model there is mapping action to-</p>
<p>To message.</p>
<p>To message.</p>
<p>One word at a time.</p>
<p>Basically one message at a time.</p>
<p>So we&rsquo;ll feed into the dialogue model,</p>
<p>like here are the actions that you should be discussing.</p>
<p>Here&rsquo;s the message.</p>
<p>Here&rsquo;s like the content of the message</p>
<p>that we would like you to send.</p>
<p>And then it will actually generate a message</p>
<p>that corresponds to that.</p>
<p>Okay, does this actually work?</p>
<p>It works surprisingly well.</p>
<p>Okay, how?</p>
<p>Oh man, the number of ways it probably goes horribly,</p>
<p>I would have imagined it goes horribly wrong.</p>
<p>So how the heck is it effective at all?</p>
<p>I mean, there are a lot of ways that this could fail.</p>
<p>So for example, I mean, you could have a situation</p>
<p>where you&rsquo;re basically like,</p>
<p>we don&rsquo;t tell the language model,</p>
<p>like here are the pieces of our action</p>
<p>or the other person&rsquo;s action</p>
<p>that you should be communicating.</p>
<p>And so like, let&rsquo;s say you&rsquo;re about to attack somebody.</p>
<p>You probably don&rsquo;t want to tell them</p>
<p>that you&rsquo;re going to attack them,</p>
<p>but there&rsquo;s nothing in the language.</p>
<p>Like the language model is not very smart</p>
<p>at the end of the day.</p>
<p>So it doesn&rsquo;t really have a way of knowing like,</p>
<p>well, what should I be talking about?</p>
<p>Should I tell this person</p>
<p>that I&rsquo;m about to attack them or not?</p>
<p>So we have to like develop a lot of other techniques</p>
<p>that deal with that.</p>
<p>Like one of the things we do, for example,</p>
<p>is we try to calculate if I&rsquo;m going to send this message,</p>
<p>what would I expect the other person to do in response?</p>
<p>So if it&rsquo;s a message like,</p>
<p>hey, I&rsquo;m going to attack you this turn,</p>
<p>they&rsquo;re probably going to attack us</p>
<p>or defend against that attack.</p>
<p>And so we have a way of recognizing like,</p>
<p>hey, sending this message</p>
<p>is a negative expected value action,</p>
<p>and we should not send this message.</p>
<p>So you have for particular kinds of messages,</p>
<p>you have like an extra function</p>
<p>that estimates the value of that message.</p>
<p>Yeah.</p>
<p>So we have these kinds of filters that like-</p>
<p>So it&rsquo;s a filter.</p>
<p>So there&rsquo;s a good,</p>
<p>and is that filter in your network or is it rule-based?</p>
<p>That&rsquo;s a neural network.</p>
<p>So we&rsquo;re, well, it&rsquo;s a combination.</p>
<p>It&rsquo;s a neural network, but it&rsquo;s also using planning.</p>
<p>It&rsquo;s trying to compute like,</p>
<p>what is the policy that the other players are going to play</p>
<p>given that this message has been sent?</p>
<p>And then is that better than not sending the message?</p>
<p>I feel like that&rsquo;s how my brain works too.</p>
<p>Like there&rsquo;s a language model that generates random crap,</p>
<p>and then there&rsquo;s these other neural nets</p>
<p>that are essentially filters.</p>
<p>At least that&rsquo;s when I tweet.</p>
<p>Usually my process of tweeting,</p>
<p>I&rsquo;ll think of something and it&rsquo;s hilarious to me,</p>
<p>and then about five seconds later,</p>
<p>the filter network comes in and says,</p>
<p>no, no, that&rsquo;s not funny at all.</p>
<p>I mean, there&rsquo;s something interesting</p>
<p>to that kind of process.</p>
<p>So you have a set of actions that you want,</p>
<p>you have an intent that you want to achieve,</p>
<p>an intent that you want your opponent to achieve,</p>
<p>then you generate messages,</p>
<p>and then you evaluate if those messages</p>
<p>will achieve the goal you want.</p>
<p>Yeah, and we&rsquo;re filtering for several things.</p>
<p>We&rsquo;re filtering like, is this a sensible message?</p>
<p>So sometimes language models will send,</p>
<p>will generate messages that are just like totally nonsense.</p>
<p>And we try to filter those out.</p>
<p>We also try to filter out messages that are basically lies.</p>
<p>So diplomacy has this reputation as a game</p>
<p>that&rsquo;s really about deception and lying,</p>
<p>but we try to actually minimize</p>
<p>the amount that the bot would lie.</p>
<p>This was actually mostly a-</p>
<p>Or are you?</p>
<p>No, I&rsquo;m just kidding, Eric, go ahead.</p>
<p>I mean, like part of the reason for this</p>
<p>is that we actually found that lying</p>
<p>would make the bot perform worse in the long run.</p>
<p>It would end up with a lower score.</p>
<p>Because once the bot lies,</p>
<p>people would never trust it again.</p>
<p>And trust is a huge aspect of the game of diplomacy.</p>
<p>I&rsquo;m taking notes here,</p>
<p>because I think this applies to life lessons too.</p>
<p>Oh, I think it&rsquo;s a really, yeah, really strong-</p>
<p>So like lying is a dangerous thing to do.</p>
<p>Like you want to avoid obvious lying.</p>
<p>Yeah, I mean, I think when people play diplomacy</p>
<p>for the first time,</p>
<p>they approach it as a game of deception and lying,</p>
<p>and they, ultimately, if you talk to top diplomacy players,</p>
<p>what they&rsquo;ll tell you is that diplomacy</p>
<p>is a game about trust,</p>
<p>and being able to build trust in an environment</p>
<p>that encourages people to not trust anyone.</p>
<p>So that&rsquo;s the ultimate tension in diplomacy.</p>
<p>How can this AI reason about</p>
<p>whether you are being honest in your communication,</p>
<p>and how can the AI persuade you that it is being honest</p>
<p>when it is telling you that,</p>
<p>hey, I&rsquo;m actually going to support you this turn?</p>
<p>Is there some sense,</p>
<p>I don&rsquo;t know if you step back and think,</p>
<p>that this process will indirectly</p>
<p>help us study human psychology?</p>
<p>So like, if trust is the ultimate goal,</p>
<p>wouldn&rsquo;t that help us understand</p>
<p>what are the fundamental aspects of forming trust</p>
<p>between humans and between humans and AI?</p>
<p>I mean, that&rsquo;s a really, really important question</p>
<p>that&rsquo;s much bigger than strategy games.</p>
<p>It&rsquo;s how can, that&rsquo;s fundamental</p>
<p>to the human-robot interaction problem.</p>
<p>How do we form trust between intelligent entities?</p>
<p>So one of the things I&rsquo;m really excited about</p>
<p>with diplomacy, there&rsquo;s never really been a good domain</p>
<p>to investigate these kinds of questions.</p>
<p>And diplomacy gives us a domain</p>
<p>where trust is really at the center of it.</p>
<p>And it&rsquo;s not just like you&rsquo;ve hired</p>
<p>a bunch of mechanical Turkers that are being paid</p>
<p>and trying to get through the task as quickly as possible.</p>
<p>You have these people that are really invested</p>
<p>in the outcome of the game,</p>
<p>and they&rsquo;re really trying to do the best that they can.</p>
<p>And so I&rsquo;m really excited that we&rsquo;re able to,</p>
<p>we actually like have put together this,</p>
<p>we&rsquo;re open sourcing all of our models,</p>
<p>we&rsquo;re open sourcing all of the code,</p>
<p>and we&rsquo;re making the data that we&rsquo;ve used</p>
<p>available to researchers</p>
<p>so that they can investigate these kinds of questions.</p>
<p>So the data of the different,</p>
<p>the human and the AI play of diplomacy</p>
<p>and the models that you use</p>
<p>for the generation of the messages and the filtering.</p>
<p>Yeah, not just even the data</p>
<p>of the AI playing with the humans,</p>
<p>but all the training data that we had,</p>
<p>that we use to train the AI</p>
<p>to understand how humans play the game.</p>
<p>We&rsquo;re setting up a system</p>
<p>where researchers will be able to apply</p>
<p>to be able to gain access to that data</p>
<p>and be able to use it in their own research.</p>
<p>We should say, what is the name of the system?</p>
<p>We&rsquo;re calling the bot Cicero.</p>
<p>Cicero.</p>
<p>And what&rsquo;s the name, like you&rsquo;re open sourcing,</p>
<p>what&rsquo;s the name of the repository and the project?</p>
<p>Is it also just called Cicero the big project?</p>
<p>Or is it still coming up with a name?</p>
<p>The data set comes from this website, webdiplomacy.net,</p>
<p>is this site that&rsquo;s been online for like 20 years now.</p>
<p>And it&rsquo;s one of the main sites</p>
<p>that people use to play diplomacy on it.</p>
<p>We&rsquo;ve got like 50,000 games of diplomacy</p>
<p>with natural language communication,</p>
<p>over 10 million messages.</p>
<p>So it&rsquo;s a pretty massive data set that people can use to,</p>
<p>we&rsquo;re hoping that the academic community</p>
<p>and the research community is able to use it</p>
<p>for all sorts of interesting research questions.</p>
<p>So to you from having studied this game,</p>
<p>is this a sufficiently rich problem space</p>
<p>to explore this kind of human AI interaction?</p>
<p>Yeah, absolutely.</p>
<p>And I think it&rsquo;s maybe the best data set</p>
<p>that I can think of out there</p>
<p>to investigate these kinds of questions of negotiation,</p>
<p>trust, persuasion.</p>
<p>I wouldn&rsquo;t say it&rsquo;s the best data set in the world</p>
<p>for human AI interaction.</p>
<p>That&rsquo;s a very broad field,</p>
<p>but I think that it&rsquo;s definitely up there.</p>
<p>It&rsquo;s like, if you&rsquo;re really interested</p>
<p>in language models interacting with humans</p>
<p>in a setting where their incentives are not fully aligned,</p>
<p>this seems like an ideal data set for investigating that.</p>
<p>So you have a paper with some impressive results</p>
<p>and just an impressive paper that taken this problem on.</p>
<p>What&rsquo;s the most exciting thing to you</p>
<p>in terms of the results from the paper?</p>
<p>Ideas or results?</p>
<p>Yeah, I think there&rsquo;s a few aspects of the results</p>
<p>and that I think are really exciting.</p>
<p>So first of all,</p>
<p>the fact that we were able to achieve</p>
<p>such strong performance,</p>
<p>I was surprised by and pleasantly surprised by.</p>
<p>So we played 40 games of Diplomacy with real humans</p>
<p>and the bot placed second out of all players</p>
<p>that have played five or more games.</p>
<p>So it&rsquo;s about 80 players total,</p>
<p>19 of whom played five or more games</p>
<p>and the bot was ranked second out of those players.</p>
<p>And the bot was really good in two dimensions.</p>
<p>One, being able to establish strong connections</p>
<p>with the other players on the board,</p>
<p>being able to persuade them to work with it,</p>
<p>being able to coordinate with them</p>
<p>about how it&rsquo;s going to work with them.</p>
<p>And then also the raw tactical</p>
<p>and strategic aspects of the game,</p>
<p>being able to understand</p>
<p>what the other players are likely to do,</p>
<p>being able to model their behavior</p>
<p>and respond appropriately to that,</p>
<p>the bot also really excelled at.</p>
<p>What are some interesting things that the bot said?</p>
<p>By the way, are you allowed to swear in the,</p>
<p>like are there rules to what you&rsquo;re allowed to say</p>
<p>and not in Diplomacy?</p>
<p>You can say whatever you want.</p>
<p>I think the site will get very angry at you</p>
<p>if you start like threatening somebody.</p>
<p>And we actually-</p>
<p>Like if you threaten somebody,</p>
<p>you&rsquo;re supposed to do it politely.</p>
<p>Yeah, politely, you know, like keep it in character.</p>
<p>The bot, we actually had a researcher</p>
<p>watching the bot 24 seven for,</p>
<p>well, whenever we play a game,</p>
<p>we had a bot watching it to make sure</p>
<p>that it wouldn&rsquo;t go off the rails</p>
<p>and start like threatening somebody or something like that.</p>
<p>I would just love it if the bot started like mocking,</p>
<p>mocking everybody,</p>
<p>like some weird quirky strategies would emerge.</p>
<p>They have you seen anything interesting that you,</p>
<p>huh, that&rsquo;s a weird,</p>
<p>that&rsquo;s a weird behavior,</p>
<p>either the filter or the language model</p>
<p>that was weird to you.</p>
<p>Yeah, there were definitely like things</p>
<p>that the bot would do that were not in line</p>
<p>with like how humans would approach the game</p>
<p>and that in a good way,</p>
<p>the humans actually, you know,</p>
<p>we&rsquo;ve talked to some expert Diplomacy players</p>
<p>about these results and their takeaway is that,</p>
<p>well, maybe humans are approaching this the wrong way</p>
<p>and this is actually like the right way to play the game.</p>
<p>So-</p>
<p>What&rsquo;s required to win?</p>
<p>Like what does it mean to mess up</p>
<p>or to exploit the suboptimal behavior of a player?</p>
<p>Like, is there optimally rational behavior</p>
<p>and irrational behavior that you need to estimate,</p>
<p>that kind of stuff?</p>
<p>Like what stands out to you?</p>
<p>Like, is there a crack that you can exploit?</p>
<p>Is there like a weakness that you can exploit in the game</p>
<p>that everybody&rsquo;s looking for?</p>
<p>Well, I think you&rsquo;re asking kind of two questions there.</p>
<p>So one, like modeling the irrationality</p>
<p>and the suboptimality of humans.</p>
<p>You can&rsquo;t, in Diplomacy,</p>
<p>you can&rsquo;t treat all the other players like they&rsquo;re machines.</p>
<p>And if you do that,</p>
<p>you&rsquo;re going to end up playing really poorly.</p>
<p>And so we actually ran this experiment.</p>
<p>So we trained a bot in a two-player</p>
<p>zero-sum version of Diplomacy,</p>
<p>the same way that you might approach a game</p>
<p>like chess or poker,</p>
<p>and the bot was superhuman.</p>
<p>It would crush any competitor.</p>
<p>And then we took that same training approach</p>
<p>and we trained a bot</p>
<p>for the full seven-player version of the game</p>
<p>through self-play, without any human data.</p>
<p>And we stuck it in a game with six humans</p>
<p>and it got destroyed.</p>
<p>Even in the version of the game</p>
<p>where there&rsquo;s no explicit natural language communication,</p>
<p>it still got destroyed</p>
<p>because it just wouldn&rsquo;t be able to understand</p>
<p>how the other players were approaching the game</p>
<p>and be able to work with that.</p>
<p>Can you just linger on that,</p>
<p>meaning like there&rsquo;s an individual,</p>
<p>there&rsquo;s an individual personality to each player</p>
<p>and then you&rsquo;re supposed to remember that?</p>
<p>What do you mean it&rsquo;s not able to understand the players?</p>
<p>Well, it would, for example,</p>
<p>expect the human to support it in a certain way</p>
<p>when the human would simply think like,</p>
<p>no, I&rsquo;m not supposed to support you here.</p>
<p>It&rsquo;s kind of like if you develop a self-driving car</p>
<p>and it&rsquo;s trained completely from scratch</p>
<p>with other self-driving cars,</p>
<p>it might learn to drive on the left side of the road.</p>
<p>That&rsquo;s a totally reasonable thing to do</p>
<p>if you&rsquo;re with these other self-driving cars</p>
<p>that are also driving on the left side of the road.</p>
<p>But if you put it in an American city, it&rsquo;s gonna crash.</p>
<p>But I guess the intuition I&rsquo;m trying to build up</p>
<p>is why does it then crush a human player heads up</p>
<p>versus multiple?</p>
<p>This is an aspect of two-player zero-sum</p>
<p>versus games that involve cooperation.</p>
<p>So in a two-player zero-sum game,</p>
<p>you can do self-play from scratch</p>
<p>and you will arrive at the Nash equilibrium</p>
<p>where you don&rsquo;t have to worry about the other player</p>
<p>playing in a very human suboptimal style.</p>
<p>That&rsquo;s just gonna be,</p>
<p>the only way that deviating from a Nash equilibrium</p>
<p>would change things is if it helped you.</p>
<p>So what&rsquo;s the dynamic of cooperation</p>
<p>that&rsquo;s effective in diplomacy?</p>
<p>Do you always have to have one friend in the game?</p>
<p>You always want to maximize your friends</p>
<p>and minimize your enemies.</p>
<p>Got it.</p>
<p>And boy, the lying comes into play there.</p>
<p>So the more friends you have, the better.</p>
<p>Yeah, I mean, I guess you have to attack somebody</p>
<p>or else you&rsquo;re not gonna make progress.</p>
<p>Right, so that&rsquo;s the tension.</p>
<p>But man, this is too real.</p>
<p>This is too real.</p>
<p>This is too close to geopolitics</p>
<p>of actual military conflict in the world.</p>
<p>Okay, that&rsquo;s fascinating.</p>
<p>So that cooperation element</p>
<p>is what makes the game really, really hard.</p>
<p>Yeah, and to give you an example</p>
<p>of how this suboptimality and irrationality comes into play,</p>
<p>there&rsquo;s a really common situation in a game of diplomacy</p>
<p>that where one player starts to win</p>
<p>and they&rsquo;re at the point where they&rsquo;re controlling</p>
<p>about half the map.</p>
<p>And the remaining players</p>
<p>who have all been fighting each other the whole game</p>
<p>all have to work together now</p>
<p>to stop this other player from winning</p>
<p>or else everybody&rsquo;s gonna lose.</p>
<p>And it&rsquo;s kind of like Game of Thrones.</p>
<p>I don&rsquo;t know if you&rsquo;ve seen the show</p>
<p>where you got the others coming from the north</p>
<p>and all the people have to work out their differences</p>
<p>and stop them from taking over.</p>
<p>And the bot will do this.</p>
<p>The bot will work with the other players</p>
<p>to stop the superpower from winning.</p>
<p>But if it&rsquo;s trained from scratch</p>
<p>or it doesn&rsquo;t really have a good grounding</p>
<p>in how humans approach it,</p>
<p>it will also at the same time</p>
<p>attack the other players with its extra units.</p>
<p>So all the units that are not necessary</p>
<p>to stop the superpower from winning,</p>
<p>it will use those to grab as many centers as possible</p>
<p>from the other players.</p>
<p>And in totally rational play,</p>
<p>the other players should just live with that.</p>
<p>They have to understand like,</p>
<p>hey, a score of one is better than a score of zero.</p>
<p>So, okay, he&rsquo;s grabbed my centers,</p>
<p>but I&rsquo;ll just deal with it.</p>
<p>But humans don&rsquo;t act that way, right?</p>
<p>The human gets really angry at the bot</p>
<p>and ends up throwing the game</p>
<p>because I&rsquo;m gonna screw you over</p>
<p>because you did something that&rsquo;s not fair to me.</p>
<p>Got it.</p>
<p>And are you supposed to model that?</p>
<p>Is the bot supposed to model that kind of human frustration?</p>
<p>Yeah, exactly.</p>
<p>So that is something that seems almost impossible</p>
<p>to model purely from scratch without any human data.</p>
<p>It&rsquo;s a very cultural thing.</p>
<p>And so you need human data to be able to understand that,</p>
<p>hey, that&rsquo;s how humans behave.</p>
<p>And you have to work around that.</p>
<p>It might be suboptimal, it might be irrational,</p>
<p>but that&rsquo;s an aspect of humanity</p>
<p>that you have to deal with.</p>
<p>So how difficult is it to train on human data</p>
<p>given that human data is very limited</p>
<p>versus what a purely self-play mechanism can generate?</p>
<p>That&rsquo;s actually one of the major challenges</p>
<p>that we faced in the research,</p>
<p>that we had a good amount of human data.</p>
<p>We had about 50,000 games.</p>
<p>What we try to do is leverage as much self-play as possible</p>
<p>while still leveraging the human data.</p>
<p>So what we do is we do self-play,</p>
<p>very similar to how it&rsquo;s been done in poker and Go,</p>
<p>but we try to regularize the self-play</p>
<p>towards the human data.</p>
<p>Basically, the way to think about it is</p>
<p>we penalize the bot for choosing actions</p>
<p>that are very unlikely under the human data set.</p>
<p>And so-</p>
<p>How do you know, is there some kind of function</p>
<p>that says this is human-like and not?</p>
<p>Yeah, so we train a bot through supervised learning</p>
<p>to model the human play as much as possible.</p>
<p>So we basically train a neural net on those 50,000 games,</p>
<p>and that gives us an approximate,</p>
<p>that gives us a policy that resembles to some extent</p>
<p>how humans actually play the game.</p>
<p>Now, this isn&rsquo;t a perfect model of human play</p>
<p>because we don&rsquo;t have unlimited data.</p>
<p>We don&rsquo;t have unlimited neural net capacity,</p>
<p>but it gives us some approximation.</p>
<p>Is there some data on the internet</p>
<p>that&rsquo;s useful besides just diplomacy?</p>
<p>So on the language side of things, is there some,</p>
<p>can you go to like Reddit?</p>
<p>And so sort of background model formulation</p>
<p>that&rsquo;s useful for the game of diplomacy?</p>
<p>Yeah, absolutely.</p>
<p>So for the language model,</p>
<p>which is kind of like a separate question,</p>
<p>we didn&rsquo;t use the language model during self-play training,</p>
<p>but we pre-trained the language model</p>
<p>on tons of internet data as much as possible.</p>
<p>And then we fine-tuned it specifically</p>
<p>on the diplomacy games.</p>
<p>So we are able to like leverage the wider data set</p>
<p>in order to fill in some of the gaps</p>
<p>in like how communication happens more broadly</p>
<p>besides just like specifically in these diplomacy games.</p>
<p>Okay, cool.</p>
<p>What are some interesting things that came to life</p>
<p>from this work to you?</p>
<p>Like what are some insights about games</p>
<p>where natural language is involved</p>
<p>and cooperation, deep cooperation is involved?</p>
<p>Well, I think there&rsquo;s a few insights.</p>
<p>So first of all, the fact that you can&rsquo;t rely purely</p>
<p>or even largely on self-play,</p>
<p>that you really have to have an understanding</p>
<p>of how humans approach the game.</p>
<p>I think that that&rsquo;s one of the major conclusions</p>
<p>that I&rsquo;m drawing from this work.</p>
<p>And that is, I think, applicable more broadly</p>
<p>to a lot of different games.</p>
<p>So we&rsquo;ve actually already taken the approaches</p>
<p>that we&rsquo;ve used in diplomacy and tried them</p>
<p>on a cooperative card game called Hanabi.</p>
<p>And we&rsquo;ve had a lot of success in that game as well.</p>
<p>On the language side, I think the fact</p>
<p>that we were able to control the language model</p>
<p>through this intense approach was very effective.</p>
<p>And it allowed us, instead of just imitating</p>
<p>how humans would communicate, we&rsquo;re able to go beyond that</p>
<p>and able to feed into its superhuman strategies</p>
<p>that it can then generate messages corresponding to.</p>
<p>Is there something you could say about detecting</p>
<p>whether a person or AI is lying or not?</p>
<p>The bot doesn&rsquo;t explicitly try to calculate</p>
<p>whether somebody is lying or not.</p>
<p>But what it will do is try to predict</p>
<p>what actions they&rsquo;re going to take,</p>
<p>given the communications,</p>
<p>given the messages that they&rsquo;ve sent to us.</p>
<p>So given our conversation,</p>
<p>what do I think you&rsquo;re going to do?</p>
<p>And implicitly, there is a calculation</p>
<p>about whether you&rsquo;re lying to me in that.</p>
<p>You know, if you&rsquo;re, based on your messages,</p>
<p>if I think you&rsquo;re going to attack me this turn,</p>
<p>even though your messages say that you&rsquo;re not,</p>
<p>then, you know, essentially the bot</p>
<p>is predicting that you&rsquo;re lying.</p>
<p>But it doesn&rsquo;t view it as lying</p>
<p>the same way that we would view it as lying.</p>
<p>But you could probably reformulate with all the same data</p>
<p>and make a classifier lying or not.</p>
<p>Yeah, I think you could do that.</p>
<p>That was not something that we were focused on,</p>
<p>but I think that it is possible that, you know,</p>
<p>if you came up with some measurements of like,</p>
<p>what does it mean to tell a lie?</p>
<p>Because there&rsquo;s a spectrum, right?</p>
<p>Like, if you&rsquo;re withholding some information, is that a lie?</p>
<p>If you&rsquo;re mostly telling the truth,</p>
<p>but you forgot to mention this,</p>
<p>like one action out of like 10, is that a lie?</p>
<p>It&rsquo;s hard to draw the line,</p>
<p>but, you know, if you&rsquo;re willing to do that,</p>
<p>and then you could possibly use it to&hellip;</p>
<p>This feels like an argument inside a relationship now,</p>
<p>what constitutes a lie.</p>
<p>Depends what you mean by the definition of the word is.</p>
<p>Okay.</p>
<p>Still, it&rsquo;s fascinating,</p>
<p>because trust and lying is all intermixed into this,</p>
<p>and it&rsquo;s language models</p>
<p>that are becoming more and more sophisticated.</p>
<p>It&rsquo;s just a fascinating space to explore.</p>
<p>What do you see as the future of this work</p>
<p>that is inspired by the breakthrough performance</p>
<p>that you&rsquo;re getting here with diplomacy?</p>
<p>I think there&rsquo;s a few different directions</p>
<p>to take this work.</p>
<p>I think really what it&rsquo;s showing us</p>
<p>is the potential that language models have.</p>
<p>I mean, I think a lot of people didn&rsquo;t think</p>
<p>that this kind of result was possible even today,</p>
<p>despite all the progress that&rsquo;s been made in language models.</p>
<p>And so it shows us how we can leverage</p>
<p>the power of things like self-play</p>
<p>on top of language models</p>
<p>to get increasingly better performance.</p>
<p>And the ceiling is really much higher</p>
<p>than what we have right now.</p>
<p>Is this transferable somehow to chatbots</p>
<p>for the more general task of dialogue?</p>
<p>So there is a kind of negotiation here,</p>
<p>a dance between entities that are trying to cooperate</p>
<p>and at the same time, a little bit adversarial,</p>
<p>which I think maps somewhat to the general,</p>
<p>you know, the entire process of Reddit</p>
<p>or like internet communication.</p>
<p>You&rsquo;re cooperating, you&rsquo;re adversarial,</p>
<p>you&rsquo;re having debates, you&rsquo;re having camaraderie,</p>
<p>all that kind of stuff.</p>
<p>I think one of the things that&rsquo;s really useful</p>
<p>about diplomacy is that we have</p>
<p>a well-defined value function.</p>
<p>There is a well-defined score</p>
<p>that the bot is trying to optimize.</p>
<p>And in a setting like a general chatbot setting,</p>
<p>it would need that kind of objective</p>
<p>in order to fully leverage the techniques</p>
<p>that we&rsquo;ve developed.</p>
<p>What about like what we talked about earlier</p>
<p>with NPCs inside video games?</p>
<p>Like how can it be used to create</p>
<p>for Elder Scrolls VI more compelling NPCs</p>
<p>that you could talk to instead of committing</p>
<p>all kinds of violence with a sword and fighting dragons,</p>
<p>just sitting in a tavern and drink all day</p>
<p>and talk to the chatbot?</p>
<p>The way that we&rsquo;ve approached AI in diplomacy</p>
<p>is you condition the language on an intent.</p>
<p>Now that intent in diplomacy is an action,</p>
<p>but it doesn&rsquo;t have to be.</p>
<p>And you can imagine, you know,</p>
<p>you could have NPCs in video games</p>
<p>or the metaverse or whatever,</p>
<p>where there&rsquo;s some intent or there&rsquo;s some objective</p>
<p>that they&rsquo;re trying to maximize</p>
<p>and you can specify what that is.</p>
<p>And then the language can correspond to that intent.</p>
<p>Now, I&rsquo;m not saying that this is happening imminently,</p>
<p>but I&rsquo;m saying that this is like a future application</p>
<p>potentially of this direction of research.</p>
<p>So what&rsquo;s the more general formulation of this?</p>
<p>Making self-play be able to scale the way self-play does</p>
<p>and still maintain human-like behavior.</p>
<p>The way that we&rsquo;ve approached self-play in diplomacy</p>
<p>is like we&rsquo;re trying to come up with good intents</p>
<p>to condition the language model on.</p>
<p>And the space of intents is actions</p>
<p>that can be played in the game.</p>
<p>Now, there is like the potential</p>
<p>to have a broader set of intents.</p>
<p>Things like, you know, long-term cooperation</p>
<p>or long-term objectives or, you know,</p>
<p>gossip about what another player was saying.</p>
<p>These are things that we&rsquo;re currently</p>
<p>not conditioning the language model on.</p>
<p>And so it&rsquo;s not able to, we&rsquo;re not able to control it</p>
<p>to say like, oh, you should be talking</p>
<p>about this thing right now.</p>
<p>But it&rsquo;s quite possible that you could expand</p>
<p>the scope of intents to be able to allow it</p>
<p>to talk about those things.</p>
<p>Now, in the process of doing that,</p>
<p>the self-play would become much more complicated.</p>
<p>And so that is a potential for future work.</p>
<p>Okay, the increase in the number of intents.</p>
<p>I still am not quite clear how you keep the self-play</p>
<p>integrated into the human world.</p>
<p>Yeah.</p>
<p>I&rsquo;m a little bit loose on understanding how you do that.</p>
<p>So we train a neural net to imitate the human data</p>
<p>as closely as possible.</p>
<p>And that&rsquo;s what we call the anchor policy.</p>
<p>And now when we&rsquo;re doing self-play,</p>
<p>the problem with the anchor policy is that</p>
<p>it&rsquo;s not a perfect approximation</p>
<p>of how humans actually play.</p>
<p>Because we don&rsquo;t have infinite data,</p>
<p>because we don&rsquo;t have unlimited neural network capacity,</p>
<p>it&rsquo;s actually a relatively suboptimal approximation</p>
<p>of how humans actually play.</p>
<p>And we can improve that approximation</p>
<p>by adding planning and RL.</p>
<p>And so what we do is we get a better approximation,</p>
<p>a better model of human play</p>
<p>by during the self-play process,</p>
<p>we say you can deviate from this human anchor policy</p>
<p>if there is an action that has, you know,</p>
<p>particularly high expected value,</p>
<p>but it would have to be a really high expected value</p>
<p>in order to deviate from this human-like policy.</p>
<p>So you basically say,</p>
<p>try to maximize your expected value,</p>
<p>while at the same time,</p>
<p>stay as close as possible to the human policy.</p>
<p>And there is a parameter</p>
<p>that controls the relative weighting</p>
<p>of those competing objectives.</p>
<p>So the question I have</p>
<p>is how sophisticated can the anchor policy get?</p>
<p>To have a policy that approximates human behavior, right?</p>
<p>Yeah.</p>
<p>So as you increase the number of intents,</p>
<p>as you generalize the space in which this is applicable,</p>
<p>and given that the human data is limited,</p>
<p>try to anticipate a policy that works</p>
<p>for a much larger number of cases.</p>
<p>Like how difficult is the process</p>
<p>of forming a damn good anchor policy?</p>
<p>Well, it really comes down</p>
<p>to how much human data you have.</p>
<p>So it&rsquo;s all about scaling the human data.</p>
<p>I think the more human data you have, the better.</p>
<p>And I think that that&rsquo;s going to be the major bottleneck</p>
<p>in scaling to more complicated domains.</p>
<p>But that said, you know, there might be the potential,</p>
<p>just like in the language model,</p>
<p>where we leveraged tons of data on the internet</p>
<p>and then specialized it for diplomacy.</p>
<p>There is the future potential</p>
<p>that you can leverage huge amounts of data across the board</p>
<p>and then specialize it in the data set</p>
<p>that you have for diplomacy.</p>
<p>And in that way, you&rsquo;re essentially augmenting</p>
<p>the amount of data that you have.</p>
<p>To what degree does this apply to the general,</p>
<p>the real world diplomacy, the geopolitics?</p>
<p>You know, game theory has a history of being applied</p>
<p>to understand and to give us hope</p>
<p>about nuclear weapons, for example.</p>
<p>The mutually assured destruction</p>
<p>is a game theoretic concept that you can formulate.</p>
<p>Some people say it&rsquo;s oversimplified,</p>
<p>but nevertheless, here we are,</p>
<p>and we somehow haven&rsquo;t blown ourselves up.</p>
<p>Do you see a future where this kind of system</p>
<p>can be used to help us make decisions,</p>
<p>geopolitical decisions in the world?</p>
<p>Well, like I said, the original motivation</p>
<p>for the game of diplomacy was the failures of World War I,</p>
<p>the diplomatic failures that led to war.</p>
<p>And the real take-home message of diplomacy is that,</p>
<p>you know, if people approach diplomacy the right way,</p>
<p>then war is ultimately unsuccessful.</p>
<p>The way that I see it,</p>
<p>war is an inherently negative sum game, right?</p>
<p>There&rsquo;s always a better outcome than war</p>
<p>for all the parties involved.</p>
<p>And my hope is that, you know, as AI progresses,</p>
<p>then maybe this technology could be used</p>
<p>to help people make better decisions across the board</p>
<p>and, you know, hopefully avoid</p>
<p>negative sum outcomes like war.</p>
<p>Yeah, I mean, I just came back from Ukraine.</p>
<p>I&rsquo;m going back there on deep personal levels,</p>
<p>think a lot about how peace can be achieved.</p>
<p>And I&rsquo;m a big believer in conversation,</p>
<p>or leaders getting together and having conversations</p>
<p>and trying to understand each other.</p>
<p>Yeah, it&rsquo;s fascinating to think</p>
<p>whether each one of those leaders</p>
<p>can run a simulation ahead of time.</p>
<p>Like if I&rsquo;m an asshole, what are the possible consequences?</p>
<p>If I&rsquo;m nice, what are the possible consequences?</p>
<p>My guess is that if the President of the United States</p>
<p>got together with Vladimir Zelensky and Vladimir Putin,</p>
<p>that there would be significant benefits</p>
<p>to the President of the United States not having the ego</p>
<p>of kind of playing down, of giving away a lot of chips</p>
<p>for the future success of a world.</p>
<p>So giving a lot of power to the two presidents</p>
<p>of the competing nations to achieve peace.</p>
<p>That&rsquo;s my guess,</p>
<p>but it&rsquo;d be nice to run a bunch of simulations.</p>
<p>But then you have to have human data, right?</p>
<p>You really, because it&rsquo;s like the game of diplomacy</p>
<p>is fundamentally different than geopolitics.</p>
<p>You need data.</p>
<p>You need like, I guess that&rsquo;s the question I have,</p>
<p>like how transferable is this to,</p>
<p>like I don&rsquo;t know, any kind of negotiation, right?</p>
<p>Like to any kind of, some local, I don&rsquo;t know,</p>
<p>a bunch of lawyers arguing, like divorce lawyers.</p>
<p>Like how transferable is this</p>
<p>to all kinds of human negotiation?</p>
<p>Well, I feel like this isn&rsquo;t a question</p>
<p>that&rsquo;s unique to diplomacy.</p>
<p>I mean, I think you look at RL breakthroughs,</p>
<p>reinforcement learning breakthroughs</p>
<p>in previous games as well, like AI for StarCraft,</p>
<p>AI for Atari.</p>
<p>You haven&rsquo;t really seen it deployed in the real world</p>
<p>because you have these problems of,</p>
<p>it&rsquo;s really hard to collect a lot of data</p>
<p>and you don&rsquo;t have a well-defined action space.</p>
<p>You don&rsquo;t have a well-defined reward function.</p>
<p>These are all things that you really need</p>
<p>for reinforcement learning</p>
<p>and planning to be really successful today.</p>
<p>Now, there are some domains where you do have that.</p>
<p>Code generation is one example.</p>
<p>Theorem proving mathematics, that&rsquo;s another example</p>
<p>where you have a well-defined action space,</p>
<p>you have a well-defined reward function.</p>
<p>And those are the kinds of domains</p>
<p>where I can see RL in the short term</p>
<p>being incredibly powerful.</p>
<p>But yeah, I think that those are the barriers</p>
<p>to deploying this at scale in the real world.</p>
<p>But the hope is that in the long run,</p>
<p>we&rsquo;ll be able to get there.</p>
<p>Yeah, but see, diplomacy feels like closer</p>
<p>to the real world than does StarCraft.</p>
<p>Like, because it&rsquo;s natural language, right?</p>
<p>You&rsquo;re operating in the space of intents</p>
<p>and in the space of natural language.</p>
<p>That feels very close to the real world.</p>
<p>And it also feels like you could get data on that</p>
<p>from the internet.</p>
<p>Yeah, and that&rsquo;s why I do think that diplomacy</p>
<p>is taking a big step closer to the real world</p>
<p>than anything that&rsquo;s came before</p>
<p>in terms of game AI breakthroughs.</p>
<p>The fact that we&rsquo;re communicating in natural language,</p>
<p>we&rsquo;re leveraging the fact that we have</p>
<p>this like general data set of dialogue</p>
<p>and communication from a breadth of the internet,</p>
<p>that is a big step in that direction.</p>
<p>We&rsquo;re not 100% there, but we&rsquo;re getting closer at least.</p>
<p>So if we actually return back to poker and chess,</p>
<p>are some of the ideas that you&rsquo;re learning here</p>
<p>with diplomacy, could you construct AI systems</p>
<p>that play like humans?</p>
<p>Like make for a fun opponent in a game of chess?</p>
<p>Yeah, absolutely.</p>
<p>We&rsquo;ve already started looking into this direction a bit.</p>
<p>So we tried to use the techniques that we&rsquo;ve developed</p>
<p>for diplomacy to make chess and go AIs.</p>
<p>And what we found is that it led to much more human-like,</p>
<p>strong chess and go players.</p>
<p>The way that AIs like Stockfish today play</p>
<p>is in a very inhuman style.</p>
<p>It&rsquo;s very strong,</p>
<p>but it&rsquo;s very different from how humans play.</p>
<p>And so we can take the techniques</p>
<p>that we&rsquo;ve developed for diplomacy.</p>
<p>We do something similar in chess and go,</p>
<p>and we end up with a bot that&rsquo;s both strong and human-like.</p>
<p>To elaborate on this a bit,</p>
<p>like one way to approach making a human-like AI for chess</p>
<p>is to collect a bunch of human games,</p>
<p>like a bunch of human grandmaster games,</p>
<p>and just to supervise learning on those games.</p>
<p>But the problem is that if you do that,</p>
<p>what you end up with is an AI that&rsquo;s substantially weaker</p>
<p>than the human grandmasters that you trained on.</p>
<p>Because the neural net is not able to approximate</p>
<p>the nuance of the strategy.</p>
<p>This goes back to the planning thing that I mentioned,</p>
<p>the search thing that I talked about before,</p>
<p>that these human grandmasters, when they&rsquo;re playing,</p>
<p>they&rsquo;re using search and they&rsquo;re using planning.</p>
<p>And the neural net alone,</p>
<p>unless you have a massive neural net</p>
<p>that&rsquo;s like a thousand times bigger</p>
<p>than what we have right now,</p>
<p>it&rsquo;s not able to approximate those details very effectively.</p>
<p>And on the other hand,</p>
<p>you can leverage search and planning very heavily,</p>
<p>but then what you end up with is an AI</p>
<p>that plays in a very different style</p>
<p>from how humans play the game.</p>
<p>Now, if you strike this intermediate balance</p>
<p>by setting the regularization parameters correctly</p>
<p>and say, you can do planning,</p>
<p>but try to keep it close to the human policy,</p>
<p>then you end up with an AI that plays</p>
<p>in both a very human-like style and a very strong style.</p>
<p>And you can actually even tune it</p>
<p>to have a certain ELO rating.</p>
<p>So you can say, play in the style of like a 2800 ELO human.</p>
<p>I wonder if you could do specific type of humans</p>
<p>or categories of humans, not just skill, but style.</p>
<p>Yeah, I think so.</p>
<p>And so this is where the research gets interesting.</p>
<p>Like, one of the things that I was thinking about is,</p>
<p>and this is actually already being done.</p>
<p>There&rsquo;s a researcher at the University of Toronto</p>
<p>that&rsquo;s working on this,</p>
<p>is to make an AI that plays in the style</p>
<p>of a particular player.</p>
<p>Like Magnus Carlsen, for example,</p>
<p>you can make an AI that plays like Magnus Carlsen.</p>
<p>And then where I think this gets interesting</p>
<p>is like, maybe you&rsquo;re up against Magnus Carlsen</p>
<p>in the world championship or something.</p>
<p>You can play against this Magnus Carlsen bot</p>
<p>to prepare against the real Magnus Carlsen.</p>
<p>And you can try to explore strategies</p>
<p>that he might struggle with and try to figure out</p>
<p>how do you beat this player in particular?</p>
<p>On the other hand, you can also have Magnus Carlsen</p>
<p>working with this bot to try to figure out where he&rsquo;s weak</p>
<p>and where he needs to improve his strategy.</p>
<p>And so I can envision this future</p>
<p>where data on specific chess and Go players</p>
<p>becomes extremely valuable because you can use that data</p>
<p>to create specific models</p>
<p>of how these particular players play.</p>
<p>So increasingly human-like behavior in bots, however,</p>
<p>as you&rsquo;ve mentioned, makes cheat detection much harder.</p>
<p>It does, yeah.</p>
<p>The way that cheat detection works in a game like poker</p>
<p>and a game like chess and Go, from what I understand,</p>
<p>is trying to see like, is this person making moves</p>
<p>that are very common among chess AIs or AIs in general,</p>
<p>but very uncommon among top human players.</p>
<p>And if you have the development of these AIs</p>
<p>that play in a very strong style,</p>
<p>but also a very human-like style,</p>
<p>then that poses serious challenges for cheat detection.</p>
<p>And it makes you now ask yourself a hard question</p>
<p>about what is the role of AI systems</p>
<p>as they become more and more integrated in our society?</p>
<p>And this kind of human AI integration</p>
<p>has some deep ethical issues that we should be aware of.</p>
<p>And also it&rsquo;s a kind of cybersecurity challenge, right?</p>
<p>To make, one of the assumptions we have when we play games</p>
<p>is that there&rsquo;s a trust that it&rsquo;s only humans involved.</p>
<p>And the better AI systems we create,</p>
<p>which makes it super exciting,</p>
<p>human-like AI systems with different styles of humans</p>
<p>is really exciting,</p>
<p>but then we have to have the defenses</p>
<p>better and better and better</p>
<p>if we&rsquo;re to trust that we can enjoy</p>
<p>human versus human game in a deeply fair way.</p>
<p>It&rsquo;s fascinating.</p>
<p>It&rsquo;s just, it&rsquo;s humbling.</p>
<p>Yeah, I think there&rsquo;s a lot of negative potential</p>
<p>for this kind of technology,</p>
<p>but at the same time,</p>
<p>there&rsquo;s a lot of upside for it as well.</p>
<p>So, for example, right now,</p>
<p>it&rsquo;s really hard to learn how to get better</p>
<p>in games like chess and poker and go</p>
<p>because the way that the AI plays</p>
<p>is so foreign and incomprehensible.</p>
<p>But if you have these AIs that are playing,</p>
<p>you can say like, oh, I&rsquo;m a 2000 Elo human.</p>
<p>How do I get to 2200?</p>
<p>Now you can have an AI that plays</p>
<p>in the style of a 2200 Elo human,</p>
<p>and that will help you get better.</p>
<p>Or, you mentioned this problem of like,</p>
<p>how do you know that you&rsquo;re actually playing with humans</p>
<p>when you&rsquo;re playing like online and in video games?</p>
<p>Well, now we have the potential of populating</p>
<p>these like virtual worlds with agents,</p>
<p>like AI agents that are actually fun to play with.</p>
<p>And you don&rsquo;t have to always be playing with other humans</p>
<p>to have a fun time.</p>
<p>So, yeah, a lot of upside potential too.</p>
<p>And I think with any sort of tool,</p>
<p>there&rsquo;s the potential for a lot of greatness</p>
<p>and a lot of downsides as well.</p>
<p>So, in the paper that I got a chance to look at,</p>
<p>there&rsquo;s a section on ethical considerations.</p>
<p>What&rsquo;s in that section?</p>
<p>What are some ethical considerations here?</p>
<p>Is it some of the stuff we already talked about?</p>
<p>There&rsquo;s some things that we&rsquo;ve already talked about.</p>
<p>I think specific to diplomacy,</p>
<p>there&rsquo;s also the challenge that the game is&hellip;</p>
<p>There is a deception aspect to the game.</p>
<p>And so, developing language models</p>
<p>that are capable of deception is I think a dicey issue</p>
<p>and something that makes research on diplomacy</p>
<p>particularly challenging.</p>
<p>And so those kinds of issues of like,</p>
<p>should we even be developing AIs</p>
<p>that are capable of lying to people?</p>
<p>That&rsquo;s something that we have to think carefully about.</p>
<p>That&rsquo;s so cool.</p>
<p>I mean, you have to do that kind of stuff</p>
<p>in order to figure out where the ethical lines are.</p>
<p>But I can see in the future it being illegal</p>
<p>to have a consumer product that lies.</p>
<p>Yeah, yeah.</p>
<p>Like your personal assistant AI system</p>
<p>is always have to tell the truth.</p>
<p>But if I ask it, did I get fatter over the past month?</p>
<p>I sure as hell want that AI system to lie to me.</p>
<p>So, there&rsquo;s a trade-off between lying and being nice.</p>
<p>We have to somehow find where&rsquo;s the ethics in that.</p>
<p>And we&rsquo;re back to discussions inside relationships.</p>
<p>Anyway, what were you saying?</p>
<p>Oh, yeah, I was saying like, yeah,</p>
<p>that&rsquo;s kind of going to the question of like,</p>
<p>what is a lie?</p>
<p>You know, is a white lie a bad lie?</p>
<p>Is it an ethical lie?</p>
<p>You know, those kinds of questions.</p>
<p>Boy, we return time and time again</p>
<p>to deep human questions as we design AI systems.</p>
<p>That&rsquo;s exactly what they do.</p>
<p>They put a mirror to humanity</p>
<p>to help us understand ourselves.</p>
<p>There&rsquo;s also the issue of like,</p>
<p>in these diplomacy experiments</p>
<p>in order to do a fair comparison.</p>
<p>You know, what we found is that</p>
<p>there&rsquo;s an inherent anti-AI bias in these kinds of games.</p>
<p>So, we actually played a tournament</p>
<p>in a non-language version of the game</p>
<p>where we told the participants like,</p>
<p>hey, in every single game, there&rsquo;s going to be an AI.</p>
<p>And what we found is that the humans</p>
<p>would spend basically the entire game</p>
<p>like trying to figure out who the bot was.</p>
<p>And then as soon as they thought they figured it out,</p>
<p>they would all team up and try to kill it.</p>
<p>And, you know, overcoming that inherent anti-AI bias</p>
<p>is a challenge.</p>
<p>On the flip side, I think when robots become the enemy,</p>
<p>that&rsquo;s when we get to heal our human divisions</p>
<p>and then we can become one.</p>
<p>As long as we have one enemy,</p>
<p>it&rsquo;s that Reagan thing when the aliens show up.</p>
<p>That&rsquo;s when we put our side, our divisions,</p>
<p>we become one human species.</p>
<p>Right, we might have our differences,</p>
<p>but we&rsquo;re at least all human.</p>
<p>At least we all hate the robots.</p>
<p>No, no, no, no.</p>
<p>I think there will be actually in the future</p>
<p>something like a civil rights movement for robots.</p>
<p>I think that&rsquo;s the fascinating thing about AI systems</p>
<p>in that is they ask,</p>
<p>they force us to ask about ethical questions</p>
<p>about what is sentience?</p>
<p>What is, how do we feel about systems</p>
<p>that are capable of suffering</p>
<p>or capable of displaying suffering?</p>
<p>And how do we design products that show emotion and not?</p>
<p>How do we feel about that?</p>
<p>Lying is another topic.</p>
<p>Are we going to allow bots to lie and not?</p>
<p>And where&rsquo;s the balance between being nice</p>
<p>and telling the truth?</p>
<p>I mean, these are all fascinating human questions.</p>
<p>It&rsquo;s like so exciting to be in a century</p>
<p>where we create systems that take these philosophical</p>
<p>questions that have been asked for centuries</p>
<p>and now we can engineer them inside systems</p>
<p>where you really have to answer them</p>
<p>because you&rsquo;ll have transformational impact</p>
<p>on human society depending on what you design</p>
<p>inside those systems.</p>
<p>It&rsquo;s fascinating.</p>
<p>And like you said, I feel like diplomacy</p>
<p>is a step towards the direction of the real world</p>
<p>applying these RL methods towards the real world.</p>
<p>From all the breakthrough performances</p>
<p>in Go and Chess and Starcraft and Dota,</p>
<p>this feels like the real world.</p>
<p>And especially now my mind&rsquo;s been on war</p>
<p>and military conflict.</p>
<p>This feels like it can give us some deep insights</p>
<p>about human behavior at the large geopolitical scale.</p>
<p>What do you think is the breakthrough</p>
<p>or the directions of work that will take us</p>
<p>towards solving intelligence, towards creating AGI systems?</p>
<p>You&rsquo;ve been a part of creating, by the way,</p>
<p>we should say a part of great teams that do this,</p>
<p>of creating systems that achieve breakthrough performances</p>
<p>on before thought unsolvable problems</p>
<p>like poker, multiplayer poker, diplomacy.</p>
<p>We&rsquo;re taking steps towards that direction.</p>
<p>What do you think it takes to go all the way</p>
<p>to create superhuman level intelligence?</p>
<p>You know, there&rsquo;s a lot of people</p>
<p>trying to figure that out right now.</p>
<p>And I should say the amount of progress that&rsquo;s been made,</p>
<p>especially in the past few years, is truly phenomenal.</p>
<p>I mean, you look at where AI was 10 years ago</p>
<p>and the idea that you could have AIs</p>
<p>that can generate language and generate images</p>
<p>the way they&rsquo;re doing today</p>
<p>and able to play a game like diplomacy</p>
<p>was just like unthinkable,</p>
<p>even five years ago, let alone 10 years ago.</p>
<p>Now there are aspects of AI that I think are still lacking.</p>
<p>I think there&rsquo;s general agreements</p>
<p>that one of the major issues with AI today</p>
<p>is that it&rsquo;s very data inefficient.</p>
<p>It requires a huge number of samples of training examples</p>
<p>to be able to train.</p>
<p>You know, you look at an AI that plays Go</p>
<p>and it needs millions of games of Go</p>
<p>to learn how to play the game well.</p>
<p>Whereas a human can pick it up in like, you know,</p>
<p>I don&rsquo;t know, how many games does a human Go player,</p>
<p>Go grandmaster play in their lifetime?</p>
<p>Probably, you know, in the thousands</p>
<p>or tens of thousands, I guess.</p>
<p>So that&rsquo;s one issue.</p>
<p>Overcoming this challenge of data efficiency.</p>
<p>And this is particularly important</p>
<p>if we want to deploy AI systems in real world settings</p>
<p>where they&rsquo;re interacting with humans,</p>
<p>because, you know, for example, with robotics,</p>
<p>it&rsquo;s really hard to generate a huge number of samples.</p>
<p>It&rsquo;s a different story when you&rsquo;re working in these,</p>
<p>you know, totally virtual games</p>
<p>where you can play a million games and it&rsquo;s no big deal.</p>
<p>I was planning on just launching like a thousand</p>
<p>of these robots in Austin.</p>
<p>I don&rsquo;t think it&rsquo;s illegal for robots to roam the streets</p>
<p>and just collect data.</p>
<p>That&rsquo;s not a crazy idea.</p>
<p>Of course, the worst that could happen.</p>
<p>Yeah, I mean, that&rsquo;s one way</p>
<p>to overcome the data efficiency problem.</p>
<p>It&rsquo;s like scale it, yeah.</p>
<p>Like I actually tried to see if there&rsquo;s a law</p>
<p>against robots, like legged robots,</p>
<p>just operating in the streets of a major city</p>
<p>and there isn&rsquo;t, I couldn&rsquo;t find any.</p>
<p>So I&rsquo;ll take it all the way to the Supreme Court.</p>
<p>Robot rights.</p>
<p>Okay, anyway, sorry, you were saying.</p>
<p>So what are the ideas for becoming more data efficient?</p>
<p>I mean, that&rsquo;s the trillion dollar question in AI today.</p>
<p>I mean, if you can figure out how to make AI systems</p>
<p>more data efficient, then that&rsquo;s a huge breakthrough.</p>
<p>So nobody really knows right now.</p>
<p>It could be just a gigantic background model,</p>
<p>language model, and then you do,</p>
<p>the training becomes like prompting that model</p>
<p>to essentially do a kind of quarrying,</p>
<p>a search into the space of the things it&rsquo;s learned</p>
<p>to customize that to whatever problem you&rsquo;re trying to solve.</p>
<p>So maybe if you form a large enough language model,</p>
<p>you can go quite a long way.</p>
<p>That, you know, I think there&rsquo;s some truth to that.</p>
<p>I mean, you look at the way humans approach</p>
<p>a game like poker, they&rsquo;re not coming at it from scratch.</p>
<p>They&rsquo;re coming at it with a huge amount</p>
<p>of background knowledge about how humans work,</p>
<p>how the world works, the idea of money.</p>
<p>So they&rsquo;re able to leverage that kind of information</p>
<p>to pick up the game faster.</p>
<p>So it&rsquo;s not really a fair comparison to then compare it</p>
<p>to an AI that&rsquo;s like learning from scratch.</p>
<p>And maybe one of the ways that we address</p>
<p>this sample complexity problem is by allowing AIs</p>
<p>to leverage that general knowledge</p>
<p>across a ton of different domains.</p>
<p>So, like I said, you did a lot of incredible work</p>
<p>in the space of research and actually building systems.</p>
<p>What advice would you give to, let&rsquo;s start with beginners.</p>
<p>What advice would you give to beginners</p>
<p>interested in machine learning?</p>
<p>Just they&rsquo;re at the very start of their journey,</p>
<p>they&rsquo;re in high school and college,</p>
<p>thinking like this seems like a fascinating world.</p>
<p>What advice would you give them?</p>
<p>I would say that there are a lot of people working</p>
<p>on similar aspects of machine learning</p>
<p>and to not be afraid to try something a bit different.</p>
<p>My own path in AI is pretty atypical</p>
<p>for a machine learning researcher today.</p>
<p>I mean, I started out working on game theory</p>
<p>and then shifting more towards reinforcement learning</p>
<p>as time went on.</p>
<p>And that actually had a lot of benefits, I think,</p>
<p>because it allowed me to look at these problems</p>
<p>in a very different way from the way</p>
<p>a lot of machine learning researchers view it.</p>
<p>And that comes with drawbacks in some respects.</p>
<p>Like I think there&rsquo;s definitely aspects of machine learning</p>
<p>where I&rsquo;m weaker than most of the researchers out there.</p>
<p>But I think that diversity of perspective,</p>
<p>when I&rsquo;m working with my teammates,</p>
<p>there&rsquo;s something that I&rsquo;m bringing to the table</p>
<p>and there&rsquo;s something that they&rsquo;re bringing to the table.</p>
<p>And that kind of collaboration becomes very fruitful</p>
<p>for that reason.</p>
<p>So there could be problems like poker,</p>
<p>like you&rsquo;ve chosen diplomacy,</p>
<p>there could be problems like that still out there</p>
<p>that you can just tackle,</p>
<p>even if it seems extremely difficult.</p>
<p>I think that there&rsquo;s a lot of challenges,</p>
<p>challenges left.</p>
<p>And I think having a diversity of viewpoints</p>
<p>and backgrounds is really helpful</p>
<p>for working together to figure out</p>
<p>how to tackle those kinds of challenges.</p>
<p>So as a beginner, so that,</p>
<p>I would say that&rsquo;s more for like a grad student</p>
<p>where they already built up a base,</p>
<p>like a complete beginner, what&rsquo;s a good journey.</p>
<p>So for you that was doing</p>
<p>some more on the math side of things,</p>
<p>doing game theory or like,</p>
<p>so it&rsquo;s basically build up a foundation in something.</p>
<p>So programming, mathematics,</p>
<p>it could even be physics,</p>
<p>but build that foundation.</p>
<p>Yeah, I would say build a strong foundation</p>
<p>in math and computer science and statistics</p>
<p>in these kinds of areas.</p>
<p>But don&rsquo;t be afraid to try something that&rsquo;s different</p>
<p>and learn something that&rsquo;s different from,</p>
<p>the thing that everybody else is doing</p>
<p>to get into machine learning.</p>
<p>There&rsquo;s value in having a different background</p>
<p>than everybody else.</p>
<p>Yeah, so, but certainly having a strong math background,</p>
<p>especially in things like linear algebra</p>
<p>and statistics and probability</p>
<p>are incredibly helpful today for learning about</p>
<p>and understanding machine learning.</p>
<p>Do you think one day we&rsquo;ll be able to,</p>
<p>since you&rsquo;re taking steps from poker to diplomacy,</p>
<p>one day we&rsquo;ll be able to</p>
<p>figure out how to live life optimally?</p>
<p>Well, what is it?</p>
<p>Like in poker and diplomacy, you need a value function.</p>
<p>You need to have a reward system.</p>
<p>And so what does it mean to live a life that&rsquo;s optimal?</p>
<p>So, okay.</p>
<p>So then you can exactly like lay down a reward function</p>
<p>being like, I wanna be rich,</p>
<p>or I want to be in a happy relationship.</p>
<p>And then you&rsquo;ll say, well, do X.</p>
<p>You know, there&rsquo;s a lot of talk today about,</p>
<p>in AI safety circles, about like misspecification</p>
<p>of reward function.</p>
<p>So you say like, okay, my objective is to be rich.</p>
<p>And maybe the AI tells you like, okay,</p>
<p>well, if you wanna maximize the probability</p>
<p>that you&rsquo;re rich, go rob a bank.</p>
<p>Sure.</p>
<p>And so you wanna, is that really what you want?</p>
<p>Is your objective really to be rich at all costs?</p>
<p>Or is it more nuanced than that?</p>
<p>So the unintended consequences.</p>
<p>Yeah.</p>
<p>Yeah, so yeah, that&rsquo;s,</p>
<p>so maybe life is more about defining the reward function</p>
<p>that minimizes the unintended consequences</p>
<p>than it is about the actual policy</p>
<p>that gets you to the reward function.</p>
<p>Maybe life is just about constantly updating</p>
<p>the reward function.</p>
<p>I think one of the challenges in life</p>
<p>is figuring out exactly what that reward function is.</p>
<p>Sometimes it&rsquo;s pretty hard to specify.</p>
<p>The same way that, you know, trying to handcraft</p>
<p>the optimal policy in a game like chess</p>
<p>is really difficult.</p>
<p>It&rsquo;s not so clear cut what the reward function is for life.</p>
<p>I think one day AI will figure it out.</p>
<p>And I wonder what that would be.</p>
<p>Until then, I just really appreciate</p>
<p>the kind of work you&rsquo;re doing.</p>
<p>And it&rsquo;s really fascinating taking the leap</p>
<p>into a more and more real-world-like problem space</p>
<p>and just achieving incredible results</p>
<p>by applying reinforcement learning.</p>
<p>Now, since I saw your work on poker,</p>
<p>you&rsquo;ve been a constant inspiration.</p>
<p>It&rsquo;s an honor to get to finally talk to you,</p>
<p>and this was really fun.</p>
<p>Thanks for having me.</p>
<p>Thanks for listening to this conversation with Noel Brown.</p>
<p>To support this podcast,</p>
<p>please check out our sponsors in the description.</p>
<p>And now, let me leave you with some words</p>
<p>from Sun Tzu in The Art of War.</p>
<p>The whole secret lies in confusing the enemy</p>
<p>so that he cannot fathom our real intent.</p>
<p>Thank you for listening, and hope to see you next time.</p>
<p>‚ô™‚ô™‚ô™</p>

</section>


    <footer class="article-footer">
    
    <section class="article-tags">
        
            <a href="/tags/english/">English</a>
        
            <a href="/tags/podcast/">Podcast</a>
        
            <a href="/tags/lex-fridman-podcast/">Lex Fridman Podcast</a>
        
    </section>


    </footer>


    
</article>

    

    

<div>
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9206135835124064"
         crossorigin="anonymous"></script>
    <ins class="adsbygoogle"
         style="display:block"
         data-ad-format="autorelaxed"
         data-ad-client="ca-pub-9206135835124064"
         data-ad-slot="8267893988"></ins>
    <script>
         (adsbygoogle = window.adsbygoogle || []).push({});
    </script>
</div>
<aside class="related-content--wrapper">
    <h2 class="section-title">Related content</h2>
    <div class="related-content">
        <div class="flex article-list--tile">
            
                
<article class="">
    <a href="/en/1310500372/">
        
	
        
        <div class="article-image">
            
            <img src="/img/related-content.png" loading="lazy" 
            data-key="en/1310500372" data-hash="" 
            style="opacity: 0.3;"/>
        </div>
        
        <div class="article-details">
            <h2 class="article-title">Lex Fridman Podcast - #368 - Eliezer Yudkowsky: Dangers of AI and the End of Human Civilization</h2>
            
            <footer class="article-time">
                <time datetime=''>Mar 30, 2023</time>
            </footer>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/en/1310500371/">
        
	
        
        <div class="article-image">
            
            <img src="/img/related-content.png" loading="lazy" 
            data-key="en/1310500371" data-hash="" 
            style="opacity: 0.3;"/>
        </div>
        
        <div class="article-details">
            <h2 class="article-title">Lex Fridman Podcast - #367 - Sam Altman: OpenAI CEO on GPT-4, ChatGPT, and the Future of AI</h2>
            
            <footer class="article-time">
                <time datetime=''>Mar 26, 2023</time>
            </footer>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/en/1310500370/">
        
	
        
        <div class="article-image">
            
            <img src="/img/related-content.png" loading="lazy" 
            data-key="en/1310500370" data-hash="" 
            style="opacity: 0.3;"/>
        </div>
        
        <div class="article-details">
            <h2 class="article-title">Lex Fridman Podcast - #366 - Shannon Curry: Johnny Depp &amp; Amber Heard Trial, Marriage, Dating &amp; Love</h2>
            
            <footer class="article-time">
                <time datetime=''>Mar 22, 2023</time>
            </footer>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/en/1310500369/">
        
	
        
        <div class="article-image">
            
            <img src="/img/related-content.png" loading="lazy" 
            data-key="en/1310500369" data-hash="" 
            style="opacity: 0.3;"/>
        </div>
        
        <div class="article-details">
            <h2 class="article-title">Lex Fridman Podcast - #365 - Sam Harris: Trump, Pandemic, Twitter, Elon, Bret, IDW, Kanye, AI &amp; UFOs</h2>
            
            <footer class="article-time">
                <time datetime=''>Mar 15, 2023</time>
            </footer>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/en/1310500368/">
        
	
        
        <div class="article-image">
            
            <img src="/img/related-content.png" loading="lazy" 
            data-key="en/1310500368" data-hash="" 
            style="opacity: 0.3;"/>
        </div>
        
        <div class="article-details">
            <h2 class="article-title">Lex Fridman Podcast - #364 - Chris Voss: FBI Hostage Negotiator</h2>
            
            <footer class="article-time">
                <time datetime=''>Mar 11, 2023</time>
            </footer>
        </div>
    </a>
</article>

            
        </div>
    </div>
</aside>

     
    
        
    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
            2021 - 
        
        2023 SWIEST - Transcripts ¬∑ Screenplays ¬∑ Lyrics
    </section>
    
    <section class="powerby">
        

        As an Amazon Associate I earn from qualifying purchases üõí<br/>

        Built with <a href="https://swiest.com/" target="_blank" rel="noopener">(Ôæâ‚óï„ÉÆ‚óï)Ôæâü™Ñüíûüíñü•∞ across the glüåçüåèüåébe</a> <br />
        
        
    </section>
</footer>


    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo="crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU="crossorigin="anonymous"
                defer
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css"crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css"crossorigin="anonymous"
            >

            </main>
        </div>
        <script 
                src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js"integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z&#43;KMkF24hUW8WePSA9HM="crossorigin="anonymous"
                
                >
            </script><script type="text/javascript" src="/ts/main.js" defer></script>


<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Noto+Serif&family=Noto+Serif+Armenian&family=Noto+Serif+Bengali&family=Noto+Serif+Devanagari&family=Noto+Serif+Georgian&family=Noto+Serif+Gujarati&family=Noto+Serif+HK&family=Noto+Serif+Hebrew&family=Noto+Serif+JP&family=Noto+Serif+KR&family=Noto+Serif+Kannada&family=Noto+Serif+Khmer&family=Noto+Serif+Lao&family=Noto+Serif+Makasar&family=Noto+Serif+Malayalam&family=Noto+Serif+Myanmar&family=Noto+Serif+Oriya&family=Noto+Serif+SC&family=Noto+Serif+Sinhala&family=Noto+Serif+TC&family=Noto+Serif+Tamil&family=Noto+Serif+Telugu&family=Noto+Serif+Thai&family=Noto+Serif+Tibetan&display=swap" rel="stylesheet">

    </body>
</html>
