<!DOCTYPE html>
<html lang="en" dir="ltr">
    <head><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content='Hi, I&amp;rsquo;m Connie Loizis, and this is Alex Gove, and this is Strictly VC Download.
Hey everybody, hope you&amp;rsquo;ve had a good week. We are just beginning to dry out here in Marin
after weeks and weeks of rain. Speaking of misery, perhaps the biggest story this week is all of the
layoffs that have been taking place. On Wednesday, Microsoft sacked 10,000 employees, roughly 5% of
its workforce. And today, Google&amp;rsquo;s parent company, Alphabet, announced that it is laying off 12,000'>
<title>StrictlyVC Download - OpenAI CEO Sam Altman on ChatGPT and Our Future with AI | SWIEST</title>

<link rel='canonical' href='https://swiest.com/en/1320100001/'>

<link rel="stylesheet" href="/scss/style.min.91b18679590f4ceed910ade4d64b1e7375cc0770ef5b8c1d822f42424f9ff2c8.css"><script>
    document.oncontextmenu = function(){ return false; };
    document.onselectstart = function(){ return false; };
    document.oncopy = function(){ return false; };
    document.oncut = function(){ return false; };
</script>

<script src="https://apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js"></script>


<script type="text/javascript">
    $(document).ready(function(){
     
     $("#back-to-top").hide();
     
     $(function () {
      $(window).scroll(function(){
       if ($(window).scrollTop()>600){
        $("#back-to-top").fadeIn(500);
       }else{
        $("#back-to-top").fadeOut(500);
       }
     });
     
     $("#back-to-top").click(function(){
      $('body,html').animate({scrollTop:0},500);
       return false;
      });
     });
    });
    </script><meta property='og:title' content='StrictlyVC Download - OpenAI CEO Sam Altman on ChatGPT and Our Future with AI'>
<meta property='og:description' content='Hi, I&amp;rsquo;m Connie Loizis, and this is Alex Gove, and this is Strictly VC Download.
Hey everybody, hope you&amp;rsquo;ve had a good week. We are just beginning to dry out here in Marin
after weeks and weeks of rain. Speaking of misery, perhaps the biggest story this week is all of the
layoffs that have been taking place. On Wednesday, Microsoft sacked 10,000 employees, roughly 5% of
its workforce. And today, Google&amp;rsquo;s parent company, Alphabet, announced that it is laying off 12,000'>
<meta property='og:url' content='https://swiest.com/en/1320100001/'>
<meta property='og:site_name' content='SWIEST - Transcripts ¬∑ Screenplays ¬∑ Lyrics'>
<meta property='og:type' content='article'><meta property='article:section' content='Post' /><meta property='article:tag' content='English' /><meta property='article:tag' content='Podcast' /><meta property='article:tag' content='StrictlyVC Download' /><meta property='article:published_time' content='2023-01-21T11:00:00&#43;00:00'/><meta property='article:modified_time' content='2023-01-21T11:00:00&#43;00:00'/>
<meta name="twitter:title" content="StrictlyVC Download - OpenAI CEO Sam Altman on ChatGPT and Our Future with AI">
<meta name="twitter:description" content="Hi, I&amp;rsquo;m Connie Loizis, and this is Alex Gove, and this is Strictly VC Download.
Hey everybody, hope you&amp;rsquo;ve had a good week. We are just beginning to dry out here in Marin
after weeks and weeks of rain. Speaking of misery, perhaps the biggest story this week is all of the
layoffs that have been taking place. On Wednesday, Microsoft sacked 10,000 employees, roughly 5% of
its workforce. And today, Google&amp;rsquo;s parent company, Alphabet, announced that it is laying off 12,000">
    <link rel="shortcut icon" href="/favicon.ico" />
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9206135835124064" crossorigin="anonymous"></script>
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    </head>
    <body class="
    article-page
    ">
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "dark");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky ">
    <button class="hamburger hamburger--spin" type="button" id="toggle-menu" aria-label="Toggle Menu">
        <span class="hamburger-box">
            <span class="hamburger-inner"></span>
        </span>
    </button>

    <header>
        
            
            <figure class="site-avatar">
                <a href="/">
                
                    
                    
                    
                        
                        <img src="/img/avatar_hu307e6a33fa6fd661ccda3b77024ef5c2_252345_300x0_resize_box_3.png" width="300"
                            height="300" class="site-logo" loading="lazy" alt="Avatar">
                    
                
                </a>
                
                    <span class="emoji">‚ú®</span>
                
            </figure>
            
        
        
        <div class="site-meta">
            <h1 class="site-name"><a href="/">SWIEST - Transcripts ¬∑ Screenplays ¬∑ Lyrics</a></h1>
            <h2 class="site-description">üåçüåèüåé</h2>
        </div>
    </header><ol class="menu" id="main-menu">
        
        
        
        <li >
            <a href='/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <polyline points="5 12 3 12 12 3 21 12 19 12" />
  <path d="M5 12v7a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-7" />
  <path d="M9 21v-6a2 2 0 0 1 2 -2h2a2 2 0 0 1 2 2v6" />
</svg>



                
                <span>Home</span>
            </a>
        </li>
        
        
        <li >
            <a href='/archives/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <rect x="3" y="4" width="18" height="4" rx="2" />
  <path d="M5 8v10a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-10" />
  <line x1="10" y1="12" x2="14" y2="12" />
</svg>



                
                <span>Archives</span>
            </a>
        </li>
        
        
        <li >
            <a href='/search/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="10" cy="10" r="7" />
  <line x1="21" y1="21" x2="15" y2="15" />
</svg>



                
                <span>Search</span>
            </a>
        </li>
        
        
        <li >
            <a href='/chart/podcastchart.html' target="_blank">
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-apple-podcast" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="#ffffff" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M18.364 18.364a9 9 0 1 0 -12.728 0" />
  <path d="M11.766 22h.468a2 2 0 0 0 1.985 -1.752l.5 -4a2 2 0 0 0 -1.985 -2.248h-1.468a2 2 0 0 0 -1.985 2.248l.5 4a2 2 0 0 0 1.985 1.752z" />
  <path d="M12 9m-2 0a2 2 0 1 0 4 0a2 2 0 1 0 -4 0" />
</svg>
                
                <span>Podcast Charts</span>
            </a>
        </li>
        

        <div class="menu-bottom-section">
                <li id="i18n-switch">  
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-language" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M4 5h7" />
  <path d="M9 3v2c0 4.418 -2.239 8 -5 8" />
  <path d="M5 9c-.003 2.144 2.952 3.908 6.7 4" />
  <path d="M12 20l4 -9l4 9" />
  <path d="M19.1 18h-6.2" />
</svg>



                    <select name="language" onchange="window.location.href = this.selectedOptions[0].value">
                        
                            <option value="https://swiest.com/" selected>English</option>
                        
                            <option value="https://swiest.com/af/" >Afrikaans</option>
                        
                            <option value="https://swiest.com/am/" >·ä†·àõ·à≠·äõ</option>
                        
                            <option value="https://swiest.com/ar/" >ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</option>
                        
                            <option value="https://swiest.com/az/" >Az…ôrbaycan</option>
                        
                            <option value="https://swiest.com/be/" >–±–µ–ª–∞—Ä—É—Å–∫—ñ</option>
                        
                            <option value="https://swiest.com/bg/" >–±—ä–ª–≥–∞—Ä—Å–∫–∏</option>
                        
                            <option value="https://swiest.com/bn/" >‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ</option>
                        
                            <option value="https://swiest.com/bo/" >‡Ωñ‡Ωº‡Ωë‡ºã‡Ω¶‡æê‡Ωë‡ºã</option>
                        
                            <option value="https://swiest.com/bs/" >Bosanski</option>
                        
                            <option value="https://swiest.com/ca/" >Catal√†</option>
                        
                            <option value="https://swiest.com/zh-hans/" >ÁÆÄ‰Ωì‰∏≠Êñá</option>
                        
                            <option value="https://swiest.com/zh-hant/" >ÁπÅÈ´î‰∏≠Êñá</option>
                        
                            <option value="https://swiest.com/cs/" >ƒåe≈°tina</option>
                        
                            <option value="https://swiest.com/el/" >ŒµŒªŒªŒ∑ŒΩŒπŒ∫Œ¨</option>
                        
                            <option value="https://swiest.com/cy/" >Cymraeg</option>
                        
                            <option value="https://swiest.com/da/" >Dansk</option>
                        
                            <option value="https://swiest.com/de/" >Deutsch</option>
                        
                            <option value="https://swiest.com/eo/" >Esperanto</option>
                        
                            <option value="https://swiest.com/es-es/" >Espa√±ol (Espa√±a)</option>
                        
                            <option value="https://swiest.com/es-419/" >Espa√±ol (Latinoam√©rica)</option>
                        
                            <option value="https://swiest.com/et/" >Eesti</option>
                        
                            <option value="https://swiest.com/eu/" >Euskara</option>
                        
                            <option value="https://swiest.com/haw/" > ª≈ålelo Hawai ªi</option>
                        
                            <option value="https://swiest.com/fa/" >ŸÅÿßÿ±ÿ≥€å</option>
                        
                            <option value="https://swiest.com/fi/" >Suomi</option>
                        
                            <option value="https://swiest.com/fo/" >F√∏royskt</option>
                        
                            <option value="https://swiest.com/fr/" >Fran√ßais</option>
                        
                            <option value="https://swiest.com/fy/" >Frysk</option>
                        
                            <option value="https://swiest.com/ga/" >Gaeilge</option>
                        
                            <option value="https://swiest.com/gl/" >Galego</option>
                        
                            <option value="https://swiest.com/gu/" >‡™ó‡´Å‡™ú‡™∞‡™æ‡™§‡´Ä</option>
                        
                            <option value="https://swiest.com/he/" >◊¢÷¥◊ë◊®÷¥◊ô◊™</option>
                        
                            <option value="https://swiest.com/km/" >·ûÄ·ûò·üí·ûñ·ûª·ûá·û∂·üî</option>
                        
                            <option value="https://swiest.com/hi/" >‡§π‡§ø‡§®‡•ç‡§¶‡•Ä</option>
                        
                            <option value="https://swiest.com/hr/" >Hrvatski</option>
                        
                            <option value="https://swiest.com/ht/" >Krey√≤l Ayisyen</option>
                        
                            <option value="https://swiest.com/hu/" >Magyar</option>
                        
                            <option value="https://swiest.com/hy/" >’Ä’°’µ’•÷Ä’•’∂</option>
                        
                            <option value="https://swiest.com/ig/" >√Ås·ª•ÃÄs·ª•ÃÅ √ågb√≤</option>
                        
                            <option value="https://swiest.com/id/" >Bahasa Indonesia</option>
                        
                            <option value="https://swiest.com/is/" >√çslenska</option>
                        
                            <option value="https://swiest.com/it/" >Italiano</option>
                        
                            <option value="https://swiest.com/ja/" >Êó•Êú¨Ë™û</option>
                        
                            <option value="https://swiest.com/jv/" >Basa Jawa</option>
                        
                            <option value="https://swiest.com/ka/" >·É•·Éê·É†·Éó·É£·Éö·Éò</option>
                        
                            <option value="https://swiest.com/kk/" >“ö–∞–∑–∞“õ—à–∞</option>
                        
                            <option value="https://swiest.com/kn/" >‡≤ï‡≤®‡≥ç‡≤®‡≤°</option>
                        
                            <option value="https://swiest.com/ko/" >ÌïúÍµ≠Ïñ¥</option>
                        
                            <option value="https://swiest.com/or/" >‡¨ì‡¨°‡¨º‡¨ø‡¨Ü</option>
                        
                            <option value="https://swiest.com/ckb/" >⁄©Ÿàÿ±ÿØ€å</option>
                        
                            <option value="https://swiest.com/ky/" >–ö—ã—Ä–≥—ã–∑—á–∞</option>
                        
                            <option value="https://swiest.com/la/" >Latina</option>
                        
                            <option value="https://swiest.com/lb/" >L√´tzebuergesch</option>
                        
                            <option value="https://swiest.com/lo/" >‡∫û‡∫≤‡∫™‡∫≤‡∫•‡∫≤‡∫ß</option>
                        
                            <option value="https://swiest.com/lt/" >Lietuvi≈≥</option>
                        
                            <option value="https://swiest.com/lv/" >Latvie≈°u</option>
                        
                            <option value="https://swiest.com/mk/" >–ú–∞–∫–µ–¥–æ–Ω—Å–∫–∏</option>
                        
                            <option value="https://swiest.com/ml/" >‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç</option>
                        
                            <option value="https://swiest.com/mn/" >–ú–æ–Ω–≥–æ–ª —Ö—ç–ª</option>
                        
                            <option value="https://swiest.com/mr/" >‡§Æ‡§∞‡§æ‡§†‡•Ä</option>
                        
                            <option value="https://swiest.com/sw/" >Kiswahili</option>
                        
                            <option value="https://swiest.com/ms/" >Bahasa Melayu</option>
                        
                            <option value="https://swiest.com/my/" >·Äô·Äº·Äî·Ä∫·Äô·Ä¨</option>
                        
                            <option value="https://swiest.com/ne/" >‡§®‡•á‡§™‡§æ‡§≤‡•Ä</option>
                        
                            <option value="https://swiest.com/nl/" >Nederlands</option>
                        
                            <option value="https://swiest.com/no/" >Norsk</option>
                        
                            <option value="https://swiest.com/pa/" >‡®™‡©∞‡®ú‡®æ‡®¨‡©Ä</option>
                        
                            <option value="https://swiest.com/pl/" >Polski</option>
                        
                            <option value="https://swiest.com/pt-br/" >Portugu√™s Brasil</option>
                        
                            <option value="https://swiest.com/pt-pt/" >Portugu√™s Europeu</option>
                        
                            <option value="https://swiest.com/ro/" >Rom√¢nƒÉ</option>
                        
                            <option value="https://swiest.com/ru/" >–†—É—Å—Å–∫–∏–π</option>
                        
                            <option value="https://swiest.com/rw/" >Kinyarwanda</option>
                        
                            <option value="https://swiest.com/si/" >‡∑É‡∑í‡∂Ç‡∑Ñ‡∂Ω</option>
                        
                            <option value="https://swiest.com/sk/" >Slovenƒçina</option>
                        
                            <option value="https://swiest.com/sl/" >Sloven≈°ƒçina</option>
                        
                            <option value="https://swiest.com/sq/" >Shqip</option>
                        
                            <option value="https://swiest.com/sr/" >–°—Ä–ø—Å–∫–∏ (Srpski)</option>
                        
                            <option value="https://swiest.com/su/" >Basa Sunda</option>
                        
                            <option value="https://swiest.com/sv/" >Svenska</option>
                        
                            <option value="https://swiest.com/ta/" >‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç</option>
                        
                            <option value="https://swiest.com/te/" >‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å</option>
                        
                            <option value="https://swiest.com/tg/" >–¢–æ“∑–∏–∫”£</option>
                        
                            <option value="https://swiest.com/th/" >‡πÑ‡∏ó‡∏¢</option>
                        
                            <option value="https://swiest.com/tl/" >Filipino</option>
                        
                            <option value="https://swiest.com/tr/" >T√ºrk√ße</option>
                        
                            <option value="https://swiest.com/uk/" >–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞</option>
                        
                            <option value="https://swiest.com/ur/" >ÿßÿ±ÿØŸà</option>
                        
                            <option value="https://swiest.com/uz/" >O&#39;zbekcha</option>
                        
                            <option value="https://swiest.com/vi/" >Ti·∫øng Vi·ªát</option>
                        
                            <option value="https://swiest.com/yi/" >◊ê◊ô◊ì◊ô◊©</option>
                        
                            <option value="https://swiest.com/zh-hk/" >Á≤µË™û</option>
                        
                            <option value="https://swiest.com/zu/" >IsiZulu</option>
                        
                    </select>
                </li>
            
            
            
                <li id="dark-mode-toggle">
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="8" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="16" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                    <span>Dark Mode</span>
                </li>
            
        </div>
    </ol>
</aside>

    

            <main class="main full-width">
    <article class="main-article">
    <header class="article-header">

    <div class="article-details">
    
    <header class="article-category">
        
            <a href="/categories/podcast/" >
                Podcast
            </a>
        
            <a href="/categories/strictlyvc-download/" >
                StrictlyVC Download
            </a>
        
    </header>
    

    <div class="article-title-wrapper">
        <h2 class="article-title">
            <a href="/en/1320100001/">StrictlyVC Download - OpenAI CEO Sam Altman on ChatGPT and Our Future with AI</a>
        </h2>
    
        
    </div>

    
    
    
    
    <footer class="article-time">
        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M11.795 21h-6.795a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v4" />
  <circle cx="18" cy="18" r="4" />
  <path d="M15 3v4" />
  <path d="M7 3v4" />
  <path d="M3 11h16" />
  <path d="M18 16.496v1.504l1 1" />
</svg>
                <time class="article-time--published">2023-01-21</time>
            </div>
        

        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



                <time class="article-time--reading">
                    53 minute read
                </time>
            </div>
        
    </footer>
    

    
</div>

</header>
<div class="article-translations">
    <ul>üéÅ<a href="https://amzn.to/471i0jl" target="_blank">üõíAmazon Prime</a>
       <a href="https://amzn.to/3QDVlVf" target="_blank">üìñKindle Unlimited</a>
       <a href="https://amzn.to/3FqzNoB" target="_blank">üéßAudible Plus</a>
       <a href="https://amzn.to/3tMT3dm" target="_blank">üéµAmazon Music Unlimited</a>
       <a href="https://www.iherb.com/?rcode=EID1574" target="_blank">üåøiHerb</a>
</ul>
</div>
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9206135835124064"
     crossorigin="anonymous"></script>
    
    <ins class="adsbygoogle"
         style="display:block"
         data-ad-client="ca-pub-9206135835124064"
         data-ad-slot="8754979142"
         data-ad-format="auto"
         data-full-width-responsive="true"></ins>
    <script>
         (adsbygoogle = window.adsbygoogle || []).push({});
    </script>
</div>


    <section class="article-content">
    
    
    <p>Hi, I&rsquo;m Connie Loizis, and this is Alex Gove, and this is Strictly VC Download.</p>
<p>Hey everybody, hope you&rsquo;ve had a good week. We are just beginning to dry out here in Marin</p>
<p>after weeks and weeks of rain. Speaking of misery, perhaps the biggest story this week is all of the</p>
<p>layoffs that have been taking place. On Wednesday, Microsoft sacked 10,000 employees, roughly 5% of</p>
<p>its workforce. And today, Google&rsquo;s parent company, Alphabet, announced that it is laying off 12,000</p>
<p>workers, or approximately 6% of its total employees. When you also take into account</p>
<p>the massive number of folks Meta, Amazon, and Salesforce have cut in recent weeks,</p>
<p>it feels like open season on the technorati. With the disappearance of so many jobs,</p>
<p>all of this talk about AI and chat GPT is good news, bad news. On the one hand,</p>
<p>artificial intelligence could spur the creation of the next Google, or Googles. On the other hand,</p>
<p>it also promises to eliminate many jobs forever. One can&rsquo;t help but think about the darker side</p>
<p>of AI when reading an article in today&rsquo;s times entitled, How Smart Are the Robots Getting?</p>
<p>In an opening anecdote, author Cade Metz recounts the experience of Klaus de Graaff,</p>
<p>a chemist from the Netherlands who is playing the online version of Diplomacy,</p>
<p>a legendary strategy game in which players assume the role of a major European power</p>
<p>and attempt to hoodwink other players in the run up to World War I. De Graaff formed an alliance</p>
<p>with a player named Franz Brosef that he believed would allow them to leapfrog the other 18 players</p>
<p>in the game, but Brosef ultimately betrayed de Graaff and finished on top. It should not</p>
<p>surprise you at this point to learn that Brosef was an AI. I was flabbergasted, de Graaff told</p>
<p>the Times. It seemed so genuine, so lifelike. It could read my texts, and converse with me,</p>
<p>and make plans that were mutually beneficial, that would allow both of us to get ahead.</p>
<p>It also lied to me and betrayed me like top players frequently do. As Metz points out,</p>
<p>the Turing test, a framework created by British scientist Alan Turing more than 70 years ago</p>
<p>to determine whether a person is conversing with a man or machine, is now wholly inadequate,</p>
<p>an anachronism in an age when AIs can write novels in the style of James Joyce at the click</p>
<p>of a mouse. Which brings us to Sam Altman, a serial entrepreneur and investor, the former</p>
<p>head of Y Combinator, and now co-founder and president of OpenAI, the company behind ChatGPT.</p>
<p>Connie sat down with Sam at our event last week in San Francisco, and Sam touched on many topics,</p>
<p>such as OpenAI&rsquo;s deal with Microsoft, what education will look like in a world in which</p>
<p>students can instantly generate term papers, and more. Stay tuned for Connie&rsquo;s interview with Sam.</p>
<p>But first, a word from our sponsor.</p>
<p>Did you know that incorrectly reporting your emissions, or worse yet, not understanding them</p>
<p>in the first place, is a form of greenwashing? It&rsquo;s time to get ahead of regulations and quit</p>
<p>misleading customers and stakeholders. Get a handle on your carbon footprint with</p>
<p>Sustain Life&rsquo;s complete carbon accounting and ESG platform. Learn how to increase the ROI</p>
<p>of your ESG program. Visit sustain.life slash StrictlyVC. That&rsquo;s sustain.life slash StrictlyVC.</p>
<p>And now, yes, I&rsquo;m so excited to introduce Sam Altman. I know you&rsquo;re all so excited about him.</p>
<p>I&rsquo;m thrilled that he&rsquo;s here. Sam is a really good sport because, you know, originally I had talked</p>
<p>to him about having an event with him and his brothers, and life gets busy, and so we realized</p>
<p>a long time ago that that wasn&rsquo;t going to be possible. And he very nicely, despite what&rsquo;s</p>
<p>happening in his life right now, came anyway. So thank you, Sam. So appreciate it.</p>
<p>Thanks for having me.</p>
<p>So Sam, you also very nicely came to an event that happened to be right here three years ago.</p>
<p>Yeah, I remember.</p>
<p>What&rsquo;s been happening?</p>
<p>Opened their eye, mostly. Yeah, it&rsquo;s just taken up a lot of my time, but it&rsquo;s super great, and</p>
<p>I think we&rsquo;re doing a lot of stuff we&rsquo;re really proud of.</p>
<p>I know. I mean, I&rsquo;m half kidding, obviously, but, you know, you&rsquo;ve been at the center of the</p>
<p>startup conversation for almost 10 years since you had taken over as the president of Y Combinator.</p>
<p>Wow, that has been 10 years, yeah.</p>
<p>Yeah, or something like that.</p>
<p>Almost.</p>
<p>Paul Graham once said that Sam is exceedingly good at becoming powerful, which I think is very funny.</p>
<p>But you are now at the center of the national conversation. I mean, to an extent that I think,</p>
<p>you know, sort of has taken us all collectively aback. I&rsquo;m just wondering, how is that for you?</p>
<p>Are you like springing out of bed? Are you like waking up dreading, you know, the headlines?</p>
<p>I saw that you had posted&hellip;</p>
<p>I don&rsquo;t read the news. Honestly, I think if I, and I don&rsquo;t really do stuff like this much,</p>
<p>at all, I think if I could, like, just stop trolling on Twitter, which I really love,</p>
<p>for some reason, I can&rsquo;t explain. I think I would just like really accomplish my goal of</p>
<p>not, you know, being very quiet. But Twitter is fun.</p>
<p>Well, I saw that you posted a barfing emoji yesterday without comment. And I wondered</p>
<p>if that had anything to do with the headlines?</p>
<p>No, I had a bad morning for like extremely pedestrian reasons. Like my house flooded,</p>
<p>I got in a car crash. And, you know, I&rsquo;m allowed to use Twitter like a regular person.</p>
<p>I&rsquo;m sorry. Sure, absolutely. Oh, well, I mean, we&rsquo;re not here to talk about Twitter,</p>
<p>but any thoughts about, you know, your friend is running it? What do you think? How do you</p>
<p>think things are going?</p>
<p>I think it&rsquo;s gonna be fine. I remember that night where everyone was like,</p>
<p>get your tweets off right now. Say your goodbyes. I heard from my like, you know, brothers,</p>
<p>roommates, father&rsquo;s uncle, whatever that like, it&rsquo;s all gonna melt down tonight. And it&rsquo;s all over.</p>
<p>And, you know, it&rsquo;s still here. I think it&rsquo;s gonna&hellip;</p>
<p>Because they went to Mastin and then they saw what the alternative was.</p>
<p>I think it&rsquo;s, I think it&rsquo;s, I would be making some different decisions. But also,</p>
<p>I have like unbelievable respect for Elon, I wouldn&rsquo;t bet against him.</p>
<p>And I think it&rsquo;s most likely going to be fine.</p>
<p>Great. Well, you know, there are a lot of reporters here who have been generating the</p>
<p>coverage that we&rsquo;ve all been reading. So I was going to say, if there&rsquo;s anything that</p>
<p>you want to confirm, or correct, I&rsquo;m sure they would be delighted. But in the meantime,</p>
<p>you know, Strictly VC is really about investors and startup founders. And I think in the same</p>
<p>way that people are very interested in open AI because of your involvement, they are really</p>
<p>interested in your work as an investor. So I thought just to start, if it&rsquo;s okay with you,</p>
<p>we could kind of talk a little bit about that aspect of your life. Starting with&hellip;</p>
<p>Sure. But can I correct one thing first? I don&rsquo;t think people are interested in open AI</p>
<p>because of my involvement. I think open AI has managed to pull together the most talent dense</p>
<p>researchers and engineers in the field of AI, who have done just like incredible work. And I think</p>
<p>what people are interested in is like, open AI from a cold start a few years ago has managed to</p>
<p>do this thing that I think is going to be incredibly important to the next many decades,</p>
<p>at least of society and how we all live our lives and what we do and what&rsquo;s possible. And I think</p>
<p>it&rsquo;s going to be tremendously good. But the reason people I think are interested in open AI is</p>
<p>because of the work that those people do. We&rsquo;ve managed to make a research lab that has been able</p>
<p>to deliver some cool stuff. And I think we&rsquo;ll deliver a lot more cool things. So just wanted</p>
<p>to add that. Absolutely. But I mean, you are one of the best storytellers in Silicon Valley,</p>
<p>possibly the business. I think that counts for a lot. So I&rsquo;m going to argue with you there. But</p>
<p>how many investments do you have, like all together? Active. Trying to get a sense for&hellip;</p>
<p>I mean, counting all the YC ones, like a few thousand personal ones,</p>
<p>I would guess 400. Wow, really?</p>
<p>Something. Well, I&rsquo;ve been doing this for a long time. Yeah, absolutely. I mean,</p>
<p>and every once in a while I see like a really gigantic deal. What makes a Sam Altman deal?</p>
<p>I try to just do things that I&rsquo;m interested in at this point. One of the things I have realized</p>
<p>is all of the companies I think I have added a lot of value to are the ones that I sort of like</p>
<p>think about in my free time on a hike or whatever, and then text the founders,</p>
<p>hey, I have this idea for you. And I have learned kind of like what those are and the ones that are</p>
<p>not. I think like every founder deserves an investor who is like going to think about them</p>
<p>while they&rsquo;re hiking. And so I&rsquo;ve tried to like hold myself to the stuff that I really love,</p>
<p>which tends to be like the hard tech years of R&amp;D, capital intensive or like sort of like risky</p>
<p>research. But if it works, it really works. Well, one of the investments that I think is</p>
<p>so interesting, and obviously it&rsquo;s very interesting to you too, is Helion.</p>
<p>That company announced, so you&rsquo;ve been investing in Helion since 2015,</p>
<p>but announced a $500 million investment last year and you participated, you wrote them a $375</p>
<p>million check, which I think probably surprised people because there&rsquo;s not that many people who</p>
<p>can write a $375 million check. Or not that many people who would like</p>
<p>do it until like one risky fusion company. Well, I mean, I wanted to ask, so you mentioned</p>
<p>your YC companies, and I guess in the aggregate, maybe that&rsquo;s the answer. I just wondered,</p>
<p>which have been your most successful investments to date?</p>
<p>I mean, probably on a multiples basis, definitely on a multiples basis,</p>
<p>Stripe. And also I think that was like my second investment ever. So it seemed like a lot easier.</p>
<p>This was also a time when valuations were different. It was great. But probably that</p>
<p>one on a multiples basis. But then, yeah, I&rsquo;ve been doing this for like 17 years, I guess. So</p>
<p>there&rsquo;s been a lot of really good ones. And super grateful to have been in Silicon Valley at what</p>
<p>was such a magical time. Helion is more than an investment to me. That&rsquo;s the other thing besides</p>
<p>OpenAI I spend a lot of time on. And just super excited about what&rsquo;s going to happen there.</p>
<p>So tell me about it, because I don&rsquo;t really, I mean, I don&rsquo;t understand this. I saw what</p>
<p>happened at Lawrence Livermore last month, and I wondered what you thought of that. It&rsquo;s a very</p>
<p>different approach. Maybe if you can sort of explain since you&rsquo;re the expert.</p>
<p>Super happy for them. I think it&rsquo;s like a very cool scientific result. As they themselves said,</p>
<p>I don&rsquo;t think it&rsquo;ll be commercially relevant. And that&rsquo;s what I&rsquo;m excited about. Not sort</p>
<p>of getting fusion to work in a lab, although that is cool, too. But building a system that</p>
<p>will work at a super low cost. So if you look at the previous energy transitions, if you can get</p>
<p>the cost of a new form of energy down, it can take over everything else in a couple of decades.</p>
<p>Just phenomenally fast. And then also a system where we can create enough energy,</p>
<p>enough reliable energy, both in terms of the machines not breaking and also not having the</p>
<p>intermittence or the need for storage of solar or wind or something like that. If we can create</p>
<p>enough for Earth in like 10 years, and I think that&rsquo;s actually the hardest challenge that Helion</p>
<p>faces. As we sketch out what it takes operationally to do that, to replace all the</p>
<p>current generative capacity on Earth with fusion and to do it really fast and to think about what</p>
<p>it really means to build a factory that&rsquo;s capable of putting out two of these machines a day for a</p>
<p>decade, that&rsquo;s really hard, but also a super fun problem. So I&rsquo;m very happy there&rsquo;s a fusion race.</p>
<p>I think that&rsquo;s great. I&rsquo;m also very happy solar and batteries are getting so cheap.</p>
<p>But I think what will matter is who can deliver energy the cheapest and enough of it.</p>
<p>And again, just knowing only what I read in a superficial way, why is Helion&rsquo;s approach</p>
<p>to your mind superior than what dozens of nations are working on in the south of France?</p>
<p>Yeah. Well, that thing I think probably will work either. But to what I was just saying earlier,</p>
<p>I think it will be commercially irrelevant. They also think it&rsquo;ll be commercially irrelevant.</p>
<p>The thing that is so exciting to me about Helion is that it&rsquo;s a simple machine that is</p>
<p>an affordable cost and a reasonable size. There&rsquo;s a bunch of different elements of it than the</p>
<p>giant tokamaks. But one that is very cool is what comes out of the reaction is charged particles,</p>
<p>not heat. Almost all others, like a coal plant or a natural gas plant or whatever,</p>
<p>makes heat, drives a steam turbine. That&rsquo;s what it does. Helion makes charged particles,</p>
<p>which push back on the magnet and drive an electrical current down a wire. There&rsquo;s no</p>
<p>heat cycle at all. And so it can be a much simpler, much more efficient system.</p>
<p>And that, I think, is missed out of the whole discussion on fusion, but really great. It also</p>
<p>means we don&rsquo;t have to deal with much nuclear material. We don&rsquo;t ever have dangerous waste or</p>
<p>even a dangerous system. You could touch it pretty shortly after it turns off.</p>
<p>And so I know it&rsquo;s building a big facility right now. Has it proven its thesis?</p>
<p>We will have more to share there shortly.</p>
<p>OK. Well, after talking to you last time a few years ago and looking back on our conversation,</p>
<p>where I was like, ah, Sam. No, everything that you said was going to happen is happening. I</p>
<p>take you more seriously than I did and should have.</p>
<p>There&rsquo;s a long way to go, but thank you.</p>
<p>So I also wanted to ask about some of your other investments, one of which I think is really</p>
<p>interesting, Hermes.</p>
<p>Yeah.</p>
<p>So Hermes is interesting for a few reasons. Hermes is a supersonic jet company that wants</p>
<p>to go at, like, five times the speed of sound. So that&rsquo;s cool. Also, a big investment from you,</p>
<p>I think. It was like a $100 million round that you led. But also, you were involved with a</p>
<p>competitor for a while. You were on the board of Boom Supersonic, whose CEO has also participated</p>
<p>in a Strictly VC event. So just wondering, why change horses?</p>
<p>Yeah. Not at all change horses. Boom is a different technology. And it&rsquo;s like a</p>
<p>Mach 2-ish airplane instead of a Mach 5-ish airplane. Hermes is like a ramjet technology</p>
<p>that has very different characteristics. But I think there will be, like, it&rsquo;s a huge market.</p>
<p>I think there will be multiple needs. I think these are very different approaches. And my</p>
<p>general approach is, if there&rsquo;s an area that I think is really important, like energy, for</p>
<p>example, I try to fund the best fusion and the best fission company I can. They&rsquo;re competitive</p>
<p>in the sense that they&rsquo;re both trying to make cheap energy, but, like, we desperately need</p>
<p>more cheap energy. It&rsquo;s a huge market. I think they can both work. I wouldn&rsquo;t have funded two,</p>
<p>like, exact same approach airplane companies. But I think these are, like, very different.</p>
<p>And also, you know, you are somebody who thinks about sort of second-order effects.</p>
<p>When you think about Hermes, I mean, first of all, I guess, is it climate-friendly? And second,</p>
<p>what are the impacts, I guess, good and bad of us traveling around the world much faster</p>
<p>than we do right now? Part of my theory is that, so it&rsquo;s not climate-friendly if it&rsquo;s using</p>
<p>current aviation fuel. I think even if something like fusion doesn&rsquo;t happen, there&rsquo;s a pretty</p>
<p>good move to sustainable aviation fuel. And, you know, at some point, we&rsquo;ll be all using that</p>
<p>anyway. If something like fusion does work, it will so change the dynamics of what&rsquo;s possible</p>
<p>in terms of our ability to create things like aviation fuel easily or capture carbon out of</p>
<p>the atmosphere, and I am confident enough in that working, that things I was much more nervous</p>
<p>about doing a few years ago, like creating faster airplanes that will increase the need for fuel,</p>
<p>because you have to burn a lot more fuel to go even a little bit faster, I&rsquo;m sort of muddling</p>
<p>I&rsquo;m sort of much more open to in terms of like the benefits of traveling fast.</p>
<p>I think human history is like a pretty good, there&rsquo;s like quite good evidence that when we</p>
<p>are able to travel faster and more conveniently, good things happen. More commerce happens,</p>
<p>more innovation happens. I think people develop much more empathy. Certainly the time I have spent</p>
<p>like traveling around the world and seeing very different things, very different problems,</p>
<p>meeting very different people have been like super formative for me, and I think more of</p>
<p>that&rsquo;s a good thing. I guess one downside is the spread of disease happens faster, but that&rsquo;s.</p>
<p>Yes, although I like, I think blaming faster planes for the spread of disease rather than</p>
<p>the incompetence of governments and insufficient funding for pandemic response is sort of the</p>
<p>wrong way to go about it. What about WorldCoin? That was a strange one, and that one was not</p>
<p>received well by the media. We probably didn&rsquo;t understand it. You can&rsquo;t win them all. Wait,</p>
<p>wait, can I read the headline in Bloomberg? Please. Sam Altman wants to scan your eyeball</p>
<p>in exchange for cryptocurrency. What is going on with that company? Is it still,</p>
<p>are you still working on it and should we be scared? I am. Yeah, like I think that&rsquo;s they&rsquo;ll</p>
<p>have more to share soon. I am. I&rsquo;m like a co-founder. I&rsquo;m on the board. I&rsquo;m not day to day</p>
<p>involved, but I think super highly of them. I think the press cycle, it was like came from a</p>
<p>leak. The company hadn&rsquo;t like was not ready to tell its story yet. That was unfortunate. I think</p>
<p>they&rsquo;ll do it soon. And I think it will go over well. I think the need, so I like, I try to think</p>
<p>about like not any individual company, but sort of where the world is going to co-evolve. And I</p>
<p>think at this point, the need for systems that provide proof of personhood and the need for like</p>
<p>new experiments with wealth redistribution and global governance of systems like say,</p>
<p>an AGI is higher. So I&rsquo;m very glad this experiment is running. I&rsquo;d like to see many more. I think</p>
<p>the, like to me personally, and again, people will have different opinions and they&rsquo;ll do what</p>
<p>they want, but like the amount of privacy you give up to like use Facebook or something versus</p>
<p>the amount of privacy you like give up for like a scan of your, of your retina and nothing else.</p>
<p>Like I&rsquo;d much rather have the latter. And many people won&rsquo;t want that and that&rsquo;s fine. But I</p>
<p>think more experiments about how, what we can do, what problems we can solve with technology</p>
<p>in this sort of new world, like great to try that stuff. I think it&rsquo;s a phenomenal team. I think</p>
<p>they&rsquo;ve got a great product. I&rsquo;m excited for the launch. When is that? I don&rsquo;t know exactly,</p>
<p>but pretty soon, like months. And you&rsquo;re a co-founder, but you&rsquo;re obviously not</p>
<p>very involved. Correct. Okay. One of the investors I just happened to notice was Sam</p>
<p>Bankman-Freed, who&rsquo;s also like you. I did not know that. Interesting. I really didn&rsquo;t. He&rsquo;s</p>
<p>personally an investor in the company. I mean, according to some report. No, I didn&rsquo;t know that.</p>
<p>Are you, do you know him? We met briefly, very briefly once only. Okay. So not enough</p>
<p>to form an opinion. Okay. Scratch that hard questions. Not good. I wanted to ask about</p>
<p>then crypto more broadly. You have a smattering of crypto investments. I don&rsquo;t know how interested</p>
<p>you are, if this is like friends that you&rsquo;ve backed. Honestly, not super interested. I&rsquo;m</p>
<p>interested in world coin, not because it&rsquo;s crypto, but because I think it&rsquo;s an interesting,</p>
<p>it&rsquo;s an interesting attempt to use technology to solve something that is beyond what even</p>
<p>like governments in the world can effectively do. And I think if we can, if we can use technology,</p>
<p>any technology to experiment with global UBI instead of what one country could do, I&rsquo;d be</p>
<p>very happy to see what happens there. But that&rsquo;s not really about any particular technology. I</p>
<p>think crypto is just like a way that we should try implementing that. And we should, again,</p>
<p>try lots and lots of other things. So we don&rsquo;t need a, like a new web. We don&rsquo;t need new</p>
<p>infrastructure. We don&rsquo;t need decentralization. You know, this is like one of the things that</p>
<p>makes me feel really old and out of touch. I&rsquo;ve never quite understood that. Like, I love the</p>
<p>spirit of the Web3 people, but I don&rsquo;t, I don&rsquo;t intuitively feel why we need it.</p>
<p>That&rsquo;s great. That&rsquo;s a relief because I think a lot of people feel the same way. I want to</p>
<p>move on soon, but another company that I think is so interesting, and again, these are all so</p>
<p>different and ambitious, is Conception, which is a startup pursuing what&rsquo;s called in vitro</p>
<p>gametogenesis, which refers to turning adult cells into gametes, sperm or egg cells. So,</p>
<p>I mean, is this fantasy? What makes you think that like artificial eggs is possible?</p>
<p>It&rsquo;s not fantasy. You know, there was a recent paper, they really truly have this not working</p>
<p>in mice. Obviously, working in mice is very different than working in humans. We&rsquo;ve learned</p>
<p>that lesson many times. But it seems to me like it should work at some point. It&rsquo;s not soon.</p>
<p>There&rsquo;s a there&rsquo;s a gigantic amount of work left to do. But I think what&rsquo;s happening in</p>
<p>biotech in general is just tremendously exciting now. It&rsquo;s, you know, I think it&rsquo;s like,</p>
<p>kind of in the shadow of AI, which has taken over like so much of the of the mindshare. But I think</p>
<p>the next five, seven years of biotech progress is going to be remarkable. And yeah, I think like,</p>
<p>like, if we do this again, three years later, it&rsquo;ll it&rsquo;ll start that one in particular,</p>
<p>we&rsquo;ll go, yeah, that&rsquo;s, that&rsquo;s gonna work. And I think things that are even further out there,</p>
<p>like, you know, human life extension or whatever will also seem like, yeah, maybe that&rsquo;s gonna</p>
<p>work. That&rsquo;s phenomenal. I guess there&rsquo;s obviously a lot of overlap, which is why</p>
<p>you think that these things are going to work. Yeah, I think a lot of these things have these</p>
<p>weirdly synergistic effects with each other. But even without that, I would just say,</p>
<p>a biotech on its own is has made quite a lot of progress.</p>
<p>There&rsquo;s so much interesting stuff going on. I interviewed a founder recently,</p>
<p>who&rsquo;s trying to extend the life of women&rsquo;s ovaries, which I also think is,</p>
<p>is really interesting. Okay, before we move on, you have been investing for 20 years,</p>
<p>you were the president of Y Combinator for something like five or six years,</p>
<p>you have your successor, Jeff Ralston, just left Gary Tan came in, you had told Tad Friend once,</p>
<p>that when a CEO takes over a company, they have to kind of refound I think was the word you use,</p>
<p>the company, do you think Gary&rsquo;s got to do anything differently?</p>
<p>Gary&rsquo;s awesome. I think Gary will do a lot of things differently, and be wildly successful at</p>
<p>it. We&rsquo;re in a very different world and market now. You know, like, I got to run, I said this</p>
<p>once to somebody, I got to like run YC at the time where like any idiot would have been wildly</p>
<p>successful. And that was great. That was a lot of fun. It&rsquo;s and then like the last couple of years,</p>
<p>I think were really hard. But now, when everything is like bombed out, I think it&rsquo;s a wonderful</p>
<p>opportunity. And I think YC can really remake itself. And I think Gary is an incredible leader</p>
<p>to do that. And at the time when all of the tourists are leaving, and all of the people</p>
<p>who are like, you know, starting startups or raising the their seed fund or whatever,</p>
<p>because it was like the fashionable thing to do are leaving like, this is when the great value</p>
<p>gets created. This is like the best time to start a startup in many, many, many years.</p>
<p>So I&rsquo;m very excited for him.</p>
<p>So moving on to AI, which is where you&rsquo;ve obviously spent the bulk of your time.</p>
<p>Since I saw you, we sat here three years ago. And as I was teasing you, but it&rsquo;s true,</p>
<p>it&rsquo;s true. You were telling us what was coming. And we all thought you were being sort of like,</p>
<p>you know, hyperbolic, I guess you were dead serious. Why do you think I mean, people knew</p>
<p>that you were working on this Google&rsquo;s working on this. Why do you think that chat GPT and Dolly</p>
<p>so surprised people? I genuinely don&rsquo;t know. I&rsquo;ve reflected on it a lot.</p>
<p>We had that we had a model in the we had the model for chat GPT in the API for like,</p>
<p>I don&rsquo;t know, 10 months or something before we made chat GPT. And I sort of thought someone</p>
<p>was going to just build it or whatever. And that, you know, enough people had played around with it.</p>
<p>Definitely, if you make a really good user experience on top of something, like one thing</p>
<p>that I very deeply believed was the way people wanted to interact with these models was via</p>
<p>dialogue. And I, you know, we kept telling people this, we kept trying to convince people to build</p>
<p>it, and people wouldn&rsquo;t quite do it. So we finally said, All right, we&rsquo;re just going to do it.</p>
<p>But yeah, I think the pieces were there for a while. I think one of the reasons I think Dolly</p>
<p>surprised people is if you asked, you know, five or seven years ago, that kind of ironclad wisdom</p>
<p>on AI. First, it comes for physical labor, truck driving, working in a factory, working factory,</p>
<p>then truck driving, then the sort of less demanding cognitive labor, then the really</p>
<p>demanding cognitive labor, like computer programming, and then and then very last of</p>
<p>all, or maybe never, because maybe it&rsquo;s like some deep human special sauce was creativity.</p>
<p>And of course, we can look now and say, really looks like it&rsquo;s going to go exactly the opposite</p>
<p>direction. But I think that is not super intuitive. And so I can see why Dolly surprised people.</p>
<p>But I genuinely felt somewhat confused about why chat GPT did, you know, one of the things we</p>
<p>really believe is that the most responsible way to put this out in society is very gradually,</p>
<p>and to get people, institutions, policymakers, get them familiar with it, thinking about the</p>
<p>implications, feeling the technology, getting a sense for what it can do and can&rsquo;t do</p>
<p>very early, rather than drop a super powerful AGI in the world all at once. And so</p>
<p>we put GPT three out almost three years ago. And then we put it into an API, like,</p>
<p>you know, kind of, I think it was maybe like June of two, like two and a half years ago.</p>
<p>And the the incremental update from that to chat GPT, I felt like should have been predictable.</p>
<p>And I want to like do more introspection on why I was sort of miscalibrated on that.</p>
<p>So, you know, you had talked when you were here about releasing things in a responsible way,</p>
<p>I guess, what gave you the confidence to release what you have released already? I mean,</p>
<p>do you think we&rsquo;re ready for it? Are there enough guardrails in place?</p>
<p>It seems like it. We do, we have like an internal process where we kind of try to break things and</p>
<p>study impacts. We use external auditors, we have external red teamers, we work with other labs and</p>
<p>have safety organizations look at stuff. There are societal changes that chat GPT is going to</p>
<p>cause or is causing. There&rsquo;s, I think, a big one going now about the impact of this on education,</p>
<p>academic integrity, all of that. But starting these now, where I think it&rsquo;s important to</p>
<p>look at where the stakes are still relatively low, rather than just put out what the whole</p>
<p>industry will have in a few years with no time for society to update, I think would be bad.</p>
<p>COVID did show us for better or for worse, or at least me, that society can update to like</p>
<p>massive changes sort of faster than I would have thought in many ways. But I still think like,</p>
<p>given the magnitude of the economic impact we expect here, more gradual is better. And so</p>
<p>putting out a very weak and imperfect system like chat GPT, and then making it a little better this</p>
<p>year, a little better later this year, a little better next year, that seems much better than</p>
<p>the alternative.</p>
<p>Can you comment on whether GPT-4 is coming out in the first quarter, first half of the year?</p>
<p>It&rsquo;ll come out at some point when we are like confident that we can do it safely and responsibly.</p>
<p>I think in general, we are going to release technology much more slowly than people would</p>
<p>like. We&rsquo;re going to sit on it for much longer than people would like. And eventually people</p>
<p>will be like happy with our approach to this. But at the time, I realized like people want</p>
<p>the shiny toy and it&rsquo;s frustrating. I totally get that.</p>
<p>I saw a visual and I don&rsquo;t know if it was accurate, but it showed GPT-3.5 versus I guess</p>
<p>what GPT-4 is expected.</p>
<p>I saw that thing on Twitter.</p>
<p>Did you? Was that accurate?</p>
<p>Complete bullshit. No.</p>
<p>Okay. Because that was a little bit scary.</p>
<p>The GPT-4 rumor mill is like a ridiculous thing. I don&rsquo;t know where it all comes from.</p>
<p>I don&rsquo;t know why people don&rsquo;t have like better things to speculate on. I get a little bit</p>
<p>of it. Like it&rsquo;s sort of fun, but that it&rsquo;s been going for like six months at this volume.</p>
<p>People are begging to be disappointed and they will be like, it&rsquo;s, you know, people</p>
<p>are going to like, the hype is just like, we don&rsquo;t have an actual AGI. And I think that&rsquo;s</p>
<p>sort of what is expected of us. And, you know, yeah, we&rsquo;re going to disappoint those people.</p>
<p>Right, right. Well, I want to talk to you about how close that is. So, you know, another</p>
<p>thing a few years ago you said, and this was funny, I thought, we were talking about revenue.</p>
<p>This is before you announced your partnership with Microsoft. And you said, and I quote,</p>
<p>basically, we made a soft promise to investors that once we built this generally intelligent</p>
<p>system, we will ask it to figure out a way to generate an investment return.</p>
<p>We all kind of laughed at this. And you said, it sounds like an episode of Silicon Valley. I know,</p>
<p>but it is actually what I believe. Someone sent me that video a few weeks ago.</p>
<p>I mean, in some sense, that&rsquo;s what&rsquo;s happening. Like we built a thing deeply imperfect as it is,</p>
<p>we couldn&rsquo;t figure out how to monetize it. You could talk to it. We put it out into the world</p>
<p>via an API, and other people, by playing around with it, figured out all these things to do.</p>
<p>So it was not quite the like ask thing, and it tells you how to monetize.</p>
<p>But it hasn&rsquo;t been hasn&rsquo;t gone totally the other direction either.</p>
<p>Okay, but we&rsquo;re not quite there yet. You obviously have figured out a way to make some revenue.</p>
<p>You&rsquo;re licensing your models.</p>
<p>Not much. We&rsquo;re very early.</p>
<p>Right. But so right now, licensing to startups. So you are early on, and people are sort of looking</p>
<p>at the whole of what&rsquo;s happening out there. And they&rsquo;re saying, you&rsquo;ve got like Google,</p>
<p>which could potentially release things this year. You have a lot of AI upstarts nipping at your</p>
<p>heels. Are you worried about what you&rsquo;re building being commoditized? And I guess, driving the</p>
<p>I mean, to some degree, I hope it is. The future I would like to see is where access to AI is</p>
<p>super democratized, where there are several AGIs in the world that can kind of like help allow for</p>
<p>multiple viewpoints, and not have anyone get too powerful. And that, and that, like, the cost of</p>
<p>intelligence and energy, because it gets commoditized, trends down and down and down,</p>
<p>and the massive surplus their access to the systems, eventually governance of the systems</p>
<p>benefits all of us. So yeah, I sort of hope that happens. I think competition is good.</p>
<p>At least, you know, until we get to AGI, I like deeply believe in capitalism and</p>
<p>competition to offer the best service at the lowest price.</p>
<p>But that&rsquo;s not great from a business standpoint.</p>
<p>We&rsquo;ll be fine. We&rsquo;ll be fine.</p>
<p>I also find it interesting that you say, differing viewpoints, or these AGIs would</p>
<p>have different differing viewpoints, I guess how I mean, they&rsquo;re all being trained on like</p>
<p>all the data that&rsquo;s available in the world. So how do we come up with differing viewpoints?</p>
<p>What I think is going to have to happen is society will have to agree and like set some laws</p>
<p>on what an AGI can never do, or what one of these systems should never do.</p>
<p>And one of the cool things about the path of the technology tree that we&rsquo;re on, which is very</p>
<p>different, like before we came along, and it was sort of deep mind having these games that were</p>
<p>like, you know, having agents play each other and try to deceive each other and kill each other and</p>
<p>all that, which I think could have gone in a bad direction. We now have these language models that</p>
<p>can understand language. And so we can say, hey, you know, model, here&rsquo;s what we&rsquo;d like you to do.</p>
<p>Here are the values we&rsquo;d like you to align to. And we don&rsquo;t have it working perfectly yet,</p>
<p>but it works a little and it&rsquo;ll get better and better. And the world can say, all right,</p>
<p>here are the rules. Here&rsquo;s the very broad bounds, very broad, like absolute rules of a system.</p>
<p>But within that, people should be allowed very different things that they want their AI to do.</p>
<p>And so if you want the super, like, you know, never offend, safe for work model,</p>
<p>you should get that. And if you want an edgier one, that, you know, is sort of like creative</p>
<p>and exploratory, but says some stuff you like, might not be comfortable with, or some people</p>
<p>might not be comfortable with, you should get that. And I think there will be many systems</p>
<p>in the world that have different settings of the values that they enforce. And really what I think,</p>
<p>and this will take longer, is that you as a user should be able to write up a few pages of here&rsquo;s</p>
<p>what I want, here are my values, here&rsquo;s how I want the AI to behave. And it reads it and</p>
<p>thinks about it and acts exactly how you want, because it&rsquo;s like, should be your AI. And,</p>
<p>you know, it should be there to serve you and do the things you believe in.</p>
<p>So that to me is much better than one system where like one tech company says, here are the rules.</p>
<p>That&rsquo;s really interesting. So also, when we sat down, it was right before your partnership with</p>
<p>Microsoft. So when you say we&rsquo;re going to be okay, I wonder if&hellip;</p>
<p>No, nothing about that. We&rsquo;re just going to build a fine business. Like even if the</p>
<p>competitive pressure pushes the price that people will like pay token down, we&rsquo;re going to do fine.</p>
<p>We also have this like cap profit model. So we don&rsquo;t have this incentive to just like</p>
<p>capture all of the infinite dollars out there anyway. And to like generate enough money for</p>
<p>our equity structure, like, yeah, I believe we&rsquo;ll be fine.</p>
<p>Well, I know you&rsquo;re not crazy about talking about deal making, so we won&rsquo;t. But can you</p>
<p>talk a little bit about your partnership with Microsoft, I guess, how it&rsquo;s going</p>
<p>and how they&rsquo;re using your tech?</p>
<p>It&rsquo;s great. They&rsquo;re the only tech company out there that I think</p>
<p>we I&rsquo;d be excited to partner with this deeply. I think Satya is an amazing CEO,</p>
<p>but more than that human being and understands. So do Kevin Scott and Mikhail, who we work with</p>
<p>closely as well, like understand the stakes of what AGI means and why we need to have all the</p>
<p>weirdness we do in our structure and our agreement with them. And so I really feel like it&rsquo;s a very</p>
<p>values aligned company. And there&rsquo;s some things they&rsquo;re very good at, like building very large</p>
<p>supercomputers and the infrastructure we operate on and putting the technology into products.</p>
<p>There&rsquo;s things we&rsquo;re very good at, like doing research. And it&rsquo;s been a great partnership.</p>
<p>Can you comment on whether the reports are accurate,</p>
<p>that it&rsquo;s going to be in being an office or maybe it&rsquo;s already in those things?</p>
<p>You are a very experienced and professional reporter.</p>
<p>You know, I can&rsquo;t comment on that. I know, you know, I can&rsquo;t comment on that. You know,</p>
<p>I know, you know, you can&rsquo;t comment on that. In the spirit of shortness of life</p>
<p>and our precious time here, why do you ask?</p>
<p>Sam.</p>
<p>I&rsquo;m genuinely curious. Like if you ask a question, you know I&rsquo;m not going to answer.</p>
<p>Well, I thought you might answer that one. No. Okay. I know there&rsquo;s some things you don&rsquo;t answer,</p>
<p>but I got to try.</p>
<p>Another company&rsquo;s product plans I&rsquo;m definitely not going to touch.</p>
<p>Well, okay. Let me ask you about yours then. Do you, is your pact with Microsoft,</p>
<p>does it preclude you from building software and services?</p>
<p>No, no. We build stuff. I mean, we just, as we talked about chat GPT,</p>
<p>we have lots more cool stuff coming.</p>
<p>Okay. And you, and what about other partnerships other than with Microsoft also?</p>
<p>Yeah. Yeah. I mean, like, again, in general, we are very much here to build AGI</p>
<p>and products and services are tactics and service of that partnerships too.</p>
<p>But important ones, and we like, we really want to be useful to people.</p>
<p>And I think if we just build this in a lab and don&rsquo;t figure out how to get out into the world,</p>
<p>that&rsquo;s, that&rsquo;s like somehow we&rsquo;re really falling short there.</p>
<p>Well, I wondered what you made of the fact that Google has said</p>
<p>to its employees, we just, it&rsquo;s too imperfect. It could harm our reputation. We&rsquo;re not ready.</p>
<p>I hope, I hope when they launch something anyway, you really hold them to that comment.</p>
<p>I&rsquo;ll just leave it there.</p>
<p>Okay. Let me ask you this. What did you think when they suspended that seven-year veteran</p>
<p>of their responsible AI organization who thought that the chat bot that he was working on for them</p>
<p>had become sentient?</p>
<p>You know, I read, I remember reading a little bit about that,</p>
<p>but not enough that I feel like I can comment. Like I basically only remember the headline.</p>
<p>I guess I thought at the time he sounded like a crackpot. And now that I&rsquo;ve seen chat GPT,</p>
<p>I think maybe that&rsquo;s why you rushed out chat GPT because yours is amazing. And if there&rsquo;s</p>
<p>this also amazing, um, you know, I haven&rsquo;t seen theirs. Um, I would, I think they&rsquo;re like</p>
<p>a competent org, so I would assume they have something good, but I, I don&rsquo;t know anything about</p>
<p>it. Um, so we talked earlier on about education. People are scared and excited. I was just telling</p>
<p>you that my 13 year old came home from school a couple of days ago and his teacher was telling</p>
<p>him, um, not to be scared by AI, but you know, you guys are going to have to sort of, um,</p>
<p>develop different skill sets in your lifetime, um, that are valued. So, but there is a lot of</p>
<p>concern. The New York public school system, just restricted access to jet GPT, which is probably,</p>
<p>um, not as big a story as it sort of seemed from the headline, but what do you think about</p>
<p>educators? What are misconceptions about what you&rsquo;re working on? How can you kind of allay</p>
<p>their concerns? Look, I get it. Um, I get why educators feel the way they feel about this.</p>
<p>And, and probably like, this is just a preview of what we&rsquo;re going to see in a lot of other areas.</p>
<p>Um, I think this is just the new, we&rsquo;re going to try to, you know, do some things in the short term.</p>
<p>Um, and there may be ways we can help teachers be like a little bit more likely to detect output or</p>
<p>anyone output of like a GPT like system. But honestly, a determined person is going to get</p>
<p>around them. And I don&rsquo;t think it&rsquo;ll be something society can or should rely on longterm. Um, we&rsquo;re</p>
<p>just in a new world now, like generated text is something we all need to adapt to. And that&rsquo;s</p>
<p>fine. Um, we adapted to, you know, calculators and changed what we tested for in math classes.</p>
<p>I imagine, uh, this is a more extreme version of that, no doubt. Um, but also the benefits of it</p>
<p>are more extreme as well. Um, you know, we hear about, we hear from teachers who are understandably</p>
<p>very nervous about the impact of this on homework. We also hear a lot from teachers who are like,</p>
<p>wow, this is like an unbelievable personal tutor for me. Um, and I think that&rsquo;s a good thing.</p>
<p>Wow. This is like an unbelievable personal tutor for each kid. And I think that I have used it to</p>
<p>learn things myself, uh, and found it like much more compelling than other ways. I&rsquo;ve learned</p>
<p>things in the past. Like I would much rather have chat GPT teach me about something, then go read a</p>
<p>textbook. Uh, so, you know, it&rsquo;s like an evolving world and we&rsquo;ll all adapt and I think be better</p>
<p>off for it. And we won&rsquo;t want to go back. Well, my 15 year old son came home one day and was</p>
<p>using it to understand some science concepts better, which I thought was really great. Yeah.</p>
<p>But the same kid also was like, could I use this to write my papers? So, so I did want to ask about,</p>
<p>um, watermarking technologies and other techniques. So it sounds like you don&rsquo;t think it&rsquo;s,</p>
<p>no, I think, you know, we will, we will experiment with this. Other people will too.</p>
<p>I think it is important for the transition. Um, but I, I would caution policy,</p>
<p>national policy, individual schools, whatever, from relying on this. Um, because I don&rsquo;t like</p>
<p>fundamentally, I think it&rsquo;s impossible to make it perfect. You&rsquo;ll think, you know, people will</p>
<p>figure out how much of the text they have to change. There&rsquo;ll be other things that modify</p>
<p>the outputted text. Um, I think it&rsquo;s good to pursue and we will. Um, but I think what&rsquo;s</p>
<p>important to realize is like the playing field has shifted and that&rsquo;s fine. Uh, there&rsquo;s good</p>
<p>and bad. And we just figure out like, rather than try to go back, we figure out the way forward.</p>
<p>So even if you develop technologies that could be sort of rendered like irrelevant</p>
<p>in a few months, I suspect. Yeah. Um, I also wanted to ask, uh, anthropic, um, arrival,</p>
<p>I guess, uh, founded by a former, yeah, again, like I arrival in some sense,</p>
<p>I think super highly of those people, uh, like very, very talented and multiple AGI&rsquo;s in the</p>
<p>world, I think is better than one. Sure. Uh, well, what I was going to ask,</p>
<p>and just for some background, um, it was founded by a former open AI VP of research who you,</p>
<p>I think met like when he was at Google. Um, but it, um, is stressing, um, an ethical layer</p>
<p>as a kind of distinction from other players. And I just wondered, um, if you think that systems</p>
<p>should adopt, uh, you know, I kind of a common code of principles and, and also whether that</p>
<p>should be regulated. Yeah. I mean, that was my earlier point. I think society should adopt</p>
<p>and should regulate what the kind of the wide bounds are, but then I think individual users</p>
<p>should have a huge amount of Liberty to decide how they want their experience and their interaction</p>
<p>to go. So I think it is like a combination of society, you know, like we have, there are a few</p>
<p>asterisks on the free speech rules. Um, and society has decided like free speech, not quite absolute.</p>
<p>I think society will decide also decide like language models, not quite absolute, but there</p>
<p>are a lot of, there&rsquo;s a lot of speech that is legal that you find distasteful that I find</p>
<p>distasteful that he finds distasteful. And we all probably have somewhat different definitions of</p>
<p>that. And I think it is very important that that is left to the responsibility of individual users</p>
<p>and groups, not, not one company and that the government they&rsquo;re like govern and not dictate</p>
<p>all of the rules. Um, and there are a lot of people here who I think want to ask you questions</p>
<p>and I know you can&rsquo;t stay forever. I wanted to ask one more question before I turn it over to the</p>
<p>crowd. Um, video, is that coming? It will come. I wouldn&rsquo;t want to make a confident prediction</p>
<p>about when, um, obviously like people are interested in it. Uh, we&rsquo;ll try to do it.</p>
<p>Other people will try to do it. Um, it could be like pretty soon it&rsquo;s, it&rsquo;s a, it&rsquo;s a legitimate</p>
<p>research project, so it could be pretty soon. It could take a while. Okay. Uh, let&rsquo;s see,</p>
<p>who would like to ask Sam a question? Oh, great. Hold on. I got to run over here.</p>
<p>Thank you. Hi fusion. When do you think there will be a commercial plant actually producing</p>
<p>electricity economically? Yeah, I think, I think by like 2028 pending, you know,</p>
<p>good fortune with regulators, we could be plugging them into the grid.</p>
<p>I think we&rsquo;ll do it, uh, you know, a really great demo well before that, like hopefully pretty soon.</p>
<p>Hey Sam, thank you. Um, what is your, and I don&rsquo;t know if you are allowed to answer this,</p>
<p>but what is your like best case scenario for AI and worst case, or more pointedly,</p>
<p>what would you like to see and what would you not like to see out of AI in the future?</p>
<p>I mean, I, I think the best case is like so unbelievably good that it&rsquo;s like hard to,</p>
<p>I, I think it&rsquo;s like hard for me to even imagine, like, I can sort of, I can sort of think about</p>
<p>what it&rsquo;s like when we make more progress of discovering new, new knowledge with these systems</p>
<p>than humanity has done so far, but like in a year instead of 70,000, um, I can sort of imagine what</p>
<p>it&rsquo;s like when we kind of like launch probes out to the whole universe and find out really, you</p>
<p>know, everything going on out there. I can sort of imagine what it&rsquo;s like when we have, you know,</p>
<p>help us resolve deadlocks and improve all aspects of reality and, uh, kind of like, let us all live</p>
<p>our best lives. But I can&rsquo;t quite like, I think the, the, the good case is just so unbelievably</p>
<p>good that you sound like a really crazy person to start talking about it. Um, and the bad case,</p>
<p>and I think this is like important to say is like lights out, right? And, and, and, and, and, and,</p>
<p>and the bad case, and I think this is like important to say is like lights out for all of us.</p>
<p>Um, I&rsquo;m more worried about like an accidental misuse case in the short term where, you know,</p>
<p>someone gets a super powerful, like, it&rsquo;s not like the AI wakes up and decides to be evil.</p>
<p>And I think all of the sort of traditional AI safety thinkers reveal a lot about more about</p>
<p>themselves than they mean to when they talk about what they think the AGI is going to be like,</p>
<p>but, but I can see the accidental misuse case clearly. And that&rsquo;s, that&rsquo;s super bad. Um,</p>
<p>so I think like, uh, yeah, I think it&rsquo;s like impossible to overstate the importance of AI</p>
<p>safety and alignment work. Um, I would like to see much, much more happening, but I think it&rsquo;s</p>
<p>more subtle than most people think. And that, you know, you hear a lot of people talk about</p>
<p>AI capabilities and AI alignment as like orthogonal vectors. And, you know, you&rsquo;re</p>
<p>bad if you&rsquo;re a capabilities researcher and you&rsquo;re, but if you&rsquo;re an alignment researcher,</p>
<p>it actually sounds very reasonable. Um, but they&rsquo;re almost the same thing. Like</p>
<p>deep learning is just going to like solve all of these problems. And so far that&rsquo;s what the</p>
<p>progress has been. And progress on capabilities is also what has let us make the systems safer</p>
<p>and vice versa, surprisingly. Um, and so I think, and none of this sort of sound bite,</p>
<p>easy answers work. Alfred Lynn told me to ask you, and I was going to ask anyway,</p>
<p>how far away do you think AGI is? He said, Sam, I&rsquo;ll probably tell you sooner than you thought.</p>
<p>The closer we get, the harder time I have answering, because I think that it&rsquo;s going</p>
<p>to be much blurrier, uh, and much more of a gradual transition than, than people think.</p>
<p>If you, if you imagine like a two by two matrix of sort of short timelines until the AGI takeoff</p>
<p>era begins and long timelines until it begins, and then a slow takeoff or a fast takeoff,</p>
<p>the world I think we&rsquo;re heading to and the safest world, the one I most hope for</p>
<p>is the short timeline, slow takeoff. But I think people are going to have hugely different</p>
<p>opinions about when in there you kind of like declare victory on the AGI thing.</p>
<p>Thank you, Sam. Um, 30 seconds versus when you spoke a few years ago, I was highly skeptical.</p>
<p>Um, and so you&rsquo;ve put me on notice, felt like Netscape when I was a teenager,</p>
<p>check, uh, GPT. Thank you very much. The question I have is less science and technology and more</p>
<p>geography, which is what&rsquo;s your take on San Francisco and Southern Valley? Cause you referenced</p>
<p>it earlier in like, man, I love this city so much. Um, and it is so sad what like the current state</p>
<p>is. I do think it&rsquo;s like somewhat come back to life after the pandemic, but yeah, like when you</p>
<p>walk down market street at night, or like if I try to walk home and walk through the Tenderloin</p>
<p>like late, it&rsquo;s not great. And I think it&rsquo;s like a real shame, uh, that we put up with treating</p>
<p>people like this. And we continue to elect leaders who sort of don&rsquo;t think this is okay, but also</p>
<p>don&rsquo;t fix the problem. Um, I totally get how hard this is. I totally get how complicated this is.</p>
<p>I also, I think, unlike other tech people will say that tech has some responsibility for it. Um,</p>
<p>but other cities managed to do better than this. Like it is a solvable problem and to entirely</p>
<p>blame tech companies who don&rsquo;t get to run the city, uh, that doesn&rsquo;t feel good either. Uh,</p>
<p>and I wish there could be a more collaborative partnership instead of all of the finger</p>
<p>pointing. Um, I am super long in-person work. I am super long, the Bay area. I&rsquo;m super long,</p>
<p>California. I think we are probably going through some trying times. Um, but I am hopeful we like</p>
<p>come out of the fire better for it. Can you talk a little bit more about, um, what you expected the</p>
<p>reaction to chat GPT to, to be, and also would you prefer that there wasn&rsquo;t so much hype? Like,</p>
<p>is that potentially detrimental to the company? Yeah. Um, I would have expected maybe like one</p>
<p>order of magnitude, less of everything, like one order of magnitude, less of, um, hype,</p>
<p>one order of magnitude, less of users. Um, yeah, I would have expected sort of one order of</p>
<p>magnitude, less on everything. Um, and I think less hype is probably better just as like a general</p>
<p>rule that one of the sort of strange things about these technologies is they are impressive, but not</p>
<p>robust. And so you use them in a first demo, you kind of have this like very impressive, like,</p>
<p>wow, this is like incredible and ready to go. Um, you use them a hundred times, you see the</p>
<p>weaknesses. And so I think people can get a much sort of a false impression of how good they are.</p>
<p>However, that&rsquo;s all going to get better. The critics who point these problems out and say,</p>
<p>well, this is why it&rsquo;s like, you know, all like, like, you know, fake news or whatever</p>
<p>are equally wrong. And so I think it&rsquo;s good in the sense that people are updating to this,</p>
<p>thinking hard about it and all of that. Can I ask, how do you use it? You know,</p>
<p>when we were emailing back and forth, I thought, am I talking to Sam? Um,</p>
<p>I have occasionally used it to summarize super long emails, but I&rsquo;ve never used it to write one.</p>
<p>Um, I actually summarized something. I use it for a lot. It&rsquo;s super good at that.</p>
<p>I use it for translation. I use it to like learn things.</p>
<p>So two quick questions. When people talk about, um, your technologies being the end of Google,</p>
<p>how do you unpack or how do you understand that? And then also your thoughts on UBI.</p>
<p>Yeah. I think whenever someone like talks about a technology being the end of some other giant</p>
<p>companies, it&rsquo;s usually wrong. Like I think people forget they get, they get to make a counter move</p>
<p>here and they&rsquo;re like pretty smart, pretty competent, but I do think it means there is</p>
<p>a change for search that will probably come at some point, but not as dramatically as people</p>
<p>think in the short term would like, my guess is that people are going to be using Google</p>
<p>the same way people are using Google now for quite some time. And also Google for whatever</p>
<p>this whole like code red thing is, it&rsquo;s probably not going to change that dramatic would be my</p>
<p>guess. Um, UBI, I think UBI is good and important, but, uh, very far from sufficient. I think it is</p>
<p>like a little part of the solution. Uh, I think it&rsquo;s great. Like, I think we should, as AGI</p>
<p>participates more and more in the economy, I think we should distribute wealth and resources much</p>
<p>more than we have. Um, and that&rsquo;ll be important over time, but I don&rsquo;t, I don&rsquo;t think that&rsquo;s</p>
<p>going to like solve the problem. I don&rsquo;t think that&rsquo;s going to give people meaning. I don&rsquo;t</p>
<p>think it means people are going to like entirely stop trying to create and do new things and</p>
<p>whatever else. So I sort of would consider it like an enabling technology, but not like a plan</p>
<p>for society. Is that why your company though, as a capped profit company, I mean, are you planning</p>
<p>to take the proceeds that presumably you&rsquo;re presuming you&rsquo;re going to make someday and</p>
<p>you&rsquo;re going to give them back to society? I mean, is that whether we do that just by like</p>
<p>saying here&rsquo;s cash for everyone, totally possible. Or whether we do that by saying like here is,</p>
<p>you know, we&rsquo;re going to like invest all of this in a nonprofit that does a bunch of science</p>
<p>because scientific progress is how we all make progress. I&rsquo;m unsure, but yeah, we would like</p>
<p>to operate for, for the good of society. And I think I&rsquo;m like a big believer in sort of design</p>
<p>a custom structure for whatever you&rsquo;re trying to do. And I think AGI is just like really different.</p>
<p>And so the cap will turn out to be super important. Can I ask selfishly? So if UBI is only</p>
<p>part of the solution and I&rsquo;ve got teenagers and we all have jobs, what should we be preparing for?</p>
<p>You know, as I said, my, my son&rsquo;s teacher was trying to prepare them, but of course you would</p>
<p>maybe be better positioned to have some ideas on this. Resilience, adaptability, ability to like</p>
<p>learn new things quickly, creativity, although it&rsquo;ll be aided creativity and aided learning</p>
<p>things quickly. I mean, I feel like my, for sure, like in some sense before Google came along,</p>
<p>there was like a bunch of things that we learned, like memorizing facts was really important.</p>
<p>And that changed. And now I think learning will change again and we&rsquo;ll probably adapt</p>
<p>faster than we think. Yeah. So, um, okay. I think we have to let Sam go, but how about like</p>
<p>two more questions. Thank you. Thank you so much. Uh, the future workplace for, um,</p>
<p>tech workers, you think it&rsquo;ll be out of the home, out of the office? What percent in each?</p>
<p>I have like, I look, I think people are going to do different things. I don&rsquo;t think there&rsquo;ll</p>
<p>be one answer. And I think people will sort the people who want fully in person. We&rsquo;ll do that.</p>
<p>People want fully remote. We&rsquo;ll do that. I think a lot of people will do like hybrid.</p>
<p>I have always been a fan of going to the office a few days a week and work at home a day or two a</p>
<p>week. Um, YC was like very much like being a YC partner was very much that way. Opening. I was</p>
<p>that way before the pandemic opening eyes that way. Now, I personally, I don&rsquo;t know if I&rsquo;m</p>
<p>I personally am skeptical that fully remote is going to be the thing that everyone does.</p>
<p>And I think even the people who thought it was a really good idea are now sort of saying like,</p>
<p>Hmm, the next, like 40 years sitting in my bedroom, looking at a computer screen on zoom,</p>
<p>do I really want that? Am I really sure with some skepticism, there are some people who do</p>
<p>what I think has been the hardest is companies who are the wrong kind of hybrid where it&rsquo;s not like,</p>
<p>you know, these four days, everyone&rsquo;s in these two days, everyone&rsquo;s home, whatever, but it&rsquo;s, uh,</p>
<p>come in if you want, be at home if you want. And then you have like half the people in the</p>
<p>meeting, this little box on the screen, have people in person. It&rsquo;s clearly a way better</p>
<p>experience in person. The people that are not there, like do get sort of like left out that,</p>
<p>that I think is the hardest, but it&rsquo;s all gonna like continue to evolve and people will sort into</p>
<p>what they want. I would bet that many of the most important companies of this decade are still</p>
<p>pretty heavily in person. Do you work for CBRE? No. Maybe that. So, um, one of you guys want to</p>
<p>wrestle for it. He has a white t-shirt. So let&rsquo;s do him too. Great, great, great, great. Sure.</p>
<p>So given your experience with the open AI safety and the conversation around it,</p>
<p>how do you think about safety and other AI fields like autonomous vehicles?</p>
<p>Yeah, I think there&rsquo;s like a bunch of safety issues for</p>
<p>any new technology and particularly any narrow vertical of AI.</p>
<p>And we kind of have learned a lot in the past few decades of, or more than a few past like</p>
<p>seven or eight decades of technological progress about how to do really good safety engineering</p>
<p>and safety systems management. And a lot of that about how we like learn how to build safe systems</p>
<p>and safe processes will translate imperfect. There&rsquo;ll be mistakes, but we know how to do that.</p>
<p>I think the AGI safety stuff is really different personally and worthy of study as its own</p>
<p>category. And they&rsquo;re there because the stakes are so high and the, and the irreversible situations</p>
<p>are so easy to imagine. We do need to somehow treat that differently and figure out a new set</p>
<p>of safety processes and standards. So you said like right now is one of the</p>
<p>best times to start a company. I found that counterintuitive. Maybe you can explain why</p>
<p>and what companies should I tell my friends to go start? Cause I have actually pretty few</p>
<p>smart friends who are looking to do something. The only thing that I think is like easy in</p>
<p>a mega bubble is capital. So it was a great time to raise capital for a startup from say 2015 to</p>
<p>20, when did that go wrong? End of 2021, but everything else was pretty hard. It was like</p>
<p>pretty hard to hire people. It was like pretty hard to like rise above the noise. It was pretty</p>
<p>hard to do something that mattered without having like thousands of competitors right away.</p>
<p>And a lot of those startups that looked like they were doing well, because of the same reason</p>
<p>capital was cheap, found that actually they were not able to like build as much enduring value as</p>
<p>they hoped. Now raising capital is like tough. It&rsquo;s still sort of reasonable, I think at like</p>
<p>seed stages, but it certainly seems much tougher at later stages. But all the other stuff is much</p>
<p>easier. You actually can concentrate talent. People are not constantly poached. You can rise</p>
<p>above the noise threshold, whether that&rsquo;s with like customers, the press, you know, users,</p>
<p>whatever. I would much rather be, have a hard time raising capital, but an easier time doing</p>
<p>everything else than the other way around. So that&rsquo;s why I think it&rsquo;s a better time.</p>
<p>In terms of like what I would do now, I would probably like go do AI for some vertical.</p>
<p>Well, it brought to mind this information story about Jasper that I thought was interesting.</p>
<p>It&rsquo;s a customer of yours, a copywriting company relying on your, you know, AI language models.</p>
<p>And now ChatGPT is so good that it&rsquo;s got to kind of like find a new reason for being, I think.</p>
<p>Is that a danger for many startups? I guess, which ones if so?</p>
<p>I heard about this article, but I didn&rsquo;t read it. But if I understand that it was basically like</p>
<p>the company was saying like, you know, we had built this thing on GPT-3 and now ChatGPT is</p>
<p>available for free and that&rsquo;s causing us problems. Is that right? I think probably the wrong thing to</p>
<p>do in, to make an AI startup. Well, let me say, I think the best thing you can do to make an AI</p>
<p>startup is the same way that like a lot of other companies differentiate, which is to build like</p>
<p>deep relationships with customers, a product they love, and some sort of moat that doesn&rsquo;t have to</p>
<p>be technology and network effect or whatever. And I think a lot of companies in the AI space</p>
<p>are doing exactly that. And you&rsquo;ve got to plan that open AI&rsquo;s models are going to get better</p>
<p>and better. We view ourselves more as a platform company, but we will do some, you know, like a</p>
<p>business strategy I&rsquo;ve always really respected is like the platform plus killer app together.</p>
<p>And so we will probably do something to help show people what we think is possible. But I think you</p>
<p>want to build a startup. And I think Jasper is going to do this or already is doing this that</p>
<p>has like deep value on top of the fundamental language model. And we are a piece of enabling</p>
<p>technology. Is there anybody knowing what you know, or you think you see coming that should</p>
<p>like basically drop what they&rsquo;re doing right now because they&rsquo;re cooked?</p>
<p>Like, I&rsquo;m sure if I had more time to think about it, I could come up with an answer. But</p>
<p>in general, I think there&rsquo;s going to be way, way more new value created. Like this is going to be</p>
<p>a golden few years, then people who are should just like stop what they&rsquo;re doing. I would not</p>
<p>ignore it. I think you got to like embrace it big time. But I think the amount of value that&rsquo;s about</p>
<p>to get created, we have not seen like, since the launch of the iPhone app store, something like</p>
<p>that. It&rsquo;s incredible. This is going to be an amazing year. I&rsquo;m sure I&rsquo;m so thankful. Thank</p>
<p>you for having me. My gosh, Sam. Thank you. For sure.</p>
<p>Thank you.</p>
<p>That&rsquo;s it. Thanks for listening, everybody. And special thanks to sustain.life. Make sure to</p>
<p>check out their site at sustain.life slash StrictlyVC. Have a great weekend. And we&rsquo;ll</p>
<p>see you back here next week.</p>

</section>


    <footer class="article-footer">
    
    <section class="article-tags">
        
            <a href="/tags/english/">English</a>
        
            <a href="/tags/podcast/">Podcast</a>
        
            <a href="/tags/strictlyvc-download/">StrictlyVC Download</a>
        
    </section>


    </footer>


    
</article>

    

    

<div>
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9206135835124064"
         crossorigin="anonymous"></script>
    <ins class="adsbygoogle"
         style="display:block; text-align:center;"
         data-ad-layout="in-article"
         data-ad-format="fluid"
         data-ad-client="ca-pub-9206135835124064"
         data-ad-slot="1055602464"></ins>
    <script>
         (adsbygoogle = window.adsbygoogle || []).push({});
    </script>
</div>
<aside class="related-content--wrapper">
    <h2 class="section-title">Related content</h2>
    <div class="related-content">
        <div class="flex article-list--tile">
            
                
<article class="">
    <a href="/en/1320100002/">
        
	
        
        <div class="article-image">
            
            <img src="/img/related-content.png" loading="lazy" 
            data-key="en/1320100002" data-hash="" 
            style="opacity: 0.3;"/>
        </div>
        
        <div class="article-details">
            <h2 class="article-title">StrictlyVC Download - Sequoia‚Äôs Alfred Lin on FTX, Crypto, and Investing for the Long Haul</h2>
            
            <footer class="article-time">
                <time datetime=''>Jan 20, 2023</time>
            </footer>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/en/1320100003/">
        
	
        
        <div class="article-image">
            
            <img src="/img/related-content.png" loading="lazy" 
            data-key="en/1320100003" data-hash="" 
            style="opacity: 0.3;"/>
        </div>
        
        <div class="article-details">
            <h2 class="article-title">StrictlyVC Download - VCs Pushing Startups May Face Investor Demands Themselves</h2>
            
            <footer class="article-time">
                <time datetime=''>Jan 19, 2023</time>
            </footer>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/en/1320100004/">
        
	
        
        <div class="article-image">
            
            <img src="/img/related-content.png" loading="lazy" 
            data-key="en/1320100004" data-hash="" 
            style="opacity: 0.3;"/>
        </div>
        
        <div class="article-details">
            <h2 class="article-title">StrictlyVC Download - VC Bradley Tusk Thinks Twitter Will Cost Elon Musk Much More Than He Paid for It</h2>
            
            <footer class="article-time">
                <time datetime=''>Jan 18, 2023</time>
            </footer>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/en/1320100005/">
        
	
        
        <div class="article-image">
            
            <img src="/img/related-content.png" loading="lazy" 
            data-key="en/1320100005" data-hash="" 
            style="opacity: 0.3;"/>
        </div>
        
        <div class="article-details">
            <h2 class="article-title">StrictlyVC Download - Economist, VC, and MIT fellow Paul Kedrosky on the Dangers of OpenAI</h2>
            
            <footer class="article-time">
                <time datetime=''>Jan 17, 2023</time>
            </footer>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/en/1307800032/">
        
	
        
        <div class="article-image">
            
            <img src="/img/related-content.png" loading="lazy" 
            data-key="en/1307800032" data-hash="" 
            style="opacity: 0.3;"/>
        </div>
        
        <div class="article-details">
            <h2 class="article-title">The History of English Podcast - Episode 30 The Celtic Legacy</h2>
            
            <footer class="article-time">
                <time datetime=''>May 04, 2023</time>
            </footer>
        </div>
    </a>
</article>

            
        </div>
    </div>
</aside>

     
    
        
    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
            2021 - 
        
        2023 SWIEST - Transcripts ¬∑ Screenplays ¬∑ Lyrics
    </section>
    
    <section class="powerby">
        

        As an Amazon Associate I earn from qualifying purchases üõí<br/>

        Built with <a href="https://swiest.com/" target="_blank" rel="noopener">(Ôæâ‚óï„ÉÆ‚óï)Ôæâü™Ñüíûüíñü•∞ across the glüåçüåèüåébe</a> <br />
        
        
    </section>
</footer>


    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo="crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU="crossorigin="anonymous"
                defer
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css"crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css"crossorigin="anonymous"
            >

            </main>
        </div>
        <script 
                src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js"integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z&#43;KMkF24hUW8WePSA9HM="crossorigin="anonymous"
                
                >
            </script><script type="text/javascript" src="/ts/main.js" defer></script>


<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Noto+Serif&family=Noto+Serif+Armenian&family=Noto+Serif+Bengali&family=Noto+Serif+Devanagari&family=Noto+Serif+Georgian&family=Noto+Serif+Gujarati&family=Noto+Serif+HK&family=Noto+Serif+Hebrew&family=Noto+Serif+JP&family=Noto+Serif+KR&family=Noto+Serif+Kannada&family=Noto+Serif+Khmer&family=Noto+Serif+Lao&family=Noto+Serif+Makasar&family=Noto+Serif+Malayalam&family=Noto+Serif+Myanmar&family=Noto+Serif+Oriya&family=Noto+Serif+SC&family=Noto+Serif+Sinhala&family=Noto+Serif+TC&family=Noto+Serif+Tamil&family=Noto+Serif+Telugu&family=Noto+Serif+Thai&family=Noto+Serif+Tibetan&display=swap" rel="stylesheet">

    </body>
</html>
