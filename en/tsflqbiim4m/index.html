<!doctype html><html lang=en dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Video Transcript ï»¿all right um hey everyone my name is sam
and i&amp;rsquo;m excited to talk to you guys
about the project i&amp;rsquo;ve been working on
for the last six months
um word to bites exploring language
situations
um so i&amp;rsquo;m going to talk a bit about my
background uh then
dive into project context uh then dive
into the project
and then talk about what i&amp;rsquo;ve learned
just during my time at open ai"><title>Words to Bytesï¼š Exploring Language Tokenizations ï½œ Sam Gbafa ï½œ OpenAI Scholars Demo Day 2021 ï½œ OpenAI | SWIEST</title>
<link rel=canonical href=https://swiest.com/en/tsflqbiim4m/><link rel=stylesheet href=/scss/style.min.9a6fe90535a0e5c60443841f100f7b698092d48dba43fdb6386bb69b6559bc3d.css><script>document.oncontextmenu=function(){return!1},document.onselectstart=function(){return!1},document.oncopy=function(){return!1},document.oncut=function(){return!1}</script><script src=https://apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js></script><script type=text/javascript>$(document).ready(function(){$("#back-to-top").hide(),$(function(){$(window).scroll(function(){$(window).scrollTop()>600?$("#back-to-top").fadeIn(500):$("#back-to-top").fadeOut(500)}),$("#back-to-top").click(function(){return $("body,html").animate({scrollTop:0},500),!1})})})</script><meta property="og:title" content="Words to Bytesï¼š Exploring Language Tokenizations ï½œ Sam Gbafa ï½œ OpenAI Scholars Demo Day 2021 ï½œ OpenAI"><meta property="og:description" content="Video Transcript ï»¿all right um hey everyone my name is sam
and i&amp;rsquo;m excited to talk to you guys
about the project i&amp;rsquo;ve been working on
for the last six months
um word to bites exploring language
situations
um so i&amp;rsquo;m going to talk a bit about my
background uh then
dive into project context uh then dive
into the project
and then talk about what i&amp;rsquo;ve learned
just during my time at open ai"><meta property="og:url" content="https://swiest.com/en/tsflqbiim4m/"><meta property="og:site_name" content="SWIEST - Transcripts Â· Screenplays Â· Lyrics"><meta property="og:type" content="article"><meta property="article:section" content="Post"><meta property="article:tag" content="English"><meta property="article:tag" content="Video Transcripts"><meta property="article:tag" content="OpenAI"><meta property="article:published_time" content="2023-11-06T02:38:44+00:00"><meta property="article:modified_time" content="2023-11-06T02:38:44+00:00"><meta name=twitter:title content="Words to Bytesï¼š Exploring Language Tokenizations ï½œ Sam Gbafa ï½œ OpenAI Scholars Demo Day 2021 ï½œ OpenAI"><meta name=twitter:description content="Video Transcript ï»¿all right um hey everyone my name is sam
and i&amp;rsquo;m excited to talk to you guys
about the project i&amp;rsquo;ve been working on
for the last six months
um word to bites exploring language
situations
um so i&amp;rsquo;m going to talk a bit about my
background uh then
dive into project context uh then dive
into the project
and then talk about what i&amp;rsquo;ve learned
just during my time at open ai"><link rel="shortcut icon" href=/favicon.ico><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9206135835124064" crossorigin=anonymous></script><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"dark")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hu307e6a33fa6fd661ccda3b77024ef5c2_252345_300x0_resize_box_3.png width=300 height=300 class=site-logo loading=lazy alt=Avatar></a></figure><div class=site-meta><h1 class=site-name><a href=/>SWIEST - Transcripts Â· Screenplays Â· Lyrics</a></h1><h2 class=site-description>ğŸ§™ğŸª„ğŸŒ</h2></div></header><ol class=menu id=main-menu><li><a href=/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg><span>Home</span></a></li><li><a href=/search/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg><span>Search</span></a></li><li><a href=/tags/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-tag" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11 3l9 9a1.5 1.5.0 010 2l-6 6a1.5 1.5.0 01-2 0L3 11V7a4 4 0 014-4h4"/><circle cx="9" cy="9" r="2"/></svg><span>Tags</span></a></li><li><a href=/chart/podcastchart.html target=_blank><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-apple-podcast" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M18.364 18.364a9 9 0 10-12.728.0"/><path d="M11.766 22h.468a2 2 0 001.985-1.752l.5-4A2 2 0 0012.734 14h-1.468a2 2 0 00-1.985 2.248l.5 4A2 2 0 0011.766 22z"/><path d="M12 9m-2 0a2 2 0 104 0 2 2 0 10-4 0"/></svg><span>Podcasts</span></a></li><li><a href=/radio.html target=_blank><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-radio" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M14 3 4.629 6.749A1 1 0 004 7.677V19a1 1 0 001 1h14a1 1 0 001-1V8a1 1 0 00-1-1H4.5"/><path d="M4 12h16"/><path d="M7 12v-2"/><path d="M17 16v.01"/><path d="M13 16v.01"/></svg><span>Radio</span></a></li><div class=menu-bottom-section><li id=i18n-switch><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-language" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 5h7"/><path d="M9 3v2c0 4.418-2.239 8-5 8"/><path d="M5 9c-.003 2.144 2.952 3.908 6.7 4"/><path d="M12 20l4-9 4 9"/><path d="M19.1 18h-6.2"/></svg><select name=language onchange="window.location.href=this.selectedOptions[0].value"><option value=https://swiest.com/ selected>English</option><option value=https://swiest.com/af/>Afrikaans</option><option value=https://swiest.com/am/>áŠ áˆ›áˆ­áŠ›</option><option value=https://swiest.com/ar/>Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</option><option value=https://swiest.com/az/>AzÉ™rbaycan</option><option value=https://swiest.com/be/>Ğ±ĞµĞ»Ğ°Ñ€ÑƒÑĞºÑ–</option><option value=https://swiest.com/bg/>Ğ±ÑŠĞ»Ğ³Ğ°Ñ€ÑĞºĞ¸</option><option value=https://swiest.com/bn/>à¦¬à¦¾à¦‚à¦²à¦¾</option><option value=https://swiest.com/bo/>à½–à½¼à½‘à¼‹à½¦à¾à½‘à¼‹</option><option value=https://swiest.com/bs/>Bosanski</option><option value=https://swiest.com/ca/>CatalÃ </option><option value=https://swiest.com/zh-hans/>ç®€ä½“ä¸­æ–‡</option><option value=https://swiest.com/zh-hant/>ç¹é«”ä¸­æ–‡</option><option value=https://swiest.com/cs/>ÄŒeÅ¡tina</option><option value=https://swiest.com/el/>ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬</option><option value=https://swiest.com/cy/>Cymraeg</option><option value=https://swiest.com/da/>Dansk</option><option value=https://swiest.com/de/>Deutsch</option><option value=https://swiest.com/eo/>Esperanto</option><option value=https://swiest.com/es-es/>EspaÃ±ol (EspaÃ±a)</option><option value=https://swiest.com/es-419/>EspaÃ±ol (LatinoamÃ©rica)</option><option value=https://swiest.com/et/>Eesti</option><option value=https://swiest.com/eu/>Euskara</option><option value=https://swiest.com/haw/>Ê»ÅŒlelo HawaiÊ»i</option><option value=https://swiest.com/fa/>ÙØ§Ø±Ø³ÛŒ</option><option value=https://swiest.com/fi/>Suomi</option><option value=https://swiest.com/fo/>FÃ¸royskt</option><option value=https://swiest.com/fr/>FranÃ§ais</option><option value=https://swiest.com/fy/>Frysk</option><option value=https://swiest.com/ga/>Gaeilge</option><option value=https://swiest.com/gl/>Galego</option><option value=https://swiest.com/gu/>àª—à«àªœàª°àª¾àª¤à«€</option><option value=https://swiest.com/he/>×¢Ö´×‘×¨Ö´×™×ª</option><option value=https://swiest.com/km/>á€á˜áŸ’á–á»á‡á¶áŸ”</option><option value=https://swiest.com/hi/>à¤¹à¤¿à¤¨à¥à¤¦à¥€</option><option value=https://swiest.com/hr/>Hrvatski</option><option value=https://swiest.com/ht/>KreyÃ²l Ayisyen</option><option value=https://swiest.com/hu/>Magyar</option><option value=https://swiest.com/hy/>Õ€Õ¡ÕµÕ¥Ö€Õ¥Õ¶</option><option value=https://swiest.com/ig/>Ãsá»¥Ì€sá»¥Ì ÃŒgbÃ²</option><option value=https://swiest.com/id/>Bahasa Indonesia</option><option value=https://swiest.com/is/>Ãslenska</option><option value=https://swiest.com/it/>Italiano</option><option value=https://swiest.com/ja/>æ—¥æœ¬èª</option><option value=https://swiest.com/jv/>Basa Jawa</option><option value=https://swiest.com/ka/>áƒ¥áƒáƒ áƒ—áƒ£áƒšáƒ˜</option><option value=https://swiest.com/kk/>ÒšĞ°Ğ·Ğ°Ò›ÑˆĞ°</option><option value=https://swiest.com/kn/>à²•à²¨à³à²¨à²¡</option><option value=https://swiest.com/ko/>í•œêµ­ì–´</option><option value=https://swiest.com/or/>à¬“à¬¡à¬¼à¬¿à¬†</option><option value=https://swiest.com/ckb/>Ú©ÙˆØ±Ø¯ÛŒ</option><option value=https://swiest.com/ky/>ĞšÑ‹Ñ€Ğ³Ñ‹Ğ·Ñ‡Ğ°</option><option value=https://swiest.com/la/>Latina</option><option value=https://swiest.com/lb/>LÃ«tzebuergesch</option><option value=https://swiest.com/lo/>àºàº²àºªàº²àº¥àº²àº§</option><option value=https://swiest.com/lt/>LietuviÅ³</option><option value=https://swiest.com/lv/>LatvieÅ¡u</option><option value=https://swiest.com/mk/>ĞœĞ°ĞºĞµĞ´Ğ¾Ğ½ÑĞºĞ¸</option><option value=https://swiest.com/ml/>à´®à´²à´¯à´¾à´³à´‚</option><option value=https://swiest.com/mn/>ĞœĞ¾Ğ½Ğ³Ğ¾Ğ» Ñ…ÑĞ»</option><option value=https://swiest.com/mr/>à¤®à¤°à¤¾à¤ à¥€</option><option value=https://swiest.com/sw/>Kiswahili</option><option value=https://swiest.com/ms/>Bahasa Melayu</option><option value=https://swiest.com/my/>á€™á€¼á€”á€ºá€™á€¬</option><option value=https://swiest.com/ne/>à¤¨à¥‡à¤ªà¤¾à¤²à¥€</option><option value=https://swiest.com/nl/>Nederlands</option><option value=https://swiest.com/no/>Norsk</option><option value=https://swiest.com/pa/>à¨ªà©°à¨œà¨¾à¨¬à©€</option><option value=https://swiest.com/pl/>Polski</option><option value=https://swiest.com/pt-br/>PortuguÃªs Brasil</option><option value=https://swiest.com/pt-pt/>PortuguÃªs Europeu</option><option value=https://swiest.com/ro/>RomÃ¢nÄƒ</option><option value=https://swiest.com/ru/>Ğ ÑƒÑÑĞºĞ¸Ğ¹</option><option value=https://swiest.com/rw/>Kinyarwanda</option><option value=https://swiest.com/si/>à·ƒà·’à¶‚à·„à¶½</option><option value=https://swiest.com/sk/>SlovenÄina</option><option value=https://swiest.com/sl/>SlovenÅ¡Äina</option><option value=https://swiest.com/sq/>Shqip</option><option value=https://swiest.com/sr/>Ğ¡Ñ€Ğ¿ÑĞºĞ¸ (Srpski)</option><option value=https://swiest.com/su/>Basa Sunda</option><option value=https://swiest.com/sv/>Svenska</option><option value=https://swiest.com/ta/>à®¤à®®à®¿à®´à¯</option><option value=https://swiest.com/te/>à°¤à±†à°²à±à°—à±</option><option value=https://swiest.com/tg/>Ğ¢Ğ¾Ò·Ğ¸ĞºÓ£</option><option value=https://swiest.com/th/>à¹„à¸—à¸¢</option><option value=https://swiest.com/tk/>TÃ¼rkmenler</option><option value=https://swiest.com/tl/>Filipino</option><option value=https://swiest.com/tr/>TÃ¼rkÃ§e</option><option value=https://swiest.com/uk/>Ğ£ĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ°</option><option value=https://swiest.com/ur/>Ø§Ø±Ø¯Ùˆ</option><option value=https://swiest.com/uz/>O'zbekcha</option><option value=https://swiest.com/vi/>Tiáº¿ng Viá»‡t</option><option value=https://swiest.com/yi/>××™×“×™×©</option><option value=https://swiest.com/zh-hk/>ç²µèª</option><option value=https://swiest.com/zu/>IsiZulu</option></select></li><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><span>Dark Mode</span></li></div></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#video>Video</a></li><li><a href=#transcript>Transcript</a></li></ol></nav></div></section><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9206135835124064" crossorigin=anonymous></script><ins class=adsbygoogle style=display:block data-ad-client=ca-pub-9206135835124064 data-ad-slot=8754979142 data-ad-format=auto data-full-width-responsive=true></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script></aside><a id=back-to-top href=#><img src=/img/top_hu7c2829da96df0e9f8f0191d120020b22_22287_40x0_resize_box_3.png></a><main class="main full-width"><form action=/search/ class="search-form widget"><p><label>Search</label>
<input name=keyword required placeholder="Type something...">
<button title=Search><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg></button></p></form><article class=main-article><header class=article-header><div class=article-details><header class=article-tags><a href=/tags/english/>English
</a><a href=/tags/video-transcripts/>Video Transcripts
</a><a href=/tags/openai/>OpenAI</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/en/tsflqbiim4m/>Words to Bytesï¼š Exploring Language Tokenizations ï½œ Sam Gbafa ï½œ OpenAI Scholars Demo Day 2021 ï½œ OpenAI</a></h2></div><footer class=article-time><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg><time class=article-time--published>2023-11-06</time></div><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg><time class=article-time--reading>12 minute read</time></div></footer></div></header><div class=article-content><p style=text-align:center><a href=https://amzn.to/3Nrdcwk target=_blank>ğŸAmazon Prime</a>
<a href=https://amzn.to/3RIBkxg target=_blank>ğŸ“–Kindle Unlimited</a>
<a href=https://amzn.to/3Rqmudl target=_blank>ğŸ§Audible Plus</a>
<a href=https://amzn.to/3TuLbbj target=_blank>ğŸµAmazon Music Unlimited</a>
<a href="https://www.iherb.com/?rcode=EID1574" target=_blank>ğŸŒ¿iHerb</a>
<a href="https://accounts.binance.com/register?ref=72302422" target=_blank>ğŸ’°Binance</a></p></div><div><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9206135835124064" crossorigin=anonymous></script><ins class=adsbygoogle style=display:block data-ad-client=ca-pub-9206135835124064 data-ad-slot=8754979142 data-ad-format=auto data-full-width-responsive=true></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script></div><section class=article-content><h2 id=video>Video</h2><div class=video-wrapper><iframe loading=lazy src=https://www.youtube.com/embed/TsFLqbiim4M allowfullscreen title="YouTube Video"></iframe></div><h2 id=transcript>Transcript</h2><p>ï»¿all right um hey everyone my name is sam</p><p>and i&rsquo;m excited to talk to you guys</p><p>about the project i&rsquo;ve been working on</p><p>for the last six months</p><p>um word to bites exploring language</p><p>situations</p><p>um so i&rsquo;m going to talk a bit about my</p><p>background uh then</p><p>dive into project context uh then dive</p><p>into the project</p><p>and then talk about what i&rsquo;ve learned</p><p>just during my time at open ai</p><p>all right um so um i&rsquo;ve worked at</p><p>software engineering for last couple</p><p>years and i was working on my startup</p><p>level</p><p>which is a platform for choice-based</p><p>stories where people could create their</p><p>own 3d adventure stories</p><p>and other people could play them during</p><p>this time i encountered gt2 and i</p><p>thought it&rsquo;d be really cool to enable</p><p>writers to create</p><p>kind of ai generated stories um gpc2</p><p>didn&rsquo;t have the greatest completions</p><p>but it did get me really interested in</p><p>language models um</p><p>in other generative models um so i was</p><p>interested in</p><p>multimodal uh explorations and maybe</p><p>videos that could</p><p>uh models that could um</p><p>maybe generate future videos from</p><p>current video or future audio from</p><p>current audio but i quickly realized</p><p>that that&rsquo;d be pretty challenging um</p><p>so um well uh so while in scholars</p><p>program i explored</p><p>lots of different things um explore</p><p>sequence models like lstms and</p><p>transformers</p><p>i learned the basics the basic problems</p><p>and solutions that occur in deep</p><p>learning</p><p>in deep networks like vanishing</p><p>exploiting gradients learn about meta</p><p>evolution</p><p>resonance a bit about reinforcement</p><p>learning um and throughout this time i</p><p>was always interested in</p><p>being able to apply some of these</p><p>techniques to learning multiple</p><p>modalities</p><p>particularly because it&rsquo;s how we learn</p><p>as humans um we don&rsquo;t just read text we</p><p>have visual and auditory experiences</p><p>that help us create</p><p>our own internal models and i was</p><p>interested in how machines can do that</p><p>um so because uh our audience is really</p><p>general i wanted to give some context</p><p>to my project um so first i wanna talk</p><p>about sequence modeling</p><p>uh sequence models are used to explore</p><p>data where your input or output data</p><p>has a particular sequence that encodes</p><p>information</p><p>um so common example is something like</p><p>siri where you&rsquo;re like hey siri turn on</p><p>the lights</p><p>um or you can have an example um like</p><p>deepmind is doing where you&rsquo;re taking</p><p>going from a dna sequence</p><p>to a folded protein um</p><p>another thing i want to uh kind of</p><p>introduce is the idea of unsupervised</p><p>learning particularly with particularly</p><p>with other aggressive models</p><p>um so auto aggressive sequence model uh</p><p>predicts current or future values uh</p><p>based on past values</p><p>so um uh gt3</p><p>is open ai&rsquo;s one of their</p><p>popular language models um and</p><p>my the model i train is really similar</p><p>so you have a training corpus</p><p>um right now i can consider all of</p><p>wikipedia as an example</p><p>as a particular article about the</p><p>titanic um you could break</p><p>you break up your corpus by taking maybe</p><p>the first 64 words in next 64 words</p><p>and come up with training examples um so</p><p>with each example</p><p>um you&rsquo;re basically giving it to your</p><p>model and having your model predict each</p><p>word</p><p>um and basically you&rsquo;re giving your</p><p>model these examples over and over and</p><p>over again</p><p>and ideally as it&rsquo;s going through these</p><p>training examples it&rsquo;s learning the</p><p>relationships there</p><p>um so if you were to perform inference</p><p>and give your model</p><p>uh an example and say that satanic was</p><p>uh your model might complete it and say</p><p>it was the largest ship</p><p>or was a british passenger liner</p><p>um so diving into my project</p><p>so my project basically looked at</p><p>sequence models</p><p>and particularly tokenizations on those</p><p>sequence models</p><p>um i looked at some previous works on</p><p>other language models</p><p>and there are some interesting findings</p><p>that led me to focus on tokenization</p><p>uh the first was that fine grain finer</p><p>grain tokenizations outperformed larger</p><p>levels of organizations</p><p>so um if you have uh sub words in your</p><p>vocabulary</p><p>more sub words then those models</p><p>outperformed</p><p>models with just really big words in the</p><p>vocabulary um and additionally learning</p><p>the segmentations</p><p>could lead to better generalizations and</p><p>i&rsquo;ll talk a bit about what i mean by</p><p>that</p><p>so for my project i took a look at</p><p>different tokenizations on the same</p><p>dataset</p><p>the data i used included articles from</p><p>wall street journal and articles</p><p>wikipedia</p><p>i looked at tokenizations i looked at</p><p>words sub words and character</p><p>tokenizations</p><p>uh and each tokenizer was pre-trained on</p><p>the training data</p><p>um so i want to give some examples of</p><p>what i mean by tokenization</p><p>um so i have an example sentence we want</p><p>swimming to mitigate the effects</p><p>of the blistering sun um so let&rsquo;s look</p><p>at words organization of this</p><p>um so here we went swimming to mitigate</p><p>the effects of blistering sun</p><p>um each space um so the tokens are</p><p>separated by white space</p><p>uh each space is represented by this</p><p>underscore um</p><p>and so yeah it&rsquo;s pretty pretty</p><p>straightforward uh a subword</p><p>tokenization</p><p>a bricks your uh it breaks your work</p><p>your sequence up into sub words</p><p>uh so here you can see went is split</p><p>into two sub words and likewise swimming</p><p>uh the ing is separated from</p><p>uh swim uh and also at the end</p><p>blistering you can see it&rsquo;s broken up</p><p>into three subwords</p><p>uh so this allows your model to learn</p><p>the relationships</p><p>between parts of words uh</p><p>most english speakers know that ing</p><p>kind of means that you&rsquo;re doing a</p><p>particular verb</p><p>um so allows your model to also build uh</p><p>understanding of that kind of</p><p>relationship as well</p><p>so what happens if you tokenize like</p><p>even smaller segments</p><p>uh so you can look at character</p><p>technicians um so here</p><p>each character is broken up or the</p><p>sequence is broken up by each character</p><p>um multilingual models are really</p><p>uh can have improved performance by uh</p><p>tokenizing on</p><p>characters um due to the nature of how</p><p>different languages are broken up</p><p>um maybe if you have uh</p><p>like a pictographic language like</p><p>chinese uh versus english you maybe</p><p>don&rsquo;t want to break it up into</p><p>into words um and then</p><p>i also took a look at uh bytes</p><p>optimizations um</p><p>so this is the same sequence in</p><p>represented as bytes uh it&rsquo;s</p><p>functionally the same as a character</p><p>tokenization when you look at english</p><p>and this is because unicode uh encodes</p><p>characters</p><p>as one to four bytes and english</p><p>characters are usually encoded as one</p><p>byte</p><p>so for example we have hui is meeting um</p><p>hue is one character</p><p>but translates to three characters um so</p><p>if we had a</p><p>uh multilingual corpus then by</p><p>tokenization would be totally worth</p><p>looking at</p><p>uh but i decided not to so um</p><p>for my project i use a 12-layer decoder</p><p>only transformer</p><p>uh it&rsquo;s about 80 million parameters um i</p><p>looked at pantry bank data</p><p>on word subword with 40 000 uh</p><p>vocabulary and character segmentations</p><p>uh the amount of compute was all</p><p>constant</p><p>and it was the same model and context</p><p>length and uh</p><p>so we&rsquo;ll talk about some of those</p><p>results here we&rsquo;re looking at the</p><p>training perplexity</p><p>so perplexity is a measure of how well</p><p>your model um the degeneration of your</p><p>model like how good they are</p><p>um so high perplexity uh your model</p><p>might generate something like</p><p>i fell off the boat and into a porcupine</p><p>um versus i fell off the boat and into</p><p>the water</p><p>um so the first statement is really</p><p>hyperplexity</p><p>second statement makes more sense lower</p><p>complexity um it&rsquo;s really hard to see</p><p>what&rsquo;s going on here um so let&rsquo;s like</p><p>take a look um at some of these training</p><p>steps</p><p>so um like zoomed in so here you can see</p><p>um your word perplexity is generally</p><p>lower um at your lowest and it&rsquo;s</p><p>increasing or decreasing</p><p>um the fastest uh with training time</p><p>um your you would ex so i would expect</p><p>um</p><p>when performing this uh this experiment</p><p>i expected subworks to outperform</p><p>characters</p><p>um but i here they don&rsquo;t and</p><p>uh it&rsquo;s partially because our training</p><p>corpus is relatively small</p><p>so using a tender tree bank data set you</p><p>have</p><p>about 10 000 vocabulary words um so</p><p>having a 40 000</p><p>vocabulary sub word um is a bit</p><p>it&rsquo;s a bit high and so it&rsquo;s your your</p><p>character</p><p>models perform actually better than your</p><p>subwoofer models um and so i&rsquo;ll talk</p><p>about ways that</p><p>uh we could prevent that additionally</p><p>um there was our validation for</p><p>flexibility is really high um</p><p>so this was a one run among many</p><p>several runs uh showed this relationship</p><p>between words upwards and characters</p><p>um however it&rsquo;s just to show that um</p><p>our model initially overfit but in</p><p>regularizing uh it wasn&rsquo;t regularized</p><p>we weren&rsquo;t generalizing well in</p><p>this particular run so</p><p>some of our findings were that smaller</p><p>segmentations can have more nuanced</p><p>representation</p><p>but you need a larger model to capture</p><p>these relationships well</p><p>it&rsquo;s partially because these transformer</p><p>buildups builds up</p><p>its representation in the earlier layers</p><p>um</p><p>so with characters if you have uh</p><p>you you have to maybe build a</p><p>representation of a word</p><p>before you are able to predict the next</p><p>word</p><p>um another thing worth considering</p><p>um in the project is to vary the context</p><p>length so if you have</p><p>um in our example from earlier um</p><p>it was 11 words but it was 59 characters</p><p>so in order to represent the same amount</p><p>of data uh your context length</p><p>the same amount of uh yeah i guess the</p><p>same amount of data your context length</p><p>needs to be</p><p>uh longer for these smaller</p><p>segmentations</p><p>um this number of subwords is a really</p><p>important hyperparameter uh when doing</p><p>these comparisons so it&rsquo;s worth</p><p>including multiple subword tokenizers</p><p>as you do a sweep</p><p>and then also uh larger and more diverse</p><p>data sets should be explored</p><p>particularly if you&rsquo;re going to explore</p><p>a byte level tokenizations um</p><p>and so i want to talk a bit about just</p><p>what i learned throughout the entire</p><p>scholars program um</p><p>so uh i come from engineering background</p><p>and not really research and so it was</p><p>really great for me to</p><p>learn how to identify and get the most</p><p>out of uh just reading papers</p><p>um that was like probably uh one of the</p><p>biggest takeaways for me is just</p><p>being able to take in a paper and uh i</p><p>didn&rsquo;t</p><p>identify what&rsquo;s useful there um i</p><p>learned just about building various</p><p>models and understanding what different</p><p>architectures are doing</p><p>um i&rsquo;m i&rsquo;ve always been interested in</p><p>just like software architecture</p><p>and architecture of models is a really</p><p>interesting place to explore</p><p>um so just learn all yeah just learned a</p><p>lot there</p><p>um i learned about getting your data</p><p>right and just how small issues and your</p><p>in your data can really blow up in a</p><p>deep network and you could kind of spend</p><p>some time trying to figure out what&rsquo;s</p><p>going wrong and it could just</p><p>be in your data um i was in a place</p><p>where my model was terrible and i</p><p>couldn&rsquo;t learn</p><p>um so i learned all about overfitting</p><p>and hyper parameter optimization</p><p>um there are a lot of little subtle</p><p>details and it&rsquo;s a really iterative</p><p>process where</p><p>maybe you&rsquo;re cheating a running race</p><p>scheduler you&rsquo;re</p><p>continuing your optimizers um just</p><p>really tweaking a lot of stuff</p><p>but when you really get it right you see</p><p>these exponential improvements and it&rsquo;s</p><p>really awesome</p><p>um i also learned about regularization</p><p>where your model is really</p><p>learning the training data but trying to</p><p>get your model to generalize</p><p>and learn something real um is like it&rsquo;s</p><p>huge</p><p>it&rsquo;s its own uh particular challenge and</p><p>um the last thing i want to talk about</p><p>was that i</p><p>just learned and thought a lot about the</p><p>implications of these generative models</p><p>um before i like joined i was really</p><p>excited about these generative models</p><p>and like just</p><p>super cool didn&rsquo;t really think about</p><p>like the implications of</p><p>releasing them um but just being open ai</p><p>and um</p><p>talking to people and just reading a lot</p><p>about this it kind of gave me this</p><p>perspective of really thinking about</p><p>what the</p><p>what are the implications of the models</p><p>we create and their impact on</p><p>like society and democracy um so that</p><p>was really great</p><p>um yeah that was um yeah</p><p>that was a lot um but i want to thank uh</p><p>i want to thank you guys for listening</p><p>i want to thank my mentor arvind um just</p><p>he was super helpful</p><p>for all this i was very patient and gave</p><p>such great insights</p><p>um and i want to thank my fellow</p><p>scholars for just being here with me</p><p>um so with that uh let&rsquo;s dive into</p><p>q a</p><p>um</p><p>okay um those size vocabulary for the</p><p>different organization schemes</p><p>um so</p><p>um for the</p><p>um for the word uh so the tokenizers</p><p>were pre-trained um</p><p>and they learned the vocabulary uh</p><p>as they went through uh the pre-training</p><p>so for the word tokenization um pinch</p><p>rebank had about ten thousand</p><p>vocabulary words uh the sub-word</p><p>tokenization</p><p>had 40 000 vocabulary words and the</p><p>uh character tokenization actually had a</p><p>much smaller vocabulary</p><p>um because it was they only learned the</p><p>unique characters</p><p>um so the character vocabulary uh</p><p>was i think about i think it was over</p><p>50 characters i don&rsquo;t know the exact</p><p>number</p><p>um uh how does</p><p>exploring tokenizations relate to</p><p>multimodal models</p><p>um well</p><p>um i guess to share that um</p><p>sorry um so uh</p><p>i wanted to um i guess i set out to do a</p><p>scaling law suite</p><p>and to look at uh these different</p><p>tokenizations and how they scale</p><p>um and this was so that i could then</p><p>maybe learn the segmentations</p><p>um and then see how learning and</p><p>segmentation improve</p><p>the model um</p><p>so by learning the segmentations</p><p>um in in text i thought there may be</p><p>some insights</p><p>in learning the segmentations and um</p><p>in other modalities um there&rsquo;s previous</p><p>research that suggests</p><p>uh if you learn the segmentations you</p><p>can really improve your performance</p><p>um so like multi multilingual</p><p>translations um seem to be improved by</p><p>uh learning and segmentation so going</p><p>from english or spanish to japanese</p><p>outperform english to japanese or</p><p>spanish to japanese if you learn the</p><p>segmentation</p><p>um so i was really interested in</p><p>learning segmentation but i first wanted</p><p>to kind of get a baseline</p><p>of what the current tokenizations did so</p><p>that&rsquo;s kind of the</p><p>projecting my project</p><p>see think i&rsquo;m at time</p><p>um but</p><p>yeah um if anyone wants to reach out to</p><p>me um uh feel free</p><p>to reach out to me over email um and</p><p>yeah with that</p><p>i would like to introduce showa and</p></section><footer class=article-footer><section class=article-tags><a href=/tags/english/>English</a>
<a href=/tags/video-transcripts/>Video Transcripts</a>
<a href=/tags/openai/>OpenAI</a></section></footer></article><div><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9206135835124064" crossorigin=anonymous></script><ins class=adsbygoogle style=display:block;text-align:center data-ad-layout=in-article data-ad-format=fluid data-ad-client=ca-pub-9206135835124064 data-ad-slot=1055602464></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script></div><aside class=related-content--wrapper><h2 class=section-title>Related content</h2><div class=related-content><div class="flex article-list--tile"><article><a href=/en/at2xkqjazns/><div class=article-image><img src=/img/related-content.png loading=lazy data-key=en/AT2XkqJAZns data-hash style=opacity:.3></div><div class=article-details><h2 class=article-title>Towards Epileptic Seizure Prediction with Deep Network ï½œ Kata Slama ï½œ OpenAI Scholars Demo Day 2020 ï½œ OpenAI</h2></div></a></article><article><a href=/en/jzohw-eybtq/><div class=article-image><img src=/img/related-content.png loading=lazy data-key=en/JZOHW-eYBtQ data-hash style=opacity:.3></div><div class=article-details><h2 class=article-title>Introductions by Sam Altman & Greg Brockman ï½œ OpenAI Scholars Demo Day 2020 ï½œ OpenAI</h2></div></a></article><article><a href=/en/-fozam9xqs4/><div class=article-image><img src=/img/related-content.png loading=lazy data-key=en/-FoZAM9xqS4 data-hash style=opacity:.3></div><div class=article-details><h2 class=article-title>OpenAI Five vs. OG, Game 2 ï½œ OpenAI Five Finals (4â§¸6) ï½œ OpenAI</h2></div></a></article><article><a href=/en/u9mjuukhuzk/><div class=article-image><img src=/img/related-content.png loading=lazy data-key=en/U9mJuUkhUzk data-hash style=opacity:.3></div><div class=article-details><h2 class=article-title>OpenAI DevDay, Opening Keynote ï½œ OpenAI</h2></div></a></article><article><a href=/en/lpe5gwuqa-k/><div class=article-image><img src=/img/related-content.png loading=lazy data-key=en/lpe5Gwuqa-k data-hash style=opacity:.3></div><div class=article-details><h2 class=article-title>Scaling Laws for Language Transfer Learning ï½œ Christina Kim ï½œ OpenAI Scholars Demo Day 2021 ï½œ OpenAI</h2></div></a></article></div></div></aside><footer class=site-footer><section class=copyright>&copy;
2021 -
2023 SWIEST - Transcripts Â· Screenplays Â· Lyrics</section><section class=powerby>As an Amazon Associate I earn from qualifying purchases ğŸ›’<br>Built with <a href=https://swiest.com/ target=_blank rel=noopener>(ï¾‰â—•ãƒ®â—•)ï¾‰ğŸª„ğŸ’ğŸ’–ğŸ¥° across the glğŸŒğŸŒğŸŒbe</a><br></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Noto+Serif&family=Noto+Serif+Armenian&family=Noto+Serif+Bengali&family=Noto+Serif+Devanagari&family=Noto+Serif+Georgian&family=Noto+Serif+Gujarati&family=Noto+Serif+HK&family=Noto+Serif+Hebrew&family=Noto+Serif+JP&family=Noto+Serif+KR&family=Noto+Serif+Kannada&family=Noto+Serif+Khmer&family=Noto+Serif+Lao&family=Noto+Serif+Makasar&family=Noto+Serif+Malayalam&family=Noto+Serif+Myanmar&family=Noto+Serif+Oriya&family=Noto+Serif+SC&family=Noto+Serif+Sinhala&family=Noto+Serif+TC&family=Noto+Serif+Tamil&family=Noto+Serif+Telugu&family=Noto+Serif+Thai&family=Noto+Serif+Tibetan&display=swap" rel=stylesheet></body></html>