<!DOCTYPE html>
<html lang="en" dir="ltr">
    <head><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content='[MUSIC]
OREN ETZIONI: Whose responsibility is it? The responsibility and liability has to ultimately rest with a person. You can‚Äôt say, ‚ÄúHey, you know, look, my car ran you over, it‚Äôs an AI car, I don‚Äôt know what it did, it‚Äôs not my fault, right?‚Äù You as the driver or maybe it‚Äôs the manufacturer if there‚Äôs some malfunction, but people have to be responsible for the behavior of the machines.'>
<title>Behind The Tech with Kevin Scott - Oren Etzioni, PhD: CEO of Allen Institute for AI | SWIEST</title>

<link rel='canonical' href='https://swiest.com/en/1308500026/'>

<link rel="stylesheet" href="/scss/style.min.91b18679590f4ceed910ade4d64b1e7375cc0770ef5b8c1d822f42424f9ff2c8.css"><script>
    document.oncontextmenu = function(){ return false; };
    document.onselectstart = function(){ return false; };
    document.oncopy = function(){ return false; };
    document.oncut = function(){ return false; };
</script>

<script src="https://apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js"></script>


<script type="text/javascript">
    $(document).ready(function(){
     
     $("#back-to-top").hide();
     
     $(function () {
      $(window).scroll(function(){
       if ($(window).scrollTop()>600){
        $("#back-to-top").fadeIn(500);
       }else{
        $("#back-to-top").fadeOut(500);
       }
     });
     
     $("#back-to-top").click(function(){
      $('body,html').animate({scrollTop:0},500);
       return false;
      });
     });
    });
    </script><meta property='og:title' content='Behind The Tech with Kevin Scott - Oren Etzioni, PhD: CEO of Allen Institute for AI'>
<meta property='og:description' content='[MUSIC]
OREN ETZIONI: Whose responsibility is it? The responsibility and liability has to ultimately rest with a person. You can‚Äôt say, ‚ÄúHey, you know, look, my car ran you over, it‚Äôs an AI car, I don‚Äôt know what it did, it‚Äôs not my fault, right?‚Äù You as the driver or maybe it‚Äôs the manufacturer if there‚Äôs some malfunction, but people have to be responsible for the behavior of the machines.'>
<meta property='og:url' content='https://swiest.com/en/1308500026/'>
<meta property='og:site_name' content='SWIEST - Transcripts ¬∑ Screenplays ¬∑ Lyrics'>
<meta property='og:type' content='article'><meta property='article:section' content='Post' /><meta property='article:tag' content='English' /><meta property='article:tag' content='Podcast' /><meta property='article:tag' content='Behind The Tech with Kevin Scott' /><meta property='article:published_time' content='2023-02-26T15:00:00&#43;00:00'/><meta property='article:modified_time' content='2023-02-26T15:00:00&#43;00:00'/>
<meta name="twitter:title" content="Behind The Tech with Kevin Scott - Oren Etzioni, PhD: CEO of Allen Institute for AI">
<meta name="twitter:description" content="[MUSIC]
OREN ETZIONI: Whose responsibility is it? The responsibility and liability has to ultimately rest with a person. You can‚Äôt say, ‚ÄúHey, you know, look, my car ran you over, it‚Äôs an AI car, I don‚Äôt know what it did, it‚Äôs not my fault, right?‚Äù You as the driver or maybe it‚Äôs the manufacturer if there‚Äôs some malfunction, but people have to be responsible for the behavior of the machines.">
    <link rel="shortcut icon" href="/favicon.ico" />
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9206135835124064" crossorigin="anonymous"></script>
<script type="text/javascript">amzn_assoc_ad_type = "link_enhancement_widget";amzn_assoc_tracking_id = "swiest00-20";amzn_assoc_linkid = "b583d47a9f44ec47064a228dad7fb822";amzn_assoc_placement = "";amzn_assoc_marketplace = "amazon";amzn_assoc_region = "US";</script><script src="//ws-na.amazon-adsystem.com/widgets/q?ServiceVersion=20070822&Operation=GetScript&ID=OneJS&WS=1&MarketPlace=US"></script>
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    </head>
    <body class="
    article-page
    ">
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "dark");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky ">
    <button class="hamburger hamburger--spin" type="button" id="toggle-menu" aria-label="Toggle Menu">
        <span class="hamburger-box">
            <span class="hamburger-inner"></span>
        </span>
    </button>

    <header>
        
            
            <figure class="site-avatar">
                <a href="/">
                
                    
                    
                    
                        
                        <img src="/img/avatar_hu307e6a33fa6fd661ccda3b77024ef5c2_252345_300x0_resize_box_3.png" width="300"
                            height="300" class="site-logo" loading="lazy" alt="Avatar">
                    
                
                </a>
                
                    <span class="emoji">‚ú®</span>
                
            </figure>
            
        
        
        <div class="site-meta">
            <h1 class="site-name"><a href="/">SWIEST - Transcripts ¬∑ Screenplays ¬∑ Lyrics</a></h1>
            <h2 class="site-description">üåçüåèüåé</h2>
        </div>
    </header><ol class="menu" id="main-menu">
        
        
        
        <li >
            <a href='/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <polyline points="5 12 3 12 12 3 21 12 19 12" />
  <path d="M5 12v7a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-7" />
  <path d="M9 21v-6a2 2 0 0 1 2 -2h2a2 2 0 0 1 2 2v6" />
</svg>



                
                <span>Home</span>
            </a>
        </li>
        
        
        <li >
            <a href='/archives/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <rect x="3" y="4" width="18" height="4" rx="2" />
  <path d="M5 8v10a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-10" />
  <line x1="10" y1="12" x2="14" y2="12" />
</svg>



                
                <span>Archives</span>
            </a>
        </li>
        
        
        <li >
            <a href='/search/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="10" cy="10" r="7" />
  <line x1="21" y1="21" x2="15" y2="15" />
</svg>



                
                <span>Search</span>
            </a>
        </li>
        
        
        <li >
            <a href='/chart/podcastchart.html' target="_blank">
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-apple-podcast" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="#ffffff" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M18.364 18.364a9 9 0 1 0 -12.728 0" />
  <path d="M11.766 22h.468a2 2 0 0 0 1.985 -1.752l.5 -4a2 2 0 0 0 -1.985 -2.248h-1.468a2 2 0 0 0 -1.985 2.248l.5 4a2 2 0 0 0 1.985 1.752z" />
  <path d="M12 9m-2 0a2 2 0 1 0 4 0a2 2 0 1 0 -4 0" />
</svg>
                
                <span>Podcast Charts</span>
            </a>
        </li>
        

        <div class="menu-bottom-section">
                <li id="i18n-switch">  
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-language" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M4 5h7" />
  <path d="M9 3v2c0 4.418 -2.239 8 -5 8" />
  <path d="M5 9c-.003 2.144 2.952 3.908 6.7 4" />
  <path d="M12 20l4 -9l4 9" />
  <path d="M19.1 18h-6.2" />
</svg>



                    <select name="language" onchange="window.location.href = this.selectedOptions[0].value">
                        
                            <option value="https://swiest.com/" selected>English</option>
                        
                            <option value="https://swiest.com/af/" >Afrikaans</option>
                        
                            <option value="https://swiest.com/am/" >·ä†·àõ·à≠·äõ</option>
                        
                            <option value="https://swiest.com/ar/" >ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</option>
                        
                            <option value="https://swiest.com/az/" >Az…ôrbaycan</option>
                        
                            <option value="https://swiest.com/be/" >–±–µ–ª–∞—Ä—É—Å–∫—ñ</option>
                        
                            <option value="https://swiest.com/bg/" >–±—ä–ª–≥–∞—Ä—Å–∫–∏</option>
                        
                            <option value="https://swiest.com/bn/" >‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ</option>
                        
                            <option value="https://swiest.com/bo/" >‡Ωñ‡Ωº‡Ωë‡ºã‡Ω¶‡æê‡Ωë‡ºã</option>
                        
                            <option value="https://swiest.com/bs/" >Bosanski</option>
                        
                            <option value="https://swiest.com/ca/" >Catal√†</option>
                        
                            <option value="https://swiest.com/zh-hans/" >ÁÆÄ‰Ωì‰∏≠Êñá</option>
                        
                            <option value="https://swiest.com/zh-hant/" >ÁπÅÈ´î‰∏≠Êñá</option>
                        
                            <option value="https://swiest.com/cs/" >ƒåe≈°tina</option>
                        
                            <option value="https://swiest.com/el/" >ŒµŒªŒªŒ∑ŒΩŒπŒ∫Œ¨</option>
                        
                            <option value="https://swiest.com/cy/" >Cymraeg</option>
                        
                            <option value="https://swiest.com/da/" >Dansk</option>
                        
                            <option value="https://swiest.com/de/" >Deutsch</option>
                        
                            <option value="https://swiest.com/eo/" >Esperanto</option>
                        
                            <option value="https://swiest.com/es-es/" >Espa√±ol (Espa√±a)</option>
                        
                            <option value="https://swiest.com/es-419/" >Espa√±ol (Latinoam√©rica)</option>
                        
                            <option value="https://swiest.com/et/" >Eesti</option>
                        
                            <option value="https://swiest.com/eu/" >Euskara</option>
                        
                            <option value="https://swiest.com/haw/" > ª≈ålelo Hawai ªi</option>
                        
                            <option value="https://swiest.com/fa/" >ŸÅÿßÿ±ÿ≥€å</option>
                        
                            <option value="https://swiest.com/fi/" >Suomi</option>
                        
                            <option value="https://swiest.com/fo/" >F√∏royskt</option>
                        
                            <option value="https://swiest.com/fr/" >Fran√ßais</option>
                        
                            <option value="https://swiest.com/fy/" >Frysk</option>
                        
                            <option value="https://swiest.com/ga/" >Gaeilge</option>
                        
                            <option value="https://swiest.com/gl/" >Galego</option>
                        
                            <option value="https://swiest.com/gu/" >‡™ó‡´Å‡™ú‡™∞‡™æ‡™§‡´Ä</option>
                        
                            <option value="https://swiest.com/he/" >◊¢÷¥◊ë◊®÷¥◊ô◊™</option>
                        
                            <option value="https://swiest.com/km/" >·ûÄ·ûò·üí·ûñ·ûª·ûá·û∂·üî</option>
                        
                            <option value="https://swiest.com/hi/" >‡§π‡§ø‡§®‡•ç‡§¶‡•Ä</option>
                        
                            <option value="https://swiest.com/hr/" >Hrvatski</option>
                        
                            <option value="https://swiest.com/ht/" >Krey√≤l Ayisyen</option>
                        
                            <option value="https://swiest.com/hu/" >Magyar</option>
                        
                            <option value="https://swiest.com/hy/" >’Ä’°’µ’•÷Ä’•’∂</option>
                        
                            <option value="https://swiest.com/ig/" >√Ås·ª•ÃÄs·ª•ÃÅ √ågb√≤</option>
                        
                            <option value="https://swiest.com/id/" >Bahasa Indonesia</option>
                        
                            <option value="https://swiest.com/is/" >√çslenska</option>
                        
                            <option value="https://swiest.com/it/" >Italiano</option>
                        
                            <option value="https://swiest.com/ja/" >Êó•Êú¨Ë™û</option>
                        
                            <option value="https://swiest.com/jv/" >Basa Jawa</option>
                        
                            <option value="https://swiest.com/ka/" >·É•·Éê·É†·Éó·É£·Éö·Éò</option>
                        
                            <option value="https://swiest.com/kk/" >“ö–∞–∑–∞“õ—à–∞</option>
                        
                            <option value="https://swiest.com/kn/" >‡≤ï‡≤®‡≥ç‡≤®‡≤°</option>
                        
                            <option value="https://swiest.com/ko/" >ÌïúÍµ≠Ïñ¥</option>
                        
                            <option value="https://swiest.com/or/" >‡¨ì‡¨°‡¨º‡¨ø‡¨Ü</option>
                        
                            <option value="https://swiest.com/ckb/" >⁄©Ÿàÿ±ÿØ€å</option>
                        
                            <option value="https://swiest.com/ky/" >–ö—ã—Ä–≥—ã–∑—á–∞</option>
                        
                            <option value="https://swiest.com/la/" >Latina</option>
                        
                            <option value="https://swiest.com/lb/" >L√´tzebuergesch</option>
                        
                            <option value="https://swiest.com/lo/" >‡∫û‡∫≤‡∫™‡∫≤‡∫•‡∫≤‡∫ß</option>
                        
                            <option value="https://swiest.com/lt/" >Lietuvi≈≥</option>
                        
                            <option value="https://swiest.com/lv/" >Latvie≈°u</option>
                        
                            <option value="https://swiest.com/mk/" >–ú–∞–∫–µ–¥–æ–Ω—Å–∫–∏</option>
                        
                            <option value="https://swiest.com/ml/" >‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç</option>
                        
                            <option value="https://swiest.com/mn/" >–ú–æ–Ω–≥–æ–ª —Ö—ç–ª</option>
                        
                            <option value="https://swiest.com/mr/" >‡§Æ‡§∞‡§æ‡§†‡•Ä</option>
                        
                            <option value="https://swiest.com/sw/" >Kiswahili</option>
                        
                            <option value="https://swiest.com/ms/" >Bahasa Melayu</option>
                        
                            <option value="https://swiest.com/my/" >·Äô·Äº·Äî·Ä∫·Äô·Ä¨</option>
                        
                            <option value="https://swiest.com/ne/" >‡§®‡•á‡§™‡§æ‡§≤‡•Ä</option>
                        
                            <option value="https://swiest.com/nl/" >Nederlands</option>
                        
                            <option value="https://swiest.com/no/" >Norsk</option>
                        
                            <option value="https://swiest.com/pa/" >‡®™‡©∞‡®ú‡®æ‡®¨‡©Ä</option>
                        
                            <option value="https://swiest.com/pl/" >Polski</option>
                        
                            <option value="https://swiest.com/pt-br/" >Portugu√™s Brasil</option>
                        
                            <option value="https://swiest.com/pt-pt/" >Portugu√™s Europeu</option>
                        
                            <option value="https://swiest.com/ro/" >Rom√¢nƒÉ</option>
                        
                            <option value="https://swiest.com/ru/" >–†—É—Å—Å–∫–∏–π</option>
                        
                            <option value="https://swiest.com/rw/" >Kinyarwanda</option>
                        
                            <option value="https://swiest.com/si/" >‡∑É‡∑í‡∂Ç‡∑Ñ‡∂Ω</option>
                        
                            <option value="https://swiest.com/sk/" >Slovenƒçina</option>
                        
                            <option value="https://swiest.com/sl/" >Sloven≈°ƒçina</option>
                        
                            <option value="https://swiest.com/sq/" >Shqip</option>
                        
                            <option value="https://swiest.com/sr/" >–°—Ä–ø—Å–∫–∏ (Srpski)</option>
                        
                            <option value="https://swiest.com/su/" >Basa Sunda</option>
                        
                            <option value="https://swiest.com/sv/" >Svenska</option>
                        
                            <option value="https://swiest.com/ta/" >‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç</option>
                        
                            <option value="https://swiest.com/te/" >‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å</option>
                        
                            <option value="https://swiest.com/tg/" >–¢–æ“∑–∏–∫”£</option>
                        
                            <option value="https://swiest.com/th/" >‡πÑ‡∏ó‡∏¢</option>
                        
                            <option value="https://swiest.com/tl/" >Filipino</option>
                        
                            <option value="https://swiest.com/tr/" >T√ºrk√ße</option>
                        
                            <option value="https://swiest.com/uk/" >–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞</option>
                        
                            <option value="https://swiest.com/ur/" >ÿßÿ±ÿØŸà</option>
                        
                            <option value="https://swiest.com/uz/" >O&#39;zbekcha</option>
                        
                            <option value="https://swiest.com/vi/" >Ti·∫øng Vi·ªát</option>
                        
                            <option value="https://swiest.com/yi/" >◊ê◊ô◊ì◊ô◊©</option>
                        
                            <option value="https://swiest.com/zh-hk/" >Á≤µË™û</option>
                        
                            <option value="https://swiest.com/zu/" >IsiZulu</option>
                        
                    </select>
                </li>
            
            
            
                <li id="dark-mode-toggle">
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="8" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="16" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                    <span>Dark Mode</span>
                </li>
            
        </div>
    </ol>
</aside>

    

            <main class="main full-width">
    <article class="main-article">
    <header class="article-header">

    <div class="article-details">
    
    <header class="article-category">
        
            <a href="/categories/podcast/" >
                Podcast
            </a>
        
            <a href="/categories/behind-the-tech-with-kevin-scott/" >
                Behind The Tech with Kevin Scott
            </a>
        
    </header>
    

    <div class="article-title-wrapper">
        <h2 class="article-title">
            <a href="/en/1308500026/">Behind The Tech with Kevin Scott - Oren Etzioni, PhD: CEO of Allen Institute for AI</a>
        </h2>
    
        
    </div>

    
    
    
    
    <footer class="article-time">
        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M11.795 21h-6.795a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v4" />
  <circle cx="18" cy="18" r="4" />
  <path d="M15 3v4" />
  <path d="M7 3v4" />
  <path d="M3 11h16" />
  <path d="M18 16.496v1.504l1 1" />
</svg>
                <time class="article-time--published">2023-02-26</time>
            </div>
        

        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



                <time class="article-time--reading">
                    50 minute read
                </time>
            </div>
        
    </footer>
    

    
</div>

</header>

    <section class="article-content">
    
    
    <p>[MUSIC]</p>
<p><strong>OREN ETZIONI:</strong> Whose responsibility is it? The responsibility and liability has to ultimately rest with a person. You can‚Äôt say, ‚ÄúHey, you know, look, my car ran you over, it‚Äôs an AI car, I don‚Äôt know what it did, it‚Äôs not my fault, right?‚Äù You as the driver or maybe it‚Äôs the manufacturer if there‚Äôs some malfunction, but people have to be responsible for the behavior of the machines.</p>
<p>[MUSIC]</p>
<p><strong>KEVIN SCOTT:</strong> Hi, everyone. Welcome to Behind the Tech. I&rsquo;m your host, Kevin Scott, Chief Technology Officer for Microsoft.</p>
<p>In this podcast, we&rsquo;re going to get behind the tech. We&rsquo;ll talk with some of the people who have made our modern tech world possible and understand what motivated them to create what they did. So, join me to maybe learn a little bit about the history of computing and get a few behind-the-scenes insights into what&rsquo;s happening today. Stick around.</p>
<p>[MUSIC]</p>
<p><strong>CHRISTINA WARREN:</strong> Hello, and welcome to Behind the Tech. I‚Äôm Christina Warren, senior cloud advocate at Microsoft.</p>
<p><strong>KEVIN SCOTT:</strong> And I‚Äôm Kevin Scott.</p>
<p><strong>CHRISTINA WARREN:</strong> Today on the show, our guest is Oren Etzioni. Oren is a professor, entrepreneur, and is the chief executive officer for the Allen Institute for AI. So, Kevin, I‚Äôm guessing that you guys have already crossed paths in your professional pursuits.</p>
<p><strong>KEVIN SCOTT:</strong> Yeah, I‚Äôve been lucky enough to know Oren for the past several years. We met after I became CTO at Microsoft, but I‚Äôve been very, very well aware of Oren professionally for many, many years.</p>
<p>The thing he probably doesn‚Äôt know is the University of Washington, where he still is a professor, was one of the places that I wanted to go to graduate school. So, the entire time I was in undergrad, I had a copy of the UW computer science course catalog sitting on my desk as an aspirational thing. I was following his work pretty closely back then, which you know, may sound a little bit creepy, I guess. (Laughter.)</p>
<p><strong>CHRISTINA WARREN:</strong> Well, you know, no, I don‚Äôt think it‚Äôs creepy. I mean, you‚Äôre a fan, and I think that‚Äôs awesome that you know each other now, and now we‚Äôre going to be able to get into the interview and hear you guys talk.</p>
<p><strong>KEVIN SCOTT:</strong> Yeah, Oren is ‚Äì he‚Äôs really an amazing teacher, leader, and scholar in the work that he‚Äôs doing with the Allen Institute for AI is really incredible. So, I‚Äôm super glad to have him on the show today.</p>
<p><strong>CHRISTINA WARREN:</strong> Likewise. Likewise. Well, let‚Äôs get to the interview.</p>
<p>[MUSIC]</p>
<p><strong>KEVIN SCOTT:</strong> Our guest today is Dr. Oren Etzioni. Oren is chief executive officer at the Allen Institute for Artificial Intelligence. He‚Äôs been professor at the University of Washington‚Äôs Computer Science Department since 1991. His awards include Seattle‚Äôs Geek of the year in 2013 and he‚Äôs founded or co-founded several companies including Farecast and Decide.com.</p>
<p>Oren has helped pioneer metasearch, online comparison shopping, machine reading, and open information extraction. Welcome to the show.</p>
<p><strong>OREN ETZIONI:</strong> Thank you, Kevin, it‚Äôs a real pleasure.</p>
<p><strong>KEVIN SCOTT:</strong> So, I would love to get started by talking a little bit about how you got interested in science and engineering in the first place. Was it when you were a little kid or later on in life?</p>
<p><strong>OREN ETZIONI:</strong> Well, both my parents are sociologists, actually, professors of sociology. And so, I think instinctively, subconsciously, I ran away from that as far as I could. Like some of your other guests, like Daphne Koller and I think yourself, I discovered that magical machine via the TRS-80 and started playing with it. It was just really fun and really new, and I kinda could sense something very powerful there.</p>
<p>But where I really got engaged was when I read the book <em>Godel, Escher, Bach</em>, which many of us did back in the day. I got kind of a whiff of the questions that we could be asking and that we could be studying using computers are really some of the most fundamental intellectual questions of all time. What is the origin of the universe? What is the nature of intelligence? How do we build an intelligent machine?</p>
<p><strong>KEVIN SCOTT:</strong> Yeah. I mean, it‚Äôs really interesting that so many of us have such an interestingly similar experience. I can‚Äôt remember ‚Äì I think I was in college when I read Hofstadter‚Äôs book the first time ‚Äì or tried to read it ‚Äì because it is intellectually dense. But it really had a remarkable impact on a bunch of people. And I‚Äôm guessing it still sort of informs some of the things that you‚Äôre doing today, because you know, in a sense, what all of us are doing a little bit with the pursuit of artificial intelligence is not just figuring out what the machines are capable of, but like what does that say about human intelligence itself, which we really don‚Äôt understand in a deep sense?</p>
<p><strong>OREN ETZIONI:</strong> That‚Äôs exactly right. One way to think about artificial intelligence or I‚Äôll just use ‚ÄúAI‚Äù for short, is really it‚Äôs almost a funny pun or homonym. It really, in my mind, refers to two very different things. One is a set of technological capabilities, which I‚Äôm sure we‚Äôll talk about some more, but are getting increasingly powerful with speech recognition, with facial recognition, with things like GPT-3, and at the same time, it‚Äôs a kind of vision, right, of how do we build human-level intelligence, artificial general intelligence, and so on.</p>
<p>And those two things are actually very different in the sense ‚Äì in my opinion ‚Äì in the sense that the technology is progressing very well, but it‚Äôs still very, very far off from the ultimate vision of the field.</p>
<p><strong>KEVIN SCOTT:</strong> Yeah, well, and you know, I think the interesting thing that we all have seen over the past several decades is we keep solving these problems that we think are reflective of high human intelligence, and as soon as we‚Äôve solved them, we decide that, ‚ÄúOh, well, maybe that wasn‚Äôt really what is the core of human intelligence.‚Äù</p>
<p>You know, I remember when it was chess playing and then it was Go playing and then it‚Äôs these feats of perception that we‚Äôve been able to do and, you know, like, there are still these things that are ‚Äì for human beings, like, very, very easy that I don‚Äôt think we think of as being cognitively sophisticated that completely elude the ability of machines ‚Äì common sense reasoning, navigating physical environments, and all sorts of fun stuff.</p>
<p>So, you know, I do think we have been confused about what the definition of intelligence is for a very long while now, which makes going after it interesting. (Laughter.)</p>
<p><strong>OREN ETZIONI:</strong> Well, what you‚Äôre saying is so true, right? There are writings in the ‚Äò60s and the ‚Äò70s and later talking about, say, chess, right, as the pinnacle of intelligence. And you can sort of see why, right? For most people, playing Grandmaster Chess is an incredible feat of intelligence. Very elusive. And then to find out that the machine can do it is startling.</p>
<p>At the same time, there is something called Moravec‚Äôs Paradox, right, that says things that are easy for the machine are hard for people ‚Äì like playing champion-level chess or Go. Conversely, things that are easy for people ‚Äì like you said, common sense, crossing the street, driving a car ‚Äì most people can do it with reasonable success, and machines are still surprisingly far away.</p>
<p>I would say, however, that one remarkable thing, which of course you‚Äôre familiar with, is the articulation of ‚ÄúHow can we tell if a machine achieved intelligence?‚Äù by Alan Turing in the ‚Äò50s, and he devised the Turing Test. And while the Turing Test sometimes is misapplied, it becomes ‚Äì so, to define it, right, the Turing Test is you‚Äôre communicating with somebody, let‚Äôs say over, I don‚Äôt know, Twitter or Slack or Microsoft Teams, I should say ‚Äì whatever it is ‚Äì and you don‚Äôt know whether it‚Äôs a person or a machine, and you have to try and guess.</p>
<p>When you can‚Äôt tell them apart, then the machine is said to have passed the Turing Test. Now the thing is, if it‚Äôs misapplied, it becomes a test of human gullibility, right? We can trick people into thinking, ‚ÄúOh, yeah, I‚Äôm talking to a person.‚Äù But if it‚Äôs done right, if you subject it to a rigorous test by, say, a panel of experts, then it‚Äôs actually quite an achievement, right, to have a machine that behaves intelligently, et cetera, et cetera.</p>
<p>So, I think we have that notion. The problem is that we take these narrow slices, like playing chess or like, I don‚Äôt know, solving the Rubik‚Äôs Cube. And it‚Äôs not surprising, by the way, that they‚Äôre often in artificial domains, that they‚Äôre often games and such. And we say, ‚ÄúOh, that‚Äôs intelligence.‚Äù And then we find out, well, not quite.</p>
<p><strong>KEVIN SCOTT:</strong> Well, and you know, I think yeah, you pointing out that they are in these artificial domains is an interesting thing for all of us to recognize about the state that AI is in right now, and where it is likely to be in the near future. So, I think some of the things that we may think are insulated from encroachment by AI, like a bunch of white collar work, for instance, is actually far more likely to have AI impact it than things like manual labor, for instance. Where, because we haven‚Äôt solved these problems where the AI has to interface with the physical world, it just ‚Äì like, we haven‚Äôt even figured out the basic experimentation loop for solving that problem.</p>
<p>So, like, we can‚Äôt iterate there nearly as fast as we can in these artificial domains, where progress is still pretty good. I don‚Äôt know whether you would agree with that or not.</p>
<p><strong>OREN ETZIONI:</strong> I think it‚Äôs a very rich topic, but I definitely agree with what you‚Äôre saying, that the speed of experimentation and iteration makes a huge difference. So if you‚Äôre dealing with a robot, say, right? And every experiment that goes awry, you can break a robot arm, or god forbid, hurt somebody, obviously, that slows things down so people work in simulation. Then, the simulation doesn‚Äôt necessarily map to the real world.</p>
<p>Whereas in games, right, with self-play, the computer can play each other and very quickly gather millions of training examples.</p>
<p>You know, the way I think about this topic is if something is very rote, you do the same thing every time ‚Äì like collecting tolls or operating elevators, those things are not great jobs, right? I mean, is that really ‚Äì you know, hopefully we can find people better jobs than those. And those are easy for the machine to do.</p>
<p>Then, the next level is making binary distinctions, right, or categorizing things. For example, take email, is it spam or is it not spam? When you have a huge number of emails ‚Äì literally billions ‚Äì you can train up a really good model that says yes or no.</p>
<p>But when it‚Äôs much more complicated, like how do I design a good podcast? How do I be the CTO of a major company? I think, Kevin, you‚Äôve got job security. We‚Äôre not going to be replacing you with a program anytime soon.</p>
<p><strong>KEVIN SCOTT:</strong> I don‚Äôt know, maybe that would be nice. (Laughter.)</p>
<p><strong>OREN ETZIONI:</strong> Well, what would be nice is to have a program that helps you, right?</p>
<p><strong>KEVIN SCOTT:</strong> Yeah.</p>
<p><strong>OREN ETZIONI:</strong> So, a lot of the work that we do and a lot of the work elsewhere really can think of AI as ‚Äúaugmented intelligence.‚Äù Would you be more effective at your job if you had a program that helped, I don‚Äôt know, prioritize your emails, right? That helps you author emails more efficiently or even papers, right, all that.</p>
<p><strong>KEVIN SCOTT:</strong> Yeah, so let‚Äôs go back a minute. So, you found the TRS-80 when you were a kid, you read, you know, <em>Godel, Escher, Bach</em> like was that when you were in high school or in college?</p>
<p><strong>OREN ETZIONI:</strong> In high school, yeah.</p>
<p><strong>KEVIN SCOTT:</strong> Yeah, so as a high school student you read this, like, really formative book. And then did you major in computer science when you went to university?</p>
<p><strong>OREN ETZIONI:</strong> Well, actually, it was ‚Äì I‚Äôll share with you a quick little anecdote. So, when I went to college, I went to what I like to call a small community college in Cambridge, Massachusetts, but it has the august name of Harvard. They didn‚Äôt have a computer science major. They had applied math. And they ‚Äì their approach, I heard this from some of the professors there, was viewing computer science as more of a kind of applied discipline. They said, ‚ÄúHey, we don‚Äôt have a major in automotive science, so why would we have a major in computer science?‚Äù</p>
<p>And right around the time I was there, so this is 1992, 1993, right at the beginning of my time there, they realized, no, this isn‚Äôt a fad, and this isn‚Äôt some applied discipline, it‚Äôs quite transformative. Again, I wasn‚Äôt privy to those discussions as a freshman. All I know is they did create a new concentration, as it‚Äôs called. And being an eager beaver, I ran to Howard Lewis to declare my new concentration and he signed my paper form, if you can believe that. And he raised his head and he said, ‚ÄúHey, you‚Äôre the first.‚Äù</p>
<p>So, I feel like my ‚Äì I‚Äôll go down in ‚Äì</p>
<p><strong>KEVIN SCOTT:</strong> Wow.</p>
<p><strong>OREN ETZIONI:</strong> -in history as the first person to major in computer science at Harvard.</p>
<p><strong>KEVIN SCOTT:</strong> That is so cool. That‚Äôs really, really neat. And so, what was that program like? Because I‚Äôm guessing, you know, given that it was early days, and this was true even when I was a freshman in 1990, and like even in 1990, we were still trying to figure out, like, what a computer science curriculum looked like and, you know, like the entire, you know, ferment of the field was just sort of being developed. So, what was it like being that first student?</p>
<p><strong>OREN ETZIONI:</strong> Well, so, again, they‚Äôd been teaching computer science courses for a while, it was just under applied math. And I would say that the Harvard curriculum was very mathematical, so it was influenced by people like the great Michael Rabin, Turing Award winner, inventor of some of the key theorems in theoretical computer science. Les Valiant was there, you know, teaching combinatorics. So, it was a very theoretical curriculum, which I actually really appreciated because, you know, you want to get that mathematical grounding right.</p>
<p>But at the same time, there was very little AI. So, I was fortunate that, you know, two T stops away was MIT and tech square, and so very quickly I started hanging out at MIT, where Minsky was there and actually Hofstadter, who was, you know, a god for me at the time, was visiting for a year or two. And so, I felt like I was very fortunate because I got my AI at the MIT AI lab and I got my computer science grounding and broader education at Harvard. So, that was really a wonderful time.</p>
<p><strong>KEVIN SCOTT:</strong> Yeah, and then you fell in love, I‚Äôm asking, not asserting. You fell in love with, you know, with computer science ‚Äì with the field, and decided to go to graduate school and get a PhD?</p>
<p><strong>OREN ETZIONI:</strong> So, again, what I was really in love with is the fundamental questions. For me, computer science and computers was always a tool. And, actually, I was also studying cognitive science and philosophy of language science at the time, and I was debating whether I should go to grad school in philosophy or in computer science, because these were methodologies for me to get at these fundamental questions.</p>
<p>And then I talked to some people and I realized the people were graduating with a PhD in philosophy and working in moving, right, it was not a great career path. Whereas I could tackle these issues in a more empirical way and, frankly, just a more satisfying from a career point of view way, as a computer scientist. So, I decided to go to grad school in computer science. But it wasn‚Äôt obvious. I could have ended up being a philosopher.</p>
<p><strong>KEVIN SCOTT:</strong> And what was your dissertation on?</p>
<p><strong>OREN ETZIONI:</strong> So, I went on to study with Tom Mitchell, who‚Äôs really the father of machine learning or one of them in many ways. It was on machine learning, a subfield of machine learning that‚Äôs much more symbolic than the kind of neural network deep learning stuff that we do today.</p>
<p><strong>KEVIN SCOTT:</strong> Yeah, but he must have even been thinking about statistical methods back then. I‚Äôve got, like, one of Tom‚Äôs textbooks that I‚Äôve had for a very long time. And I think it‚Äôs the first place that I ever read about Bayesian inference. So, I don‚Äôt know whether he was thinking about things like the statistical approach to machine learning back when you were his student or not, but he certainly has done some interesting work there.</p>
<p><strong>OREN ETZIONI:</strong> Absolutely. He was and he did, and his classic textbook covered it. Geoff Hinton was visiting at the time, and there was very lively and intense discussion of his ideas. I think the thing that Tom and certainly I missed was the power, the potential power of neural networks to ‚Äì when you have awesome amounts of data and tremendous amounts of computational power. So, at the time, they didn‚Äôt necessarily do better than other statistical mechanisms. So, it was very clear that we wanted statistical methods, but it was a lot less clear that we wanted neural networks.</p>
<p><strong>KEVIN SCOTT:</strong> I think that‚Äôs one of the sort of classical timing problems in computer science and engineering, where it was a good idea, but because ‚Äì we effectively didn‚Äôt have the data volume and the distributed computing infrastructure that came along with the internet revolution and like these big internet companies and their distributed computing and cloud infrastructure, which wasn‚Äôt called cloud infrastructure at the time.</p>
<p>And so, I just sort of wonder what are we missing right now? Like, the good ideas that happened 10 years ago that are, you know, left by the wayside that are now feasible and like we don‚Äôt even have someone ‚Äì I mean, the good thing about Geoff is he was stubborn, like, he was convinced that it was a good idea and he kept pushing on it, you know, for a very long time until the conditions were right for it to be successful.</p>
<p>And I just sort of wonder, like, you know, what conditions are going to change in the future that are going to make you know some of the things that are infeasible now actually possible? It‚Äôs one of the reasons why I‚Äôm like really excited about all of this large-scale compute infrastructure that we‚Äôre building right now, because like it‚Äôs just ‚Äì it may not get us to AGI, which is a thing I do want to talk to you about in a minute, but it certainly gets us something, and I‚Äôm really interested to see what that something is.</p>
<p><strong>OREN ETZIONI:</strong> Me too. I think it‚Äôs a really interesting time to be a computer scientist, to be a computer professional. I do want to say, off the top of my head, here are three things that the current technology doesn‚Äôt yet touch. The first one is the current technology ‚Äì maybe this is a good phrase ‚Äì is kind of profligate in its use of compute and data. Yeah, I need millions of examples at least for pre-training and then thousands for tuning. Yeah, I need this massive amount of computation, millions of dollars of computation to build my model.</p>
<p>Whereas of course human intelligence, which is the standard, sits in this little box, right, that‚Äôs on top of my neck and is powered by the occasional salad and a cup of coffee, right? We know, right, you know, kids, they‚Äôll see one example and they‚Äôll go to the races. So, I think we can build far more frugal machines in terms of data and compute, that‚Äôs one.</p>
<p>And then the second thing, and this goes right back to the discussions we were having at CMU in the early ‚Äò90s is, ‚ÄúWhat is the cognitive architecture?‚Äù In other words, okay, you can take a narrow question like, ‚ÄúIs this email spam or not,‚Äù or ‚ÄúDid I just say ‚ÄúB‚Äù or ‚ÄúP?‚Äù Speech - phoneme recognition. And you can train models that‚Äôll do ‚Äì they have super-human performance at that.</p>
<p>But the key thing in artificial general intelligence ‚Äì in AGI ‚Äì is the ‚ÄúG.‚Äù So, how do we build what was called, then, a unified cognitive architecture? How do we build something that can really move fluidly from one task to another, when you form a goal, automatically go and say, ‚ÄúOkay, here‚Äôs a subgoal, here‚Äôs something I need to do or learn in order to achieve my goal.‚Äù There‚Äôs just so much more to general intelligence than these savant-like tasks that AI is performing today.</p>
<p>The third topic in AI that I think we ought to be paying more attention to is the notion of a unified cognitive architecture. So, this is something we studied at CMU back in the day. And it‚Äôs the notion of not just being a savant, not just taking one narrow problem, but going from one problem to the next and being able to fluidly manage living, where right now we‚Äôre talking. Soon, I will be crossing the street, then I‚Äôll be reading something.</p>
<p>Putting all those pieces together and doing it in a reasonable way is something that‚Äôs way beyond the capabilities of AI today.</p>
<p><strong>KEVIN SCOTT</strong>: Yeah, and we‚Äôve got a little bit of that starting ‚Äì</p>
<p><strong>OREN ETZIONI:</strong> I know, I ‚Äì</p>
<p><strong>KEVIN SCOTT</strong>: In transfer learning, like, but just beginning.</p>
<p><strong>OREN ETZIONI</strong>: Right, but the thing about the transfer learning is that it‚Äôs still from one narrow task to another. Maybe it‚Äôs from one genre of text to another genre of text. We don‚Äôt really have transfer learning from, okay, I‚Äôm reading a book, to now I can take what I read in the book and apply it to my basketball game, right? We‚Äôre very far from anything like that.</p>
<p><strong>KEVIN SCOTT:</strong> Yeah, the other thing that I‚Äôm also really curious about, we‚Äôve ‚Äì you know, we‚Äôve chatted with some people on the podcast who are doing research on insect biomechanics, for instance. You know, which ‚Äì and they‚Äôve done very, very detailed studies of, like, what the neural architecture is for the control systems that manage insect flight and navigation, for instance.</p>
<p>And they are very, very highly specialized neural circuits. It‚Äôs not a, you know, sort of a general like deep network that you know ‚Äì like maybe a deep network could learn that behavior, but like there‚Äôs certainly ‚Äì there seems to be an efficiency opportunity.</p>
<p>And like I could not more strongly agree with that point. I forget what the numbers are, but if you look at like the world champion Go player, Lee Sedol, like, he probably got to world-champion levels of expertise on a small number like, low tens of thousands of hours‚Äô worth of game play, which is like more than you or I would ever be willing to commit, but far, far less than the millions of simulated hours that a thing like AlphaGo Zero invested to get to the point where it could play competitively with him.</p>
<p>And that is ‚Äì you know, that amounts to millions of dollars and millions of watts of power and it‚Äôs a very, very interesting chasm that I think we have an opportunity to cover at some point ‚Äì hopefully in the not-too-distant future.</p>
<p><strong>OREN ETZIONI:</strong> Absolutely. You know, at the Allen Institute, we‚Äôve recently written a paper that‚Äôs going to appear in Communications of the ACM on something we call ‚Äúgreen AI.‚Äù And the idea of it is both to think about the carbon footprint, right, and the ‚ÄúCan we build these more efficient systems?‚Äù But there‚Äôs another thread here that I want to highlight, which is making sure that the research that we‚Äôre doing is sufficiently inclusive.</p>
<p>So, back in the day, it used to be that you or I or a talented undergraduate in India or some other country with a laptop could do something really cool and write a paper about it and get noticed. If we reach the point where you have to have so much infrastructure and so much compute to do an experiment that leads to a published paper, that‚Äôs a real problem for the field, right? We don‚Äôt get to harness all the brilliant ideas and creativity of a broader population. And so we suggested some pragmatic ideas of how to fix that not by, you know, forbidding or cutting off this very exciting, high-end research, but by saying, ‚ÄúOkay, let‚Äôs also look at efficiency, at results of, okay, how can we run these types of models on a much more limited device?‚Äù</p>
<p><strong>KEVIN SCOTT:</strong> But I‚Äôm so glad to hear that you all have written that paper and are pushing on that because I do think it‚Äôs one of the fundamental issues that we‚Äôve got at this particular moment in time with AI research, these models are not only extremely expensive to train, they are extremely expensive to serve. So, you‚Äôve got this cost thing that makes it difficult to make them widely available.</p>
<p>I mean, like, we could ‚Äì I‚Äôll give you an example. I won‚Äôt talk about GPT-3, but I‚Äôll talk about this model that we built called Turing NLG, which is a 17-billion parameter transformer model.</p>
<p><strong>OREN ETZIONI:</strong> Only 17 billion.</p>
<p><strong>KEVIN SCOTT:</strong> Yeah, only 17 billion. So, like, it was extremely ‚Äì I mean, we trained this on a very large, very sophisticated cluster of GPUs and it consumed a lot of resources and like we wrote a bunch of very specialized software to manage the distributed training task.</p>
<p>And the model is very, very powerful. And so, one of the things that we‚Äôre struggling with right now is - I would love to get that model into the hands of as many people as humanly possible. One impediment to getting it into the hands of as many people as possible is cost. And like I think, you know, to your point, we can bring the costs down by, you know, making a whole bunch of these investments. Like, the infrastructure could be better. You can distill the model, there‚Äôs all sorts of like really interesting things that you can do to like still preserve the model‚Äôs power and make it much cheaper to serve.</p>
<p>But the other, you know, interesting thing with these models is it‚Äôs a general language model. It will enable people to put it in use cases that we would find objectionable. And like by ‚Äúwe‚Äù I don‚Äôt mean Microsoft, I mean ‚Äúwe‚Äù society. And so you know, it‚Äôs ‚Äì and I don‚Äôt know how you train the model to allow it to do all of the powerful things that it can do and exclude the objectionable things that we‚Äôre not going to want it to do.</p>
<p>And so that is another thing that makes access a little bit tricky. So, like, how do you get that into the hands of responsible people so that they can discover all of the good uses that the tech companies that have the resources to build these models will never be able to imagine on their own without, you know, opening Pandora‚Äôs box and creating more misery in the world.</p>
<p><strong>OREN ETZIONI:</strong> Very important questions. The good news is, I do think that we‚Äôre making progress there. So, some of it is the old adage, garbage in, garbage out. So, you have to be careful what you feed. This model is kind of like an innocent child, right, who will read anything. So, you have to be careful what you feed it.</p>
<p>That‚Äôs typically not enough, because these things consume, right, you know, billions and billions of sentences and documents. I‚Äôm a great believer in auditing techniques. So, we also need to make models like this eternally auditable so other bodies can help discover if there‚Äôs, you know, problems hidden there or if it can be tuned in a negative direction. So, I do think that you and Microsoft are very smart to think carefully about these issues, but I do think that help is on the way.</p>
<p><strong>KEVIN SCOTT:</strong> Yeah, well, and that I think is one of the foundational things I would like to be able to figure out sooner rather than later is just a way to allow the help to happen in an efficient and transparent and open manner, because at least that much needs to be happening.</p>
<p>It would have very ironic to have a situation where the very, very necessary public and open work that needs to happen on responsibility and safety and ethics and all of these other things can‚Äôt happen because the people who are doing that work outside of corporations don‚Äôt have access to the models.</p>
<p><strong>OREN ETZIONI:</strong> Well, so then if I may ask you a question, right, with GPT-3 and Microsoft‚Äôs recent exclusive ability to license it, are you planning to make it available to academia, to places like AI2?</p>
<p><strong>KEVIN SCOTT:</strong> Yeah, we‚Äôre trying to figure out exactly how to do that right now. Like, in a safe way and ‚Äì I mean, the thing with GPT-3 is, like, it‚Äôs, you know, it‚Äôs ten times bigger even than the Turing NLG model that we built.</p>
<p>And so there, we probably will have to serve it on our infrastructure just because the task of figuring out how to ‚Äì like, if I gave you a bag of weights or we gave you a bag of weights and then you had to go figure out how to serve it for doing your research, like, that would be its own research project that would be daunting. And so, like, we are working through those issues right now.</p>
<p><strong>OREN ETZIONI:</strong> Well, I‚Äôm glad to hear it. And, of course, you‚Äôre absolutely right. With something that big or even the Turing NLG model, right, what people really want is an API, not a file that you download with lots of numbers in it.</p>
<p><strong>KEVIN SCOTT:</strong> Yeah, and so the nice thing about an API is it lets you, through like the access control to the API, like, have some sort of, you know, guarantees around responsible use. And then it just ‚Äì it really does become about cost.</p>
<p>[32:29]</p>
<p>And, you know, cost is ‚Äì we want to be able to get the cost down to the point where you can do reasonable amounts of inference and exploration with the model in a way that doesn‚Äôt break my personal budget at Microsoft. (Laughter.)</p>
<p><strong>OREN ETZIONI:</strong> Sure, which I‚Äôm sure is quite sizable. But here‚Äôs a simple idea that we advocated in the Green AI paper. The reporting standards, when we report accuracy of models, you know, how often they get things right, are very clear and so on. But the reporting standards on how much did it cost you to produce that performance, aren‚Äôt. People often don‚Äôt report that, or if they do, they don‚Äôt report some of the dead ends that they went into.</p>
<p>If they reported that more rigorously, then as you said, the distillation efforts ‚Äì basically, the efforts to build a cheaper model, maybe a far-cheaper one, would be a lot easier. Because I could say, okay, here‚Äôs your model, it costs, let‚Äôs say, $100,000 to train it. Here‚Äôs my model. It only performs 70% at the level of your model, but you know what? It costs 1/10th to produce.</p>
<p>Or here‚Äôs my model, maybe it‚Äôs only 40% of your model, but I can run it on a phone. So, the ‚Äì but I can only publish that result if I have a baseline, right? And that baseline has to include the cost, because then I can make that.</p>
<p>So, a really simple step on the part of everybody ‚Äì kind of the rich players in the ecosystem of simply being rigorous on reporting their costs would enable everybody else to start whole new ‚Äì really sub areas of the field.</p>
<p><strong>KEVIN SCOTT:</strong> Yeah, I think that‚Äôs an interesting idea and, certainly, something we will think about. I mean, one of the interesting things that I‚Äôve seen in ‚Äì so, my Microsoft Research reports to me at Microsoft. And, you know, one of the things that we‚Äôve struggled with this same thing even internally, right? So, like, you may imagine that, you know, Microsoft is you know like has a very big capital and R&amp;D budget, which means that you know, once we have one of these models, then everyone can use it, which isn‚Äôt even true internally.</p>
<p>So, you know, the amount of resources required to train a very big model and then to, like, go serve it in an application where you may have a billion users is ‚Äìit‚Äôs sort of daunting on the training side, there‚Äôs just limited amount of compute.</p>
<p>[34:15]</p>
<p>And so, like, you have to decide who is going to be training what. And on the serving side, we really do very carefully measure how much it costs to, you know, in terms of compute and power and depreciation on the capital for a single API call to a thing, because we have to make sure that when we‚Äôre putting it into a product or a service that you know, you‚Äôre profitable still.</p>
<p>And, so, you know, our teams inside of the company even have these issues about, like, you know, what engineering work do I have to do to make this thing useful for me? Because we haven‚Äôt even sorted the problems of access out inside of the company. And I know for a fact, you know, that everyone is struggling with this right now because these models are so big.</p>
<p><strong>OREN ETZIONI:</strong> That makes a lot of sense, yeah.</p>
<p><strong>KEVIN SCOTT:</strong> Yeah, so, you started your career ‚Äì or early parts of your career, you were doing, you know, a bunch of super-interesting stuff in information retrieval and you ‚Äì you know, you were starting companies, you ‚Äì like I think may have built the first comparison shopping site on the Web.</p>
<p>How did you ‚Äì it sounds like you‚Äôve always been interested in artificial intelligence, and you know, my question is: Like, have you ‚Äì you know, were you always able to see, you know, this through line through all of this stuff that you were doing, like, everything always connects back to AI? Or was it, like, all right, these are just super interesting problems of the moment that I have the skill you know to address and the interest in.</p>
<p><strong>OREN ETZIONI:</strong> Anybody who tells you that over a long career and here I‚Äôm betraying my age, I‚Äôve been doing this for 30-plus years, there‚Äôs a connecting through line and a grand plan is either far smarter than I am, or far more strategic, or is just kind of selling you a bill of goods, you know, the Brooklyn Bridge, as they say. There are themes that I‚Äôve always been fascinated by.</p>
<p>For example, all the companies that have started have always been about empowering the consumer with information ‚Äì particularly about price, like when to buy your airline ticket, right, that was so you get the best price. That was Farecast, or the first company I co-founded with Professor Dan Weld on online comparison shopping, ‚ÄúWhere do you find the best price?‚Äù particularly this was in the world before Amazon.</p>
<p>Amazon was just getting started. So, and it wasn‚Äôt just, by the way, about price, it was also about selection, right? Nowadays, we kind of assume we can always find it at a decent price at Amazon, say, but A, sometimes you can get a better price elsewhere, and B, at the time, often it wasn‚Äôt clear where to buy a particular good.</p>
<p>So that was a big theme for me. And the toolkit, we all have our toolkit. Certainly, AI and information retrieval related to that, machine learning, that was my go-to toolkit, so it was natural to go there.</p>
<p>But I kind of view a lot of these as side adventures. I feel like my two long-term passions are ‚Äì one is the fundamental intellectual question of AI that we talked about earlier, ‚ÄúHow do we build an intelligent machine?‚Äù And then the second one is, ‚ÄúHow do we use AI as a technology to make the world a better place?‚Äù</p>
<p>And, you know, better search engine can do that, better shopping can do that. Right now, at the Allen Institute of AI ‚Äì or AI2, as I call it ‚Äì a project that I‚Äôm particularly proud of is semantic scholar. How do we make scientific research more efficient and more productive using AI? And actually a callout to Microsoft Research and the work on the Microsoft Academic Graph. Right? We‚Äôve made extensive use of those resources to build Semantic Scholar.</p>
<p><strong>KEVIN SCOTT:</strong> That is awesome. So, I want to dig a little bit into the particulars of these big models that folks are building right now, particularly around language, although soon they‚Äôre going to be multimodal and you know sort of applied to a bunch of different domains.</p>
<p>But one of the interesting things that you all did. I think this was sometime the middle of last year was this system called Arista that is your test-taking system. And so you‚Äôve been working on this for a really long time, and my understanding is that you were able to leverage some of these newer, self-supervised language models like Google‚Äôs BERT model in particular, to finally get the system to the point where it can reach parity with students at taking science tests. Talk a little bit about that.</p>
<p><strong>OREN ETZIONI:</strong> Sure, so this really starts with the late Paul Allen‚Äôs vision. And he asked the question, ‚ÄúGosh, if our technology is so great, be it computer science or AI, why can‚Äôt it pick up a book ‚Äì a textbook ‚Äì read the textbook and then answer the questions at the back of the book?‚Äù</p>
<p>And he had a project even before Allen AI, which started in 2014, he had an earlier project that attempted to do that in various ways and were not successful.</p>
<p>So, when we launched Allen AI, AI2, in 2014, we said, ‚ÄúWhy don‚Äôt we focus on grade school tests?‚Äù Let‚Äôs work our way up to reading a college-level biology textbook.</p>
<p>And the way we do that is we‚Äôre going to have the program take a fourth-grade science test, and eighth-grade test, take the SATs. And the beautiful thing about that is we can measure the system‚Äôs performance and we‚Äôll take it on unseen tests, right, the same way, you know, the Regents New York State publishes a new test every year.</p>
<p>So, we‚Äôll take an unseen test, the machine has never seen the test before. And like a kid, we‚Äôll measure the performance. We‚Äôll also compare it to human performance. We‚Äôll have a benchmark where we say, ‚ÄúOkay, how is our progress going?‚Äù</p>
<p>And I think that helped Paul Allen, reassure him that he could get a sense, right, without being there every minute, get a sense of our progress and that we were really making progress rather than building towers in the air. So that became our benchmark is these science tests. And we struggled mightily with these tests in part because it turns out the tests are written in English and they require a lot of background knowledge. They require understanding of various phrases. They have phrases in there like ‚Äúthe onset of winter.‚Äù What the heck is the onset of winter? So, a lot of tricky issues that we don‚Äôt have time to get into.</p>
<p>We were making steady progress, but it was hard. It was very difficult. We set ambitious goals every year and we struggled mightily to meet them. What happened, as you said, this new class of models came, and they actually originated at AI2. We had a model called ELMO, won the best paper award in 2018. It was quickly followed by Google‚Äôs model called BERT, which is a nod to ELMO, won the best paper award in 2019.</p>
<p>And people have gone from there, and Turing NLG, which you mentioned, right, is yet another instantiation. Others have Roberta, et cetera. There are all these models are actually ‚Äì I should mention because they‚Äôre actually pretty simple. All they do, right, is take a word and say, ‚ÄúWe‚Äôre going to figure out what this word means based on its context.‚Äù Not its context in one page or one sentence, but in all the places it appears in billions of sentences, we‚Äôre going to compute statistics on its context and these statistics are going to enable us to predict if I see a word or a sentence or a phrase, what‚Äôs going to come next ‚Äì what might even come before ‚Äì just based on what typically happens.</p>
<p>It turns out that that basic idea, with a lot of technical bells and whistles, is incredibly powerful ‚Äì more powerful than I think anyone would have anticipated. So, we started using that in our work and we said, ‚ÄúOkay, it‚Äôll help. This tide will boost all boats.‚Äù But we never anticipated how much it will help.</p>
<p>So, we found that very quickly, we were able to get 90% ‚Äì at least on the multiple-choice parts of the test ‚Äì that involved text. And so, all of a sudden, this model led us to pass and even ace a fourth-grade test, eighth-grade test, even 12th-grade science tests. And that was a surprise. And it leads me to make a prediction. I think that we‚Äôre going to see ‚Äì we‚Äôre already seeing, but we‚Äôre going to see even more in the next five years, tremendous applications of natural language all over the world.</p>
<p>There‚Äôs machine translation, which we‚Äôve already seen. There‚Äôs ‚Äì in the medical and the healthcare system, everywhere where there‚Äôs text, which is kind of everywhere, right, because we have text in our emails, we have text in physician records, we have text in scientific papers, we have text in insurance claims, you know, you name an arena of life, I‚Äôll tell you the text that‚Äôs there.</p>
<p>Our ability to understand that has really had an inflection point. And that inflection point is going to result in both improved science, but also new startups, new capabilities out of companies like Microsoft and Google. It‚Äôs really an exciting time to work on what‚Äôs called NLP.</p>
<p><strong>KEVIN SCOTT:</strong> Yeah, it is. I mean, we had a similar phenomenon, I guess, with convolutional neural networks, which like really were a step function improvement in image recognition and like some of these visual domain tasks. But you know, if anything, because so much of our world is about written human language, like, the impact that I‚Äôm seeing from these models like ELMO, I mean, it‚Äôs just unbelievable.</p>
<p>Like, I completely agree with you about the far-ranging impact and, like, probably we‚Äôre going to see an acceleration over the next five years of, you know, companies and applications and all sorts of interesting things.</p>
<p>I want to pick your brain, though, as we reach these inflection points on domains where AI starts to get really good it always comes with implications for what does it mean for you know individual humans and greater society.</p>
<p>Like, one of the things I‚Äôve been really, really asserting to my kids‚Äô teachers are that, you know, we have these systems that already are pretty good at taking standardized tests, and like, we ‚Äì you know, we probably don‚Äôt want to be training our kids as test-takers, you know, unless there‚Äôs some much better understood cognitive benefit of the test-taking activity or you know like it really is a verification that they have you know ingested and learned, like, deeper knowledge than they need just to do the test-taking activity, because the machines are going to be able to take the tests with super-human performance very soon, I would guess.</p>
<p>You know, which means that ‚Äì you know, I‚Äôm sure you‚Äôre glad that you went to Harvard and you had, like, a pretty diverse training, like, you were interested in cognitive science and mathematics and got a liberal education. And I think liberal education becomes more and more important as we get expert machines in these narrow domains.</p>
<p>Like, what are some of the other things that you all are thinking about ‚Äì because this is part of the AI2‚Äôs mission, right, is to think about AI‚Äôs impact on the world, like, how are you thinking about these things?</p>
<p><strong>OREN ETZIONI:</strong> Well, I think the topic of education in the modern world is near and dear to my heart. You know, I have three kids and a ten-year-old. And I worry both about the fact that they‚Äôre not really getting nearly as much computer literacy as I would like, and literacy with statistics and the ability to analyze data, right, which we have more and more of.</p>
<p>That impacts even their ability to be a good citizen, right? So many of the issues ‚Äì let‚Äôs take climate change, right, that we face, you know, come to statistics or the issues of what is going to be the role of computers and algorithms in society.</p>
<p>So, I really think that we do need to have the basics, right? You don‚Äôt want people who, you know, can‚Äôt read, because the computer will read to me or can‚Äôt do arithmetic, right? So, you want to have the basics, but you want to go way beyond that. And you want to develop the skills of working together with the machine. The machine will do its part and the kid will learn to use it in important ways.</p>
<p>At AI2, we think about a number of issues not so much having to do with kids and education, but certainly having to do with bias. How do we prevent machines from amplifying the bias that‚Äôs in their input data, right? Because these models that we talk about, right, they take typically data from the past, they crunch it in the present, and then they make predictions or even decisions in the future.</p>
<p>So, if our past has racism and sexism and other ‚Äò-isms‚Äô that are very unfortunate, or more than unfortunate, they can be horrific, the last thing we want to do is carry them forward to the future.</p>
<p>And, again, that‚Äôs a very hot area of research, both at AI2 and more broadly we had a paper a few years ago won the best paper award called <em>Men Also Like Shopping</em>, that looked at the bias that‚Äôs actually in images, right?</p>
<p>You type in shopping, you‚Äôll see more images of women than men. How does that affect our computer vision systems? Et cetera, et cetera. So, there‚Äôs a lot of work there.</p>
<p>I would say that the focus at AI2 has been on the beneficial use cases. So, there‚Äôs some work to do to fight against the negative ones, but why do we even go into this in the first place. We go into why do we build this advanced technology? Why do we do this basic research? We do it because we see opportunities for technology to make the world a better place.</p>
<p>And, of course, now when we‚Äôre all ‚Äì the entire international society is questing for a vaccine to COVID-19, I think that‚Äôs a very important illustration of that, right? We are reliant on technology, and by the way, AI is heavily used there, but we‚Äôre looking for technology to solve some of humanity‚Äôs thorniest problems. And we‚Äôre working to build what I would call ‚Äúbeneficial AI‚Äù systems.</p>
<p><strong>KEVIN SCOTT:</strong> So, what do you think we collectively can do? And, like, you can interpret ‚Äúwe‚Äù however you want ‚Äì we the technology industry, we academia, we the governments of the world‚Äôs nations can be doing to leverage the power that we‚Äôre building with AI and to get people prepared?</p>
<p>I mean, you mentioned numeracy, for instance, which is mathematical equivalent of literacy, which I think is at least as important as literacy in the modern world or, like, 21st century.</p>
<p>But, like, what are the other things, like, policy-wise, education-wise, investment-wise that we should be doing to, like, receive the benefit that AI is going to be able to create over the next handful of years?</p>
<p><strong>OREN ETZIONI:</strong> Well, in terms of policy, I think we do actually have to be very careful not to use the kind of blunt and slow and easily distorted instrument of regulation to harm the field. So, I would be very hesitant, for example, to regulate basic research. And I would, instead, look at specific applications and ask, ‚ÄúOkay, if we‚Äôre putting AI into vehicles, how do we make sure that it‚Äôs safe for people? Or if we put AI into toys, how do we make sure that‚Äôs appropriate for our kids, for example? The AI doesn‚Äôt elicit confidential information from our kids or manipulate them in various ways.‚Äù</p>
<p>So, I‚Äôm a big believer in regulate the applications of AI, not the field on its own. I think some of the overarching regulatory ideas, for example, in the EU, there‚Äôs the right to an explanation. And it sounds good, right? AI is opaque, it‚Äôs confusing, these are called black box models. Surely, if an AI system gives us a conclusion, we have a right to an explanation, that sounds very appealing.</p>
<p>Actually, I think it‚Äôs a lot trickier than that because there are really two kinds of explanations of AI models. One is explanations that are simple and understandable but turn out not to be accurate. They‚Äôre not high-fidelity explanations, because the system is complex. And a great example of that is if you go to Netflix and it recommends a movie to you, they‚Äôve realized that people want to know, why did you recommend this movie? And say, ‚ÄúWell, we recommended this movie because you liked that movie, right? We recommended Goodfellas because you liked The Godfather.‚Äù</p>
<p>Well, if you look under the hood, right, the model that they use is actually a lot more complicated than that. So, they gave me a really simple explanation that‚Äôs just not true. So, that‚Äôs one kind.</p>
<p>The other kind is I can give you a true explanation, but it‚Äôll be completely incomprehensible. So, now if the EU says, you know, you have a right to an explanation, what you‚Äôre going to end up with is one of these two horns of the dilemma ‚Äì something that‚Äôs incomprehensible, or something that is inaccurate.</p>
<p>So, I think that it‚Äôs really important that we are careful not to go with kind of popular notions like right to explain, but instead, think through what happens in particular contexts.</p>
<p><strong>KEVIN SCOTT:</strong> Yeah, I think that is an extraordinarily good point. These models are already at the complexity where they‚Äôre as complex as some natural phenomenon. We‚Äôre not able to explain many natural phenomena because, you know, when we get down to the point of like these are the electrostatic interactions of atoms that comprise this system. You have to look at the phenomenology of the system. It‚Äôs why statistics is going to be such a really important skill for everyone. It‚Äôs why understanding the scientific method and having an experimental mindset I think is important.</p>
<p>I think this is such a good point about not deceiving ourselves that an incomprehensibly complex answer to a question of like ‚ÄúWhy did this thing do what it did?‚Äù even if it‚Äôs couched in terms of language that we might otherwise understand, that‚Äôs not real understanding.</p>
<p><strong>OREN ETZIONI:</strong> Exactly. And I‚Äôm not suggesting that the solution is, hey, just trust us, you know, we‚Äôre ‚Äì we‚Äôre all (inaudible, crosstalk)</p>
<p><strong>KEVIN SCOTT:</strong> Yeah, yeah, yeah, for sure ‚Äì</p>
<p><strong>OREN ETZIONI:</strong> ‚Äì going to work. But, again, going back to the auditing idea, rather than an explanation, if we want ‚Äì you know, one of the most jarring ones are uses of AI in the criminal justice system, right?</p>
<p><strong>KEVIN SCOTT:</strong> Yes.</p>
<p><strong>OREN ETZIONI:</strong> To help make parole decisions and things like that. Well, we should audit these systems, test them for bias, right? The press should be doing that, the ACLU should be doing that, regulatory agencies should be doing that. But the solution is not to get some strange explanation for the machine. The solution is to be able to audit its behavior statistically and test it, hey, are you exhibiting some kind of demographic bias?</p>
<p><strong>KEVIN SCOTT:</strong> Yeah, I mean, one of the things we do at Microsoft is we have these two bodies inside of the company, this thing called the Office for Responsible AI that sits in our legal team. And we have this thing called Aether, that‚Äôs the AI and ethics committee inside of the company.</p>
<p>What we do with both of these bodies is we try to have both the lawyers and the scientists thinking about how you inspect both the artifacts that you‚Äôre building in your AI research, but their uses. And we have a very clearly defined notion of a sensitive use. And depending on how sensitive a use a particular model is being deployed in, we have different standards of auditing and scrutiny that go along with it.</p>
<p>And, recommendations, like, for a criminal justice application, for instance, you may say that a model can only advise, like, we do not condone it making a final decision. You know, just so that there‚Äôs always human review in the loop.</p>
<p><strong>OREN ETZIONI:</strong> I think that‚Äôs smart. And I also think that this relates to another key principle when we think about both regulatory frameworks and ethical issues. Whose responsibility is it? The responsibility and liability has to ultimately rest with a person. You can‚Äôt say, ‚ÄúHey, you know, look, my car ran you over, it‚Äôs an AI car, I don‚Äôt know what it did, it‚Äôs not my fault, right?‚Äù You as the driver or maybe it‚Äôs the manufacturer if there‚Äôs some malfunction, but people have to be responsible for the behavior of the machines.</p>
<p>The same way that, look, I‚Äôve got ‚Äì the car‚Äôs already a complex machine with 150 CPUs and so on, I can‚Äôt say, ‚ÄúOh, well, the car ran you over, I had very little to do with it.‚Äù The same is true when I have an AI system. I have to be the one who‚Äôs responsible for an ethical decision. So, very much agree with you there.</p>
<p><strong>KEVIN SCOTT:</strong> Yeah, so we are just about out of time, but before we go, I wanted to ask you, what do you do for fun outside of work?</p>
<p><strong>OREN ETZIONI:</strong> Well, I would say that spending time with people, you know, my family. Like everybody in the Northwest, you know, getting outdoors and hiking is fun. I also ‚Äì I love team sports. My knees no longer tolerate it, but for many years, I played soccer and basketball.</p>
<p>So, you know, do a variety of those things. But most recently, particularly under COVID, I have to admit that I‚Äôve developed a vice. And that is playing Bug House online. So, Bug House is team chess, right, where you have two players facing off two other players. And you have ‚Äì used to be five minutes, now online three minutes is popular.</p>
<p>So, you have a three-minute game. And in that game, you have to defeat your opponent, working together with your partners. That is, if your partner is the white player and you‚Äôre the black player, she might hand you a black piece, right, because she takes her opponent‚Äôs black piece, she hands it to you. This is all mediated by the computer. And you place it on your board instead of making a move. So, it‚Äôs a crazy, crazy game, which is what the phrase Bug House alludes to. And it has communication, it has adrenaline, it has stopwatch, you know, split-second timing, and it‚Äôs a wonderful distraction from worrying about when we‚Äôre going to have a vaccine.</p>
<p><strong>KEVIN SCOTT:</strong> That sounds like a lot of fun.</p>
<p>This has been an amazing conversation. I‚Äôm so happy to know that there are people like you ‚Äì and institutions like AI2 that are not just advancing the state of the art, but like, thinking very, very carefully about how these technologies can have a positive benefit for society. So, like, thank you so much for the work you do and for being here with us for an hour today.</p>
<p><strong>OREN ETZIONI:</strong> Well, thank you, Kevin. I really appreciated the opportunity to talk to you and to talk to your audience. It‚Äôs a real pleasure.</p>
<p><strong>KEVIN SCOTT:</strong> Awesome.</p>
<p>[MUSIC]</p>
<p><strong>CHRISTINA WARREN:</strong> Well, that was Kevin‚Äôs conversation with Oren Etzioni. Wow, you went through so many different paths and talked about so many different interesting things.</p>
<p>For you, Kevin, I‚Äôm curious, as someone who works on the industry side of artificial intelligence, what excites you or I guess is most interesting to you about some of the stuff that Oren is pursuing from more of the academic perspective?</p>
<p><strong>KEVIN SCOTT:</strong> Well, look, I think AI2 is doing some of the most interesting work in the field right now, and you sort of heard in our conversation, this giant leap forward that we have had in natural language processing and natural language understanding over the past handful of years.</p>
<p>Started at AI2 with their work on this technology called ELMO, which then resulted in BURT and Roberta and Turing NLG and GPT and a whole bunch of these technologies that really are reshaping how natural language and AI is working right now.</p>
<p>One of the things that Oren was chatting about that‚Äôs really impressive both from a technical perspective as well as just beneficial use for society is the work that they‚Äôre doing on Semantic Scholar, which is applying some of these really advanced AI technologies to the task of trying to understand and make more accessible the huge amount of scientific literature that the researchers of the world are producing right now.</p>
<p>And things like that become even more important when you have a moment like we‚Äôre in now with COVID, where getting that research digested and to the right people as quickly as humanly possible so that you really are able to get those right people to understand the salient points can just mean the difference between literal life and death as we‚Äôre scrambling to develop therapies and vaccines for SARS coronavirus-2.</p>
<p>So, it‚Äôs just wonderful that you have this combination of such incredibly clever people there who are also working on these problems that can create such benefit in the world.</p>
<p><strong>CHRISTINA WARREN:</strong> Yeah, no, I totally agree. And when he was talking about some of that work, I was thinking just about all the ‚Äì the use cases and ‚Äì and you, obviously, go to some of the most important ones, which would be, you know, life-and-death decisions. But just in general, the ability to really help get people the right information by you know translating and kind of digesting and getting the essence of those documents out. It‚Äôs really powerful.</p>
<p>And that‚Äôs just talking about, you know, in one language. I think about what could happen when we talk about, you know, like, machine translation and that sort of work, too. I‚Äôm excited about what GPT-3 and other things that I ‚Äì that you know about that I read about and try to kind of understand promise and it‚Äôs really exciting to think about.</p>
<p><strong>KEVIN SCOTT:</strong> Yeah, I think in general, it‚Äôs an exciting time to be working on AI right now. And just a good reminder from this conversation today that it is equally important to be thinking about how you point that work in a direction that is safe and responsible and benefits the public good.</p>
<p><strong>CHRISTINA WARREN:</strong> What Oren is doing, he is still a professor. He works with students and he‚Äôs training the next generation of people who ‚Äì whether they‚Äôre going to be researchers or people working in industry are going to be solving these problems and inspiring those next generation of thinkers and innovators is awesome, and I‚Äôm glad we have people like him doing that kind of work.</p>
<p><strong>KEVIN SCOTT:</strong> Yeah, I mean, as I wrote about in my book and I‚Äôve talked about over and over and over again, we should be thinking about AI as a tool, and a tool that can enhance and augment the things that human beings are trying to do. And I think Oren raised a really good point in our conversation today around the important role that education has to play in preparing our future citizens and people even in the workforce today in being able to pick those tools up and make the best possible use of them.</p>
<p>And it‚Äôs a little bit different than, you know, the education system that we have right now, which is fundamentally engineered around the needs of an industrial economy. In the future, we may need to train people to better operate inside of an AI economy.</p>
<p><strong>CHRISTINA WARREN:</strong> Yeah, no, that‚Äôs really interesting things to think about. And I also really liked when he was talking about how, you know, he thinks of AI as ‚Äúaugmented‚Äù intelligence, and I think that to your point, especially if we‚Äôre thinking about having to train people to work inside an AI economy, that‚Äôs where that kind of comes into place is being able to augment or in some cases supplement other types of learnings and other things that people are doing so that we can adjust and I guess be agile.</p>
<p><strong>KEVIN SCOTT:</strong> Yep, absolutely.</p>
<p><strong>CHRISTINA WARREN:</strong> Okay, well, that‚Äôs a wrap. Thank you so much to Oren for joining us today. Also, buy Kevin‚Äôs book or read it, because it‚Äôs fantastic. Get it from your local library, your favorite local bookstore, wherever. It‚Äôs awesome.</p>
<p>And to our listeners, thank you for joining us. Thank you for being in this conversation. Send us a message anytime at <a class="link" href="mailto:behindthetech@Microsoft.com" >behindthetech@Microsoft.com</a>. And tell us what‚Äôs on your mind. And please, stay safe out there.</p>
<p><strong>KEVIN SCOTT:</strong> See you next time.</p>

</section>


    <footer class="article-footer">
    
    <section class="article-tags">
        
            <a href="/tags/english/">English</a>
        
            <a href="/tags/podcast/">Podcast</a>
        
            <a href="/tags/behind-the-tech-with-kevin-scott/">Behind The Tech with Kevin Scott</a>
        
    </section>


    </footer>


    
</article>

    

    

<aside class="related-content--wrapper">
    <h2 class="section-title">Related content</h2>
    <div class="related-content">
        <div class="flex article-list--tile">
            
                
<article class="">
    <a href="/en/1308500052/">
        
	
        
        <div class="article-image">
            
            <img src="/img/related-content.png" loading="lazy" 
            data-key="en/1308500052" data-hash="" 
            style="opacity: 0.3;"/>
        </div>
        
        <div class="article-details">
            <h2 class="article-title">Behind The Tech with Kevin Scott - Bill Gates, Co-chair, Bill &amp; Melinda Gates Foundation</h2>
            
            <footer class="article-time">
                <time datetime=''>Mar 22, 2023</time>
            </footer>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/en/1308500051/">
        
	
        
        <div class="article-image">
            
            <img src="/img/related-content.png" loading="lazy" 
            data-key="en/1308500051" data-hash="" 
            style="opacity: 0.3;"/>
        </div>
        
        <div class="article-details">
            <h2 class="article-title">Behind The Tech with Kevin Scott - Rana el Kaliouby, Founder of Affectiva, Deputy CEO of Smart Eye, and Emotion AI Pioneer</h2>
            
            <footer class="article-time">
                <time datetime=''>Mar 11, 2023</time>
            </footer>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/en/1308500050/">
        
	
        
        <div class="article-image">
            
            <img src="/img/related-content.png" loading="lazy" 
            data-key="en/1308500050" data-hash="" 
            style="opacity: 0.3;"/>
        </div>
        
        <div class="article-details">
            <h2 class="article-title">Behind The Tech with Kevin Scott - Tobi L√ºtke: CEO and Founder, Shopify</h2>
            
            <footer class="article-time">
                <time datetime=''>Mar 10, 2023</time>
            </footer>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/en/1308500049/">
        
	
        
        <div class="article-image">
            
            <img src="/img/related-content.png" loading="lazy" 
            data-key="en/1308500049" data-hash="" 
            style="opacity: 0.3;"/>
        </div>
        
        <div class="article-details">
            <h2 class="article-title">Behind The Tech with Kevin Scott - Year in Review 2022</h2>
            
            <footer class="article-time">
                <time datetime=''>Mar 09, 2023</time>
            </footer>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/en/1308500048/">
        
	
        
        <div class="article-image">
            
            <img src="/img/related-content.png" loading="lazy" 
            data-key="en/1308500048" data-hash="" 
            style="opacity: 0.3;"/>
        </div>
        
        <div class="article-details">
            <h2 class="article-title">Behind The Tech with Kevin Scott - Randall Munroe: XKCD Cartoonist, Author, &amp; Physicist</h2>
            
            <footer class="article-time">
                <time datetime=''>Mar 08, 2023</time>
            </footer>
        </div>
    </a>
</article>

            
        </div>
    </div>
</aside>

     
    
        
    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
            2021 - 
        
        2023 SWIEST - Transcripts ¬∑ Screenplays ¬∑ Lyrics
    </section>
    
    <section class="powerby">
        

        As an Amazon Associate I earn from qualifying purchases üõí<br/>

        Built with <a href="https://swiest.com/" target="_blank" rel="noopener">(Ôæâ‚óï„ÉÆ‚óï)Ôæâü™Ñüíûüíñü•∞ across the glüåçüåèüåébe</a> <br />
        
        
    </section>
</footer>


    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo="crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU="crossorigin="anonymous"
                defer
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css"crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css"crossorigin="anonymous"
            >

            </main>
        </div>
        <script 
                src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js"integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z&#43;KMkF24hUW8WePSA9HM="crossorigin="anonymous"
                
                >
            </script><script type="text/javascript" src="/ts/main.js" defer></script>


<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Noto+Serif&family=Noto+Serif+Armenian&family=Noto+Serif+Bengali&family=Noto+Serif+Devanagari&family=Noto+Serif+Georgian&family=Noto+Serif+Gujarati&family=Noto+Serif+HK&family=Noto+Serif+Hebrew&family=Noto+Serif+JP&family=Noto+Serif+KR&family=Noto+Serif+Kannada&family=Noto+Serif+Khmer&family=Noto+Serif+Lao&family=Noto+Serif+Makasar&family=Noto+Serif+Malayalam&family=Noto+Serif+Myanmar&family=Noto+Serif+Oriya&family=Noto+Serif+SC&family=Noto+Serif+Sinhala&family=Noto+Serif+TC&family=Noto+Serif+Tamil&family=Noto+Serif+Telugu&family=Noto+Serif+Thai&family=Noto+Serif+Tibetan&display=swap" rel="stylesheet">

    </body>
</html>
